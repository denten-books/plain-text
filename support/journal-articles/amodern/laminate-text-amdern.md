---
title: "Laminate Text: Media History in the Strata of Digital Inscription"
documentclass: scrartcl
---

Digital text, at the basis of all computer-mediated epistemological activity,
appears to view at once an ephemeral and enduring phenomenon. It is, as Wendy
Hui Kyong Chun wrote, an "enduringly ephemeral" inscription that "create[es]
unforeseen degenerative links between humans and machines."[^1] At the site of
its projection, on "soft" screens, the text shimmers and wanes, suspended in
liquid crystal. At the site of its storage, on "hard" drives, among "floating
gates" and ferromagnetic polarities, the text persistently adheres to
recondite surfaces, where it multiplies and spreads like silicon dust.

This inherent duplicity leads to a conflicted critical account: enduring and
ephemeral. Furthermore, it engenders a fundamental alienation from the
material contexts of digital knowledge production. Reading digitally takes
place, in part, at quantum scale, beyond the reach of humans senses.
Clandestine forces of capital and control subsequently contest such newly
found microscopic expanses, thus limiting the scope of possible interpretive
activity. Such alienation ultimately threatens critical disempowerment.
*Laminate text* is meant to name the condition by which a singular inscription
fractures to occupy multiple surfaces and topographies. By traversing these
difficult terrains, I hope to ground our theoretical intuitions historically,
not just as a matter of theoretical conjecture but as material grounds that
can support the everyday labor of reading and writing.

## Literary Composites

Little separates ink from paper in print. Ink permeates paper; the conduit is
firmly embedded into its host. The amalgam of ink and paper entails specific
physical properties and their related affordances: what the medium *is*
relates to what can be *done* with it.[^2] A book printed on high-quality
acid-free paper will remain inert for decades and sometimes centuries. That is
not to say that print is a stable medium. At the very least, readers know that
a text will keep its shape as it passes from one pair of hands into another.
As interpreters of texts, we usually can (with some effort) make certain to
find ourselves, literally, on the same page, ensuring that our discussion
concerns roughly the same piece of writing.

The architecture of contemporary computational media---screens, hard drives,
and keyboards---cannot sustain such an assumption of fixity. Electromagnetic
inscription occupies several available surfaces at once. It exists on screen,
itself a composite of glass panes and liquid crystal, and "in memory," as
manifested in the arrangement of silicon and circuitry. The word is in the
wires. When reading digitally, on a personal computer for example, the
distance between these localities may extend a few inches, enough to cover the
space between screen and hard drive. In other contexts, when viewing text on a
commercial "electronic reader," that space may span continents as stored data
are transmitted over vast distances, between content "owners" and its "users,"
who hold only a temporary right to peruse, limited in scope to specific
timelines and geographies. An electronic book borrowed from the New York
Public Library may be stored somewhere in the city or abroad, on library
servers. It vanishes from my devices when the terms of my book borrowing
expire. I cannot tell where that book is physically: I know only that it
appears on my screen.

This apparent instability is, in short, the source of my puzzlement and an
occasion to dwell on the resulting discomfort. The digital sign is continually
stretched, elongated, and fractured across diverse material strata, subject to
distinct local affordances. A simple act of erasure on screen, as when one
backspaces over a word written in error, simulates a comparable action in
print. On disk, metaphoric "erasure" assumes a different connotation,
entailing an entirely new set of operations, not congruent with the implied
action on screen or in print.[^68] The incongruence is often benign. Readers
and writers are sometimes interested in handling surface representation alone,
on the level of words and ideas. In certain contexts however, our inability to
perceive the mechanics of inscription at depth severely undermines critical
acuity. To take a blunt example, imagine a scholar or a journalist who needs
to redact unpublished materials in order to protect her sources. Surface
erasure in this case is insufficient to guarantee true anonymity. Words erased
on screen may persevere through deeper structures on disk and among remote
servers, in a way susceptible to malicious breach or state-sponsored
surveillance.

The affordances of laminate text depend not only on the medium, but also on
the contexts of its reception. The same "source text" may be transformed
according to its geography or the identity of its reader. The composition of
the sign changes as a text changes hands. A digital document may respond to a
reader's location, gender, age, ethnicity, or immigration status. Think of an
online newspaper, where the very composition of headlines and stories is
routinely tailored to the individual reader. Such dynamic inscriptions contain
the rules of their own transformation. Content and code intertwine to produce
an amalgamated artifact, designed for remote content control. The electronic
book implies a socialized environment, even when consumed in intimacy.
Friends, advertisers, censors, and intelligence agents are always potentially
present, in part because the digital inscription is in perpetual motion:
moving past and through multiple infrastructures on the way to the iris.

The chain of transmission is difficult to reconstitute. Governments that
monitor reading habits by judicial means may decide to prosecute those who
express opinions contrary to the reigning ideology. More insidiously,
mechanisms of "soft" censorship may be encoded into the fabric of the laminate
itself, through technologies that outright prevent prohibited ideological
formations from appearing on screen. Unlike those censored by an explicit
edict, readers under the reach of remote, algorithmic governance may not be
immediately aware of control mechanisms structuring their everyday
interpretive experience. The reader is left with a rough remainder of an
imposed identity. The dynamic text determines its audience: a man will be
interested in cars and women, a Eastern European in jewelry and Adidas, an
inmate, or otherwise an enemy of the people, in a blank page and a home visit
from your friendly librarian.

The stratified nature of digital inscription poses obvious general challenges
in the social sphere, which this essay can address only obliquely. Our ability
to mobilize against censorship or surveillance is in peril when such
mechanisms operate at a microscopic scale, requiring specialized skills and
tools for interpretation. A tactical response requires not just the awareness
of one's history, but training and advocacy efforts. Laminate texts present a
specialized challenge to the practice of literary hermeneutics. How does
critical interpretive practice persist in conditions where readers can no
longer rely on the continuing stability of the medium? The theoretical problem
is not one of fixing a text as either an immanent object or a transcendent
idea, enduring or ephemeral. We are confronted instead with texts that do not
converge on a single location and whose multivalence is derived from their
structural diffusion. Composite media force us to reconsider long-standing
critical assumptions about the physics of inscription at the foundation of
hermeneutics.[^4]

## Stratigraphy

Several parallel literary and media archaeologies were formative to my
approach to thinking through the history of laminate inscription.

The specter of Friedrich Kittler haunts most work on literature and
technology. Kittler opened the floodgates between critical, literary theory
and media history. However, his legacy is complicated by his often fatalistic
pronouncements. "Under the conditions of high technology, literature has
nothing more to say," he wrote in the conclusion of *Gramophone, Film,
Typewriter*.[^69] Scholars such as Lori Emerson, Lisa Gitelman, Matthew
Kirschenbaum, and others have commenced the patient task of recuperating
writing's recent material pasts.[^70] I build on their achievements by
bringing to light a number of new historical archive materials, which lead me
to diverge in my conclusions. A generation of textual and media scholars has
issued an important corrective to an era of thinking about "electronic texts"
as disembodied, virtual artifacts. Yet, the emphasis on materialism misses
some of the real, qualitative properties of electromagnetic inscription which
produce an ephemeral effect. When earlier writers such as Michael Heim refer
to the "ephemeral quality" of the electronic text or when Pamela McCorduck
describes it as "impermanent, flimsy, malleable, [and] contingent" they are
identifying a felt facet of digital inscription.[^72] The paradox cannot
therefore be reduced to categorical terms: true or false. Electricity is truly
difficult to behold. Inscriptions on screen really do disappear with the loss
of power. And, as the corrective has it: elsewhere, a trace also remains. Our
mistake is to treat digital text in analogy to print, on a singular,
two-dimensional plane.

The electric text extends in multiple dimensions simultaneously. Its facets
afford different views and strategies of interpretation depending on the
reader's vantage. The physics of inscription determine some of its
capabilities: where paper rapidly degrades under the heel of an eraser, a
solid state drive can be erased millions of times before failure. Crucially,
the medium is also affected by the physical limitations placed on the reader.
A drive that is hermetically sealed or encrypted is hypothetically amenable to
a forensic reading, but practically inaccessible. I turn to the field of
Science and Technology Studies and particularly to the recent work of Mara
Mills, Hans-Jörg Rheinberger, Jessica Riskin, and Nicole Starosielski, among
others who in one way or another have inspired me to take a distinctly
infrastructural approach to the historical study of epistemic artifacts.[^71]

I further borrow the term "stratigraphy" from the field of archaeology proper,
as opposed to media archaeology where the term is used in its more evocative
and metaphoric sense.[^6] The art of analyzing sedimentary rock layers dates
back at least to the geological observations of the seventeenth century Danish
scientist Nicolas Steno, later extended by John Strachey in his *Observations
on the Different Strata of Earths and Minerals* (1727), and to the geological
cross-sections of William Smith and William Maclure, who drew beautifully
detailed cross-sections of the British and American landscapes [Figure 1].

![Stratigraphic map legend. "Sketch of the Succession of Strata and their
relative Altitudes." William Smith, "DELINEATION of the STRATA of ENGLAND and
WALES with part of SCOTLAND; exhibiting the COLLIERIES and MINES; the MARSHES
and FEN LANDS ORIGINALLY OVERFLOWED BY THE SEA; and the VARIETIES of Soil
according to the Variations in the Sub Strata; ILLUSTRATED by the MOST
DESCRIPTIVE NAMES," Section 16 (1815). Image in the public domain. Reproduced
from the collection of Sedgwick Museum of Earth Sciences, University of
Cambridge.](figure-1.jpg)

The concept of stratigraphy is an apt borrowing when applied to the history of
computer technology, where the various layers of historical development are
often extant in one and the same device. In this manner, the legacy of machine
alphabets such as the Morse and Baudot alphabets is, in some real way, present
on modern devices through the ASCII and UTF-16 conventions. A
"conversational," text-based, model of human computer-interaction developed in
the 1960s, coexists with the later, graphic-based "direct-interaction" modes
of interaction in the innards of every modern mobile phone, game console, or
tablet.[^8] The same can be said about "low-level" assembly languages,
continuously in use since the 1950s alongside their modern descendants.

For the purposes of our conversation, which concerns the paradoxically
conflicting nature of electromagnetic inscription, at once enduring and
ephemeral, we may separate the formation of electromagnetic composites into
three historical periods, each leaving behind a distinctive media sediment. A
summary of that history is as follows:

First, with the advance of telecommunications, we observe the increasing
admixture of human-readable text and machine-readable code. Removable storage
media such as ticker tape and punch cards embodied a machine instruction set
meant to effect a mechanism, which in turn produced human-legible inscription.
Unintelligible (to humans without special training) control codes that
actuated machinery were thereby mixed with plain text, the content of
communication. Inscription thus split between the sites of storage, where an
expanded machine instruction set was archived, and projection, where the human
legible portion of the inscription was displayed.

Second, whereas ticker tape and punch cards were legible to the naked eye,
magnetic tape, a medium which supplanted paper, made for an inscrutable
substance, inaccessible directly without instrumentation. In the 1950s and
1960s machine operators worked blindly, using complicated workarounds to
verify equivalence between data input, storage, and output. Writing began to
involve multiple typings and printings. Specialized magnetic reading devices
were developed to make inscription more apparent and to establish a
correspondence between input, storage content, and output of entered text. The
physical properties of electromagnetic inscription also allowed for rapid
re-mediation. Tape was more forgiving than paper: it could be written and
re-written at high speeds and in volume. However, the opacity of the medium
has also placed it, in practice, beyond human sense.

Finally, the appearance of cathode-ray tube (CRT) displays in the late 1960s
restored a measure of legibility lost to magnetic storage. The sign reemerged
on-screen. Crucially, it framed a simulacrum of archived inscription: typing a
word on a keyboard produced one sort of a structure on tape or disk and
another on-screen. The two related contingently, without necessary congruence.
The lay reader lost the direct means to ensure a correspondence between
visible trace and stored mark. An opaque black box of "word processing," a set
of rules for transmediation, began to intercede between simultaneous acts of
reading and writing.

I have selected three paradigmatic textual artifacts to mark this episodic
history: the Controller patented by Hyman Goldberg in 1911; the Magnetic
Reader introduced by Robert Youngquist and Robert Hanes in 1958; and, for a
lack of a better name, the Display System, introduced by Douglas Engelbart in
1968. Each illustrates a distinct layer of abstraction, which in aggregate
      comprise contemporary laminates. Together, these devices tell a story of
a fissure at the heart of our contemporary textual predicament. The
inscription appears to the eye in one place, to the hand for editing in
another, and to the machine for storage yet somewhere else. At each stage of
its physical transfiguration---from thought to keystroke, pixel, and electric
charge---the sign attains new capabilities while losing some of the old ones.
Historically-contingent, physical properties of the laminate give rise to its
phenomenological, perceived qualities, at once persistent and ephemeral.

## 1. Controller

The turn of the twentieth century was a pivotal period in the history of
letters. It saw the languages of people and machines enter the same mixed
communications stream. Artificial fixed-length alphabets, such as the Baudot
code, paved the way for the automation of language. The great variety of human
scripts was reduced to a set of discrete and reproducible characters. So
regularized, type was converted into electric signal, sent over great
distances, and used to program machines remotely. These expanded textual
affordances came at a price of legibility. Initially, a cadre of trained
machine operators were required to translate human language into
machine-transmittable code. Eventually, specialized equipment automated this
process, removing the human from the equation.

The advent of programmable media (punch cards and ticker tape) coupled
human-compatible alphabets with machine control code.[^9] Reduced to a
discrete and reliably reproducible set of characters, natural languages could
be conveyed as electric signals. In such a transitive state language became
more mobile than ever before. It was transmitted efficiently across vast
distances. The mechanization of type also introduced new control characters
into circulation capable of affecting machine state changes at a distance.
Initially, such state changes were simple: “begin transmission,” “sound error
bell,” or “start new line.” With time, they developed into what we now know as
programming languages. Thereby content meant for human consumption was
routinely intermixed with code meant to control machine devices. A text stream
could "mean" one thing to a human interpreter and another to a machine one.
Such early remote control capabilities were quickly adapted to automate
everything from radio stations to advertising billboards and knitting
machines.[^10]

Hundreds of alphabet systems vying to displace Morse code were devised to
speed up automated communications. These evolved from variable-length
alphabets such as Morse and Hughes codes, to fixed-length alphabets such as
Baudot and Murray codes. The systematicity of the signal---equal length at
regular intervals---minimized the "natural" aspects of human languages, affect
and variance, in favor of "artificial" aspects like consistency and
reproducibility.

The fixed-length property of Bacon’s cipher, later implemented in the 5-bit
Baudot code, signaled the beginning of the modern era of serial
communications.[^11] The Baudot and Murray alphabets were designed with
automation in mind.[^12] Both did away with the “end of character” signal that
separated letters in Morse code. Signal units were to be divided into letters
by count, with every five codes representing a single character. Temporal
synchronization was therefore unnecessary, given the receiver’s ability to
read the message from the beginning. A character was simply a unit of space
divisible by five.

Fixed-length signal alphabets drove the wedge further between human and
machine communication. Significantly, the automated printing telegraph
decoupled information encoding from its transmission. Fixed-length encoding of
messages could be done in advance, with more facility and in volume. Prepared
messages could then be fed into a machine without human assistance. In 1905
Donald Murray wrote that the “object of machine telegraphy [is] not only to
increase the saving of telegraph wire [...] but also to reduce the labour cost
of translation and writing by the use of suitable machines.”[^15] Baudot and
Murray alphabets were not only more concise but also simpler and less
error-prone to use.

With the introduction of mechanized reading and writing techniques, telegraphy
diverged from telephony to become a means for truly asynchronous
communication. It displaced signal transmission in time as it did in space.
The essence of algorithmic control, amplified by remote communication devices,
lies in its ability to delay execution; a cooking recipe, for example, allows
novice cooks to follow instructions without the presence of a master chef.
Similarly, delayed communication could happen in absentia, according to
predetermined rules and instructions. A message could activate a machine that
sells trades stocks and another that replies with a printed confirmation.

Just as perforated music could be used to displace the act of performance in
time, programmable media deferred the act of inscription. Telegraph operators
became de facto programmers. One could strike a key in the present, only to
feel the effects of its impact later, at a remote location. Decoupled from its
human sources, inscription could be compressed and optimized for speed and
efficiency. Electromechanical readers could ingest prepared ticker tape and
punch cards at rates far exceeding the possibilities of hand-operated Morse
telegraphy.

Besides encoding language, the Baudot schema left space for several special
control characters. The "character space" of an existing alphabet was expanded
further by switching the receiving mechanism into a special control mode in
which every combination of five bits represented an individual control
character, instead of a letter. In this manner, human content and machine
control intertwined to occupy the same spectrum of communication.

By the 1930s, devices variously known as printer telegraphs, teletypewriters,
and teletypes displaced Morse code telegraphy as the dominant mode of
commercial communication. A 1932 U.S. Bureau of Labor Statistics report
estimated a more than 50 percent drop in Morse code operators between 1915 and
1931. Morse operators referred to teletypists on the sending side as
“punchers” and those on the receiving side as “printer men.”[^16] The
printer men responsible for assembling pages from ticker tape were called
“pasters” and sometimes, derisively, as “paperhangers.”[^17] Teletype
technology automated this entire process, rendering punchers, pasters, and
paperhangers obsolete. Operators could enter printed characters directly into
the machine, using a keyboard similar to the typewriter, which, by that time,
was widely available for business use. The teletype would then automatically
transcode the input into transmitted signal and then back from the signal onto
paper on the receiving end.

Machine code thus occupied a gray area between "plain text" and "cipher," both
legal as well as technical terms, governed by international treaties that
guaranteed the passage of plain text communications. According to conventions,
code was considered intelligible only when the schema for its decoding was
available to the transmitter.[^18] Without such keys, a transmitted message
was considered secret and therefore not subject to free passage across
national boundaries. In practice, the proliferation of encodings and machine
instructions had the effect of selective illiteracy, if not outright secrecy.
Telegraph operators used multiple cheat sheets to help decipher encoded
messages.

In this sense, telegraphy reintroduced a pre-Lutheran problem of legibility
into human letters. To speak in telegraph was to learn arcane encodings, not
spoken in the vernacular. A number of failed communication schemas
consequently attempted to bridge the rift between human and machine alphabets.

“You must acknowledge that this is readable without special training,” Hymen
Goldberg wrote in the patent application for his 1911 Controller.[^19] The
device was made “to provide [a] mechanism operable by a control sheet which is
legible to every person having sufficient education to enable him to read.” In
an illustration attached to his patent, Goldberg pictured a “legible control
sheet [...] in which the control characters are in the form of the letters of
the ordinary English alphabet.”[^20] Goldberg’s perforations did the “double
duty” of carrying human-readable content and mechanically manipulating machine
“blocks,” “handles,” “terminal blades,” and “plungers.”[^21] Unlike other
schemas, messages in Goldberg’s alphabet could be “read without special
information,” effectively addressing the problem of code’s apparent
unintelligibility [Figure 2].[^22]

![Goldberg's control cards. Machine and human languages coincide on the same
surface. The perforations that actuate levers can also be read "without
special training," in contrast to other text encodings. Goldberg, Hyman Eli.
"Controller." US1165663 A, issued December 1915, sheet 3.](figure-2.jpg)

The inscription remained visible at the surface of Goldberg’s control sheet,
as a perforated figure punched through the conduit. Whatever challenges punch
cards and ticker tape presented for readers, these were soon complicated by
the advent of magnetic tape.

## 2. Magnetic Reader

The Goldberg Controller and its contemporary devices reveal a growing concern
with the comprehensibility of machine alphabets. One could hardly call early
programmable media ephemeral. Anecdotes circulate about Father Roberto Busa,
an early pioneer of computational philology, who in the 1960s carted his punch
cards around Italy in his truck.[^23] Codified inscription, before its
electromagnetic period, was fragile and unwieldy. Just like writing with pen
and paper, making an error on ticker tape entry required cumbersome
corrections and sometimes wholesale reentry of lines or pages. On the surface
of ticker tape, the inscription still made a strong commitment to the medium.
Once committed to paper, it was nearly immutable. Embossed onto ticker tape or
punched into the card, early software protruded through the medium.

Morse code and similar alphabet conventions left a visible mark on the paper.
They were at least legible if not always intelligible. At the 1967 Symposium
on Electronic Composition in Printing, Jon Haley, staff director of the
Congressional Joint Committee on Printing, still spoke of “compromises with
legibility [that] had been made for the sake of pure speed in composition and
dissemination of the end product.”[^24]

Magnetic tape changed the commitment between inscription and medium. It gave
inscription a temporary shelter, where it could dwell lightly and be
transformed, before finding its more permanent, final shape on paper. A new
breed of magnetic storage devices allowed for the manipulation of words in
“memory,” on a medium that was easily erased and rewritten.

The magnetic charge adhered lightly to the tape surface. This light touch gave
the word its newfound ephemeral quality. But it also made inscription
physically illegible. In applications such as law and banking, where fidelity
between input, storage, and output was crucial, the immediate illegibility of
magnetic storage posed a considerable engineering challenge. After the advent
of teletype but before cathode ray screens, machine makers used a variety of
techniques to restore a measure of congruence between invisible magnetic
inscription and its paper representation. What was entered had to be
continually verified against what was stored.

The principles of magnetic recording were developed by Oberlin Smith (among
others), an American engineer who also filed several patents for inventions
related to weaving looms. In 1888, inspired by Edison’s mechanical phonograph,
Smith made public his experiments with an “electrical method” of sound
recording using a “magnetized cord” (cotton mixed with hardened steel dust) as
a recording medium. These experiments were later put into practice by Valdemar
Poulsen of Denmark, who patented several influential designs for a magnetic
wire recorder.[^25]

Magnetic recording on wire or plastic tape offered several distinct advantages
over mechanical perforation. Tape was more durable than paper; it could fit
more information per square inch; and it was reusable. “One of the important
advantages of magnetic recording,” Marvin Camras, a physicist with the Armour
Research Foundation, wrote in 1948, “is that the record may be erased if
desired, and a new record made in its place.”[^26] Most early developments in
magnetic storage were aimed at sound recording. The use of magnetic medium for
data storage did not take off in earnest until the 1950s.[^27] However, early
developers of electromagnetic storage and recording technology already
imagined their work in dialog with the long history of letters (and not just
sound). In an address to the Franklin Institute on December 16, 1908, Charles
Fankhauser, the inventor of the electromagnetic telegraphone, spoke as
follows, comparing magnetic recording to the invention of the Gutenberg press:

> It is my belief that what type has been to the spoken word, the
telegraphone will be to the electrically transmitted word [...] As printing
spread learning and civilization among the peoples of the earth and influenced
knowledge and intercourse among men, so I believe the telegraphone will
influence and spread electrical communication among men.[^29]

In that speech Fankhauser also lamented the evanescence of telegraph and
telephone communications. The telephone, he rued, fails to preserve “an
authentic record of conversation over the wire.”[^30] Fankhauser imagined his
telegraphone being used by

> the sick, the infirm, [and] the aged [...] A book can be read to the
sightless or the invalid by the machine, while the patient lies in bed.
Lectures, concerts, recitations--what one wishes, may be had at will. Skilled
readers or expert elocution teachers could be employed to read into the wires
entire libraries.[^31]

Anticipating the popularity of twenty-first-century audio formats like
podcasts and audiobooks, Fankhauser spoke of “tired and jaded” workers who
would “sooth [themselves] into a state of restfulness” by listening to their
favorite authors.[^32] Fankhauser saw his “electric writing” emerge as “clear”
and “distinct” as “writing by hand,” “an absolutely legal and conclusive
record.”[^33] Whereas written language was lossy and reductive, Fankhauser
hoped that electromagnetic signals would hold high fidelity to the original.

In 1909 Fankhauser thought of magnetic storage as primarily an audio format
that would combine the best of telegraphy and telephony. Magnetic data storage
technology did not mature until the 1950s, when advances in composite plastics
made it possible to manufacture tape that was cheaper and more durable than
its paper or cloth alternatives. The state-of-the-art relay calculator,
commissioned by the Bureau of Ordinance of the Navy Department in 1944 and
built by the Computation Laboratory at Harvard University in 1947, still made
use of standard-issue telegraph “tape readers and punchers” adapted for
computation with the aid of engineers from Western Union Telegraph
Company.[^34] It was equipped with a number of Teletype Model 12A tape readers
and Model 10B perforators, using 11/16-inch-wide paper tape, partitioned into
“five intelligence holes,” where each quantity entered for computation took up
thirteen lines of code.[^35] Four Model 15 Page-Printers were needed to
compare printed characters with the digits stored on the ticker tape print
register. The numerical inscription in this setup was therefore already split
between input and output channels, with input stored on ticker tape and output
displayed in print.

The Mark III Calculator, which followed the Computation Laboratory’s earlier
efforts, was also commissioned by the Navy’s Bureau of Ordinance. It was
completed in 1950. Its “floor plan” (or “system architecture,” in modern
terms) did away with punch cards and ticker tape, favoring instead an array of
large electromagnetic drums coupled with reel-to-reel tape recorders. The
drums, limited in their storage capacity, revolved at much faster speeds than
tape reels. They were used for fast, temporary internal storage. A single Mark
III calculator used twenty-five such drums, rotating at 6,900 rpm, each
capable of storing 240 binary digits.

In addition to the fast “internal storage” drums, the Mark III floor plan
included eight slow “external storage” tape-reader mechanisms. Tape was slower
than drums but also cheaper. It easily extended to multiple reels, thus
approaching the architecture of an ideal Turing machine, which called for tape
of “infinite length.”[^37] In practice, tape was in limited supply, available
in segments long enough to answer the needs of military computation. Unlike
stationary drums, tape was portable. Operators could prepare tape in advance,
in a different room, at the allotted instructional tape preparation table. The
information on tape would then be synced with and transferred to a slow drum.
In the next stage, the slow drum accelerated to match the higher rotating
speeds of the more rapid internal storage drums, and the information was
transferred again for computation. The Mark III Calculator was further
equipped with five printers “for presenting computed results in a form
suitable for publication.” The printers were capable of determining the
“number of digits to be printed, the intercolumnar and interlinear spacing,
and other items related to the typography of the printed page.”[^38]

In reflecting on these early “supercomputers,” one imagines the pathway of a
single character as it crosses surfaces, through doorways and interfaces,
gaining new shapes and temporalities with each transition.

Electromagnetic signals were transcoded into binary numerical notation. To
transfer characters onto tape, operators sat at the numerical tape preparation
table, yet another separate piece of furniture. Data were stored along two
channels, running along the tape’s length. Operators entered each number
twice, first into channel A and then into channel B. This was done to prevent
errors, because the operators worked blindly, unable to see whether the
intended mark registered properly upon first entry. An error bell would sound
when the first quantity did not match the second, in which case the operator
would reenter the mismatched digits. To “ensure completely reliable results,”
one of the five attached Underwood electric teletypes could further be used to
print all channels and confirm input visually.[^39]

Advances in magnetic storage found their way into small businesses and home
offices a decade later. In 1964 IBM combined magnetic tape (MT) storage with
its Selectric line of electric typewriters (ST). Selectric typewriters were
popular because they were ubiquitous, relatively inexpensive, and could be
used to reliably transform a keyboard’s mechanical action into binary electric
signal. Consequently, they became a common input interface in a number of
early computing platforms.[^42] The MT/ST machine could be considered one of
the first personal “word processing” systems in that it combined
electromagnetic tape storage with keyboard input. Where typists previously had
to stop and erase every mistake, the IBM MT/ST setup allowed them to
“backspace, retype, and keep going.” Mistakes could be corrected in place, on
magnetic tape, “where all typing is recorded and played back correctly at
incredible speed.”[^43]

Despite its advantages, MT/ST architecture inherited the problem of legibility
from its predecessors. Information stored on tape was still invisible to the
typist. In addition to being encoded, electric alphabets were written in
magnetic domains and polarities, which lay beyond human sense.[^44] One had to
verify input against stored quantities to ensure correspondence. But the
stored quantity could be checked only by transforming it into yet another
inscription. To verify what was stored the operator was forced to redouble the
original inscription, in a process that was prone to error, because storage
media could not be accessed directly without specialized instruments.[^45]

Another class of solutions to the legibility problem involved making the
magnetic mark more apparent. A pair of American inventors described their 1962
magnetic reader as "a device for visual observation of magnetic symbols
recorded on a magnetic recording medium in tape or sheet form." They wrote:

> Magnetic recording tape is often criticized because the recorded signals are
invisible, and the criticism has been strong enough to deny it certain
important markets. For example, this has been a major factor in hampering
sales efforts at substituting magnetic recording tape and card equipment for
punched tape and card equipment which presently is dominant in automatic
digital data-handling systems. Although magnetic recording devices are faster
and more troublefree, potential customers have often balked at losing the
ability to check recorded information visually. It has been suggested that the
information be printed in ink alongside the magnetic signals, but this
vitiates major competitive advantages of magnetic recording sheet material,
e.g., ease in correction, economy in reuse, simplicity of equipment,
compactness of recorded data, etc.[^46]

The magnetic reader was supposed to address the loss of visual acuity. The
magnetic reader consisted of two hinged plates [Figure 3]. The inventors
proposed to fill its covers with a transparent liquid that would host
“visible, weakly ferromagnetic crystals.” When sandwiched between the plates,
a piece of magnetic tape incited the crystal medium, which would in turn
reveal the signal’s “visibl[e] outline.”[^47]

!["Magnetic recording tape is often criticized because the recorded signals
are invisible." Youngquist and Hanes imagined a device that physically reveals
the magnetic inscription. Robert Yongquist and Robert Hanes, "Magnetic
Reader," Patent US3013206, 1961.](figure-4.jpg)

Devices like the Magnetic Reader attempted (and failed) to address the
fundamental incongruence between paper and tape. Data plowed into rows on the
wide plains of a broad sheet had to be replanted along the length of a narrow
plastic groove.

To aid in that transformation, the next crop of IBM Magnetic Selectric (MS)
typewriters added a composer control unit, designed to preserve some of the
formatting lost in transition between paper and plastic. It could change
margin size or justify text in memory. The original IBM Composer unit
justified text (its chief innovation over the typewriter) by asking the
operator to type each line twice: “one rough typing to determine what a line
would contain, and a second justified typing.”[^48] After the first typing, an
indicator mechanism calculated the variable spacing needed to achieve proper
paragraph justification. The formatting and content of each line thus required
separate input passes to achieve the desired result in print.

IBM’s next-generation Magnetic Tape Selectric Composer (MT/SC) build on the
success of its predecessors. It combined a Selectric keyboard, magnetic tape
storage, and  a “composer” format control unit. Rather than having the
operator type each line twice, the MT/SC system printed the entered text
twice: once on the input station printout, which showed both content and
control code in red ink, and a second time as the final Composer output
printout, which collapsed the layers into the final typeset copy. Output
operators still manually intervened to load paper, change font, and include
hyphens. The monolithic page unit was thereby further systematically
deconstructed into distinct strata of content and formatting.

Like other devices of its time, the IBM MT/SC suffered from the problem of
indiscernible storage. Error checking of input using multiple printouts was
aided by a control panel consisting of eleven display lights. The machine’s
manual suggested that the configuration of lights be used to peek at the
underlying data structure for verification.[^49]

In an attempt to achieve ever greater congruence between visible outputs and
data archived on a magnetic medium, IBM briefly explored the idea of storing
information on magnetic cards instead of tape. On tape, information had to be
arranged serially, into one long column of codes. Relative arrangement of
elements could be preserved, it was thought, on a rectangular magnetic card,
which  resembled paper in its proportions. The 1968 patent “Data Reading,
Recording, and Positioning System” described a method for arranging
information on a storage medium “which accurately positions each character
recorded relative to each previous character recorded.”[^50] In 1969, IBM
released a magnetic card-based version of its MT/ST line, dubbed the MC/ST
(magnetic card, Selectric type). Fredrick May, whose name often appears on
word-processing-related patents from this period, would later reflect that a
“major reason for the choice of a magnetic card for the recording of medium
was the simple relationship that could be maintained between a typed page and
a recorded card.” The card approximated a miniature page, making it a suitable
“unit of record of storage for a typed page.”[^51] Although it offered a
measure of topographic analogy between tape and paper, the “mag card” was
short-lived partly because of its limited storage capacity, capricious feeding
mechanism, and persistent inscrutability.[^52]

For a few decades after the advent of magnetic storage media but before the
arrival of screen technology, the sign’s outward shape disappeared altogether.
It is difficult to fathom now, but at that time---after the introduction of
magnetic tape in the 1960s but before the widespread advent of CRT displays in
the 1980s---typewriter operators and computer programmers manipulated text
blindly. Attributes such as indent size and justification were decided before
ink was committed to paper.

In the 1980s an engineer thus reflected on the 1964 MT/ST’s novelty: “It could
be emphasized for the first time that the typist could type at ‘rough draft’
speed, ‘backspace and strike over’ errors, and not worry about the pressure of
mistakes made at the end of the page.” The MT/SC further added a programmable
control unit to separate inputs from outputs. Final printing was then
accomplished by

> mounting the original tape and the correction tape, if any, on the
two-station reader output unit, setting the pitch, leading, impression control
and dead key space of the Composer unit to the desired values, and entering
set-up instructions on the console control panel (e.g., one-station or
two-station tape read, depending on whether a correction tape is present; line
count instructions for format control and space to be left for pictures, etc.;
special format instructions; and any required control codes known to have been
omitted from the input tape). During printing the operator changes type
elements when necessary, loads paper as required, and makes and enters
hyphenation decisions if justified copy is being printed.[^53]

The tape and control units thus intervened between keyboard and printed page.
The “final printing” combined “prepared copy,” “control and reference codes,”
and “printer output.”[^54] Historical documents often mention three distinct
human operators for each stage of production: one entering copy, one
specifying control code, and one handling paper output.

Researchers working on these early IBM machines considered the separation of
print into distinct strata a major contribution to the long history of
writing. One IBM consultant went so far as to place the MT/SC at the
culmination of a grand “evolution of composition,” which began with
handwriting and continued to wood engraving, movable type, and letterpress:
“The IBM Selectric Composer provides a new approach to the printing process in
this evolution.” He concluded by heralding the “IBM Composer era,” in which
people would once again write books “without the assistance of
specialists.”[^55] Inflationary marketing language aside, the separation of
the sign from its immediate material contexts and its new composite
constitution must be considered a major milestone in the history of writing
and textuality.

The move from paper to magnetic storage had tremendous social and political
consequences for the republic of letters. Magnetic media reduced the costs of
copying and dissemination of the word, freeing it, in a sense, from its more
durable material confines. The affordances of magnetic media---its very speed
and impermanence---created the illusion of light ephemerality. Yet the
material properties of magnetic tape itself continued to prevent direct access
to the site of inscription. Magnetic media created the conditions for a new
kind of illiteracy, which divided those who could read and write at the site
of storage from those who could only observe its aftereffects passively, at
the shimmering surface of archival projection.

The schematics I discuss in this section and above embody textual fissure in
practice. The path of a signal through the machine leads to multiplicity of
inscription sites. These are not metaphoric but literal localities that
stretch the sign across manifold surfaces. Whereas pens, typewriters, and hole
punches transfer inscription to paper directly, electromagnetic devices
compound them obliquely into a laminated aggregate. The propagation of
electric signal across space required and continues to require numerous phase
transitions between media: from one channel of tape to another, from tape to
drum, from a slow drum to a fast one, and from drum and tape to paper. On
paper the inscription remains visible in circulation; it disappears from view
on tape, soon after key press. Submerged beneath a facade of opaque oxide,
inscriptions thicken and stratify into laminates.

## 3. Display System

The contemporary textual condition took its present form in the late 1960s.
Computers subsequently changed in terms of size, speed, and ubiquity.
However, they retain the same essential architecture, consisting of
programmable media, electromagnetic storage, and screens.

The addition of a screen finally promised to redress the problem of
electromagnetic legibility. In the first stage of its digital development,
language became “programmable.” Coupled with electromagnetic storage in the
second stage, programmable media was "freed," at least in appearance, from its
immutable contexts. It was “lighter,” faster, more portable and therefore more
itinerant and malleable than print or punch. Ferric oxide became the preferred
medium for digital storage. But this new memory layer lay also beyond the
reach of human senses. It was "weighty" in another sense, difficult to access
and manipulate mentally.

Screens added a much needed window onto an opaque memory abstraction.
On-screen, the topography of electromagnetic storage could be represented
visually, obviating the need for double entry or frequent printouts. Screens
interjected to mediate between input and output. They flattened the stratified
complexity of a laminate medium to facilitate use. Digital inscription
remained invisible. The screen simulation could restore the appearance of a
single surface. As it did so it also obscured the very dynamics of mediation.

On December 9, 1968, Douglas Engelbart, then the  primary investigator at the
NASA- and ARPA-funded Augmentation Research Center at the Stanford Research
Institute, gave what later became known as the “mother of all demos” to an
audience of roughly 1,000 or so computer professionals attending the Joint
Computer Conference in San Francisco. The demo announced the arrival of almost
every technology prophesied by Vannevar Bush in his influential 1945 Atlantic
essay, “As We May Think.” During his short lecture, Engelbart presented
functional prototypes of the following: graphical user interfaces, video
conferencing, remote camera monitoring, links and hypertext, version control,
text search, image manipulation, windows-based user interfaces, digital
slides, networked machines, mouse, stylus, and joystick inputs, and “what you
see is what you get” (WYSIWYG) word processing.[^57]

In his report to NASA, Engelbart described his colleagues as a group of
scientists “developing an experimental laboratory around an interactive,
multiconsole computer-display system” and “working to learn the principles by
which interactive computer aids can augment the intellectual capability of the
subjects.”[^58] CRT displays were central to this research mission. In one of
many patents that came out of his “intellect augmentation” laboratory,
Engelbart pictured his “display system” as a workstation that combines a
typewriter, a CRT screen, and a mouse. The schematics show the workstation in
action, with the words “now is the time fob” prominently displayed on-screen.
The user was evidently in the process of editing a sentence, likely to correct
the nonsensical “fob” into “for” [Figure 4].[^59]

![Schematics for Engelbart's "Display System." The arrangement of keyboard,
mouse, and screen will define an epoch of human-computer interaction. Source:
Douglas Engelbart, "X-Y Position Indicator for a Display System," Patent
US3541541, 1970.](figure-5.jpg)

Reflecting on the use of visual display systems for human-computer
interaction, Engelbart wrote, “One of the potentially most promising means for
delivering and receiving information to and from digital computers involves
the display of computer outputs as visual representations on a cathode ray
tube and the alteration of the display by human operator in order to deliver
instructions to the computer.”[^60] The first subjects to read and write
on-screen reported feeling freedom and liberation from paper. An anonymous
account included in Engelbart’s report offered the following
self-assessment:[^61]

```
1B2B1 To accommodate and preserve a thought or
piece of information that isn't related to the work
of the moment, one can very quickly and easily
insert a note within the structure of a file at such
a place that it will neither get in the way nor get
lost.

1B2B2 Later, working in another part of the file,
he can almost instantly (e.g. within two seconds)
return to the place where he temporarily is storing
such notes, to modify or add to any of them.

1B2B3 As any such miscellaneous thought develops,
it is easy (and delightful) to reshape the structure
and content of its discussion material.
```

Writing, which this typist previously perceived as an ordered and continuous
activity, subsequently was performed in a more disjointed way. The typist
could delight in shaping paragraphs that more closely matched her mental
activity. Screens restored some of the fluidity of writing that typewriters
denied. Writers could pursue two thoughts at the same time, documenting both
at different parts of the file as one would in a notebook. Not constrained by
the rigidity of a linear mechanism, they moved around the document at will.

Engelbart recorded what must count as some of the most evocative passages to
appear in a NASA technical report. His “Results and Discussion” section
contains the following contemplation by an anonymous typist. Numbered passages
along with unexpected enjambment heighten the staccato quality of prose, which
attains an almost lyrical quality:[^61]

```
1B4A I find that I write faster and more freely,

    1B4A1 pouring thoughts and trial words onto the
    screen with much less inhibition,

    1B4A2 finding it easy to repair mistakes or wrong
    choices

        1B4A2A so while capturing a thought I don’t
        have to inhibit the outpouring of thought and
        action to do it with particular correctness,

    1B4A3 finding that several trials at the right
    wording can be done very quickly

        1B4A3A so I can experiment, easily take a look
        and see how a new version strikes me--and often
        the first unworried attempt at a way to express
        something turns out to be satisfactory, or at
        least to require only minor touch up.

    1B4A4 Finding that where I might otherwise
    hesitate in search of the right word, I now pour out
    a succession of potentially appropriate words,
    leaving them all there while the rest of the
    statement takes shape. Then I select from among
    them, or replace them all, or else merely change the
    list a bit and wait for a later movement of the
    spirit.
```

The lines remind us that when input and output coincide in time, as they do on
paper, mistakes are costly. Once inscribed, the sign gains permanence; it is
difficult to emend. An eraser can help remove a layer of physical material.
Alternatively, writers use white ink to restore the writing surface.
Engelbart’s anonymous typist reports the feeling of freedom from such physical
commitment. She can simply backspace and start over. Words come easily because
there are no penalties for being wrong. Virtual space seems limitless and
endlessly pliable.

The feeling of material transcendence--the ephemeral quality of digital
text--is tied directly to the underlying physical affordances  of
electromagnetic storage. Screens expose the pliability of the medium, where
erasure is effortless. Content can be addressed in memory and copied at the
stroke of a key. The numbered paragraphs suggest a novel system for
recollection. Data storage units become, in a sense, mental units. I am struck
by the distinctly phenomenological quality of technical description: The
editor does not merely resemble a page; it is, for the writer, a newly
discovered way of thought that changes the writer’s relation not only to text
but also to her own thoughts. The highly hierarchical and blocky paragraph
structure, along with its repetitive refrain (“finding” and “I find that”),
gives the prose a hypnotic drive forward. The cadence matches the reported
experience of discovery.

The passages appear too contrived to be spontaneous. Despite its experimental
structure, these phenomenological reflections advance key elements of
Engelbart’s research program, which aimed to develop new data structures in
combination with new ways of displaying them. Yet I cannot help but be moved
by the fluency of the prose and by the sheer audacity of the project.

Engelbart’s research into intellect augmentation created tools that augment
research. In an image that evokes Baron Münchhausen pulling himself out of a
swamp by his own bootstraps, Engelbart called his group’s methodology
“bootstrapping,” which involved the recursive strategy of “developing tools
and techniques” to develop better tools and techniques.[^62] The “tangible
product” of such an activity was a “constantly improving augmentation system
for use in developing and studying augmentation systems.”[^63]

It was an appealing vision, but only so long as it remained recursive.
Engelbart’s group benefited from creating their own tools and methods.
Engelbart also hoped that his system could be “transferred--as a whole or by
pieces of concept, principle and technique--to help others develop
augmentation systems for many other disciplines and activities.”[^64]
Undoubtedly, Engelbart’s ideas about intellect augmentation have had a broad
impact on knowledge work across disciplines. However, his vision loses the
property of self-determination when transferred outside the narrow confines of
a laboratory actively engaged in the transformation of material contexts of
their own knowledge production. Word processing today rarely involves
communities pulling themselves up by their own bootstraps: using their tools
and techniques of their own design. Augmentation enforced from without often
advances values and principles no longer comprehensible to the entity being
augmented.

To bring his system into being, Engelbart convened a community that through
recursive self-improvement could lift itself up toward a smarter, more
efficient, more human way of doing research. The group crafted novel
instruments for reading and writing. They engineered new programming
languages, compilers to interpret them, and debuggers to troubleshoot them.
The system shows care and love for the craft of writing. But there is also
complexity. “This complexity has grown more than expected,” Engelbart wrote in
conclusion.[^65] The feeling of transcendence that the anonymous typist
describes in using the system engages a sophisticated mechanism. The mechanism
was not, however, the primary instrument of augmentation. Rather, it was the
process of designing, making, and experimenting with tools that enhanced the
intellect. Engelbart wrote, “The development of the Bootstrap Community must
be coordinated with the capacity of our consoles, computer service, and file
storage to support Community needs, and with our ability to integrate and
coordinate people and activities.”[^66] In other words, the development of the
community must form a feedback loop with software development. It involves
training, practice, critical self-reflection, and thoughtful deliberation.

***

Modern word processors enable us to drag and drop passages with unprecedented
facility. We live in Engelbart’s world to the extent that we use his lab’s
complex systems daily and in a smaller configuration: screens, keyboards,
storage. Today’s computer users rarely form a self-determined bootstrapping
community, however. The contemporary writer is bootstrapped passively to the
prevailing vision of intellect augmentation. The very metaphor of
bootstrapping suggests the impossibility of using one’s bootstraps to pull
others out of the Platonic cave. Engelbart’s liberatory research program thus
left another less lofty imprint on the everyday practice of modern
intellectual life. Text, which before the advent of the CRT was readily
apparent on the page in all its fullness, finally entered a complex system of
executable code and inscrutable control instruction. The material lightness of
textual being came at the price of legibility. Complexity has grown more than
expected.

Short-lived screenless word processors of the early 1960s (as as the IBM
MT/ST) were difficult to operate, because typists had no means to visualize
complex data structures on tape. Screens helped by representing document
topography visually, restoring a sense of apparent space to otherwise opaque
media. The contemporary digital document may resemble a page on-screen, but
beneath it, it is a jumble of bits, split into the various regions of internal
memory. Screens simulate document unity by presenting holistic images of
paragraphs, pages, and books.[^ The simulation seems to follow the physics of
paper and ink: One can turn pages, write in margins, and insert bookmarks. But
the underlying inscription remains in fracture. Simulated text does not
transcend matter.  Screens merely conceal its material properties while
recreating others, more seemingly transcendent ones. The act of continual
dissemblage, one medium imitating the other, manufactures an ephemeral
illusion by which pages fade in and out of sight, paper folds in improbable
ways, and words glide effortlessly between registers of copy and paste.

In the rift between  input and output, programmable media inject arbitrary
intervals of time and space. Forces of capital and control occupy the void as
the sign acquires new dimensions and capabilities for automation. Code and
codex subsequently sink beneath the matte surface of a synthetic storage
medium. Screens purport to restore a sense of lost immediacy, of the kind felt
on contact between pen nib and paper as the capillary action of cellulose
conveys ink into its shallow conduit.

Screens are meant to open a window onto the unfamiliar physicalities of
electromagnetic inscription. They obviate the need for multiple typings or
printouts. Projected image should, in theory, correspond to its originating
keystroke. The gap separating inputs and outputs appears to close. Crucially,
the accord between archived inscription and its image cannot be guaranteed.
The interval persists in practice and is actively contested. Deep and shallow
inscriptions entwine. Laminate text seems weightless and ephemeral at some
layers of the composite, allowing for rapid remediation. At other layers its
affordances are determined by its physics; at still other layers they are
carefully constructed to resist movement or interpretation. Alienated from the
base particulates of the word, we lose some of our basic interpretive
capacities to interrogate embedded power structures.[^67] The history of
digital text is one of its gradual disappearance and the rise of a simulation.

## Bibliography

Adler, Alfred, and Harry Albertman. "Knitting Machine". US1927016A. New York,
NY, filed August 1, 1922, and issued September 19, 1933.

American Bar Association. “The $10,000 Typewriter.” *ABA Journal*, May 1966.

Atkinson, Paul. “The Best Laid Plans of Mice and Men: The Computer Mouse in
the History of Computing.” *Design Issues* 23, no. 3 (2007): 46–61.

Bardini, Thierry. *Bootstrapping: Douglas Engelbart, Coevolution and the
Origins of Personal Computing*. Stanford, CA: Stanford University Press, 2000.


Beauchamp, K. G. *History of Telegraphy*. London: The Institution of
Engineering and Technology, 2001.

Bishop, D.A., R.S. Heard, R.E. Hunt, J.E. Jones, and R.A. Rahenkamp.
“Development of the IBM Magnetic Tape SELECTRIC Composer.” *IBM Journal of
Research and Development* 12, no. 5 (September 1968): 380–98.

Brackbill, Hervey. “Some Telegraphers’ Terms.” *American Speech* 4, no. 4
(April 1, 1929): 287–90.

Camras, Marvin. “Magnetic Recording Tapes.” *Transactions of the American
Institute of Electrical Engineers* 67, no. 1 (January 1948): 503–6.

Casper, Louis. "Remote Control Advertising and Electric Signaling System".
US1953072A. Richmond Hill, NY, filed September 9, 1930, and issued April 3,
1934.

Chun, Wendy Hui Kyong. “The Enduring Ephemeral, or the Future Is a Memory.”
*Critical Inquiry* 35, no. 1 (September 1, 2008): 148–71.

Clancy, Douglas, George Hobgood, and Frederick May. "Data Reading, Recording,
and Positioning System." US3530448A, filed January 15, 1968, and issued
September 22, 1970.

Daniel, Eric D., C. Denis Mee, and Mark H. Clark, eds. *Magnetic Recording:
The First 100 Years*. New York: Wiley-IEEE Press, 1998.

Dee, R.H. “Magnetic Tape for Data Storage: An Enduring Technology.”
*Proceedings of the IEEE* 96, no. 11 (November 2008): 1775–85.

Denning, Peter J. “Third Generation Computer Systems.” *ACM Computing Surveys*
3, no. 4 (December 1971): 175–216.

Eisenberg, Daniel. “History of Word Processing.” In *Encyclopedia of Library
and Information Science*, 49:268–78. New York: Dekker, 1992.

Emerson, Lori. *Reading Writing Interfaces: From the Digital to the
Bookbound*. Minneapolis: University Of Minnesota Press, 2014.

Engel, Friedrich K. “1888-1988 : A Hundred Years of Magnetic Sound Recording.”
*Journal of the Audio Engineering Society* 36, no. 3 (March 1, 1988): 170–78.

Engelbart, Douglas. “Doug Engelbart 1968 Demo,” December 9, 1968.
http://web.stanford.edu/dept/SUL/library/extra4/sloan/mousesite/1968Demo.html.

Engelbart, Douglas C., and William K. English. “A Research Center for
Augmenting Human Intellect.” In *Proceedings of the December 9-11, 1968, Fall
Joint Computer Conference*, Part I, 395–410. AFIPS ’68 (Fall, Part I). New
York, NY, USA: ACM, 1968.

Engelbart, Douglas, C. “Human Intellect Augmentation Techniques.” NASA
Contractor Report, January 1969.

Epstein, Herman, and Frank Innes. "Electrographic Printer". US3012839A.
Detroit, MI, filed July 15, 1954, and issued December 12, 1961.

Fankhauser, Charles. “The Telegraphone.” *Journal of the Franklin Institute*,
no. 167 (January 1909): 37–70.

Frutiger, A. “The IBM SELECTRIC Composer: The Evolution of Composition
Technology.” *IBM Journal of Research and Development* 12, no. 1 (January 1968):
9–14.

Fuller, Matthew. *Media Ecologies: Materialist Energies in Art and
Technoculture*. Cambridge, MA: The MIT Press, 2007.

Gadamer, Hans-Georg. Truth and Method. New York: Seabury Press, 1975.

Geikie, Archibald. *The Founders of Geology*. New York: Macmillan, 1905.

Gitelman, Lisa. *Paper Knowledge: Toward a Media History of Documents*.
Durham, NC: Duke University Press, 2014.

Goldberg, Hyman Eli. "Controller". US1165663 A, filed January 10, 1911, and
issued December 28, 1915.

Hayles, N. Katherine. *Writing Machines*. Cambridge, MA: MIT Press, 2002.

Heim, Michael. "Electric Language: A Philosophical Study of Word Processing."
New Haven: Yale University Press, 1987.

Hockey, Susan. “The History of Humanities Computing.” In *Companion to Digital
Humanities* (Blackwell Companions to Literature and Culture). Blackwell
Companions to Literature and Culture. Oxford: Blackwell Publishing
Professional, 2004.

Hough, Clinton. "Wired Radio Program Apparatus". US1805665A. New York, NY,
filed April 27, 1927, and issued May 19, 1931.

Huhtamo, Erkki, and Pekka Parikka. *Media Archaeology: Approaches,
Applications, and Implications*. Berkeley, CA: University of California Press,
2011.

Jennings, Tom. “An Annotated History of Some Character Codes or ASCII:
American Standard Code for Information Infiltration,” October 29, 2004.
https://web.archive.org/web/20120113050309/http://wps.com/projects/codes/index.html

Kirschenbaum, Matthew G. *Mechanisms: New Media and the Forensic Imagination*.
The MIT Press, 2008.

Kittler, Friedrich A. *Gramophone, Film, Typewriter*. Translated by Geoffrey
Winthrop-Young and Michael Wutz. Stanford, CA: Stanford University Press,
1999.

Koetsier, Teun. “On the Prehistory of Programmable Machines: Musical Automata,
Looms, Calculators.” *Mechanism and Machine Theory* 36, no. 5 (May 2001):
589–603.

Lee, Richard and Roy Worrall. *Symposium on Electronic Composition in
Printing*. Washington, DC: National Bureau of Standards, 1968.

Levine, Caroline. *Forms: Whole, Rhythm, Hierarchy, Network*. Princeton, N.J.:
Princeton University Press, 2015.

May, F.T. “IBM Word Processing Developments.” *IBM Journal of Research and
Development* 25, no. 5 (September 1981): 741–54.

Mills, Mara. “Deafening: Noise and the Engineering of Communication in the
Telephone System.” *Grey Room* (April 1, 2011): 118–43.

Morgan, J.S., and J.R. Norwood. “The IBM SELECTRIC Composer: Justification
Mechanism.” *IBM Journal of Research and Development* 12, no. 1 (January
1968): 68–75.

Murray, Donald. “Setting Type by Telegraph.” *Journal of the Institution of
Electrical Engineers* 34, no. 172 (May 1905): 555–97.

Ohmori, Hiroyuki, Masanori Hosomi, Kazuhiro Bessho, Yutaka Higo, Kazutaka
Yamane, and Hiroyuki Uchida. "Memory Element, Method of Manufacturing the
Same, and Memory Device". United States Patent Application 20150097254 Kind
Code: A1, filed September 4, 2014, and issued April 9, 2015.

Perry, Sara, and Colleen Morgan. “Materializing Media Archaeologies: The MAD-P
Hard Drive Excavation.” *Journal of Contemporary Archaeology* 2, no. 1 (April
24, 2015): 94–104.

Poulsen, Valdemar. "Method of Recording and Reproducing Sounds or Signals."
US661619 A, filed July 8, 1899, and issued November 13, 1900.

Randell, Brian, Maurice V. Wilkes, and Paul E. Ceruzzi. “History of Digital
Computers.” *In Encyclopedia of Computer Science*, 545–570. Chichester, UK:
John Wiley and Sons Ltd., 2003.

Rheinberger, Hans-Jörg. *Toward a History of Epistemic Things: Synthesizing
Proteins in the Test Tube*. Stanford, CA: Stanford University Press, 1997.

Ricoeur, Paul. *Interpretation Theory: Discourse and the Surplus of Meaning*.
Fort Worth: Texas Christian University Press, 1976.

Riskin, Jessica. “The Defecating Duck, Or, the Ambiguous Origins of Artificial
Life.” *Critical Inquiry* 29, no. 4 (June 1, 2003): 599–633.

Rogers, Rosemary. “The Demo.” MouseSite, 2005.
http://web.archive.org/web/20150415203743/http://web.stanford.edu/dept/SUL/library/extra4/sloan/MouseSite/1968Demo.html.

Rowberry, Simon. “Vladimir Nabokov’s Pale Fire: The Lost ‘Father of All
Hypertext Demos’?” In *Proceedings of the 22Nd ACM Conference on Hypertext and
Hypermedia*, 319–324. HT ’11. New York, NY, USA: ACM, 2011.

Schenck, Hubert G. “Applied Paleontology.” *AAPG Bulletin* 24, no. 10 (1940):
1752–78.

Simonetti, Cristián. “Between the Vertical and the Horizontal: Time and Space
in Archaeology.” *History of the Human Sciences* 26, no. 1 (February 1, 2013):
90–110.

Smith, Oberllin. “Some Possible Forms of the Phonograph.” *The Electrical
World*, September 8, 1888, 116–17.

Staff. *Description of a Magnetic Drum Calculator*. Vol. XXV. Annals of the
Computation Laboratory of Harvard University. Cambridge: Harvard University
Press, 1952.

Staff. *Description of a Relay Calculator*. Vol. XXIV. Annals of the
Computation Laboratory of Harvard University. London: Oxford University Press,
1949.

Starosielski, Nicole. *The Undersea Network*. Durham: Duke University Press
Books, 2015.

Stefanita, Carmen-Gabriela. *Magnetism: Basics and Applications*. Springer
Science & Business Media, 2012.

Thiele, Heinz H. K. “Magnetic Sound Recording in Europe up to 1945.” *Journal
of the Audio Engineering Society* 36, no. 5 (May 1, 1988): 396–408.

Turing, A. M. “Computing Machinery and Intelligence.” *Mind* 59, no. 236
(October 1, 1950): 433–60.

U.S. Bureau of Labor Statistics. “Displacement of Morse Operators in
Commercial Telegraph Offices.” *Monthly Labor Review* 34, no. 3 (March 1,
1932): 501–15.

Vasic, Bane, and Erozan M. Kurtas. *Coding and Signal Processing for Magnetic
Recording Systems*. CRC Press, 2004.

Weller, Charles Edward. *The Early History of the Typewriter*. La Porte,
Indiana: Chase & Shepard, Printers, 1918.

Wythoff, Grant. “Artifactual Interpretation.” *Journal of Contemporary
Archaeology* 2, no. 1 (April 24, 2015): 23–29.

Youngquist, Robert, and Robert Hanes. "Magnetic Reader". US3013206A.
Stillwater, MN, filed August 28, 1958, and issued December 12, 1961.

[^1]: Chun, "Enduring Ephemeral," 148.

[^2]: See Levine, *Forms*, 6-11. Levine explains: "Affordance is a term used
to describe the potential uses or actions latent in materials and designs.
Glass affords transparency and brittleness. Steel affords strength,
smoothness, hardness and durability. Cotton affords fluffiness, but also
breathable cloth when it is spun into yarn and thread" (6).

[^4]: See for example Gadamer, *Truth and Method*, 110: "In both legal and
theological hermeneutic there is an essential tension between the fixed
text---the law or the gospel---on the one hand and, on the other, the sense
arrived at by applying it at the concrete moment of interpretation." See also
Ricoeur, *Interpretation Theory*, 28.

[^6]: See, for example, Huhtamo and Parikka's "Introduction" in *Media
Archaeology*, 3: "Media Archaeology should not be confused with archaeology as
a discipline. When media archaeologists claim they are 'excavating'
media-cultural phenomena, the word should be understood in a specific way."
See also Grant Wythoff, "Artifactual Interpretation." On the use of
stratigraphy related to hard drive forensics see Perry and Morgan,
"Materializing Media Archaeologies: the MAD-P Hard Drive Excavation."

[^7]: See Schenck, "Applied Paleontology"; Simonetti, "Between the Vertical
and the Horizontal: Time and Space in Archaeology"; and Geikie, "The Rise of
Stratigraphical Geology in England" in *The Founders of Geology*, 337-364.

[^8]: For periodization of computer systems see Denning, "Third Generation
Computer Systems."

[^9]: Programmable media have multiple origins, worthy of their own extended
history. The French textile worker Basile Bouchon used "drill paper" to
automate industrial drawlooms. The invention of the loom could also be
attributed to the Banu Musa brothers, ninth-century automata inventors from
Baghdad; to Jacques de Vaucanson, who delighted the public with his lifelike
mechanisms in the mid-eighteenth century; or to Joseph Charles Marie Jacquard,
who improved on and popularized Bouchon’s looms on an industrial scale around
the same time. See Koetsier, "Prehistory of Programmable Machines," 593-95;
Randell et al., "History of Digital Computers"; and Riskin, "Defecating Duck."

[^10]: Adler and Albertman, “Knitting Machine”; Casper, “Remote Control
Advertising”; Hough, “Wired Radio Program Apparatus.”

[^11]: Jennings, “Annotated History.”

[^12]: The Australian Donald Murray improved on the Baudot system to minimize
the amount of holes needing to be punched, allotting fewer perforations to
common English letters. See Murray, “Setting Type,” 567.

[^15]: Murray, "Setting Type," 557.

[^16]: According to the U.S. Bureau of Labor Statistics, women made up 24
percent of the Morse operators in 1915 (before the widespread advent of
automated telegraphy). By 1931 women made up 64 percent of printer and Morse
manual operators. U.S. Bureau of Labor Statistics, “Displacement of Morse
Operators,” 514.

[^17]: Brackbill, “Some Telegraphers’ Terms,” 290.

[^18]: International Telegraph Union, "Telegraph Regulations," 12-13.

[^19]: Goldberg, “Controller,” , sheet 3.

[^20]: Goldberg, “Controller,” 1.

[^21]: Goldberg, Controller, 1-4.

[^22]: Goldberg, “Controller,” 1.

[^23]: For example, Susan Hockey says, “Father Busa has stories of truckloads
of punched cards being transported from one center to another in Italy”
(^Hockey, “History of Humanities Computing,” n.p.).

[^24]: Lee and Worral, *Electronic Composition*, 48.

[^25]: Daniel et al., Magnetic Recording; Engel, “1888-1988”; Poulsen, “Method
of Recording”; Oberlin Smith, “Some Possible Forms”; Thiele, “Magnetic Sound
Recording”; Vasic and Kurtas, Coding and Signal Processing.

[^26]: Camras, “Magnetic Recording Tapes,” 505.

[^27]: Dee, “Magnetic Tape,” 1775.

[^28]: Fankhauser, “Telegraphone,” 37-38.

[^29]: Fankhauser, “Telegraphone,” 40.

[^30]: Fankhauser, “Telegraphone,” 39-40.

[^31]: Fankhauser, “Telegraphone,” 44.

[^32]: Fankhauser, “Telegraphone,” 45.

[^33]: Fankhauser, “Telegraphone,” 41.

[^34]: The staff of the Computation Laboratory of Harvard University wrote:
“Two means are available for preparing the functional tapes required for the
operation of the interpolators. First, when the tabular values of f(x) have
been previously published, they may be copied on the keys of the functional
tape preparation unit [...] and the tape produced by the punches associated
with this unit, under manual control. Second, as suitable control tape may be
coded directing the calculator to compute the values of f(x) and record them
by means of one of the four output punches, mounted on the right wing of the
machine” (Staff, Description of a Relay Calculator, 33).

[^35]: Staff, Description of a Relay Calculator, 30.

[^37]: Turing, "Computing Machinery and Intelligence," 444.

[^38]: Staff, Description of a Magnetic Drum Calculator, 34-35.

[^39]: Staff, Description of a Magnetic Drum Calculator, 35 & 143-88.

[^42]: Eisenberg, “Word Processing.”

[^43]: ABA Journal,“The $10,000 typewriter.”

[^44]: See Ohmori et al., “Memory Element”; and Stefanita, Magnetism, 1-69.

[^45]: Recall Wittgenstein’s broken reading machines, which exhibited a
similarly recursive problem of verification. To check whether someone
understood a message, one has to resort to another message, and so on.

[^46]: Youngquist and Hanes, “Magnetic Reader,” 1.

[^47]: Youngquist and Hanes, “Magnetic Reader,” 1.

[^48]: Morgan and Norwood, “IBM Selectric Composer,” 69.

[^49]: Bishop et al., “Development.”

[^50]: Clancy et al., “Data Reading,” 1.

[^51]: May, “IBM Word Processing Developments,” 743.

[^52]: May, “IBM Word Processing Developments,” 743.

[^53]: Bishop et al., “Development,” 382.

[^54]: Bishop et al., “Development,” 382. See also May, “IBM Word Processing
Developments.”

[^55]: Frutiger, “IBM Selectric Composer,” 10.

[^56]: Rogers, “The Demo”; Tweney, “Mother of All Demos.”

[^57]: Engelbart, “Doug Engelbart 1968 Demo.” The demo is subject to numerous
academic studies. See Atkinson; Bardini; Rowberry; Chun, 85.

[^58]: Engelbart, Human Intellect Augmentation Techniques, 1.

[^59]: The source of the cryptic phrase is likely Charles Edward Weller: “We
were then in the midst of an exciting political campaign, and it was then for
the first time that the well known sentence was inaugurated--‘Now is the time
for all good men to come to the aid of the party’; also the opening sentence
of the Declaration of Independence, [...] which sentences were repeated many
times in order to test the speed of the machine” (Weller, Early History of the
Typewriter, 21, 30).

[^60]: Weller, Early History of the Typewriter, 1.

[^61]: Engelbart, Human Intellect Augmentation Techniques, 50-51. I have
reproduced the text verbatim, preserving the line breaks, because formatting
is an integral part of the reported experience.

[^62]: Engelbart and English, “Research Center,” 396.

[^63]: Engelbart, Human Intellect Augmentation Techniques, 6.

[^64]: Engelbart, Human Intellect Augmentation Techniques, 6.

[^65]: Engelbart, Human Intellect Augmentation Techniques, 67.

[^66]: Engelbart, Human Intellect Augmentation Techniques, 67.

[^67]: A portions of this essay in their extended form appear in Chapter 4 of
*Plain Text: The Poetics of Computation* (Stanford University Press, 2017).

[^68]: See Kirschenbaum, 50 on the persistence of erased data.

[^69]: Kittler, 263.

[^70]: See Drucker, Emerson, Fuller, Gitelman, Hayles, Kirschenbaum.

[^71]: See Mills, Rheinberger, Riskin, Starosielski.

[^72] McCorduck tells the story of a rabbinate court, which, when interpreting
a law that prohibits observant Jews from erasing God's name, deemed that words
on a screen do not constitute writing, and therefore sanctioned their erasure.
See Mccorduck, 51 and Heim, 192.

[^73]: Kirschenbaum tells another aspect of the IBM story related to random
access memory in *Mechanisms*, 76-86.

[^74]: On simulation see Manovich
