# Part I: Simulation
## Chapter 1: Metaphor Machines

Reading Jean Baudrillard at the end of the century prior, I understood his
writing on simulacra in relationship to ersatz entertainment: amusement parks,
virtual reality, reality television, and the like. I am only now beginning to
comprehend the extent of the simulation. Computational metaphor machines
mediate experience ubiquitously. They interject in simple everyday acts from
drinking coffee in the morning, through brewing and payment systems, to going
to bed as alarm clocks and night activity monitors.

Baudrillard writes:

> At the limit of an always increasing elimination of references and
> finalities, an ever-increasing loss of resemblances and designations, we
> find the digital and programmatic sign, whose "value" is purely *tactical*,
> at the intersection of other signals ("bits" of information/tests) whose
> structure is that of a micromolecular code of command and control
> [@baudrillard_selected_1988, 139-140].

Somewhere between the sites of storage (what is) and projection (what appears
to be), the computed sign undergoes a series of structural transformations.
What starts out as a thought becomes a letter, a signal, a magnetic mark, a
phase of the liquid crystal, and finally a ray of light. Programming languages
guide thought through a series of transformations in the passage between
bodies, screens, and archives. Languages, natural and artificial, break
thought up into differentiated units. Simulation reassembles the units back
into a continuous integrated whole. Texts made of discrete pixels congeal into
holistic literary works.

Roman Jakobson called such construction and deconstruction of meaning the
"profuse exchange of ritualized formulas" or the phatic function of language
[@malinowski_problem_1923, 146; @jakobson_closing_1960, 355]. In the phatic
function lies the essence of formatting. But before we can begin to peel apart
layers of form, formatting, and formula in the next chapters, we must discover
the metaphor at the heart of computation. Computational metaphors occlude the
incongruence between visible representation and the underlying material
affordances of the medium. What you see is not always what you get. We are
instead confronted with a composite image, which under examination reveals a
complex process of transfiguration between the visible sign and the sign at
the site of the inscription.

To understand the "loss of resemblances" in the process of simulation, imagine
communicating by telegraph in two different languages with a friend.
Occasionally, besides whatever else you wanted to say, envision also sending a
signal to your partner's device that indicates a change in the transmission
language. Thus in addition to the message, you would also send a predetermined
code that would switch the receiving apparatus from the "English language"
into the "French language" mode. Such an instruction would attune the receiver
to a different mode of apprehension. In our example, it would transform an
English language machine into a French language one. It is in that sense of
attunement that the programmatic sign acquires its non-representational,
tactical character. Stripped of references, resemblances, and designations the
programmatic sign commands and controls.

Yet despite the formative impact on the structure of comprehension, the
programmatic sign does not often figure in our theories of meaning making.
Instead, we erroneously consign it to the ornamental "formatting" layer of
document structure. We do so at our peril. Unlike passive decorative elements
like fleurons (❦ ❧), daggers and pilcrows (†‡¶), box drawings (╝╞╟), and other
dingbats (✇ ❖ ➿ ) the programmatic sign actively molds text to context. At the
maximally blunt limit of its abilities, the formatting layer affects
visibility. For example, it can selectively render some words and sentences on
the screen while suppressing others. The ability to hide text from view
completely or to make it so small as to be illegible affects not just the
style but the politics of text. Formatting, in that sense, can determine its
audience, privileging certain voices and modes of access over others.

Unlike figurative language, machine control languages function in the
imperative.  They do not stand for action---they are action. More binding than
J.L.  Austin's "speech acts," control codes arrange and regulate. The
difference between representation and control is one of brute force. It lies
in the distinction between a restraining order and physical restraint. A
restraining order *represents* the calling forth of codified power. Physical
restraints, like the plastic handcuffs widely used in contemporary policing,
*enact* the exercise of codified power. Like all violence they do not stand
for anything. Stripped of references, resemblances, and designations, they are
in themselves an arrangement and rearrangement of matter. The handcuffs
contort the body into the shape of submission. Absent a body, the restraints
draw an empty shape.

Code acts similarly to shape the word. Located somewhere between idea and
material, formatting relates content to matter. It mediates by imposing
structure. Think of a paragraph, for example. By convention, writers use
paragraphs to break up the flow of monolithic thought on a page. The paragraph
contains information. Emptied of content, it simply ceases to exist. Can there
be an empty paragraph? Can the shape of the paragraph persist outside of the
material confines of the page or the screen? Can one imagine a paragraph that
unfolds spatially not in two dimensions, but in one, along a straight line?
What about a three dimensional paragraph? Could it take shape of a cuboid
instead instead of a rectangle? These questions boggle the mind because the
paragraph draws a singular shape. It is a textual container of a type. Any
other shape less or more than the paragraph would go by another name. It would
constitute another format. To imagine something like a one-dimensional
paragraph is akin to imagining a flat shoebox. A flat shoebox could no longer
hold shoes. It would contain something else like images of footwear.
Similarly, a paragraph identifies a particular arrangement of elements. It is
a box or a data structure of a shape, made to hold words and sentences. Like
nesting dolls, words and sentences are in themselves data structures that
contain further, smaller arrangements of information.

One could say, what of such arrangements? Who cares about paragraphs? It is
merely one type of a container among many. It has only an instrumental
function to help get the point across. The meat of interpretation lies in the
stuff within. Words come in other shapes and sizes. The outer container is
disposable and therefore insignificant. Formats could only seem insignificant
in the past when they were few and simple. The transition between static and
dynamic media necessitates renewed attention to form and format. What you saw
is what you got on the page. On the screen, what you see is but a small part
of what you get. The content---all that is contained on a page---shifts
beneath the projected image.

In print, the content can be gleaned from the surface. There is nothing but
surface on a page. The screen is a layered surface. Sandwiched between panes
of glass, liquid crystal moves in response to electrical modulation. The ebb
and flow of electricity in turn reflects yet another layer of codification,
inscribed onto yet other recondite planes of inscription. A byte, made up of
eight binary bits, holds a letter. The string of letters spelling out "hello
world" occupies eleven bytes, if you count the space. A file in the Portable
Document Format (`.pdf`) containing nothing but "hello world" takes up 24,335
bytes on my system. Formatting accounts for the disparity between plain text
and fancy text, the latter defined as "text representation consisting of plain
text plus added information" [@unicode_consortium_unicode_1990]. What is the
nature of this "added information?"

Historically, the added information included machine instructions for viewing
and printing text, encoding, or encryption, used for clandestine
communication. Portable Document Format specifically can also contain features
that enable "accessibility of content to those with disabilities," "digital
signatures to certify authenticity," "electronic forms to gather data,"
"preservation of document fidelity independent of the device, platform, and
software," and "security and permission to allow the creator to retain control
of the document and associated rights" [@iso_portable_2008, vii]. These
capabilities operate somewhere between the visible content and stored
information. More than passive conduits of meaning, electronic texts contain
the rules for engagement between authors and their readers. Embedded
structures project an ontology. In our example, the Portable Document Format
encodes, among other things, ideas about "reading," "authenticity,"
"fidelity," "preservation," and "authorship." Whatever literary theoretical
framework the reader brings to the process of interpretation must therefore
meet the framework implicit in the electronic text itself. Such an encounter
happens not on the level of representation or ideology, but on the level of
the physical, the phatic, and the imperative, where formatting and control
reside.

The familiar paper paragraph structure already presents several interesting
problems for analysis. In claiming typographical space on a page the paragraph
suggests corresponding mental units. A unit of written language thus also
becomes in some sense a unit of thought. But no such structures as paragraphs
exist in the mind. At the level of physiology, the brain arranges information
otherwise. Things get significantly more complicated when the paragraph acts
to mediate between the mind and the page on the one side of comprehension, and
the page and the machine on the other.

![Forms and formats.](images/forms.png)

Just like there is nothing inherently paragraph-like in the neural arrangement
of the brain, there is also nothing inherently paragraph-like or page-like in
the arrangement of bits along the surface of the magnetic disk or the solid
state drive. We are presented instead with metaphors of paragraphs, pages,
files, and folders. Screen representations of paragraphs, pages, files, and
folders look like their counterparts on the page, yet they represent other
structures in the head, and yet other structures on the disk. The metaphor
thus mediates between mental image---information stored in the head---and
inscription---information stored in the machine. As Alexander Galloway wrote
in *The Interface Effect*, the nature of the interface stems from the
incompatibility between incommensurate systems [@galloway_interface_2012,
viii]. The interface is also a metaphor that transports structure from one
entity to the other, at the point of contact between human and machine. In
this chapter, we will begin to unpack the interface metaphor.

### 1.1 Verisimilitude

In the language of cognitive metaphor theory, the kind of interface metaphors
that we have been discussing so far go under the name of *structural metaphors*.
"Structural metaphors allow us to do much more than just orient concepts,"
Lakoff and Johnson wrote [@lakoff_metaphors_1980, 61]. Grounded in "systematic
correlations within our experience," they transfer organizing principles from
one domain to another. Thus to say something like "time is money" is not just
to compare time an money visually or ontologically, but to suggest that
something in the arrangement of the financial system resembles something in
the arrangement of the temporal system [@lakoff_metaphors_1980, 65-8]. If
metaphors work by transferring qualities, structure is the quality being
transferred in all of the above cases. Structural metaphors organize one thing
in the shape of another.

On an abstract level, structural substitution defines computation in general.
Recall for a moment Turing's seminal definition of the universal computing
machine.[^ln1-turing] What he calls a "computing machine" involves a finite
number of configurations of "tape" and "symbol." The machine attains a
universal quality when configurations of tape and symbol can substitute for
all other forms of symbolic manipulation. In this way a universal computer can
emulate a calculator, but also typewriter, a book, and a fairy tale world.
Turing's universal computing machine is a type of a structural metaphor by
definition. It has the ability to represent all other symbolic machine states,
symbolically. Being a universal symbolic manipulator, the Turing machine is
able to extend all metaphors. That is not to say that it can *do* anything.
For example, one cannot use a computational device to hammer nails.  But a
computer can be used to create the verisimilitude of hammering nails in the
virtual realm.

The language of computation reveals its reliance on metaphor in practice.
Consider the following passage from a patent filed by Xerox in 1991. It
describes, in its own words, "an electronic library metaphor," which includes:

> a shared books with database metaphor, a reference books metaphor, and a
> card catalog metaphor in one system that allows large object oriented data
> bases to be organized and accessed in an exclusive environment and in
> addition allows access to screen icons, creates a visual hierarchy of
> related and shared objects, and allows mutually exclusive access to the
> metaphors within the library [@pajak_electronic_1992, 1].

The invention ultimately enables the "organizing, accessing, and querying of
information unique to physical libraries in an electronic workstation
environment" [@pajak_electronic_1992, 1]. Setting aside, for a moment, the
peculiarity of being able to patent a metaphor, note the idiosyncrasy of the
technical language. What does it mean to "access" a metaphor? When someone
"checks out" a book from the electronic library, do they gain access to the
book or to the metaphor alone? And what mechanisms assure the correspondence
between a database and database metaphor, the book and book metaphor, and the
catalog and catalog metaphor? Traditional metaphor theory strains to help
us answer such questions.

In the so-called classical view, metaphors are simply a type of figurative
language. To say "the day stands tiptoe on the misty mountain tops" is to use
the verb "stand" in a novel linguistic context. Days have no literal legs to
stand on. John Searle, John Lakoff, and Mark Turner, among others, have argued
that metaphor is a more broadly a cognitive phenomenon, mapping distinct
ontological categories across "conceptual domains" [@lakoff_metaphors_1980;
@turner_death_1987; @lakoff_contemporary_1998, @searle_metaphor_1998]. In the
modified view, even such basic semantic concepts as "state, quantity, action,
cause, purpose, means, modality" are metaphorical in nature
[@lakoff_metaphorical_1980; @lakoff_contemporary_1998, 212]. Beyond
figurative, lyrical language, Lakoff and others have argued that metaphors
structure everyday experience. Thus the analysis of common phrases like
"things are looking up" and "I can't get that tune out of my mind" reveals
underlying figuration like "good things are up" and "the mind is a container
[@lakoff_metaphorical_1980, 195-198].

!["An exemplary interface for viewing a three dimensional book"
[@card_methods_2006, 3].](images/book-metaphor.png)

!["Alternate display techniques for information about a big book"
[@card_methods_2006,4].](images/book-3d.png)

The transference of structuring principles from one system to another---from
"physical libraries" to "electronic workstations environments," in our case---
reveals the formative nature of the structural metaphor. Metaphors that can be
touched and handled in some way exist neither wholly in language nor wholly in
the mind. Rather, they operate in action, at hand. John Carrol, one of the
pioneers in the field of human--computer interaction, summarized the role of
metaphors in the design of computing systems as follows:

> Professional programmers might learn a new system X by metaphorizing at
least initially from what they already know about system Y. More casual or
naive end-users might rely on metaphors drawn from more distant knowledge
domains, e.g. on what they have already learned about electric typewriters.
The implications of this proposal are simple and direct. If people employ
metaphors in learning about computing systems, [MISSING WORD] of those systems
should anticipate and support likely metaphorical constructions to increase
the ease of learning and using the system [@carroll_metaphor_1982, 107-108]."

In essence, Carroll imagines human--computer interfaces that enact Lakoff and
Johnson's "conceptual blending" in practice. In this way, the familiar gesture
of discarding a crumpled piece of paper into the waste bin can be simulated
digitally to handle the deletion of electronic documents. Apple's influential
*Human Interface Guidelines*, at the core of Apple's desktop interfaces in the
1980s, echo Carroll proscriptions:

> You can take advantage of people's knowledge of the world around them by
using metaphors to convey concepts and features of your application. Use
metaphors involving concrete, familiar ideas and make the metaphors plain,
so that users have a set of expectations to apply to computer environments.
For example, people often use folders to store paper documents in their
offices. Therefore, it makes sense to people to store computer documents in
computer-generated folders that look like files and folders. People can
organize their hard disks in a way that's analogous to the way they organize
their file cabinets [@apple_apple_1987, 4].

Apple's designers understood also that the mapping of concepts between the
physical and the computer-generated worlds is imperfect. For example, unlike a
real-world file folder, constrained by the size of its containing cabinet, a
computer folder can hold a nearly unlimited amount of files. Or, to be more
precise, the electronic folder metaphor is subject to different constraints
than those that limit the use of a paper file. The image of the paper file
should not therefore limit the possibilities of the metaphor's implementation,
the manual explains. It further advises to "strike a balance between the
metaphor's suggested use and the ability of the computer to support and extend
the metaphor" [@apple_apple_1987, 5].

A number of patents from IBM, Xerox, and Microsoft rely on the language of
metaphor extension. Consider United States Patent #5,907,854 by Paula J. Cox
et.al. of International Business Machines. The invention describes "a library
metaphor that allows a user to organize the online books in a manner that has
meaning and utility." The authors go on to explain that "while the actual
books may be stored in many separate and distinct locations [...] the bookcase
provides a familiar classification system." They go on to write that the
creation of bookcase metaphors involves "the creation of appropriate links to
the actual online book/bookshelf/bookcase." The "book metaphor" ultimately
"provides an easy to understand and intuitive model for a user who might not
be familiar with on-line viewing tools" [@cox_method_1999].

Another metaphor machine can be found in the collaboration between the
influential product design firm IDEO and Xerox. The two worked on an early
file manager shell PC Catalog, later renamed to TabWorks. In describing the
design process, IDEO developers wrote about defining "key elements of the
metaphor" contained in the image of "tabs" and "catalogs." "The book *cover*,"
they wrote, "opened to display three *rings* binding a set of divider *tabs*,
each containing one or more *pages*." Pages, in turn contained *items* or
"icons representing documents or applications"
[@moll-carrillo_articulating_1995, 1-7]. In a similar binder-based software
application, the engineers at IBM describe the "contents of the notebook
metaphor," which are "displayed as a stack of sheets." "In this way, the
interface [...] permits a user to directly manipulate the sheets in the
notebook metaphor" [@glaser_graphical_1995]. The user is meant to handle the
metaphor in all of the above examples. The metaphor structures the material
affordances of the simulation according to the rules of the physical world.

Metaphor machines present us with a special case of conceptual domain
blending. In the cognitive view, the metaphor performs a number of
"conventional mapping from one domain to another" [@lakoff_contemporary_1998,
239]. Lakoff mentions for example the common trope of "a state is a person,"
implicit in the ideas of a "friendly" or a "hostile" states
[@lakoff_contemporary_1998, 243]. In this way ideas about agency, emotion, and
mental life usually attached to people can be extended to state actors.
Similarly, to say that someone is "boiling mad," instantiates the common trope
of "anger is a hot liquid in a container." In this case, common known
properties attached to the domain of physics can be mapped onto the domain of
emotion. Lakoff further explains that such domain mappings tend follow a few
rules. They are usually partial and asymmetrical. "Mappings are not
arbitrary," he writes, "but grounded in the body and in everyday experience
and knowledge." Finally domain mapping obeys what Lakoff call the Invariance
Principle, by which "the image schema structure of the source domain is
projected onto the target domain in a way that is consistent with inherent
target domain structure" [@turner_conceptual_1995; @lakoff_contemporary_1998;
@ruiz_de_mendoza_ibanez_nature_1998; @lakoff_invariance_2009].

The principles of metaphor-driven design contain an implicit model of
human--computer interaction. It implies that humans prefer to manipulate
digital information stored on computational media by the means of familiar
mediating structures---paragraphs, pages, files, and folders---associated
figuratively to the affordances of print media. We know, in other words, what
paragraphs, pages, files, and folders can do on paper and we would like for
digital paper to behave in a similar way. For example, one affordance of paper
is that it can be folded. It therefore becomes possible to "earmark" a page by
folding a corner. The fold enables subsequent recollection of read text. By
these means, a reader is able to mark a notable place in the text and to
return to it later quickly, if needed. The digital medium cannot physically be
folded in the same way because it offers a set of affordances that differ from
paper. But because readers are not familiar with "what can be done" digitally,
the affordances of digital media are presented through metaphor. Thus a
virtual "earmark" on a "page" can be made to represent a numerical pointer to
a specific address in the computer memory. And a "page" could stand for a
range of related addresses that correspond roughly to the information visible
on an analogous page in print. Similarly one "drops a folder into the trash
bin" or "drags and drops a file" or "bookmarks a page." Such metaphors rely on
habituated insight with one medium extended into another. We do not literally
"drag" or "drop" bits, but we use metaphors of paper and trashcan to help us
manipulate bits and bytes as if they were household objects. The metaphor
opens figurative possibilities. But it also obscures the actual physical
contingencies of interacting with bits and bytes, logic gates and magnetic
traces.

Bits and bytes differ from files and folders, pages and paragraphs in what
they can do. The affordances of the physical medium differ drastically from
affordances of the simulated one. The metaphorical substitution encourages
readers to extend the facility they have with manipulating one sort of media
(paper and ink) to another (screen and pixels). But what readers gain in
facility, they lose in critical faculty. Alienated from the actual physical
structures of information storage and retrieval, readers gain access to the
metaphor alone. Thus we "turn the page" but in reality redraw the screen. We
"highlight a passage" but in reality send information about the highlighted
passage to a data aggregation service. We "share a book" but in reality assign
a temporary license to another user. Where did the text go? someone asks when
downloading a paper from an online journal.[^ln4-nested] It is in your "home"
I answer. But unless one of us is familiar with the material contingencies of
file storage, neither has a mental map of any physical location corresponding
to the "home" directory, the default location of personal files on many
systems. When confronted with the actual affordances of digital text, the user
grasps for neutered metaphors. We "reside" in such homes, "own," "share," and
"create" only in the simulacrum.

The metaphors of human-computer interaction conceal the structure of
computation. Print offers a relatively static and stable medium for knowledge
transmission. Ink and paper do not change in transit. By contrast, the vessels
of computation are capable of altering the content dynamically. Imagine me
asking you to read Shakespeare's *Hamlet*, for example, by lending you a copy
of the text. In the case of a paper book, I may be sure that the text in my
hands will remain the same as I pass it into yours. But the computed sign also
has the capability to adjust itself to new contexts. For example, the
simulated *Hamlet* may adapt to the new reader's geographic location, mood, or
political affiliation. In fact, most texts we consume today come to us in such
computationally constructed way. The front page of the New York Times viewed
in Beijing will differ from the front page viewed in New York. The two "pages"
or "sites" are in some sense two completely different texts. But in another
sense, the "front page" identifies the same location of the same text, in two
diverging and dynamically composed versions. They feed off of the same
sources. The same source code gives rise to both texts.

Nothing is guaranteed in the passage of electronic text from one pair of hands
into another. Digital formatting expands its purview far beyond typographical
convention. The erasure of words, word substitution, automatic summarization,
wholesale generation of discourse by algorithmic means---the command and
control layer contains all such possibilities. What does it mean to read and
to interpret a dynamic text, which changes depending on its context? How can
literary analysis---close reading, philology, hermeneutics---persist without
the fixity of print?

The key to understanding "the loss of resemblances" that accompanies
ubiquitous simulation lies in the inner dynamics of metaphor machinery. A
functioning metaphor, if you would recall from Lakoff, is one which ferries
the schematic composition of one domain into another. Thus to say "life is a
stage" is to transpose something about theater onto life. In literary terms,
the theater is "tenor" where "life" is "vehicle" of the composite figure
[@richards_philosophy_1936]. Simulations work differently. Where a traditional
metaphor structure crosses several domains, the simulation substitutes the
"signs of the real for the real" [@baudrillard_simulacra_1994, 2]. It is a
subtle difference that engenders not-so-subtle effects. For example, it is one
thing to say "you are the apple of my eye" and quite another to actually
confuse apples for eye pupils. Baudrillard gives the example of a map that no
longer corresponds to any territory. He calls such a condition of pure
simulation without a referent *hyper-reality*. We expect a simulation to
attain a measure of correspondence between representation and the thing being
represented. For example, in theory, a weather simulation should be capable of
modeling observed meteorological conditions. But would it be a weather
simulation if the model was broken in some way, or, in the extreme, if it had
no correspondence to the physics of clouds, wind, and water? The hyper-real
breaks further still by usurping the underlying reality. The model does not
merely obscure, it takes place of the thing being modeled. In other words, it
begins to simulate itself, according to its own rules. The simulation no
longer corresponds to any situation "on the ground." Severed from its
referent, the symbol itself attains the status of reality. Thus hyper-reality:
a symbol that folds onto itself. It is a weather simulation confused for
weather.

The interface metaphor similarly exchanges one referent for another.
Simulation should, by definition, "assume a form resembling that of something
else" [@_simulation_2015]. Metaphor machines assume the form of one thing,
while structuring another. To drag and drop a document into a trashcan on the
screen, for example, should in theory correspond to an analogous set of of
data manipulations on the disk. Yet, "discarding a file" in this manner does
not necessarily include deletion of data from the storage medium, as expected.
The representation of the document may disappear visually where the
inscription endures. Such "loss of resemblances" could be insignificant. Does
one care if the file was actually deleted or not when performing deletion?
Perhaps not in many cases. But in some cases, when it really matters---under
the threat of censorship or persecution, for example---the incongruence
exposes the frailty of our alienation from the material contexts of digital
knowledge production. Our grasp on the medium weakens the more convincing the
simulacrum.

Consider the commonplace task of "turning pages" in the act of writing or
reading digital texts. In cognitive linguistic terms, the idea of paper pages
should somehow extend into the domain of manipulating digital information. In
literary terms, the projection of a page on the screen carries the tenor of
paper pagination. In this way, the turning of simulated pages implies a
certain familiar arrangement of matter. Readers know what to do with paper
pages. They understand its affordances. The metaphor encourages readers to
extend their knowledge of the physical world into the projected, virtual
world. For example, paper pages can be turned. We know they usually proceed
one another, sequentially. And we are attuned to expect the same attributes to
hold true in the vehicle---the domain receiving the tenor of the metaphor.
The action of turning virtual pages should, in theory, set off a series of
corresponding actions in the target digital domain. In other words, turning
the page on the screen should correspond to a similar action on the disk. But
the action does necessarily meet our expectations. The arrangement of
information stored on the disk affords different physical actions from the
arrangement of information on a page. For example, an English-language
character on the disk occupies eight bits on a disk where a print character
occupies one. The disk can tolerate millions of rewrites, where the paper
medium wears out after only a few. The paper inscription is visible to the
naked eye where the digital inscription is not.

The simulation is necessary perhaps, because the reading and writing of
digital data can involve processes far outside of everyday experience. For
example, in reading data from solid state (FLASH) memory a circuit imparts
electrical charge through quantum tunneling onto a connected series of
floating gate transistors [@pavan_flash_1997; @bez_introduction_2003].

!["Perspective view of a portion of a charge translating device illustrating a
preferred electrical contact arrangement." From
[@boyle_information_1974].](images/floating-gate.png)

Whatever the complexities of solid state storage architecture, the difference
in arrangement of information between pages and floating gates---at the root
of modern "sold state" storage---is apparent. The structure of one has only an
arbitrary connection to the structure of the other. Consequently change in the
structure of one domain do not necessitate changes in the structure of
another: to "erase a word" on a projected, virtual page thus may not have the
corresponding effect on the level of the storage medium. The information may
persist despite the intended erasure. As dwellers of simulated worlds, we hope
that the analogy between paper and pixel achieves a level of verisimilitude.
Turning the page or erasing a word on the screen should do something similar
on the disk. But we also know that not to be the case. The metaphor is broken
similar to Baudrillard's map that no longer reflects any terrain. The
computational metaphor simulates the familiar but absent affordances tied to
an absent print artifact. The simulation suggests a structuring of one kind,
while enacting a structure of another.

### 1.2 Death of a Metaphor

In poetics, a metaphor is said to be "motivated" when a set of concepts from
one domain extends into another to produce insight [@lakoff_contemporary_1998,
210-1]. Lakoff explains that to say something like "to spin one's wheels" when
referring to someone who is thinking is to apply the reader's knowledge of
automobiles to the mental realm. The speaker may hold a notion that spinning
wheels waste energy without moving the car forward. The metaphor suggests that
something like that is happening mentally as well [@lakoff_contemporary_1998,
211]. A metaphor in a figurative genre like prose or poetry works similarly by
suggesting novel and hitherto unexplored connections between domains. In his
influential essay on metaphor the English literary critic I.A. Richards
explained that "when we use metaphor we have two thoughts of different things
active together and supported by a single word, or phrase, whose meaning is a
resultant of their interaction" [@richards_philosophy_1936, 95]. Richards's
radical contribution to the study of metaphor lay in the observation that
metaphor operates in language, thought, and action ubiquitously. It does not,
as previously thought, exist merely in the realm of poetic language. Thought
in itself, Richards believed, is metaphoric in that the mind continually
searches for patterns and comparisons [@richards_philosophy_1936, 94]. The
motivated metaphor produces novel insight: a tool to explore and to make sense
of the world.

Some metaphors are, in this way, more productive than others. The poetic use
of the metaphor does not merely carry meaning across known domains, it
produces new and unexpected connections between them. To this effect, Richards
cites the poet Percy Shelley who wrote the following in defence of poetry:

> [poetic] language is vitally metaphorical; that is, it marks the before
> unapprehended relations of things and perpetuates their apprehension, until
> the words which represent them, become, through time, signs for portions or
> classes of thoughts instead of pictures of integral thoughts; and then if no
> new poets should arise to create afresh the associations which have been
> thus disorganized, language will be dead to all the nobler purposes of human
> intercourse [@shelley_essays_1840].

Shelley anticipated what the cognitive school of metaphor theory was to
confirm by empirical means more than a century later [@mojtabai_delusion_2000;
@billig_metaphor_2005]. Metaphors do not "die" as such. They continue to live,
but also become naturalized: that is understood literally. They create
connections that with time become habituated and invisible to their users. In
other words, taken for literal truth, the metaphor loses its metaphoric
quality. For example, for many readers the very idea of a "dead metaphor"
itself may no longer evoke death as such. Perhaps they understand the "death"
of the "dead metaphors" to function synonymously with "conventional" or
"idiomatic metaphors."[^ln4-dead] In Shelley view, such metaphors are destined
to become dead and habituated only to be reborn again in poetry. At its most
generative stage, the metaphor actively produces new meaning. The creative
juxtaposition between two as before unrelated domains brings new aspects of
experience to light. But with time, the poetic metaphor becomes a tired
cliché. It longer "perpetuates understanding." It dies in a sense of becoming
a mere shortcut to understanding. In Viktor Shklovsky's words, we "cease to
experience" the trope. The metaphor "dries up" when we begin recognizing it
without apprehension [@shklovsky_voskreshenie_1914]. It no longer generates
new connection between domains, but merely reinforces existing ones. In Vilem
Flusser's words, habituated idiom proceeds smoothly, giving us no pause,
without bumps or interruptions [@flusser_freedom_2003, 13 and 82].

Lakoff famously took exception with the idea of dead metaphors, arguing that
even those metaphors that are thoroughly habituated still play a vital part in
structuring everyday experience. He gave the example of the sentence: *He
still can't quite grasp the basic ideas of quantum mechanics*. Grasping in
this case is used as a synonym to "understanding." It indicates a transference
of properties between physical action (grasping) and mental action
(understanding). Despite being a cliché, the metaphor is alive according to
Lakoff, because it continues to perform a function, giving a name to a mental
activity that we would otherwise find difficult to explain precisely. Such a
metaphor is more alive than other, perhaps more novel, "one off" poetic
metaphors that failed to become cultural tropes. Shelly's and Shklovsky's
ideal poetic metaphors works once and never again. Their value lies in their
novelty. Lakoff's everyday metaphor is not new, but it is vital precisely
because it is used widely. It continues to bridge domains productively.

A truly dead metaphor for Lakoff is one in which the original source image no
longer makes sense. He gives the example of the English word *pedigree*, which
originally referred to the French for "crane's foot," or *pied de grue*. The
foot was used as a typographical flourish to decorate centuries-old
family-tree diagrams. In the previous example, when we spoke of the
metaphorical "grasping" of ideas, both sides of the domain transference were
readily available us. We understood something about grasping things and
extended it to the capacity of the mind to take hold of ideas. By contrast,
the *pied de grue* contained within the English *pedigree* is no longer
accessible to the average speaker. In the first case the metaphor is merely
tired, where it is completely dead in the other. In use, naturalized metaphors
like "grasping" and "pedigree" lose their symbolic connotations. But unlike
"pedigree," the metaphorical nature of "grasping ideas" is at least available
for casual interpretation. The underlying metaphor THE MIND IS LIKE A HAND
generates other meaningful phrases like "you have to let go of this idea." The
crane's foot does not. The conventional notion of dead metaphors does not
appropriately differentiate between the two cases [@lakoff_death_1987;
@muller_metaphors_2008]. The metaphor sometimes "dies" but continues to
perform its function of intuitively connecting two disparate domains. At other
times, the metaphor dies in the sense of one domain becoming no longer
accessible to its user. Furthermore, we might add that a wholly unmotivated
metaphor does no work at all. Thus the nonsensical riddle the Mad Hatter
famously posed to Alice in Lewis Carroll's *Alice in Wonderland*: How is a
raven like a writing desk? The dissimilarity between the two domains---of
animals and furniture---prevents any productive congruence.[^ln4-carroll] No
domain mapping happens between ravens and writing desks. Thus, not having been
born, the metaphor dies in yet another sense.

To what extent does the interface metaphor live by the above definitions? When
discarding a document into a trash bin, in our reoccurring example, users
should theoretically map their knowledge of paper documents and paper waste
baskets onto the computational domain. Instead, the *idea* of discarding
something substitutes for the *material reality* of the corresponding action.
The concept blends not with another conceptual domain but with the material
affordances of the target medium. Such material affordances---our ability to
actually discard data, for example---stand in arbitrary relationship to the
source domain. Simply put, we expect the thing to be deleted, but it is not.
The incongruence breaks Lakoff's Invariance Principle. Whatever structural
changes we expect to happen in the source domain do not carry on to the
target. The metaphor breaks almost as badly as the transference between desks
and ravens. The appearance of taking out the trash without the corresponding
erasure of data becomes a dead metaphor even under Lakoff's strict
definitions.

As was the case with the "crane's foot" in the English "pedigree," the user of
the simulated document dustbin is missing one part of the metaphor equation.
Where in the case of "pedigree" English speakers fail to grasp the source or
the tenor of the metaphoric substitution, the case of the virtual dustbin is
missing the target, or the vehicle of the action. Discarding a document into
trash does not in fact correspond to a similar action in the target domain.
In either case, failing the full transference the metaphor ceases to function
properly [@lakoff_death_1987]. The interface metaphor fails to achieve
motivation. The analogy between discarding paper and erasing bits breaks down
in the worst possible way. The material realities of the metaphor are not
simply missing, they are misrepresented.

### 1.3 Mimesis (Direct Manipulation)

"An interface is by nature a form of artistic imitation: a *mimesis*," Brenda
Laurel wrote in her seminal 1984 essay "Interface as Mimesis." She went on to
write that "if designing interfaces feels like painting on cave walls by
flickering torchlight, it is only because we, the designers, have not availed
ourselves of better illumination: the science of the mimetic arts, poetics"
[@laurel_brenda_interface_1986, 67]. Laurel, who started her academic career
in theater studies, went on to work for companies like Apple, Activision,
Atari, and Sun Microsystems. Her work, cited in more than 120 technical
patents, reminds us of the close link between poetics and the design of
human--computer interaction. It is all the more important today, as immersive
computational environments begin to structure experience beyond the merely
instrumental. Computers mediate in the interface between the public and the
private, between art and politics, and between forces of capital and control.
The simulacrum requires that we advance a reflective "science of the mimetic
arts" lest we we lose a sense of what Michail Taussig has called the space
ulterior to mimesis [@taussig_mimesis_1993, 129-144]. In other words, the
suspension of disbelief must remain, as it was in Samuel Coleridge's original
formulation, a *willful* act, containing further a "semblance of truth"
required to animate the shadows of imagination [@coleridge_biographia_1917,
6-7]. An involuntary or worse yet forced suspension of disbelief can only lead
to a total critical disempowerment.

Before the 1980s, the dominant paradigm of interacting with machines was the
dialog [@shaw_joss:_1964; @cameron_dialog:_1967; @gaines_timesharing_1986;
@martin_computerized_1970; @martin_design_1973]. Already in 1950, Turing
imagined a conversation between a critic and an artificially intelligent poet:

```
Interrogator: In the first line of your sonnet which reads "Shall I compare
thee to a summer's day," would not "a spring day" do as well or better?

Witness: It wouldn't scan.

Interrogator: How about "a winter's day," That would scan all right.

Witness: Yes, but nobody wants to be compared to a winter's day.

Interrogator: Would you say Mr. Pickwick reminded you of Christmas?

Witness: In a way.

Interrogator: Yet Christmas is a winter's day, and I do not think Mr. Pickwick
would mind the comparison.

Witness: I don't think you're serious. By a winter's day one means a typical
winter's day, rather than a special one like Christmas
[@turing_computing_1950].
```

The goal of conversational programming was to provide a similarly naturalized
dialog between the operator and the machine. Although machine understanding of
informal speech human did not come to fore until the twenty-first century,
interactive computing environments like DIALOG and JOSS attempted to abstract
away from machine language towards interfaces that understood a limited number
of English words. JOSS, an experimental on-line computing system created by
the RAND corporation in 1963, consisted of a typewriter connected to the
JOHNNIAC computer. Prior to JOSS, programmers would interact with the JOHNNIAC
machine via keyboard and punch card, initially using octal number notation and
then binary assembler language [@gruenberger_history_1979]. These methods of
programming were time consuming and prone to error. "An octal desk calculator
was nice to have," a historian of the system would later quip
[@gruenberger_history_1979, 58]. The JOSS experiment was meant to introduce a
kind of an interpreter that sat between the human operator and the machine,
facilitating communication in a friendly, English-like language. Think of JOSS
as the "user's computing aide and a single contact with the computer," the
engineers wrote [@shaw_joss:_1964, 456]. Instead of feeding punch cards into
the machine, the operator would now use a standard typewriter. Instead of
flipping switches the operator typed words. JOSS thus referred both to the
"simple language" for machine instruction and to this new "remote console" way
of interacting with the computer. JOSS and the user would "take turns
controlling the typewriter" in the words of the documentation. The
computerized aide understood simple commands like `do`, `go`, and `type`.
Given a number of predetermined commands, it would attempt to respond with a
result. When confused, or when given an unfamiliar command, its default for an
unspecified error mimicked human confusion: "Eh" [@shaw_joss:_1964]?

This mode of conversational interaction was captured also in one of the
earliest text adventure games, the *Colossal Cave Adventure*, designed by Will
Crowther in 1975 [@montfort_twisty_2003]. The following dialog illustrates the
call-and-response game play typical of the genre:

```
You are standing at the end of a road before a small brick building. Around
you is a forest. A small stream flows out of the building and down a gully.

> enter
You are inside a building, a well house for a large spring. There are some
keys on the ground here. There is a shiny brass lamp nearby. There is food
here. There is a bottle of water here.

> get keys
OK

>get lamp
OK

>exit
You're at end of road again.
```

Although much more accessible and interactive than communication in octal or
binary machine code, the conversational model posed several significant
downsides. While resembling human communication, it in fact utilized only a
limited vocabulary. Researchers from the U.S. Air Force academy would later
write:

> The lower cost of computer access and the proliferation of on-line systems
produced a new breed of users, people whose expertise was in some area other
than computer technology. As their initial fascination with conversational
computing wore off, users reported experiencing feelings of intense
frustration and of being "manipulated" by a seemingly unyielding, rigid,
intolerant dialogue partner [@walther_-line_1974, 379;
@gaines_timesharing_1986, 15].

By the 1980s, a new breed of metaphorical interfaces gained widespread
prominence. If *Colossal Cave Adventure* epitomized the conversational model
of computing, games like the early but popular *Pong*, *Space Invaders*, and
*Donkey Kong* epitomized the paradigm of "direct manipulation." According to
Ben Shneiderman, the researcher who coined the term in 1982, direct
manipulation involved three key principles:

1. Continuous representation of the object of interest.
2. Physical actions or labelled button presses instead of complex syntax.
3. Rapid incremental reversible operations whose impact on the object of
interest is immediately visible [@shneiderman_future_1982, 251;
@hutchins_direct_1986, 91].

The goal of direct manipulation was therefore to achieve a perfect
correspondence between "representation" and the "object of interest."
Shneiderman sites Leibniz in reference to symbolic notation, which in theory
should also "express the exact nature of a thing briefly and, as it were,
picture it." For Leibniz, the symbol, an exact and portable picture of an
idea, could subsequently diminish the mental effort required for abstract
thought, leading to a "great advantage for discovery"
[@shneiderman_direct_1983, 57]. Thus, the calculus of Leibniz and his notation
for infinitely small and infinitely large numbers---ideas that would not fit
on the page or in the mind otherwise, without compact representation
[@cajori_history_1923; @thurston_leibnizs_1973; @grabiner_is_1974]. For
Shneiderman and others, a computer game like *Pong* provided the paradigmatic
example for direct symbolic manipulation. When playing, the player would
control a virtual table-tennis paddle by rotating rotate a physical knob on
gaming console. The movement of the physical knob corresponded directly to the
movement of the paddle---clockwise for up and counter-clockwise for
down---thus achieving the correspondence between "operation" and the "impact
on the object of interest" [@shneiderman_direct_1983, 60].

By contrast, the conversational model of human--computer interaction was
plagued (in their view) by what researchers considered an arbitrary, symbolic
relationship of the sign to its signifier. In this way, when using *EMACS*, a
text editor commonly found on UNIX systems of the time, one would enter the
command `k` in combination with other keys to delete or to "kill" a file,
where on other systems, Shneiderman complains, `k` stood for "keep a file,"
the opposite from killing it as one would expect [@shneiderman_direct_1983,
65]. In the conversational model, the command stood in an arbitrary
relationship to the intended effect, where in the direct manipulation model
something like the knob and the movement of the paddle related mimetically. To
be more precise, the direct manipulation paradigm advocated for an "iconic"
relationship between representation and the object of interest
[@norman_user_1986, 110]. Like onomatopoetic words, the movement of the knob
resembles the movement of the thing it represents.  Edwin Hutchins, Donald
Norman, and James Hollan write: "There is an economy here in that the user's
knowledge of the structure of the surface acoustical form has a non-arbitrary
relationship to meaning [...] The same sort of thing can be done in the design
of interface languages" [@norman_cognitive_1991, 123]. An iconic image
requires no explanation. It is intuitive. Instead of searching for the right
command the user relies on the habituated affordances of real-world
objects---table tennis paddles and paper trashcans---to manipulate virtual
objects---computer games and file systems.

Crucially, the full immersion in the "mimetic context" of the virtual object
could elicit the "suspension of disbelief" [@laurel_brenda_interface_1986,
76]. In use, the metaphor machine fades from view. This in opposition to the
now often-repeated Heideggerian insight into the nature of tool use. If the
reader would recall, in *Being and Time*, Heidegger writes about the
particular *handiness* of a tool, like a hammer. He writes, "the less we stare
at the thing [...] the more actively we use it, the more original our relation
to it becomes and the more undisguisedly it is encountered as what it is, a
useful thing" [@heidegger_being_1996, 65]. For Heidegger, there was no way to
understand a tool like a hammer theoretically, by detached reflection. One
must understand it through use, in what he called *circumspection*
[*Umsicht*]---the awareness of the object ready-to-hand [*zuhanden*]
[@heidegger_sein_1967, 69]. Through use a hammer comes into peripheral vision,
"its own kind of seeing" [@heidegger_being_1996, 65].  The metaphoric device
frustrates the Heideggerian intuition about tools like hammers, planes, and
needles. At hand, the device takes shape as a keyboard, a mouse, or a touch
screen. But in the mind, as a simulation, it dissembles to behave like a page,
a folder, or a wastepaper bin. The tool---a keyboard or a touch screen---is
not encountered for what it is. Nor does simulated tool produce a special kind
of knowledge of the sort elicited through mastery over actual instruments.

Instead, the explicit function of the simulation is to obscure the mediated
nature of the virtual experience and to manufacture an "interactive mimesis,"
in what Laurel and others call "first personness," the experience of "directly
living and acting within the world established by the computer"
[@norman_user_1986, 490-1]. Hutchins, Hollan, and Norman write: "when an
interface presents world of action rather than a language of description,
manipulating a representation can have the same effects and the same feel as
manipulating the thing being represented" [@hutchins_direct_1986, 98-99].
Similar to Heidegger's distinction between practice and theory, the theorists
of direct manipulation make a distinction between action and description. But
unlike Heidegger, who is thinking about tools at hand, direct manipulation
theory imagines the handling of representations. The actual instrument
enabling the manipulating of image or word on the screen is supposed to
disappear entirely, giving rise to the immersive, interactive, first-person
experience *without mediation*. "The user of a well-designed *model world*
interface can willfully suspend disbelief that the objects depicted are
artifacts of some program and can thereby directly engage the world of the
objects," the authors write [@hutchins_direct_1986, 99]. In this view, the
dialogic model of tool use encouraged by *Colossal Cave Adventure*---get keys,
get lamp---amounts to nothing more than just "using the computer"
[@laurel_brenda_interface_1986, 74]. "End users are not interested in *making*
representations," Laurel writes. "They want to move around *inside* one,"
favoring the mimetic context over their actual, physical surroundings
[@laurel_brenda_interface_1986, 75]. Verbal representations, like "get keys"
or "get lamp," puncture the first-person illusion. By contrast, the fully
immersive modeled world should support the "sensation of directness," in which
direct, iconic expressions "behave in such a way that a user can assume that
they, in some sense, *are* the things they refer to" [@hutchins_direct_1986,
110].

![Direct manipulation of simulated objects. [@minsky_manipulating_1984,
199]](images/minsky.png)

!["ViewPoint screen image." On screen menus for the Xerox 6085 Daybreak
workstation, 1985 [@johnson_xerox_1989, 13].](images/xerox_star.png)

The principles of direct interaction stood against what Laurel called the
"ill-formed" presence of the mediator, like JOSS in the examples above, or
like the command prompt in the *Colossal Cave Adventure*. The computerized
aide attempts to arbitrate mediate between the human and the machine, where
humans earn the unmediated "pleasure" and "catharsis" of direct engagement
[@laurel_brenda_interface_1986, 75]. The intermediary takes the place of the
player in a game: it swings the sword for her, takes a beating, and reports on
the experience. Laurel writes:

> In the file management example, the intermediary takes the form of command
menus that are invoked in order to activate processes in the program that will
create the desired results. The user does not have the experience of pushing
files around, stowing them and grabbing them, or blowing them away. Instead,
the user has the experience of communicating with the file management
intermediary [@laurel_brenda_interface_1986, 75].

Combined, the ideas behind cognitive domain blending and direct manipulation
gave rise to the now ubiquitous WYSIWYG (what you see is what you get)
interfaces, put into mass production by Apple, Xerox, and other companies in
the early- to mid-1980s. The Xerox 8010 Star workstation introduced in 1981
and the Xerox 6085 Daybreak workstation, introduced in 1985, heralded the era
of accessible, metaphor-driven personal computing, characterized by the use of
virtual graphical objects like windows, icons, desktops, folders, and buttons.
The Star and Daybreak workstations were some of the earliest machines to put
the principles of domain blending and direct manipulation into action. The
interface was meant to "reveal the structure" of the simulated objects
intuitively, without training or lengthy written explanation. In Laurel's
words, the mimetic interface employed "logic and aesthetics to create
representations that *engage humans in pleasurable ways"
[@laurel_brenda_interface_1986, 85].  The mimetic context is simply "the
experience we desire," Laurel wrote. Direct participation enables actors to
experience "the full pleasure of the mimetic form"
[@laurel_brenda_interface_1986, 75].

Designers advocating for direct manipulation understood the trade-offs that
came with an emphasis on such immersive and mimetic experiences
[@hutchins_direct_1986, 118]. Mimesis fundamentally relies on the user's
familiarity with the source domain. In this way, we understand what to do with
"folder" icons because we know how folders behave in real life. Direct mimetic
manipulation does not however tell us anything new about the capabilities of
virtual folders. Immersion precludes critical reflection beyond the
pre-defined confines of the modeled world. The user has access to no more than
the simulated experience allows and can provide. More problematically, the
ideas behind mimetic immersion contain a kind of a logical fallacy. The
literature on direct manipulation often refers to the example of driving a car
to illustrate the type of an interface by which inputs and outputs are
directly correlated. Thus instead of giving complicated commands to the
vehicle, the drivers turns the wheel to the right, and the car immediately
follows. A direct causal link exists between the steering wheel and the car's
axle. Similarly, when operating a computer game like *Space Invaders* via a
joystick, the player experiences an immediate correspondence between the
movement of the controlling mechanism and the movement of the
player-controlled space ship on the screen.

Writers attempting to delete sensitive information by dragging and dropping an
icon of a document to the icon of a trash stand in a relationship to the
object of their interest unlike drivers or video game players. The car is the
"direct object of interest" for a driver, just like the virtual space ship is
for a gamer. But in our example, authors are not interested in the virtual
representation of the document slated for erasure. The object of their
interest is not mimetic. They would like to erase the document itself, located
somewhere within the machine. In many cases like these, the inhabitants of the
virtual world have an interest in objects outside of it. The paradigm of
direct manipulation instead veils the object from view, suspending the rules
of material interaction in favor of the virtual. Far from being direct, the
iconic representation of the document---the image of a file---usurps the
physical object---the file itself. Where in the conversational paradigm the
nature of the mediation was at hand, open to circumspection, in the direct
manipulation paradigm the simulacrum occludes the very nature of the
simulation.

### 1.4 Speculative Formalism

In his 1949 paper on "The Genesis and Speed of Telegraph Codes," Frank
Halstead noted that "the practical upper limits of [telegraph transmission]
speed will also be limited by the ability of some human beings to operate a
keyboard, until such time as electrical connection be made direct with the
receiver's central nervous system" [@halstead_genesis_1949, 451]. The history
of human--computer interaction began with the manipulation of physical
switches, first by hand and then by removable storage media like paper tape
and punch card. The next phase was dialogic and conversational in nature.
Conversational computing introduced the idea of a mediating agent, an
interpreter, who could translate from a limited number of natural human
language commands into the specialized vocabulary of signals that could alter
the machine configuration. The "direct manipulation" school of human--computer
interaction has led us further towards mimesis, simulating machine states as
virtual environments resembling real-world objects and their properties.

The trajectory from direct *physical* manipulation to direct *virtual*
manipulation leads to the totalizing loss of resemblances and designations. At
its logical extreme, the simulacrum supplants the thing being simulated. It
appears as hyper-reality, the experience of direct and unmediated interaction
without awareness of the underlying referent. All "objects of interest" within
such a modeled world are fabricated objects. They are thus limited to the
external artificial constraints imposed by their makers. Such manufactured
experiences present us, the "users," with compelling, cathartic even,
metaphors. The metaphors extend far beyond entertainment: subsuming all
spheres of social activity mediated by computers. The manipulation of
metaphors---a reflective, not merely circumspect inhabitance of virtual
worlds---therefore requires not just a willing suspension of disbelief, but
also poetics: hermeneutics, close reading, distant reading, deconstruction,
trope analysis, in short precisely the legacy of interpretive practice that
stretches from Aristotle to Susan Sontag and beyond. The suspension of
disbelief otherwise threatens to become a permanent condition, disempowering
as it is pleasurable or cathartic.

At the time of writing this book, our society stands at the threshold of a new
paradigm of interacting with computers and hence with each other.  Direct
brain to computer interfaces are common enough today to be turned into a
toy.[^ln3-mindflex] Early brain--computer interfaces used either imprecise
"noisy" electroencephalographic (EEG) scalp sensors or electrode implants that
required invasive surgery. In 2004 a team of scientists developed a way of
controlling "a one-dimensional computer cursor rapidly and accurately" using
electrocorticographic (ECoG) activity recorded from the surface of the brain
[@leuthardt_braincomputer_2004; @miller_spectral_2007]. And in 2015, a
quadriplegic woman piloted an F-35 Joint Strike Fighter using her brain in a
simulation developed by the University of Pittsburgh's Human Engineering
Research Laboratories in collaboration with the Defense Advanced Research
Projects Agency (DARPA) [@collinger_collaborative_2014; @prabhakar_how_2015].
At the surface, the advance of brain--computer interfaces seems to bring us
closer to the vision of increasing directness: no interface, interaction
between people and machines without intermediary symbols, words, or images.
Military applications aside, we must prepare for a future in affective arts,
the ultimate loss of references and resemblances: literature without
representation, painting without figure, message without sign.

However futuristic such possibilities may seem to us today, brain to computer
and subsequently brain to computer to brain interfaces should be considered in
the context of the long history of brain-to-brain interfaces, routinely
mediated by paper, ink, code, and silicon. Media intercedes. But as
technological dreams become reality they also grow less interesting and more
mundane. Habituation smoothes the rough edges of irreconcilability. The tool
recedes from view and begins to seem like a natural and direct extension of
the body. The goal of computational poetics is to denaturalize the encounter,
to bring the receding media to light, and to expose the mediating systems
supporting the simulation. A measure of discomfort in the fit between bodies
and screens ensures our ability to structure the encounter on our own terms
and to opt out when needed. My concern is not with the metaphysical
entailments of a possible post-human future. The illusion of directness rather
conceals the very human mechanisms of command and control. The simulation is
ultimately a power structure and an economy of exchange between physical and
mental resources.

The above comments apply to computation generally. We will spend the following
chapters peeling apart the layers of the literary and the bibliographic
simulation in particular. Once the electronic book can be perceived as
computation in kind, we can begin to examine the incongruence in the
structures of meaning-making at the sites of storage and projection. If we
consider "what you see is what you get" as a type of a promise, the following
chapters will help us understand the ways of seeing and the material
particulates of getting. The electronic book shall come to fore as a literary

<!-- notes -->
<!-- notes -->
<!-- notes -->

[^ln4-nested]: The notion of "digital text" itself is a metaphor. Files do not
really hold texts. The idea of "text" identifies a segment of stored memory
coupled with control codes that govern layout and projection in specific
material context. Together, these diverse signals and physical affordances
create the illusion of a single text.

[^ln4-carroll]: @carroll_annotated_1960, 55. See @huxley_raven_1976 and
@susina_why_2001 for a range of possible answers, including Carroll's own:
"Because it can produce a few notes, though they are very flat; and it is
nevar [sic] put with the wrong end in front" [@carroll_alices_1971, xv;
@susina_why_2001, 16-7].

[^ln4-dead]: For a book length summary on this very topic see
@muller_metaphors_2008.

[^ln3-mindflex]: The American toy giant Mattel makes a game called "Mindflex."
The Frequently Asked Questions page includes the following prompt: "Have you
ever dreamed of moving an object with the power of your mind? Mindflex Duel™
makes that dream a reality! Utilizing advanced Mindflex Duel™ technology, the
wireless headset reads your brainwave activity. Concentrate...and the ball
rises on a cushion of air! Relax...and the ball descends. It's literally mind
over matter!" (@mindflex_mindflex:_2015)
