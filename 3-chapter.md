---
title: "Plain Text: The Poetics of Human-Computer Interaction (Sample Chapters)"
subtitle: "Chapter 3: Solid States (Splitting the Sign)"
author: "Dennis Tenen"
style: csl/chicago-note.csl
bibliography: plain-text.bib
toc: true
documentclass: article
cover-image: images/steno.png
header-includes:
- \usepackage{ftnxtra}
- \usepackage{titlesec}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \newcommand{\sectionbreak}{\clearpage}
- \rhead{DRAFT | do not circulate }
- \lhead{}

---

Tie to the first two chapters. Easy multiplicity of documents.
Bring in Trilling? Digitality as something imposed from without or imposed on
us! Because the book is different it fucks with authenticity.

The possibility of text that reconfigures itself.

# Chapter 2: Solid States

The bifurcated sign resides in two distinct locations, each entailing
drastically differing affordances for reading.

The long history of the word proceeds in stages, from the immutable sign to the
universal implement, capable of reproducing all symbolic representation
dynamically. The universal Turing machine culminates the development of the
symbol. Through it, the symbol gains its ideal form, capable of representing
everything that can be represented. All further symbolic engines constitute
lesser versions of the universal archetype.[^ln1-brain] Yet the archetype
machine itself is also limited to an ideal. It can only exist as a thought
experiment. All real-world Turing machines must contain non-representational
elements, dispelling the illusion of immateriality.

When viewed in the context of book history, the universal Turing machine
signifies a consummation of several broad, long-term trends that begin with the
invention of writing itself. The God of the Hebrew Bible etched his
commandments into stone (Exodus 34:1). Moses broke the first set of tablets,
but the word remained, for a time, immutable. The material history of literary
computing begins with petrified words that endure forever, and ends with word
as an electrical charge: animated, radiant, fluid, and iridescent
[@mcgann_radiant_2001; @bryant_fluid_2002].

Although much of contemporary popular discourse on computation speaks the
language of disruption, the history of computational symbolism, of the sort I
am suggesting here, must be seen as an evolutionary trajectory.

## 3.1 WYSINAWYG (What You See Is Not Always What You Get)

I do not trust the text appearing before my eyes. Wendy Hui Kyong Chun calls
magnetic storage the "enduring ephemeral," which "creates unforeseen
degenerative links between humans and machines" [@chun_enduring_2008, 148]. If
the floating gate transistor,[^ln1-gate] where my text now lives, can be called
the enduring ephemeral, I will call my liquid crystal display, where the text
shows itself, fading persistence. This is not to believe that text on the
screen lacks materiality. Not at all. Only that it seems to drift from surface
to surface, beyond the field of vision, in ways that erode trust in the general
permanence of the literary system. If we are destined to dwell on surfaces, I
do not know to which surface to attach my attention: the screen or the floating
gate.

I have before me at least two inscriptions: one as circuit state on my hard
drive, and another as crystal phase on the screen. They denote the same idea,
but in two distinct places. How did this duplicity come to be? And what impact
does it have on the life of a mind? In an attempt to answer, I offer the
following three historical preconditions for digital textuality. They are not
meant as history, but rather as signposts to mark the journey ahead. The schema
proceeds roughly as follows: first, content and control couple at the visible
surface of removable storage media (ticker tape and punch card); second,
inscription splits into input and output, retreating into magnetic storage to
reemerge at last on screen, in the same guise, but also, as we suspect, somehow
transformed: less solid and concealing something beneath the phantasmal shell
of its former appearance.[^ln1-denning]

Where does text reside? If you are reading this book in print, you can point to
the page and be fairly certain of the answer: here, on the page. If you are
reading the book on a *device*, things get more complicated. You can point to
the screen and yet it would not be enough to say that the text resides there.
The screen will go dark when the device loses power, but the text will
persevere within, stored at another physical location. Deep within a device,
the text will be embedded into some sort of a storage medium, usually a
magnetic or a "solid state" drive. Where the digital text resides affects even
those who prefer to read in print. Like most literature today, print materials
are also "born digital." At some point of time, they occupy the same
duplicitous position between storage medium and pixel.

The seeming immateriality of digital media entails real-world effects: the
costs of replication plummet, for example. Computational text can be copied
effortlessly, with minimal cost, and with near-perfect fidelity.
Hyper-reproducibility of the sort was unthinkable for most of the twentieth
century. The machine allows for rapid remediation. Lowered costs of copying
further reduce barriers to access and conveyance. Symbols that adhere lightly
to their medium are easy to store and to transport. Witness the rise of
massive, global public knowledge projects like online search engines and
encyclopedias as a direct consequence. Such projects unfold the logic of
immateriality, which moves towards totalizing archives and universal
accessibility.[^ln1-google] When representation appears to weigh nothing, one
imagines a weightless totality of all representation, available immediately and
everywhere. The perceived weightlessness of text has other side-effects as
well. For example, a text that adheres lightly to its medium is also difficult
to contain, making onerous the governance of symbolic representation and
weakening traditional controls like censorship and intellectual property
rights.

Yet, despite the appearances, the sign does not and cannot exist in a vacuum.
Rather, the symbol splits in two: with one half arising visibly, a weightless
and apparent screen simulation, and the other half, opaque, etched into the
hefty and hidden material contingencies of the device.

Thus when when Michael Heim refers to the "ephemeral quality" of the electronic
text or when Pamela McCorduck describes it as "impermanent, flimsy, malleable,
[and] contingent" they are both identifying real-world technological
affordances of simulated screen textuality [@mccorduck_universal_1985, 51;
@heim_electric_1987, 211]. McCorduck tells the story of a rabbinate court,
which, when faced with the law prohibiting observant Jews from erasing God's
name, rule that words on "screens, disks, and tapes" are not to be considered
as writing, therefore sanctioning erasure [@mccorduck_universal_1985, 51; also
quoted @heim_electric_1987, 192]. Other technological and legal fictions rise
to restore a measure of "stickiness" to electronic media. For example,
manufacturers commonly embed digital rights management circuits into video
streaming devices to artificially limit the duplication of broadcast material.
Similarly, electronic book sellers usually disable the reader's ability to copy
and paste from the material. Such measures mimic some of the constraints
associated with static, paper-and-ink media regimes.

When scholars like Johnna Drucker, Katherine Hayles, and Matthew Kirschenbaum
respond to Heim and company with hardened materialism, they are also rightly
identifying actual properties of electronic text. But the two camps speak
neither of the same phenomenon nor at the same site. The former group points to
the screen as the impermanent and ephemeral state of the written word: like
tomatoes suspended in aspic, writes Heim [@heim_electric_1987, ix]. The latter
points instead to the "uniquely indelible nature of magnetic storage"
[@kirschenbaum_mechanisms_2008], to "drives, tapes, and disks" as the
"fundamental physical support" and "material substrates of computing"
[@drucker_performative_2013]. Both locations, the screen and the disk, are
real. Neither can be reduced to the other. Both contain distinct constraints
and affordances for action.

The material substrates of computational text likewise carry real-world
affordances and consequences. They are first and foremost hidden from view.
Drives and tapes reside inside of black or aluminum boxes. If only because they
carry electrical current and have the potential to catch fire, they are
regulated. They contain heavy and rare metals, often hazardous if touched or
ingested. The computational part of the sign is sealed in miniaturized
containers that prevent access and to resist tempering. These are but some of
the realities of material text. It is text intertwined with machine internals
and control code and it is often hermeneutically sealed to resist human
interpretation.

Few readers today will be able to give an account of a pixel's passage from
keystroke to ink or pixel. The vast machinery that brings literature to life
hides from the reader's view. Literature conceals. Even on the level of
stylistics, writing well is meant to evoke a sense of ease where it is usually
the product of painstaking labor. Let us hold on to that intuition for the
duration of this chapter: writing conceals labor.

I want to foreshadow now what will become the punchline of the whole book:
namely that the ghost in the machine cannot be reduced to some vague notions of
value---these amount to a distraction, which lies plainly upon the surface. The
conspicuous ghostly apparition (indicating the absence of a living subject) is
agency itself, which, for now, necrotically attaches itself to dead things like
systems, mediums, and automated discourses. If all this talk of value, ghosts,
and necromancy sounds familiar, the reader will not be surprised when I advance
Karl Marx as a preeminent theorist of the algorithm and someone able to help us
reason through Kittler's computational conundrum. On towards Marx then (who
will appear much later), through the machine that, although intimately familiar
to every writer and consumer of text by touch, remains alien and alienating in
its hidden possibilities, soothing and threatening all at once.

[^ln1-translate]: "In our discussion of this text we have been using an
authoritative French translation of Plato, the one published by Guillaume Bude.
In the case of *Phaedrus*, the translation is by Leon Robin. We will continue to
refer to it, inserting Greek text in parenthesis [@derrida_dissemination_1981,
71]."

[^ln1-gurevich]: Kittler mistakingly attributes "Algorithms in the World of
Bounded Resources" to Brosl Hasslacher. The author is rather Yuri Gurevich,
Principle Researcher at Microsoft Research and then a professor at the
University of Michigan. Hasslacher's essay entitled "Beyond the Turing Machine"
appeared in the same volume of collected essays, @herken_universal_1988.

[^ln1-bottom]: For example, in the Open Systems Interconnection (OSI) model of
communication, the top-most layer of protocols and interface method is called
the "application layer" and the bottom-most layer the "physical layer"
[@peterson_computer_2007, 26-28]. Timothy Colburn and Gary Shute describe it as
being "responsible for encoding bits onto a transmission medium, whether wires,
fiber optics, or radio broadcast, in ways that maximize the transmission rate
and minimize sensitivity to noise [@colburn_abstraction_2007, 181].

[^ln1-abstraction]: This is a topic of some contention in the literature. In
his influential paper on the topic, James Moor includes the immateriality of
software as one of the "three myths" of computer science. "As a practical
matter, what we regard as computer instructions, and consequently what we
regard as computer programs, is determined by computers available," he writes
[@moor_three_1978, 215]. Nurbay Irmark argues that software is instead a purely
abstract artifact, akin to a musical work [@irmak_software_2012]. See also
@turner_programming_2013; @colburn_software_1999.

[^ln1-turing]: The intellectual history of the Turing machine is well
established, in multiple works on the subject. It follows the Greek Diophantus,
René Descartes, Georg Cantor, David Hilbert, Gottlob Frege, Bertrand Russell,
Kurt Gödel, Ludwig Wittgenstein [@petzold_annotated_2008;
@herken_universal_1988; @grattan-guinness_development_1981].

[^ln1-alt]: "We have to think (in a completely novel way) the relation between
a science and the ideology [...] the fact that such an investigation confronts
us with the observation that every science, in the relationship it has with
ideology it emerged from, can only be thought as a 'science of ideology, would
disconcert us, were we not forewarned of the name of the *object* of knowledge,
which can only exist in the form of ideology" [@althusser_reproduction_2014,
46].

[^ln1-derr]: See @derrida_writing_1978. I am alluding particularly to
statements like "ethnology-like any science-comes about within the element of
discourse," and "this moment was that in which language invaded the universal
problematic; that in which, in the absence of a center or origin, everything
became discourse-provided we can agree on this word-that is to say, when
everything became a system where the central signified, the original or
transcendental signified, is never absolutely present outside a system of
differences. The absence of the transcendental signified extends the domain and
the interplay of signification ad infinitum" (278-294).

[^ln1-flip]: There is a long-standing joke in Marxist literature that involves
flipping Hegel, who prioritized the transcendent spiritual over the physical
and material forms of life, over "back to his feet." See for example
@marx_marx-engels_1978: "The form of wood, for instance, is altered, by making
a table out of it. Yet, for all that, the table continues to be that common,
every-day thing, wood. But, so soon as it steps forth as a commodity, it is
changes into something transcendent. It not only stands with its feed on the
ground, but, in relation to all other commodities, it stands on its head, and
evolves out of its wooden brain grotesque ideas, far more wonderful than
'table-turning' ever was" (320). See also @engels_ludwig_1941: "Thereby the
dialectic of the concept itself became merely the conscious reflex of the
dialectical motion of the real world and the dialectic of Hegel was placed upon
its head; or rather, turned off its head, on which it was standing before, and
placed on its feet again" (44).


As we embark to explore the consequences of simulated text, I propose we keep
the following three landmark mechanisms in view as signpost along our journey:
Goldberg's Controller, the IBM MT/ST, and Engelbart's Time Fob. In the first of
these, text structure and machine control lie before us for inspection. The
second one is mute: a black slate. The last of these belongs to what Peter
Denning calls the "third generation" of computer systems---an assemblage of
storage, input, and output technologies that continue to shape the contemporary
human encounter with text today. These devices tell us a story of the fracture.
Through them, a part of the sign fades from view as an arrangement of magnetic
charge and floating gate. Another part appears as flicker of the cathode ray
and the flow of the liquid crystal.

### A. Removable storage media and automation, 1725--1964.[^ln1-loom]

"You must acknowledge that this is readable without special training," reads
the schematic illustration to a Goldberg 1911 patent, simply titled
"Controller." "My invention relates to all controllers," Goldberg writes.
Furthermore, the object of his invention is "to provide a mechanism operable by
a control sheet which is legible to every person having sufficient education to
enable him to read." Goldberg illustrates his invention in attaching to his
patent "a control sheet in which the control characters are in the form of the
letters of the ordinary English alphabet"  [@goldberg_controller_1915]. Rather
than using ticker tape, Goldberg uses perforations that form letters. On
Goldberg's control sheets, the language of machines and the language of humans
coincide.

![Goldberg's Control Cards [@goldberg_controller_1915].](images/control-2.png)

The Controller never caught on, but the patent makes it clear that Goldberg,
among others, was aware of the problem: the mechanization of type, automation,
and remote control required specialized training. With the advent of the
automated telegraph, content meant for people was now being intermixed with
machine-controlling code. To combat mutual unintelligibility, Goldberg imagines
using cards, perforated in the shape of the English alphabet. Besides carrying
(human-readable) content, the perforations do "double duty" to mechanically
manipulate the machine's "blocks," "handles," "terminal blades," and "plungers"
[@goldberg_controller_1915]. Early paper-based storage media, from Morse
code-based ticker tape systems, to the telegraphs of Hughes and Baudot, and to
punch cards that powered weaving looms, player pianos, and census tabulators
coupled message and control. The era of ticker tape punch cards can be thought
to end with the mass-market introduction of IBM's Magnetic Tape/Selectric
Typewriter in 1964.

### B. Magnetic tape, 1888--1968

"Historically unforeseen, barely a thing, software's ghostly presence produces
and defies apprehension," Wendy Chun writes in her *Programmed Visions*, an
influential monograph that continues to shape the field of software studies.
She quotes several prominent computer scientists and media historians to the
same effect. But what gives software its ephemeral quality? Embossed onto
ticker tape or punched into the card, early software protrudes through the
medium. In the age of the telegraph, the largest barrier to the comprehension
of software was encoding. But once the cipher is known and the format
identified, the inscription makes itself visible to view. Early programmable
media could hardly be called ephemeral or immaterial. Anecdotes circulate in
the digital humanities circles of Father Roberto Busa, an early (post-WWII)
pioneer in the field of computational philology, carting his punch cards around
Italy on a truck.[^ln3-busa] Code before its electromagnetic period was
burdensome, fragile, unwieldy, and, most of all, visible.

![IBM Mag Card II, introduced in 1969 for use in the Magnetic Card/Selectric
Typewriter (MC/ST) in 1969. "A simple relationship could be maintained between
a typed page and a recorded card" [@may_ibm_1981, 744]. Image by Pointillist
under GNU Free Documentation License, Version 1.2.](images/ibm-card.png)

The principles of magnetic recording were developed by Oberlin Smith (among
others), the American engineer who also filed several inventions related to
weaving looms at the end of the nineteenth century. In 1888, inspired by
Edison's mechanical phonograph, Smith made public his experiments with an
"electrical method" of sound recording using a "magnetized cord" (cotton mixed
with hardened steel dust) as a recording medium. These experiments were later
put into practice by Valdemar Poulsen of Denmark, who patented several
influential designs for a magnetic wire recorder [@smith_possible_1888;
@poulsen_method_1900; @engel_1888-1988_1988; @thiele_magnetic_1988;
@daniel_magnetic_1998; @vasic_coding_2004].

In 1964, IBM combined magnetic tape storage with its *Selectric* line of
electric typewriters, introducing the Magnetic Tape Selectric (MT/ST) line of
typewriters to the mass market. Writing for the *Encyclopedia of Library and
Information Science* in 1992, Daniel Eisenberg mentions the MT/ST as one of the
first word processors, defined by the ability to record strokes and to print
them onto paper *as a separate operation* [@eisenberg_word_1992]. The
separation of input and output allows for word processing as such. An article
in the *IBM Journal for Research and Development* explains that the real
significance of the MT/ST workstation was in the introduction of new "power
typing" technologies: "For the first time the typist could type at 'rough
draft' speed, 'backspace and strike over' errors, and not worry about the
pressure of mistakes made at the end of the page" [@may_ibm_1981, 742].

We may think of word processing as a temporal extension of the page. Words on
magnetic storage media begin to exist in the ephemeral state, giving the typist
an opportunity to edit and emend *before* commitment to paper, in its immutable
form, and as a separate operation, removed from the immediate process of
inscription. The very invention of word processing thus corresponds to the
decline of text into ephemera. What was visible through a hole punch on ticker
tape, was now submerged into tape. The tape no longer afforded human legibility
nor comprehension. Encoding used by MT/ST retained the familiar (from the
earlier sections) underlying structure (7-bit encoding, in this case) which, on
tape, ceased to be recoverable by the naked eye. The inscription lay literally
beyond (human) sense. We lack the perceptual apparatus to perceive "magnetic
domains" and "polarities"[^ln3-magnet] that take place of visible alphabets.
Magnetic storage remains, for all unassisted intents and purposes, a black
slate.

### C. Screen, 1968--today

By decoupling input and output, magnetic storage and solid state media afford
the injection of time and space, in arbitrary intervals, between the process of
inscription and comprehension. Content, coupled with control code, sinks
beneath the matte surface of electrical charge. The final movement in the
emergence of automated discourse reintroduces the illusion of immediacy into
the process of inscription. Text, invisible in its material substratum,
reappears on the screen, but, crucially, it no longer corresponds to its mirror
inscription. This property is as perilous as it is liberating: perilous,
because the flows of power and control can now be submerged under the
shimmering surface of the screen, and liberating, because loosely coupled to
their material substratum texts become both more fluid and more portable.
Plainly put, the systematic barriers to copying, sharing, exchanging, editing,
remixing, and disseminating texts are reduced to a minimum.

Ersatz skeuomorphism (between disk storage and screen image) leads to the
reception of digital text as an ephemeral artifact. With the illusory role of
the screen in mind, I propose 1968 as the year in which the contemporary
textual condition takes its present form. On December 9, 1968 Douglas
Engelbart, then founder and primary investigator at the NASA- and ARPA-funded
Augmentation Research Center lab at the Stanford Research Institute, gave what
later became known colloquially as "the mother of all demos
[@tweney_mother_2008]" before an audience of roughly one thousand or so
computer professionals attending the Fall Joint Computer Conference held at the
Convention Center in San Francisco [@rogers_demo_2005]. The demo announced the
arrival of almost every technology prophesied by Vannevar Bush in his
influential 1945 piece for *The Atlantic* [@bush_as_1945]. Speaking a little
over an hour,  through a headset, in a prerecorded address, Engelbart features
functional (live) prototypes of the following: graphical user interfaces, video
conferencing, remote camera monitoring, links and hypertext, version control,
text search, image manipulation, windows-based user interfaces, digital slides,
networked machines, mouse, stylus, and joystick inputs, and "what you see is
what you get" (WYSIWYG) word processing.

!["NOW IS THE TIME FOB." Schematics for a "display system"
[@engelbart_x-y_1970].](images/engel.png)

In his report to NASA, which sponsored research on "intellect augmentation"
along with DARPA, Engelbart describes his lab as a group of scientists
"developing an experimental laboratory around an interactive, multiconsole
computer-display system" and "working to learn the principles by which
interactive computer aids can augment the intellectual capability of the
subjects" [@engelbart_human_1969, 1]. Cathode Ray Tube (CRT) displays were
central to this research mission. In one of many patents that came out of
"intellect augmentation" laboratory, Engelbart pictures the "display system" as
a workstation that combines a typewriter, a CRT, and a mouse. The system is
frozen in mid-action, with the words "THE TIME IS NOW FOB" prominently
displayed on the screen. Although Engelbart does not explain the message, the
system's user is evidently in the process of editing a sentence and about to
correct the nonsensical FOB into a FOR. Engelbart writes, "One of the
potentially most promising means for delivering and receiving information to
and from digital computers involves the display of computer outputs as visual
representation on a cathode ray tube and the alternation of the display by
human operator in order to deliver instructions to the computer"
[@engelbart_x-y_1970].

The CRT closes the circuit between human and machine, with a few caveats. In
practice, the short-lived screen-less word processors (like the IBM MT/ST)
necessitated for the cognitively arduous task of continuously keeping the
underlying document structure in the mind's eye. The CRT lifts that burden by
unfolding the structure topographically, allowing for spatial navigation along
the document---restoring, in a sense, the natural affordances of print. Data
becomes visible again. Moreover, represented in the shimmer of the cathode ray,
it attaches itself lightly to the retina. Users trying out this way of writing
for the first time report that the screen liberates them from the material
confines of print textuality. One user, possibly Engelbart himself, writes the
following:[^ln3-follow]

[^ln3-follow]: I reproduce the text verbatim and preserving the line breaks,
since formatting is an important part of the reported experience.

```
    1B2B1 "To accommodate and preserve a thought or
    piece of information that isn't related to the work
    of the moment, one can very quickly and easily
    insert a note within the structure of a file at such
    a place that it will nether get in the way nor get
    lost.

    1B2B2 "Later, working in another part of the file,
    he can almost instantly (e.g. within two seconds)
    return to the place where he temporarily is storing
    such notes, to modify or add to any of them.

    1B2B3 "As any such miscellaneous thought develops,
    it is easy (and delightful) to reshape the structure
    and content of its discussion material.
```

Engelbart, interested in collecting empirical phenomenological accounts of the
system, records what must count as several of the most evocative passages to
appear on the pages of a NASA technical report. In the "Results and Discussion"
section an anonymous user continues to report:

```
1B4 "I find that I can express myself better, if I can
make all the little changes and experiments with wording
and structure as they occur to me." [Here the user
experiments a little with using structural decomposition
of a complex sentence.]
```

A deconstruction indeed follows, as the author begins to deviate from the
conventions of the technical report. The numbered passages, and unexpected
enjambment, heightens the staccato quality of the prose, which at times reaches
towards the lyric:


```
    1B4A "I find that I write faster and more freely,

        1B4A1 "pouring thoughts and trial words on the
        screen with much less inhibition,

        1B4A2 "finding it easy to repair mistakes or wrong
        choices

            1B4A22 "so while capturing a thought I don't
            have to inhibit the outpouring of thought and
            action to do it with particular correctness,

        1B4A3 "finding that several trials at the right
        wording can be done very quickly

            1B4A3A "so I can experiment, easily take a look
            and see how a new version strikes me--and often
            the first unworried attempt at a way to express
            something turn out to be satisfactory, or at
            least to require only minor touch up.

        1B4A4 "Finding that where I might otherwise
        hesitate in search of the right word, I now pour out
        a succession of potentially appropriate words,
        leaving them all the while the rest of the
        statement takes shape. Then I select from among
        them, or replace them all, or else merely change the
        list a it and wait for a later movement of the
        spirit.
```

When input and output coincide in time, as they do on paper, mistakes can be
costly. The writer must commit to making an inscription and, once made, the
inscription gains permanence in a way that is difficult to correct. One can
erase, removing a layer of physical material, or cover up, adding a layer of
white ink to repair the damage. Engelbart's anonymous writer reports a feeling
of freedom from such commitment to physical medium. He or she can simply
"backspace" and start over. The contemporary reader may take such things for
granted now, but imagine trying to write in that way for the first time.
Writing "comes easy," becomes "uninhibited," and it "pours out" experimentally.
Rather than manipulate language mentally, the writer "pours" the words onto the
screen and then "selects" the right one, without hesitation. The highly
hierarchical and blocky paragraph structure, along with its repetitive refrain,
"finding" and "I find that," gives the prose a hypnotic drive forward, which
matches the reported experience of liberation. Anonymous continues:

```
    1B4B "I find that,

        1B4B1 "being much more aware of

            1B4B1A "the relationships among the phrases of a
            sentence,

            1B4B1B "among the statements of a list,

            1B4B1C "and among the various level and members
            of a branch,

        1B4B2 "being able

            1B4B2A "to view them in different ways,

            1B4B2B "to rearrange them easily,

            1B4B2C "to experiment with certain special
            portrayals,

                1B4B2C1 "not available easily in unstructured data

                1B4B2C2 "or usable without the CRT display,

        1B4B3 "and being aware that

            1B4B3A "I can (and am seeking to) develop still
            further special conventions and computer aids

            1B4B3B "to make even more of this available and
            easy,

        1B4B4 "all tend to increase

            1B4B4A "my interest and experimentation

            1B4B4B "and my conviction that this is but a
            peek at what is to come soon.
```

The passages are too contrived to be spontaneous admissions of phenomenological
experience. Despite the experimental structure, the passages contain a
well-formed rhetorical message advancing key elements of Engelbart's research
program, which aimed to develop new data structures in combination with new
ways of displaying them. Yet I cannot help but be carried away by the fluency
of the prose and by the sheer audacity of the project. Here's someone who has
not only glimpsed the future, but has also brought it into being. The
contemporary author can drag and drop passages around with more facility, but
he has not himself structured his cognitive environment. In Engelbart's terms,
someone else has augmented the author's intellect, in ways that may or may not
fit the individual psyche. That feeling of effortless textuality cannot
therefore be taken at face value, by the unreliable phenomenological accounts
alone. To bring his system into being, Engelbart convened what he called a
"bootstrap community," which through recursive self-improvement could lift
itself up towards a smarter, more efficient, and as the report's lexicon
betrays, a more human way of working. To accomplish this, the group crafted
novel instruments for input and output. They wrote new programming languages,
compilers to interpret them, and debuggers to troubleshoot. They invented word
editors and format control languages. Here's how Engelbart diagrams a *part* of
his text-manipulation language in the same report:

!["State--chart portrayal of part of text--manipulation control language"
[@engelbart_human_1969, 36].](images/engel-edit.png)

The diagram shows much attention to the detail of and love for the writing
craft. But there is also much complexity. It is near impenetrable. In building
their own tools, Engelbart's team lifted themselves up by the bootstraps. But
it was not the machine that lifted them up---it was the process of creating the
machine. The very metaphor of bootstrapping suggests the impossibility of using
one's bootstraps to pull others out of the Platonic cave. As a side effect of
that effort, text, before readily apparent on the page, now enters a complex
system of executable code and control structure. The perception of material
lightness of textual being comes at the price of legibility. Would new authors
find the same ease in the complication of the mechanism? I suspect not unless
they become an active part of a "bootstrapping community" of their own.

[^ln1-brain]: We will later entertain the (real) possibility of
non-representational communication, suggested by early experiments in direct
brain-to-brain or brain-to-machine interfaces.

## Gerard Genette and Nelson Goodman on the nature of textual copies,

## 3.4 Hyper Erudition

Writing on the state of
twenty-first century poetics Craig Dowrkin speaks about poetry's "Malthusian limit."
"Bound by discreptant rates of production and consumption, the readerly economy
of poetry in the twenty-first century cannot avoid a catastrophic calculus: the
rate of consumption quickly hits an arithmetic limit (any one person can only
read so much), but the rate of production is increasing geometrically"
[@dworkin_seja_2008, 9].

Flattening of the knowledge realm.
https://medium.com/the-physics-arxiv-blog/the-extraordinary-growing-impact-of-the-history-of-science-642022a39d67

Impact on the study of textual artifact. If are to take the hypothesis of
extended cognition seriously, we must treat the tools of cognitive augmentation
as seriously as we would our own mental development, in the traditional sense.

The flattening of the knowledge realm. It is not the absence of topography. It
is our ability to readily perceive topography, and to place ourselves within
that discourse. The knowledge of the mechanic vs. the knowledge of a surgeon.
The surgeon should get more money because of the subjective experience of
cutting people up. That part does not transfer. The technical literature is
actually quite understandable. Incommensurability of subjective experience.
Commensurability of knowledge. The fundamental problem of modern world is the
problem of expertise.

http://word.mvps.org/faqs/general/wordvswordperfect.htm
http://wptoolbox.com/tips/MSWordToWP.html
modal vs. other kinds of processing
5.2 Copy Text (textual criticism)

The division of text into form and content makes a difference in more
utilitarian ways as well. For example, imagine the challenge of compiling all
known commentaries on Shakespeare's *Hamlet*, by hand or programmatically. The
problem of what edition to use as the "base" for such a project presents itself
immediately. In the words of Barbara Mowat and Paul Werstine, the editors of
*Folger Digital Texts*, "readers assume that there is a single text for the
plays: what Shakespeare wrote. But Shakespeare's plays were not published the
way modern novels or plays are today: as a single, authoritative text. In some
cases, the plays have come down to us in multiple published versions,
represented by various Quartos (Qq) and by the great collection put together by
his colleagues in 1623, called the First Folio (F). There are, for example,
three very different versions of *Hamlet*, two of *King Lear*, *Henry V*,
*Romeo and Juliet*, and others. Editors choose which version to use as their
base text, and then amend that text with words, lines or speech prefixes from
the other versions that, in their judgment, make for a better or more accurate
text" [@mowat_textual_2012]. In other words, where the readers expect to
encounter *Hamlet* as a single, unified idea, they instead encounter a
multiplicity of slightly diverging textual "witnesses." Errors in transcription
and editorial interventions accumulate. The proliferation of unlicensed copies,
translations, and imitations further adds to the complexity of the problem.

Editors of classical literature will often solve the problem of diverging
copies by designating one version as canonical, preserving the formal
characteristics of the given version down to individual line breaks, as is
often done with Platonic dialogs. It then becomes possible to collate
commentaries, connecting each to individual words and passages at their
canonical location. The problem remains in the abstract: which version to count
as canonical? The act of deciding on what constitutes an authoritative edition
can quickly become a contentious issue, particularly when the text in question
carries religious or political significance.

A whole field of textual criticism exists in the service of negotiating
"critical" editions which in some way preserve the struggle to reconstruct a
measure of authority. But what should count for being authoritative? A number
of logical possibilities find as many ardent adherents. For some, the act of
deriving the authoritative text lies in reconstructing authorial intent, using
the author's notes, for example, or from first-hand witness testimony. Others
place a premium on reconstructing and analyzing the writing process itself, in
what has been dubbed as "genetic criticism" [@deppman_genetic_2004, 1-36]. Yet
another approach will compare multiple editions of the same text to derive a
possible meta-text, preserving all extant variations. Yet others will simply
rely on their judgment to produce what they believe is a "true" text based on a
number of personal and eclectic considerations [@bowers_rationale_1950,
@bowers_shakespeares_1954, @mcgann_radiant_2001]. Such approaches to textual
criticism have at least this one thing in common: behind the fuzzy profusion of
textual material they perceive the outlines of a single, unified work. As G.
Thomas Tanselle (a prominent textual scholar) puts it, "one must be able to
distinguish the work itself from attempts to reproduce it."[^ln11-tanselle] For
a textual critic of his kind, all real-word variants and reproductions are
suspect because possibly corrupt in some way. Despite its careful attention to
the materiality of the text as artifact, textual criticism in this vein remains
a classically idealistic pursuit. The work exists as an ideal form in the realm
of the ideal.

[ln11-tanselle]:  "Whatever concept of authorship one subscribes to, the act of
reading or listening to receive a message from the past entails the effort to
discover, through the text (or texts) one is presented with, the work that lies
behind" [@tanselle_rationale_2010, 13-18.].

Restoration and Anti-restoration. Eugene-Emmanuel Viollet-le-Duc (for) and
William Morris and John Ruskin (against). Also Teoria del restaruo by Brandi.

"To restore an edifice means neither to maintain it, nor to repair it, not to
rebuild it; it means to reestablish it in a finished state, which may in fact
never have actually existed at any given time." [@price_historical_1996, 314;
orig from @viollet-le-duc_foundations_1990, 195]

"It is for all these buildings, threfore, of all times and styles, that we
plead, and call upon those who hve to deal with them to put Protection in the
place of Restoration, to stave off decay by daily care, to prop a perilous wall
or mend a leaky roof by such means as are obvioiusly mant for support or
convering, and show no pretence of other art, and othrwise to resist all
tampering with either the favric or ornament of the buildings as it stands; if
it has become 

But whose who make the change wrout in our day under the name of Restoration,
while professing to bring back a building to the best time of its hisory, have
no guide but each his own individual whim to point out to them what i s
admirable and what contemptible; while the very nature o their task compels
them to destroy something and to supply the gap by imagining what the earlier
builders should or might have done." Data munging. Irreversible changes.
@price_historical_1996, 320; orig in "William Morris, "The Principles of the
Society as Set Forth Upon its Foundation," Builder 35 August 1877.

Ruskin lamp of memory.

"It is impossible, as impossible as to raise the dead, to restore anything that
has every been great or beautiful in architecture [...] That spirit which is
given only by the hand and eye of the workman, never can be recalled. Another
spirit may be given by another time, an it is then a new building; but the
spirit of the dead workman cannot be summoned up, and commanded to direct other
hands, and other thoughts. And as for direct and simple copying, it is palpably
impossible. What copying can there be of surfaces that have been worn half an
inch down [@staniforth_historical_2013, 2]?"

"But it is said there may come a necessity for restoration! Granted. Look the
necessity full in the face and understand it on its own terms. It is a
necessity for destruction. Accept it as such, pull the building down, throw its
stones into neglected corners, make ballast of them, or mortar, if you will'
but do it honestly, and do not set up a Lie in its
place"[@staniforth_historical_2013, 3].

On the Restoration of The Circumcision by Signorelli. "At Volterra, over the
alter of a Company in the Church of S. Francesco, he painted in fresco the
Circumcision of Our Lord, which in considered beautiful to a marvel, although
the Infant, having been injured by damp, was restored by Sodoma and made much
less beautiful than before. And, in truth, it would be sometimes better to
leave works half spoilt, when they have been made by men of excellence, rather
than to have them retouched by inferior masters." 1550 Tim's Vermeer.

picture cleaning as removing as removal of "varnishes and other encrustations,
by which a paininting may be obscured, but by which it is usulaly also in some
measur protected from injury." [@bomford_issues_2004, 60] Original in the
Report from the Select Committee on the National Gallery, London 1853, vi-xi.

Colliveau set about [restoring]this picture with uncommon solenity, because it was his
own. He began with the most delicate pumice stone, and very soon got into the
walls of th building, but was astonished to find the apearance of bricks and
mortar still, although not guite soneat; he soon cleared away the wall on
discovering a room beyond, and pictures, furniture, &c. most beautiful.
Gracious powers! how was he agitated; forgetting totally the mischief he was
commiting, his elbow went like a fiddler's; every thing vanished.---However,
finding a bed, the curtains of which (a dark green) were drawn close, he went
to work upon it ver tenderly; presently a pot de chambre came  in sight!---His
whole souldwas absorbed; his face all one ghastly grin; his legs (like German
flutes) tottered under him. Not that great philosopher Guffin Ragba, was more
agitated while cutting the leather from off his bellow, to disover how wind was
make, than was Monsieru Collifeau while scroring off the bed cloaths; at last
he found a lady asleep, very beautiful, because very fat, and a Dutch woman.
Now this part I did not see, and I believe but very few besides himself; but
alas! hew was soon to be at the end of his discoveries. Having got a glimpse of
some gilding, he redoubled his efforts, when he found it was an inscription; it
was in Dutch, and nearly thus, as translated by Mr. Peter La Cave:---"Now
caitiff, meditate on th havoc though hast made throughout thy lie, and go thang
thyself. In this picture, wretch! though have destroyed, what to the end of the
world, can never be replaced." [@bomford_issues_2004, 44-45]. Originally from
Julio Caesar Ibbetson, An Accidence, or Gamut, of Painting in Oil and water
Colous . London: Darton and Harvey, 1803, 5-14.

"The sculptor wastes away th rudo block til he has accomplished the desired
form. not so the painter. he builds up his forms from a blank surface, and
hides, as he rogresses all the preliminary layers upon which the etxternal
colours depend for durability and lustre. And hence, not on the meaning and
spririt of the work must be understood; the restorer must also be familiar with
he naure of the materials and the manner of their employment.
[@bomford_issues_2004, 70]. Original from @merritt_dirt_1854, 67-72


The wound
that heals.

Just giving you a taste of restoration vs. preservation. What would


[^ln11-counter]: A documentary on counterfeit goods produced by BBC4
interviews Christophe Zimmerman, Senior Technical Officer at World Customs
Organization, who deplores the industry's lack of cooperation with law
enforcement [@bbc4_counterfeiting_2013].



We have now traveled from the pixel down to magnetic storage media and back
from the storage media to the screen. The passage opens up space between
visible content, media, and the imposed forms that govern any and all higher
notions of literary activity "floating" above this nominally "digital" layer.
Technology does not determine the literary space: it has only the potential to
hide implicit mechanisms of machine control, or, to offer possibilities for
transformation not otherwise available to other forms of textuality. Loosely
coupled to its material contexts, text can continue its relentless drive from
matter to idea and into other matters as long as its passage is not hampered by
regimes that prohibit further sharing, remixing, and transmediation. I say nothing
yet of the potential necessity of such regulation. Under certain conditions, in
the name of privacy, security, or property rights, it may become necessary to
flatten out and to treat text as more of an analog, media-bound modality of
communication, limited in its ability to move across minds and cultures. But,
it is also in our broadly human, civic interest to keep such mechanisms of
constraint visible to view, under continual scrutiny of critical, close, and
closest possible reading.


## "reading" from the perspective of a copy machine

which "sees" pages
as monolithic images. 

We often think of literary works as completed products. *To the Lighthouse,*
*Hamlet,* *Moby Dick* seem to circulate as complete, fixed entities. Textual
critics, in charge of creating a work out of a multiplicity of texts, remind us
that the work is a carefully-crafted illusion. The text multiplies, always
threatening to undermine the unity of the work. Think of something substantial
you have written recently: a paper or a proposal perhaps.

"Computer assisted tracing of text evolution"

Goodman's "Art and Authenticity." Benjamin. Immanence and transcendence.
Goodman: thinking about the perfect copy. But there is a confusion here: fake
art is not necessarily about a copy, it is about provenance. Autographic vs.
allographic art. Whether forgery is possible. Digital vs. analog art. Analog
art is medium bound. Digital abstracts from the material.

Duplicates in Computer Science. Almost 30% of webpages are "very similar to
other pages" [@fetterly_evolution_2003].

It is a commonplace sentiment now that the printing press brought with it the
Protestant Reformation [@dittmar_information_2011, @febvre_coming_2010,
@mcluhan_gutenberg_1962, @eisenberg_word_1992]. Movable type is responsible for
at least a part of that story. The mechanization of print is what turned
writing from an autographic into a supremely allographic art. The Gutenberg
press helped place a copy of the bible into the hands of every ordinary
believer. That meant also minimizing the role of the priest as a privileged
interpreter. Without books in hand Martin Luther could not have written "all
who are in the church are priests" [@hillerbrand_protestant_2009]. Movable type
lifted text from rarefied media of parchment into that of the reified and
disposable leaflet. But until well into the middle of the 20th century, the
printing press remained in the realm of big technology: expensive, centralized,
unwieldy, and relatively easy to suppress. The liberatory potential of media
independence comes into its full fruition after the age of the typewriter.
After a historically brief flowering in the wild, our daily textual practice is
once again in danger of returning to controlled, media-bound, and
tightly-regulated conditions of existence.

Several important developments in the twentieth century aided in the liberation
of text from its material contexts. The first is the copy machine.  It is an
entirely unglamorous job to ponder the phenomenology of reading from the point
of view of a photocopier. Yet the impact of the humble Ditto and Xerox machines
has only recently began to get the scholarly attention it deserves. In the
United States, the copy machine placed a smaller version of Gutenberg press
into every office. And it allowed for the flourishing of a vibrant samizdat
(self-publishing) scene, usually connected to underground culture movements
without access to conventional publishing: punks, skinheads, computer- and
game- geeks, feminists, fans of science fiction and queer-core music
[@klanten_behind_2011, @piepmeier_girl_2009, @duncombe_notes_2008].

The word "xerox" firmly entered the English lexicon by the
mid-1960s[^ln11-xerox] along with stencil duplicators, mimeograph machines,
microfiche, spirit duplicators,[^ln11-spirit] hectographs, and dot-matrix
printing. A whole industry of photocopying still exists to seamlessly peel the
content away from one material medium and plaster it into another.

From the "point of view" of a photocopier, the text exists only as pure form.
The electro-photographic process at the basis of modern photocopying (invented
in the 1930s, but with patents dating back to the middle of the 19th century)
describes documents in terms of "electric charge patterns," "photoemissive
layers," and "sheet surfaces"  [@carlson_electron_1940,
@carlson_electrophotography_1942, @carlson_graphic_1953]. The photocopier is a
device for total graphesis and extreme surface reading.[^ln11-ooo]. There is no
word or content for the photocopier: only paper and image. The photocopier's
"job", if you will, is to lift a picture from one page and to impress it into
another. It does so by temporarily imaging text (as picture) onto a
photo-sensitive drum. Ink powder sticks to the electrically charged surfaces of
the drum in correspondence to the shapes on the page. The shapes are then
rolled onto a new page, re-inscribing the image into the new medium. The text
is never immaterial. But for a moment it finds shape as an invisible electric
charge. The transformation should not be reduced to some sort of mystical,
metaphysical moment. On the contrary, in instrumental terms we observe the
relatively mundane process of media independence.

Let's linger on that moment of remediation. The process of textual
transcription by hand involves a similar transformation. When a scribe copies a
page from the bible, for example, he also "lifts" content from paper.  Not
unlike a photocopier, the human stores text in the electro-chemical pathways of
the brain, before reproducing it once again into another medium. And like a
photocopier, the human can perform the copy function mechanically, without
comprehension and on a purely formal, visual level. In fact, the historical
record is full of errors that suggest that pre-modern scribes wrote at widely
varying levels of literacy [@goudsmit_illiterate_1974,
@bucking_training_2007].[^ln11-literacy] In the Muslim tradition, the prophet
Muhammad himself is sometimes called "the unlettered prophet," to emphasize
fidelity and lack of mediation in the transcription of the message
[@calder_ummi_1990, @gunther_muhammad_2002, 1-26]. In other words, the Qur'an
claim to authenticity relies on the prophet's ability to copy the message
"verbatim." On the conservative Muslim view, anything but a faithful
transcription of the original text amounts to an interpretation, not
self-identical to the letter of the text (a translation, for example)
[@tibawi_is_1962, @fatani_translation_2005, @wilson_first_2009].[^ln11-quran]

Where the photocopier placed a printing press into every office, the printer
placed one on every desk. Falling cost of print.

Finally, the text exists on the screen and magnetic media only, where the cost
of reproduction approaches zero.


## the crisis of authenticity

It is quite odd, if you think about it, to believe that objects somehow retain
an aura or a trace of their history: "a handkerchief used by Princess Diana,"
or "the cigar box owned by President Kennedy." In some real sense, the
historical patina covering these objects is only imagined. President Kennedy's
fingerprints and the tears of Princess Diana have long disappeared from their
physical medium. Their trace cannot be reduced to "mere" physical
characteristics: that is, to actual scratches, stains, or molecules,
recoverable from the object. Rather, the object had to "be there" in some way,
acquiring a patina of authenticity. "Having been there" is what gives the
object value, sentimental or otherwise, in a condition that refuses formal
reduction to a set of merely material properties. The high price contemporary
society places on authentic artifacts is therefore a type of magical thinking.
Walter Benjamin's famous essay on the work of art in the age of mechanical
reproduction appears to both celebrate and lament the demise of such magic.
"The technique of reproduction detaches the reproduced object from the domain
of tradition," wrote Benjamin. "By making many reproductions it substitutes a
plurality of copies for a unique existence. And in permitting the reproduction
to meet the beholder or listener in his own particular situation, it
reactivates the object reproduced. These two processes lead to a tremendous
shattering of tradition which is the obverse of the contemporary crisis and
renewal of mankind" [@benjamin_work_1969, 217-253]. And yet, for Benjamin, the
easy reproducibility of modern art forms like film and photography also
"emancipates the work of art from its parasitical dependence on ritual"
[@benjamin_work_1969, 217-253]. One could read Benjamin's famous essay as a
piece of technological nostalgia, or as an expose on the magic and superstition
latent in modernist art. Crisis or emancipation? Benjamin feels both, and in
doing so he captures the metaphysical anxiety of the modern age. We desire for
our Vermeers to stay special but also for a Vermeer to hang in every home,
peering back at us from a multitude of anonymous reproductions.

The modern world faces the challenge of authenticity, which we have only began
to assimilate: politically, economically, and philosophically. The ubiquitous
holographic certificate of authenticity on a luxury handbag or on a "Digital
Versatile Disk" (how antiquated the DVD sounds already!) is a cheap band-aid
hiding the immaterial nature of these artifacts. Fashion and software companies
are reluctant to talk publicly about piracy,[^ln11-counter] because the so
called "knock-offs" are essentially exact duplicates, often "leaked" from the
very same factories producing the original.

Note that it makes no sense to talk about "what was meant" by the designer of
the handbag, the way textual critic may talk about authorial intention. Nor
would it make sense to "correct" some perceived flaw in the painting by
Vermeer. The practice parallel to "textual criticism" in visual arts is
restoration. Although similar to textual criticism in its aims to recover some
notion of the original, crucially, the practice of art restoration takes place
without reproduction. Unlike a critical volume, which essentially reprints the
work in its reconstructed entirety, restoration happens at the site. All
"unauthorized" copies constitute a forgery that competes for attention with the
original. One could say that for painting and handbags "matter is synonymous
with meaning," but the sentiment strains at the limits of critical vocabulary
in the tradition that gives us only the binaries of form and content.

The context-dependence of an artifact is not even medium-specific, as
Goodman would suggest. Texts are more allographic than handbags and paintings,
but Vermeers and Louis Vuitton purses are also in some sense perfectly
reproducible, like texts. They are texts, and I do not mean it in some
post-structuralist notion of "everything is a text."[^ln11-derrida]

Technologies like 3D scanning and printing increasingly reduce physical objects
to their textual representation, as is the case with the stereo lithographic
document (STL) format that describes objects for 3D printing.  Here, for
example, I reproduce code that describes "a surface" of a functional gun (the
code made available online by *Defense Distributed*, a self-described civic
liberty activist group):

```
22=(
BOUNDED_SURFACE()
B_SPLINE_SURFACE(1,2,((#34104,#34105,#34106),(#34107,#34108,#34109)),
 .UNSPECIFIED.,.F.,.F.,.F.)
B_SPLINE_SURFACE_WITH_KNOTS((2,2),(3,3),(15.1641909236141,15.3257778193699),
(2.99329024107099,3.14159265358979),.UNSPECIFIED.)
GEOMETRIC_REPRESENTATION_ITEM()
RATIONAL_B_SPLINE_SURFACE(((1.,0.997252058758362,1.),(1.,0.997252058758362,
1.)))
REPRESENTATION_ITEM('')
SURFACE()
);
```

This piece of code exists in its Platonic ideal *before* the physical artifact.
As costs of reproduction approach zero, so does the line between an object and
its description. Imagine a world where to think "gun" is also to seamlessly
bring one into existence. The erosion of boundaries between object and idea has
a pronounced effect on the governance of goods, felt precisely at the
distinction between the autographic and the allographic. Governments currently
regulate the manufacture and the distribution of guns as artifacts, but how
does one regulate guns as texts and ideas? Any such effort amounts to
censorship. What was first regulated under the regime of property law, now
increasingly falls under the regimes of intellectual property and rights to
speech. Where does that leave the practice of textual criticism? In such a
world there can be no distinction between works and texts. Unlike millions of
reproduced Vermeers (which no doubt occupy this world in the form of postcards,
posters, and photographs), text is text. It lies before us in glorious
flatness, as thick as a sheet of paper.

Text as I have already began to define it Chapter One, is a digital mode of
representation, defined, at least in part, by a relative lack of "stickiness"
to its physical medium. Textual artifacts therefore exhibit the dualism between
text and work to a much greater extent than other forms of art and
communication. A Vermeer is always a work. Not so with *Hamlet*. "Hamlet" may
indicate a category of relate, or, an individual instance of a given work.
Philosophers Nelson Goodman and Catherine Elgin explain this peculiarity by
making the distinction between "works of art whose identity depends on their
history of production" and works whose identity does not. The former they call
"autographic" and the latter "allographic" [@goodman_reconceptions_1988, 65].
These terms will be useful for us throughout the book. Architecture and
painting, in this view, are strongly autographic disciplines. An exact copy of
a Vermeer or of a building by Frank Lloyd Wright could never rise to the status
of the original. The originals have what Walter Benjamin called an "aura or
authenticity." No amount of precision, down to the molecular level, could
substitute for the historical patina of the original artifact.

### 5.4 Problem of Drafts

Text as vector. Barthes: text as "an organism which grows by vital
expansion"[@barthes_work_1978, 161].  "The metaphor of the Text is that of the
*network*" [@barthes_work_1978, 161].

Internet is not rhyzomatic. Mediation is at stake. " But the bottom line is
that dumb-pipe email is unmediated, and therefore it's a business that Google
wants to get out of as soon as it can."

" It's also why I believe Google will kill Gmail as soon as it comes up with a
mediated alternative everyone loves. Of course, Google may offer an antiquated
"Gmail view" as a semi-obscure alternative to the default "Inbox"-like mediated
experience."

Problem of Drafts and Versions Documents as vectors. Not completed things.
Files as cognitive scaffolding for collective memory. Vissman.

Science lecture vs. humanities. Stuff that is known. Stuff that is not known

What does it really mean to "know" something? Or to have "read" a book? I have
had the following conversation countless times. Someone asks, "Have you read
Nabokov's *Pale Fire*," and I respond, "Yes I have." But there is a world of a
difference between reading it yesterday, last week, or ten years ago. The book
as an interface leaves an organic trace in the human mind---an imprint that
begins to fade as soon as it is created.

How much knowledge is there in the world? According to a recent paper published
in Science, 295 exabytes (or billion gigabytes).[@hilbert_info_2012;]

Whatever consciousness is, it is propelled forward on a thin edge of material
substratum. Reality exists only in the now, where the past is a memory and the
future only a possibility. Imagine whispering something to a friend. It does
not have to be very complicated, something like "I love you" or "I miss you."
The whisper dissipates as soon it is uttered. The percussion of the speaker's
breath creates temporary order: giving shape and pushing air molecules into
waves of pattern and form. That order begins dissipating as soon as it is
created. Within milliseconds, molecules return to their natural state of chaos.

To steel ourselves against entropy, we change the substratum from air to stone.
It's molecules are more stable. Etched in stone will be the same message. It
will last longer now. But it will also take longer to create. You will have to
carry around your tablet and chisel. The message etched in stone will outlive
the whisper and indeed will

Repercussion? How we preserve ourselves today affects the future. Appointment
with self.

Leroi-Gourhan, André.

The book as an interface between human and ?. We must see it in the context of
interfaces.

Wikipedia as a Turing complete language. The power of versioning. Text as a
vector. The problem of annotation. What are we annotating? Annotation solutions
force a platform. Is Hamlet a platonic object? A family of related objects?
Standard English editions in Europe.


related to the plummeting costs of digital
reproduction. The supposedly "dead" authors continue to draw checks from
copyrighted work. 


## Authorship function

The telegraph further weakens the
authorial function in transposing writing from its immediate physical
environment across vast geographical distances. The advent of telecommunication
lengthens the chain of technological mediation between author and reader. In
the absence of the identifying "hand," the telegraph clerk's and the censor's
mark cannot be distinguished from the author's (a common literary plot device
in the fiction of the period). The notion of a telegram's "fidelity" therefore
becomes an attribute of the communication channel as a whole (instead of an
attribute attached to authorial intent).
## 5.3 Smart Contracts (A Legal Interlude)

Legal fictions rise to veil the emerging affordances of
textual technology.

Exposing the Document Object Model that governs the production of text through
contemporary reading and writing devices gives the question of surface and
depth yet another connotation. What lies beneath the text? We are accustomed to
thinking about document structure metaphorically and answer in accord: meaning,
narrative, representation, order, discourse, or ideology. Interpretation, at
that level of analysis, happens in the head, which physically limits the
possibility of depth to personal introspection, magnetic resonance imaging, or,
at best, to an archive of extant reader responses (which in themselves need
further interpretation).

Introducing the literary device as machine, gadget, or appliance into the
formula suggests another, more literal answer. Beneath a text one finds cloth
and wood pulp and, increasingly, also glass, plastic, liquid crystal, copper,
laminates, and silicone.

The move between paper and composite device carries with it a profound shift in
the physical affordances of the deep structure supporting all subsequent,
higher-order, surface-level representations of textuality. Not much space
separates ink from paper. There, textuality lies flat, in two dimensions. What
you see is truly what you get. Not so on the screen connected to other screens.
Networked and time-shared textuality extends into the third dimension, away
from the reader and deep into the bowels of the machine. The Open Systems
Interconnection (OSI) reference model of communication[^ln3-osi] describes no
less than seven layers: from the Application Layer, concerned with the
semantics of application ("all services directly comprehensible to the user
[@miller_iso_1981, 285] to the Physical Layer, providing the "mechanical,
electrical, functional, and procedural characteristics" of communication
[@ncs_open_1981; @ncs_national_1988; @day_revised_1995].[^ln3-layers] These
protocols further envelop a document already thickly stratified by the
Document Object Model.[^ln3-domlayer]

[^ln3-domlayer]: The DOM technically exists at the application layer of the OSI
model.

![A zoomed out view of the connected OSI model. Single node structure on the
left. Connected devices on the right. The user has access through the top-most
(application) level, outermost to the network [@piatkowski_iso-ansi_1980,
114-15].](images/osi.png)

These are the same layers that Alexander Galloway unites in a system of what he
calls decentralized and distributed control [@galloway_protocol_2006, 28-54].
It is distributed to be sure, although to what extent decentralized is a matter
of some debate. Like a good soldier, each device in the pictured network
internalizes dozens if not hundreds of protocols that enable the system to
function seamlessly as a whole (in the way, for example, that your machine can
at one moment connect to one wireless access point, and at another moment to
another, with minimal loss of connectivity). Yet, OSI protocols and the DOM are
also densely consolidated. They are, for example, legislated by specific
international governing bodies[^ln3-w3c], susceptible to the usual political
pitfalls of pan-global consortia.

Once bifurcated between storage and screen, the inscription travels along a
"pipeline" of protocols, undergoing a set of arbitrary transformations
throughout. On one device, that pipeline may extend just a few inches,
connecting disk storage and output display. On a network device that pipeline
can stretch across continents, spanning widely divergent regions of legal and
administrative control. The book you are reading here may be stored in another
state or country. Whatever the case may be, the subject encounters the
"protocol stack" from without, on the periphery of the onion-like network. When
paging through an electronic book (usually an OSI-compliant device displaying
DOM-structured files), for example, the reader has access only to the outputs
emanating from the application layer, and, at that, only at the exposed
"window" level of the DOM. The perceived "content" constitutes a small fraction
of the underlying "formal" topology. What you see is far less than what you
get.

[^ln3-w3c]: The International Standards Organization (ISO) in the case of OSI,
the Internet Engineering Task Force in the case of TCP/IP, and the World Wide
Web Consortium (W3C) in the case of the DOM.

The application layer stops at the subject. Access to the layers intrinsic to
device operation (and consequently to analysis) are sometimes "merely" obscured
and sometimes made illicit outright, as is arguably the case with U.S. Code,
Title 17, Chapter 12, §1201, titled "Circumvention of copyright protection
systems" and passed as part of the "Digital Millennium Copyright Act" (DMCA) in
1998. A literary scholar may be familiar with some provisions of American
copyright law governing text as surface representation: US Code, Title 17
extends "exclusive rights" to "copyright owners" of "literary works." The
rights include the ability to "reproduce," "to prepare derivative works," "to
distribute copies," and "to perform and to display publicly" (17.1.106).
Surface representation is further subject to professional rules of conduct,
embodied in practices of quotation, citation, and attribution (or lack thereof,
as plagiarism).

In practice, the easy reproducibility of digital text (and image) has served to
erode the efficacy of copyright restrictions as a system of laws and
regulations. The work of art in the age of digital reproduction has lost much
of its already tenuous hold on the material substratum.[^ln3-illusion] Copy
technologies from photocopiers, to desktop printers, to cheap magnetic storage
and peer-to-peer file sharing networks reduce the price of copying and
dissemination to near frictionless levels. The response from the film, game,
music, and publishing industries has been to transpose mechanisms of copyright
enforcement from legal down to the infrastructural levels of enforcement, as
software and hardware: from Code to code. In the words of Charles Clark, the
late British publisher and prominent copyright attorney, "the answer to the
machine is in the machine [@clark_copyright_1996, 81-82]"---by which he meant
that copyright enforcement should be taken up on the device level by the
International Standards Organization, the very body responsible for the DOM and
the OSI communication protocol stack [@clark_copyright_1996, 84].

As an example of how that might work, Clark cites the Copyright in Transmitted
Electronic Data Report (CITED), which suggests building "a tamper proof
software module which acts rather like indestructible tachometers installed on
long-distance coaches and lorries, recording everything that happens to the
copyrighted or commercially valuable material [...] The basic idea is to link
the 'valuable material' of intellectual property to a specific piece of
software and hardware" [@consortium_c.i.t.e.d._1994; @clark_copyright_1996,
83-84].

The emergence of embedded contractual enforcement at the level of the device
can be subsumed under the broader idea of "smart contracts." In his seminal
article on "Formalizing and Securing Relationships in Public Networks," Nick
Szabo explains that "smart contracts combine protocols, user interfaces, and
promises expressed via those interfaces to formalize and secure relationships
over computer networks" [@szabo_formalizing_1997]. Clark, CITED, and Szabo were
instrumental in the rise of smart contracts in the 1990s in an attempt to
redress the fading efficacy of legal copyright protections.[^ln3-smart] "Method
and System for Managing a Data Object so as to Comply with Predetermined
Conditions for Usage" (US5845281, issued in 1998) can be instructive in this
regard. Greg Benson and Gregory H. Urich, both of Sweden, write:

> The data object owner may want to have permanent secure control over how,
when, where, and by whom his property is used. Furthermore, he may want to
define different rules of engagement for different types of users and different
type of security depending on the value of particular objects. The rules
defined by him shall govern the automated operations enabled by data services
and networking. The owner may also sell composite objects with different rules
governing each constituent objects. Thus, it is necessary to be able to
implement variable and extensible control.

The data object, in this case, stands for any media content, from books to
music, video, and software. Rather then legislating rules for copying and
distributing media, the inventors suggest that the medium itself should contain
a control layer that would "comply with predetermined conditions of usage," in
a way that can be "universally adapted to the needs of both the owner and the
user of the data object" [@benson_method_1998, 2:55].

!["Concatenated control data and AVI file in memory" [@benson_method_1998].](images/avi-control.png)

!["Concatenated and encrypted control data and AVI file in memory"
[@benson_method_1998].](images/avi-control2.png)

The associated schematics (pictured here) show data and control codes
"concatenated" into the same underlying data structure (in this case, AVI media
container format). The seemingly innocuous "text control" layer of the 1960s,
used to specify formatting and visual style, was now extended to carry
mechanisms for legal control, tied to specific legislation.

The idea of smart contracts contains a notable artifact of implementation,
relevant to our discussion on surface reading. To the extent that control codes
are legible to the interpreter, they are also open to "abuse and
circumvention." For this reason, encryption plays a key part in the smart
contracts system. Once intertwined, data and control must be encrypted to
prevent "unauthorized access." This brings us to the glaring problem at the
very heart of smart contract implementation. The spirit of contractual law by
its very nature demands *explicit* consent. In the language of English common
law, contracts involve promises as "manifestation of intention," which "adopt
an external or objective standard for interpreting conduct
[@american_law_institute_restatement_1973, §1-2.]" The key words in this
passage are "external," "objective," and "interpretation."

By contrast, smart contracts, as described in the patent archive, must rely on
encrypted---that is, not human-legible---forms of tacit compliance: neither
external, objective, nor available for interpretation. The idea of encrypted
consent stands in stark opposition to a tradition of contract law that relies
on models of consent that involve expressed, mutual, explicit, and uncoerced
forms of acquiescence. Even if smart contracts were to be accompanied by
legible documentation (as Terms of Service, for example), the device user would
be compelled to blindly trust in the correspondence between the expressed
letter and the implicit mechanism of the document---the implementation still
enacted beyond scrutiny, as hidden, encrypted, and purposefully illegible
script.

Moreover, the Digital Millennium Copyright Act (DMCA) stipulates that "no
person shall circumvent a technological measure that effectively controls
access to a work protected under this title (17.1201.a.1.A)." The letter of the
law further specifies that to "circumvent a technological measure," in this
case, means "to descramble a scrambled work, to decrypt an encrypted work, or
otherwise to avoid, bypass, remove, deactivate, or impair a technological
measure, without the authority of the copyright owner (17.1201.a.3.A)." A
technological measure that "effectively controls access" is further defined as
a measure that "in the ordinary course of its operation, requires the
application of information, or a process or a treatment, with the authority of
the copyright owner, to gain access to the work (17.1201.a.3.B)." For a
literary scholar, that means that, when encountering a text on a digital
device, reading sometimes *must* limit itself to surface phenomena. An attempt
at reading for depth---to discover the implemented terms of a smart contract,
for example---may carry with it a set of official (even criminal)
sanctions.[^ln3-fairuse]

The short history of DMCA "anti-circumvention" provisions is already littered
with ambiguous case law, that the Electronic Frontiers Foundation believes to
have the effect of "stifling a wide range of legitimate activities," "chilling
free expression and academic research," "jeopardizing fair use," and "impeding
innovation [@von_lohmann_unintended_2010]." Several incidents stand out as
particularly relevant to the study of texts and literature. One, a security
researcher exploring the activity of censorship filters on public library
computers was threatened and forced to seek DMCA exemption from the Librarian
of Congress [@fry_circumventing_2009]. Two, a Russian programmer speaking at a
security conference was jailed and detained for several months for developing
software that converts Adobe electronic book files into `.pdf` format, in a
process that could potentially remove embedded digital rights management
protections [@ferullo_major_2004; @mueller_reinventing_2004;
@postigo_information_2010]. Finally, in 2005 Agfa Monotype Corporation took
Adobe Systems to court in a dispute over the Adobe Acrobat "Free Text" tool,
which allowed users to "change text annotations using Plaintiff's TrueType
fonts" without a license [@_agfa_2005; @lipton_c_2009; @von_lohmann_unintended_2010]. If they become precedent, any of these cases could conceivably
be used to physically limit the efficacy of reading, close and distant.

[^ln3-fairuse]: DMCA 1201 provides for a number of complicated exemptions,
which may, under some interpretations, sanction limited use for academic
purposes. See @liu_dmca_2003; @ku_critique_2004; @herman_catch_2005;
@armstrong_digital_2006.

The impact of DMCA and smart contracts on the practices of reading, writing, and
literary analysis is potentially immense. In the language of the DMCA, the
electronic book is not a book at all, but a "data object," in which the modest
copyright symbol gives way to "control layers [@fischer_digital_2003]." An
essay in the *Yale Journal of Law & Technology* explains it this way:

> While e-books and their print counterparts embody essentially identical
> content, from a transactional standpoint they differ considerably. Books are
> tangible goods that can be owned, sold, and passed on without express
> limitation--the Uniform Commercial Code (U.C.C.) governs their sale, while
> copyright law protects their content. But despite appearances, Kindle e-books
> are not, according to Amazon, sold at all: they are distributed under
> restrictive license terms, similar to downloaded software
[@seringhaus_e-book_2010, 150].

In these conditions, something like a poem or a novel must relinquish its claim
on the universal concrete. In doing that, it ceases to be literature and
becomes instead a device, firmly tied to its given physical affordances.
Reified as a concrete object, no longer lasting and universal, but rather
ephemeral and contingent, it is subject to the whims of the market. The device
now gains the ability to dynamically adapt itself "to the needs of both the
owner and the user." These adaptations could of course take a benign form, of
the kind suggested in "*Remix: Literatur*," where Michel Chaouli imagines a
device akin to a "literature equalizer," empowering readers to "tune" any given
text to their liking [@chaouli_remix_2009]. Don't really like intensifiers?
Just turn the "adverb knob" down! I hold on to the possibility of building such
a device with Chaouli. In the meantime, existing electronic book software and
hardware devices adapt themselves to the reader in less creative ways. Some
prevent simple copy and paste actions. Others can be used to censor and
surveil. For a textual critic, such instability of medium means analysis cannot
be confined to reading for surface meaning alone. How can close or distant
reading practices persist, when the reading device reconfigures a text
dynamically, to fit individual taste, mood, or politics?[^ln3-modern] Or, when
it simply prevents access to some of the content?

[^ln3-modern]: Note that these effects are not limited to contemporary
literature at all. In purchasing a medieval text, the reader still buys not a
text or a work but a device, which, despite the content being out of copyright
protection, may still restrict access to other, protected layers of device
function.

Smart contracts and DMCA are a conspicuous symptom ailing all text gadgets,
which offer only the illusion of flat textuality. Where a literary scholar
could hope to gleam the machinations of ideology from surface representation in
print, the literary device obscures literal flows of governance. Isomorphic
application design makes the situation worse in giving a measure of similarity
between page and screen (the definition of isomorphism), obscuring material
divergence beneath. The condition is not one of ephemeral, immaterial text, but
one of text burdened with hardware and illegible control structure. The task of
the critic becomes then to restore text to its proper mode of being in the
concrete universal: to give it permanence in the world of ideas and to free it
from its arbitrary material constraint. To lay bare the device literally would
mean to make the mechanisms of naked political control visible. For any sort of
reading to commence, one would first need to peel away the DOMs and the
OSIs---today a task fraught with legal consequence.

[^ln1-dirt]: Think of text as substance and literature as surface. The first is
like dirt where the second is gound. We play with one on top of the other.

[^ln1-gate]: Solid state memory technology, flash memory for example, store
information in capacitor "circuit states." This by contrast with
electromagnetic storage that works by modulating electrical charge over a
magnetic surface. Solid state capacitor storage was used in the earliest
computers [@kahng_semipermanent_1967, 1296], but was prohibitively expensive to
manufacture until well into the twenty-first century, when solid state drives
began to replace electromagnetic storage in consumer electronics. In an early
(1967) paper on "A Floating Gate and Its Application to Memory Devices," Kahng
and Sze explain: "A structure has been proposed and fabricated in which
semipermanent charge storage is possible. A floating gate is placed a small
distance from an electron source. When an appropriately high field is applied
through an outer gate, the floating gate charges up. The charges are stored
even after the removal of the charging field due to much lower back transport
probability [...] Such a device functions as a bistable memory with
nondestructive read-out features. The memory holding time observed was longer
than one hour" [@kahng_floating_1967, 1288]. See also @horton_experimental_1962
and @frohman-bentchkowsky_fully_1971 on "floating gate avalanche injection."

[^ln1-denning]: These stages correspond roughly to the "three generations of
electronic computing" outlined in Peter Denning's "theory of operating systems"
[@denning_third_1971].
