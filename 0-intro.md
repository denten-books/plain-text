# Computational Poetics: An Introduction

While I write these introductory remarks, a ceiling-mounted smoke detector in
my kitchen emits a loud noise every three minutes or so. A pleasant female
voice announces also "low battery." This is, I learn, a precaution stipulated
by US National Fire Alarm Code 72-108 11.6.6 (2013). The clause requiring a
"distinct audible signal before the battery is incapable of operating" is
encoded into the device. The smoke detector literally embodies that piece of
legislation in its circuitry. We thus obtain a condition where two meanings of
code---as governance and machine instruction---coincide. Code equals code.

I am at home, but I also receive a notification of the alarm on my mobile
phone. Along with monitoring apps that help make my home "smarter," the phone
contains most of my library. I often pick it up to read a book. The phrase
"reading a book," however, obscures a number of metaphors for a series of odd
actions.  The "book" is a small, thin black rectangle: three inches wide, five
inches tall, and barely a few millimeters thick. A slab of polished glass
covers the front of the device, where the tiny eyes of a camera and a light
sensor also protrude. At the back, made of smooth soft plastic, we find
another, larger camera. At the foot of the device, a grid of small
perforations indicates breathing room for a speaker and several microphones.
To "open" a book I touch the glass. The machine recognizes my fingerprint. I
then tap and poke at the surface until I find a small image that represents
both my library and book store, where I can "buy" and "borrow" books. Buying
or borrowing books does not, however, involve the possession of physical
objects. Rather, I agree to a licence that grants limited access to data,
which the software then assembles into something resembling a book on screen.
I tap again to begin reading. The screen dims to match room ambiance as it
fills up with words. A passage on the first page appears underlined: other
readers in my social circle must have found it notable. I swipe across the
glass surface to turn a "page." The device emits a muffled rustle to reinforce
the pretense of manipulating paper. The image curls ever so slightly as
another "page" slides into view. My tiny library metaphor contains hundreds of
such page metaphors.

Despite appearances, the electronic metaphor-making device on my desk has more
in common with smoke detectors than it does with several paper volumes
scattered on my desk. The electronic book and smoke alarm contain printed
circuit boards, capacitors, and resistors. Both draw electric current. Both
require firmware updates and both are governed by codes, political and
computational. Smoke alarms and mobile phones connect to the internet. They
communicate with distant data centers and with each other. Yet, I continue to
"read" these devices as if they were familiar, immutable, and passive objects:
just books. I think of them as intimate artifacts---friends even---wholly
known to me, comforting, and warm. The electronic book is none of those
things. Besides prose, it keeps my memories, pictures, words, sounds, and
thoughts. It records my reading, sleeping, and consumption habits. It tries to
sell me things, showing me advertisements for cars, jewelry, and pills. It
comes with a manual and terms of service. It is my confidant, my dealer, my
spy.

*Plain Text* concerns the nature of digital inscription---the material trace
that gives rise to textual phenomena, and, more broadly, to all cultural
artifacts in which computers mediate. We find ourselves today in an
unprecedented, since the Middle Ages, position of selective *asemiosis*: the
loss of signification. Many contemporary texts---like poems inscribed into
bacteria and encrypted software---exist simply beyond the reach of human
senses.[^ln-dna] Other forms of writing are illegible by design, in ways that
prevent access or comprehension. Increasingly, we write not in the sense of
making marks on paper but in simulation. Key presses leave lasting traces in
computer memory, which then appear on screen redoubled and ephemeral. On disk,
marks endure in a form legible only to those who possess the specialized tools
and training necessary to decipher them.

I appeal to the idea of "plain text" in the title of this book to signal an
affinity with a particular mode of computational meaning-making. Plain text
identifies a file format and frame of mind. As file format, it contains
nothing but a "pure sequence of character codes." Plain text stands in
opposition to "fancy text," "text representation consisting of plain text plus
added information" [@unicode_consortium_unicode_1990, 9-10]. In the tradition
of American textual criticism, "plain text" alludes to an editorial method of
text transcription which is both "faithful to the text of its source" and is
"easier to read than the original document" [@cook_considerations_1988].
Combining these two traditions, I mean to build a case for a kind of a
systematic minimalism when it comes to our use of computers---a minimalism
that privileges access to source materials, ensuring legibility and
comprehension. I do so in contrast with other available modes of
human-computer interaction, which instead maximize system-centric ideals like
efficiency, speed, performance, or security.

The title further identifies an interpretive stance one can assume in relation
to the making and the unmaking of literary artifacts. Besides visible content,
all contemporary documents carry with them a layer of hidden information.
Originally used for typesetting, that layer affects more than innocuous
document attributes like "font size" or "line spacing." Increasingly, devices
that mediate literary activity also embody governing structures. For example,
the Digital Millennium Copyright act, passed in the United States in 1996,
goes beyond written injunction to require in some cases the management of
digital rights (DRM) at the level of hardware. An electronic book governed by
DRM may subsequently prevent the reader from copying or sharing stored
content, even for the purposes of academic study.[^ln-dmca] In some
situations, the device may collect reader activity.

Machine instruction thus embodies new forms of technological control. To speak
truth to power---to retain a civic potential for critique---we must therefore
perceive the mechanisms of its codification. Critical theory cannot otherwise
endure apart from material contexts of textual production, which today emanate
from the fields of computer science and software engineering. Conversely, a
tighter coupling with the critical tradition can reveal technology's often
occluded political implications. To create a novel algorithm that predicts
crime by analyzing one's reading habits, for example, is also to invite the
dystopian possibility of thought policing, unless, that is, such algorithms
remain legible, in public view, and under continual counter-scrutiny. A
vibrant discursive practice of textual exegesis is crucial for the
preservation of whatever ideals that demand a literate populace.

## Thesis and Archive

*Plain Text* is a response to a particular situation of a literary scholar
encountering the field of software engineering. For a long stretch of my
professional life, these two areas of activity remained separate. I worked at
one and I studied the other. At the time, I simply did not think that code had
much to do with poetry. Initially, my two selves---the scholar and the
engineer---spoke different languages. Reconciling them was and continues to be
a disconcerting process by which things dear and familiar to me, in both
worlds, grew strange and unfamiliar, showing themselves to be sometimes less
than, and sometimes more than I comfortably expected. Nothing could be assumed
from the start. Field specific language, down to its foundations, had to be
examined for hidden assumptions that prevented dialog. With time, I saw that
code and poetry have much to do with one another. Writing this book has taught
me to embrace the remaining incongruence.

The idea for *Plain Text* came in a moment of realization, after I was asked
one of those seemingly naive but fundamental questions that can set research
in motion down a long and winding path.

A childhood friend who shares a love for reading asked why he could not lend
me a copy of the novel that he recently purchased from a major online
retailer.[^ln0-amazon] In my struggle to answer, I realized that some of my
deepest intuitions about literature relied on assumptions firmly attached to
print media. Despite my professional experience as a programmer and academic
training in literary studies, I could not readily explain the mechanisms by
which electromagnetic charges transformed into pixels and pixels into words.
Where to begin? To recount the passage of digital text, one has to know
something about chip architecture, operating systems, file permissions,
networking, and encryption. I could describe parts of that ecosystem, but my
knowledge was also riddled with unexamined gaps. It did not amount to a
coherent story.

Worse yet, it quickly became apparent that these technical details affect all
higher-level interpretive activity. To read together---to form a shared
understanding of a text---we had convene on the same page, which was made
difficult in our case by imposed geographic restrictions. The text changed as
it passed hands. I now had to draw on philology and sociology of literature to
reflect on textual variants, recensions, and authorship attribution. Digital
text was more obviously entwined with its reception history: reader reviews
and algorithmic recommendation engines. Despite the new copy, it was marked
and highlighted. It synchronized with other media like audio books and related
television promotions. The work was pre-processed, in both technical and
social senses of the word, to privilege certain meanings and modes of
comprehension.

The task of "coming to terms" with these emergent contingencies entails an
expansive research program, that could only be commenced here in part. The
digital literary ecosystem is evolving rapidly. A historical approach to its
development extrapolates its trajectory into the future. Crucially, digital
knowledge ecologies are only coming into being; they are still pliable, still
in their formative state. Their cultural importance necessitates active
commentary and experimentation. Without it, we risk the dominion of what
Langdon Winner has called "autonomous technology"---a condition by which
complex systems begin to irrevocably determine our politics. "Modern people
have filled the world with the most remarkable array of contrivances," Winner
wrote. We are then surprised to find them resistant to change. "The human kind
faces a woefully permanent bondage to the power of its own inventions," he
concluded. And I hope, along with him, that it is still possible to
"reconsider and reconstruct" those outcrops that in retrospect impoverish
culture, to "learn and start again," and to retain the "prospect of
liberation" [@winner_autonomous_1978, 335].

To these ends, *Plain Text* tells a story of a major morphological shift
affecting cultural production, particularly as it relates to the mechanics of
writing. Were I to interrupt a digital typist to ask---Where do these words
reside?---I would likely receive several conflicting answers in response. In
some sense, the words are on screen, where they appear to view. In another
sense, they are somewhere within the machine, on remote and hermeneutically
sealed surfaces: silicone chips, hard drives, flash memory cards. Yet in
another sense, visible signs are still further removed from the contexts of
their production. The word is in the wires. It spreads across servers,
routers, and data centers. What was once apparent now takes on a more complex
structure, stretched across planes and temporalities. The book---this book,
any book---gains a new shape. Digital texts form a live lattice---a
multidimensional grid---which connects the letter's tactile response, at one's
fingertips, to its optic and electromagnetic traces. In aggregate, these
*laminates* incorporate the scaffolding of synthetic inscription. I cannot
consequently pass a digital note to another, in the same sense that one passes
notes in class, on paper. It is impossible to give the entire structure over.
Text is irrevocably intertwined with its stratified material contexts. It
means---it *becomes*---something else when recreated under conditions not
fully congruent to my own.

Much contemporary anxiety about the intrusion of computational culture into
the everyday can be traced to such fundamental reshaping of the sign. Its
fracture leads to its multivalence. The lattice expands into spaces between
signs, where forces of capital and control intervene to monitor and
monetize.[^ln-capital] Many are vaguely aware that they no longer read or
write alone. Who shares the page? What forces contest that space for thought?
In this book we will confront the technological other, if not to answer such
questions, but to know where to look for answers.

Reflecting on the development of Morse Code in 1949 in the *Proceedings of the
American Philosophical Society*, Frank Halstead mentioned the difficulty of
finding a home in either the arts or sciences for what he called "code
development." "It is a matter somewhat related to the general art of
cryptology," he wrote, "yet it is not wholly divorced from electrical
engineering nor from general philology" [@halstead_genesis_1949, 456]. As
Halstead anticipated, research into codification has led me to a rich
multidisciplinary archive of materials from the history of literary theory,
semiotics, telegraphy, and electrical engineering from the middle of the
nineteenth to the end of the twentieth century. That archive includes patents
and technical manuals, formalist manifestos, studies of animal communication,
human-computer interaction textbooks, as well as foundational texts in
aesthetics and literary theory.

I deploy the archive to argue that extant theories of interpretation evolved
under conditions tied to static print media. By contrast, digital text changes
dynamically to suit its reader, political context, and geography.
Consequently, I advocate for the development of *computational poetics*: a
strategy of interpretation capable of reaching past surface content to reveal
platforms and infrastructures that stage the construction of meaning. Where
"distant reading" and cultural analytics perceive patterns across large-scale
corpora, computational poetics breaks textuality down into its minute
constituent components. It is a strategy of micro- rather than
macro-analysis.[^ln-iarkho]

In *Plain Text*, I will also argue that some of contemporary public sphere's
ideological afflictions---the acquiescence to routine surveillance and
censorship, for example---relate to our failure as readers and writers to come
to terms with the changing material conditions of digital text. A society that
cares about the long-term preservation of complex discursive formations like
free speech, privacy, or online deliberation, would do well to take heed of
the textual building blocks at their foundation. The structure of discursive
formation---documents and narratives---has long been at the center of both
computer science and literary theory. Using primary sources from both
disciplines, *Plain Text* uncovers the shared history of literary machines,
bringing computation closer to its humanistic roots, and the humanities closer
to its computational realities.

The book makes a historical case for the recovery of textual thought latent in
the machinery of contemporary computing. Just as literary scholarship cannot
survive without awareness of its computational present, the design of
computational platforms cannot advance without greater awareness of its
cultural contexts. The political struggle for meaning-making, the very
opportunity to engage in the act of interpretation, thus begins and ends with
the material affordances of the epistemic artifact.[^ln0-levine]

[^ln0-levine]: Affordances, as Caroline Levine explains, "describe the
potential uses or actions latent in materials and designs." For example,
"[g]lass affords transparency" where "[s]teel affords strength"
[@levine_forms:_2015, 6].  See also @hutchby_technologies_2001, 447.

The future of reading and writing is inexorably intertwined with the
development of computer science and software engineering. Even if you are not
reading these words on a screen, my message has reached you through a long
chain of machine-mediated transformations: from the mechanical action of the
keyboard on which I am now typing, to the arrangement of electrons on magnetic
storage media, to the modulation of fiber-optic signal, to the shimmer of the
flowing liquid crystal display rendering the text. Computation occupies the
space between keyboard and screen, which in turn gives rise to higher-order
cultural institutions: from the architecture of social media platforms to the
formation of massive shared archives. "Cultural techniques" that guide our use
of such technologies are formative of the society as a whole
[@leroi-gourhan_gesture_1993, 83-84; @siegert_cultural_2015]. Daily choices
like choosing a text editor, a filing system, or a social networking platform
cannot therefore be addressed in shallow instrumental, system-centric ideals.
Complex computational systems cannot give rise to ideals any more than
financial markets can. From the many available visions of human-computer
interaction I argue for choosing one that confirms to a humanist ethos,
whatever the reader's politics.

## Theory
### Displacement

*Plain Text* is ultimately an exploration of textual space.[^ln-space] It is
thus inherently concerned with the dynamics of settlement and displacement,
which frame the book's historical argument and form its theoretical
underpinnings.

[^ln-space]: I am influenced in this regard by the philosophical poetics of
Gaston Bachelard and Henri Lefebvre, extended into the realm of everyday
computation. See @lefebvre_production_1991; @bachelard_poetics_1994.

I mean settlement in the way one lives among and within one's own notebooks,
bookshelves, and archives. Smart toasters and electronic heart valves are
distinct from their dumb mechanical counterparts in that they similarly give
grounds to inscription. Computers are machines that need to perform reading
and writing operations at scale. To support that activity, they necessarily
found vast, in terms of information capacity, expanses.  Commercial, private,
and public interests rush in to colonize newly opened territories. Boundaries
are drawn. Areas of exclusion are created, even in our most intimate spaces:
bedsides, living rooms, kitchens, the heart and the mind: a diabetic is not
able to modify her insulin pump software; the smart television contains
proprietary firmware, controlled at a distance and without explicit consent.
The struggle is not one for virtual, but actual grounds for inscription.

These intimate territories are however remote, in that they unfold at quantum
scale. Individuals not privy to the mechanics of micromolecular writing are
hence in peril of unprecedented dispossession. I am concerned here with our
basic ability to shape discourse---to read and write---along surfaces that are
not available for immediate scrutiny. Poetics---the affordance of literary
space---physically limits the possibility of interpretation. A sign illegible
is one that never enters the hermeneutic circuit.

In making the case for a computational poetics, I am helped by recent
scholarship in the historically- and philosophically-inflected studies of
media and technology.[^ln0-influences] My notion of poetics builds also on the
long history of literary theory, in the genealogy of formalist and
structuralist schools. My approach is not however limited to the canonical,
straight-ahead structuralisms of Roman Jakobson or Jonathan Culler. I am
borrowing rather from a more peripheral tradition represented best by third
culture thinkers like Viktor Shklovsky and Vilém Flusser, consummate
immigrants both, who extracted a methodology out of the fabric of their
displacement.

Flusser in particular considered the condition of unease that comes with
migration, both physical and mental, to be a kind of information processing.
His thought was influential in making sense of my own displacements, first as
a refugee fleeing the dissolution of the former Soviet Union, then a
transplant into Silicon Valley from a strict literary education, and now a
lapsed engineer among humanists. These vantage points offer a singular view
onto the material conditions of contemporary intellectual life.

Both Shklovsky and Flusser wrote lucidly about the dynamics of settlement.
Their work sheds light onto an irresistible compromise, at the core of all
technology, by which we trade critical understanding for comfort. Habit covers
the various homes we make for ourselves in the world "like a fluffy blanket,"
Flusser wrote: "[i]t smoothes the sharp edges of all phenomena that it covers,
so that I no longer bump against them, but I am able to make use of them
blindly." When we sit at our desks, for example, we fail to see "papers and
books that are lying all about." We are used to them being there as they are
[@flusser_freedom_2003, 13; @finger_vilem_2011, 132]. We do not thereafter
parse them as information. Like water that surrounds fish, habituated things
pass into the background of experience. Mediums become media. They cease
producing meaning, become stages for meaning-making, and like a stage
disappear from view.

Losing sight of the material contexts of knowledge production is politically
perilous, because those who own the contexts set the terms of engagement.
Estrangement arrests material concealment. Exile allows the displaced to once
again transform habituated media into meaningful information. In exile,
"everything is unusual," Flusser wrote [@flusser_freedom_2003, 81]. Migrants
experience the world as ex-perience [*er-fahrung*], or literally a driving
out. Discovery, he concluded "begins as soon as the blanket is pulled away,"
where familiar objects can pass into view again [@flusser_freedom_2003, 82-3].

One could write, to take a simple example, "a field of study," without much
thought about figurative space. Shklovsky would have readers pause to consider
the implications [@shklovksy_sborniki_1917]. In what sense do ideas resemble
(or not) a field? The poet could take things further and elaborate: "to scythe
a verdant field of literary study." The verb (to scythe) and the adjective
(verdant) create an unexpected transference of new qualities not present in
the original image (intellectual field). These qualities "overdetermine" or
"saturate" the metaphor, exposing its conceit. One can do to fields of grass
what one cannot to ideas. Subsequently, we realize that the two
domains---intellectual and horticultural---do not map onto each other
perfectly, leaving a semantic remainder: the chaff. Readers discover
intellectual "fields" for what they are: habituated metaphors, neither natural
nor self-apparent. Metaphors are made strange again through purposeful
defamiliarization. To take the technique to its logical conclusion, a writer
could depict several fictional characters in the act of scything a field of
grass while discussing the relative merits of structuralism: a discussion
about the field on a field. Such literary artifice would make actual the
implied connections between fields of grass and ideas. The writer now shows
what was merely told before. The technique of defamiliarization finally renews
the figure: discarding hardened clichés while suggesting novel linkages
between constituent concepts: ideational chaff, leaves of mental grass,
combines of thought.

I would like to affect a similar sense of estrangement when it comes to our
use of technology. The formalists understood habituated metaphors to diminish
the vitality of experience. Shklovsky quotes from the diaries of Lev Tolstoy,
who, while dusting his room, could not remember if he had already dusted his
sofa. Tolstoy wrote:

> because actions like these are habituated and unconscious, I could not
> remember [...] whether I dusted and forgot or just did so without
> thinking---it was as if the action never happened [...] thus when life
> passes without conscious reflection, it passes as if one has not lived at
> all.

Shklovsky added that life so habituated disappears into nothingness, when the
automatization of experience "consumes things, clothing, furniture, your
spouse, and the fear of war."[^ln-brik]

The formalists rarely quoted Marx directly. Yet Marx resonated throughout.
For Marx, dead metaphors marked alienation from humanity.[^ln0-marx] The point
at which material artifacts disappear from conciousness is also one where they
appear within the social sphere as fetishes.

Shklovksy changed Marx's German alienation [*Entfremdung*], which for Marx
always denied life, into the Russian estrangement [*ostranenie*], literally an
"othering," of the kind that affirms it. The difference is one of agency. In
the first case, subjects are treated like objects by others. In the second,
they recognize and reject the objectified other within. Formalist
estrangement---sometimes also translated as defamiliarization---arrests the
momentum of tacitly received habit. Once estranged and extracted like a
splinter, ossified experience can be revitalized.

Our challenge today is to uproot ourselves from the comforts that rapidly
descend on the dwellings of our intellectual life. Dulling the senses,
seemingly inconspicuous conduits of agency---electronic books and smart
desks---acquire a sense of intelligence of their own. Devices that "watch,"
"hear," "see," and "think" give rise to object-oriented ontology and the
internet of things. A new generation of objects clamours for participatory
intelligence. They claim space in the home, near bed and hearth. Smart phones,
smart light bulbs, smart thermostats, smart homes, and smart watches, enter
the networked public sphere in the role of independent agents.[^ln-winner] A
conversation begins about their personhood: their levels of trust,
friendships, rights, and accountability [@bohn_living_2004;
@jianhua_ma_towards_2005; @calverley_android_2006; @hildebrandt_ambient_2007;
@atzori_smart_2014]. Marx's table that "evolves out of its wooden brain
grotesque ideas" now becomes Surface and PixelSense---product names of actual
smart tables, available for purchase [@marx_capital:_1906, 82;
@wigdor_designing_2009].

If we hope to understand digital culture and especially literature, as
Friedrich Kittler would write, "under conditions of high technology," we can
only do so from the position of humanism. One cannot otherwise lament the
systematic erasure of the human from the literary process and, at the same
time, advocate for a post- or anti-humanism. Unlike Kittler, who wrote that
under conditions of high technology "literature has nothing more to say," I
believe that literature and literary analysis continue to have a voice in
contemporary life [@kittler_gramophone_1999, 263]. Technology does
not---cannot be allowed to---determine literary silence. Rather, as the
material grounds for all reflective textual activity recede from view, readers
face the prospect of selective illiteracy.[^ln-digitalliteracy] The command of technologies like
networking and encryption separates those able to read and write under
conditions of high technology from those who no longer are: another
dispossession.

When we mistake things for animate actors, we ourselves become enmeshed in a
system of digital production that commodifies human experience. Objects that
surround us collect our reading habits, social interactions, and intimate
conversations. Agents that benefit from trade in personal data are neither
cyborgs nor post-human assemblages. The bargain that trades critical
understanding for comfort benefits specific, individual interests. To address
objects as if they could respond in kind shifts our attention from seats of
power to things powerless, inarticulate, and indifferent to our protestations.
One can no more extract justice from a smart desk than hold a bureaucracy
accountable. Notions of justice and accountability presuppose a robust model
of agency, absent in the assemblage.

The internal exile that we must undergo for smart books and smart desks to
come into view cannot compare in difficulty to the experience of physical
displacement that follows natural disaster, war, poverty, or political
instability. Yet, our systematic reluctance to take on even those small
intellectual discomforts that could lead to acts of localized dissent and
disobedience---to write using free software, build open archives, or share
memories in private---cannot be said to exist outside complex systems that
perpetuate inequity and violence globally. The emotional affirmation that
accompanies exuberant technesis---the ecstasy of constant communication, for
example---brings with it governing structures evoked in the name of law
enforcement and national security. Comfort and security constitute the same
ill-conceived bargain that leads to critical disempowerment. But where it is
difficult to imagine or to enact strategies of digital disobedience on a
universal scale, we can begin to address them through numerous minute
transactions that in aggregate brace everyday literary exchange. This we can
do now. Computational poetics begins with machines in our immediate proximity,
closest to thought and touch.

To pick up an electronic book and to take it apart may be against the law in
some jurisdictions [@fry_circumventing_2009]. Given the extent to which
emergent thought-things---epistemic artifacts like electronic books and smart
phones---participate actively in the production of meaning, we can no longer
employ strategies of interpretation at the level of ideology or representation
alone.[^ln-rhein] The praxis of close reading must reach down to the silicon
bedrock: material entities and physical structures that bear the weight of
interpretation. Literary theory, a discipline fundamentally engaged in the
exegesis of figurative trope, is therefore crucial to the understanding of new
computational environments, which have enveloped intellectual life through
metaphoric substitution. To read the machine is to learn how it is made, but
also to unpack the rich metaphors that guide our tactical engagement with the
word: the boot in rebooting, the wares in software, the bug and the joystick,
the interpreter and the shell.

### Settlement

Estrangement cannot however be practiced effectively in monologue. To produce
meaning, Flusser reminds us, it needs to become a dialogical, dialectical
practice. Perpetual exile is otherwise uninhabitable [@flusser_freedom_2003,
81]. Without the shelter of one's home, everything turns to noise. Information
cannot exist without dwelling, Flusser wrote, "and without information, in a
chaotic world, one can neither feel nor think nor act" [@flusser_freedom_2003,
12]. Estrangement thrusts the displaced into the chaos of unsettled existence.
With time, they make a new home, from which they can once again "receive noise
as information" and produce meaning. "I am embedded in the familiar," Flusser
wrote, "so that I can reach out toward the unfamiliar and create things yet
unknown" [@flusser_freedom_2003, 12]. A dialectics of exile leads to "informed
renewal" of shared space, through what Flusser called a "creative dialogue"
between the settled and the displaced [@flusser_freedom_2003, 84].

In *Plain Text*, I thus model the reciprocal movement to "making strange" on
the diverse practices of reverse engineering. Similar in method to what
Matthew Kirschenbaum called "forensic argumentation," reverse engineering
recalls the formalist strategy of structural decomposition.[^ln0-reverse] The
function of case studies in an engineer's education, as Henry Petroski
explained in his *Invention by Design*, is to understand the ways by which one
gets "from thought to thing" [@petroski_invention_1996, 3-7]. From thought to
thing would be another apt definition of poetics and an alternate subtitle to
this book. Along with literary and historical exposition, each of my chapters
contains at least one literary thought-thing. Each enacts a deconstruction---a
literal taking apart---of that device. The epistemic object is meant to
challenge received theoretical intuition.

Reverse engineering of literary devices reveals that not all texts are created
equal. In print, traditional distinctions between form and content lie flat.
The printing press embeds ink into paper, leaving no space between type and
page. Materially-minded critics like Johanna Drucker, Katherine Hayles, and
Jerome McGann have urged literary scholars to re-evaluate textuality in its
media-specific contexts [@drucker_digital_2001; @mcgann_radiant_2001;
@hayles_print_2004]. Their work reminds us that the flatness of digital text
is an illusion. Low-level operational intuitions governing textuality---ideas
about form, content, style, letter, and word---change profoundly as text
shifts its confines from paper to pixel.

A substantial gap separates visible text from its storage medium. The two
sites of inscription---screen and electromagnetic storage---are physically
incongruent. One must be translated, transformed into the other. Control codes
govern the process of trans-figuration, which brings with it physical control
at the level of platform and architecture. This is a layer where, for example,
we can find spyware and censorship filters, digital rights management and
advertisement delivery.

I propose we begin then with this obvious sense of difference between paper
and pixel: where print is governed by law from without, think for example of
England's Obscene Publication Acts, digital text is governed by code, from
within [On Obscene Publication Acts see @mccalman_unrespectable_1984;
@roberts_morals_1985]. I will go further than others to maintain that digital
text *is* code, in the sense that it is always parsed and potentially
executable [See discussion in @manovich_language_2002, 48;
@chun_software_2004, 27-8; @galloway_anti-language_2010]. Control binds to
content inextricably, to become an organ in the same unified corpus.

Changing material conditions of textual transmission push against familiar
ideas of literary criticism. For example, the easy reproduction of digital
text weakens the material basis for authorship attribution. Text that is easy
to copy is easy to cite and plagiarize. The weakening of the authorship
function makes certain ways of talking about ideas like "authorial intent" and
"fidelity to the original" difficult to sustain. The emergence of massive,
community-based writing initiatives like Wikipedia along with algorithms that
write spam or summarize news automatically, further erode notions of
authorship based on individual genius.

Author do not die, however; they continue to live and collect
royalties.[^ln-dead] Autopoiesis---literature writing or discourse speaking
itself---does not displace the social institution of authorship.[^ln-varela]
Codification merely makes the flows of poiesis less apparent. It is difficult,
but not impossible, for example, to find the programmer responsible for
sending spam or credit writers based on Wikipedia contribution history.
Spammers are sentenced just as notable Wikipedia contributors receive barn
stars in recognition of their efforts.

Extant models of literary transmission assume movement through passive and
immutable media. Paper constitutes the document of record, which, once
archived, does not change its contents. Philological techniques like genetic
criticism and forensic reading make it possible to reconstruct if not
"authorial intent," then at least a trace of an author's hand. In some
cases---think manuscripts and folios---we may even ascribe properties like
"fidelity" to "original" works of art. When media are immutable, one imagines
a causal chain of custody between works and their creators, who at some point
must have occupied the same contiguous time and space: the closer a parchment
to Shakespeare, the higher its evidentiary (and market) value.

The transition between Gutenberg press and Project Gutenberg, an online
library containing thousands of texts, complicates the linkage. Unlike pen and
paper, which come in direct contact with each other during writing, the bridge
between keyboard and screen passes through multiple mediating filters.
Writing itself becomes a programmed experience. We do not write in the
conventional sense of etching marks into a static host, "at the same time and
space." The act is a simulation displaced. We neither immediately touch nor
see the textual conduit. The visible does not correspond to the actual.
Simulated erasure for example, of the kind that happens when a writer presses
the backspace key, does not necessarily entail the corresponding erasure of
content on disk. The "erased" word could persist and even multiply across
other storage drives and devices. Erasure itself becomes a meaningful data
point, used to train algorithms or in evidence of intent to conceal. The
sign's fracture entails such palpable consequences.

Poetics reconstructs a sequence of willful delegation: from
thought---someone's thought---to thing. A discipline of close attention to the
minute particulars of encoding, transmission, storage, and the decoding of
texts reclaims a measure of intent and thereby authorial responsibility. In
many cases, we may not care to speak of it. One would hardly find Tolstoy "at
fault" for his *War and Peace*, for example. In other contexts, as when
unsolicited advertisement clutters bandwidth to the exclusion of other forms
of speech, we must. This may seem strange at first: to recover the subject in
the physical minutiae of the encounter between text and machine. The point of
contact between human, text, and device is significant because it is here, in
the liminal zone of semiotic exchange, where subjects disappear into machines
and where machines step forth as animated and seemingly intelligent actors.
Our ability to apprehend the politics of smart objects therefore depends on
the formulation of their poetics: how they are made.

## Method

> We cannot separate the two things: head and hand [...] the science of life
> [...] is a superb and dazzlingly lighted hall which may be reached only by
> passing through a long and ghastly kitchen [...] [W]e shall reach really
> fruitful and luminous generalizations about vital phenomena only in so far
> as we ourselves experiment and, in hospitals, amphitheaters, or
> laboratories, stir the fetid or throbbing ground of life.[^ln-bernard]

My approach to writing *Plain Text* stems from the desire to enact theory
capable of addressing the grim picture Friedrich Kittler painted at the end of
his influential monograph.[^ln-kittler2] By all accounts, Kittler was neither
a technological romantic nor Luddite. I hence understand his *Gramophone,
Film, Typewriter* as a call to action. When Kittler wrote that "media
determine our situation," he challenged his reader to choose between
complicity and defiance [@kittler_gramophone_1999, xxxix]. It was not a
statement of fact but the articulation of a question: What can one do to
counteract technological determinism? In what follows, I outline several
intellectual lineages---materialist, pragmatist, and experimental---which
frame my answer.

Critical theory at its best aims to see "the human bottom of nonhuman things"
[@horkheimer_critical_1982, 143]. As such, it is one of our most powerful
tools for analysis and resistance against technological determinism. Max
Horkheimer wrote that the issue "is not simply the theory of emancipation; it
is the practice of it as well" [@horkheimer_critical_1982, 233]. Recently,
scholars like Kathleen Fitzpatrick, Tiziana Terranova, and Trebor Scholz have
began to turn the tools of critical theory towards the instrumental contexts
of knowledge production [@scholz_digital_2013; @fitzpatrick_planned_2011;
@terranova_network_2004]. I join them to argue that in treating the
instruments of intellectual production and consumption uncritically, all of
us---readers and writers---accumulate an ethical debt. It is one thing to
theorize about the free movement of literary tropes across cultures and
continents, and quite another to have that theory appear in print behind
paywalls inaccessible to most global reading publics.[^ln-sarab] Similarly, a
theoretical distinction between form and content, when instantiated in
specific file formats like Microsoft Word (`.docx`) or Adobe Reader (`.pdf`),
establishes divisions of labor between editors, book sellers, and offshore
typesetting firms.[^ln-sweatshop] One group trades content in the economy of
prestige, another formatting in the economy of survival, yet another controls
distribution in economy of the market.

Distinctions of labor will persevere as long as theory persists in the
abstract. A materialist critique cannot achieve its stated aims without
purchase on the material world. Contemporary knowledge workers stare into
rectangular black boxes for a considerable part of their days, suspecting, in
the absence of other feedback, that their gaze is met in bad faith. Bad faith
points to a misalignment between thought and action.[^ln-sartre]

Connecting theories of meaning-making to their practice offers a way out of
the conundrum. The solution to connect "meaning" with "operational meaning"
thus belongs equally to a species of pragmatism, as it does to critical
theory. William James articulated the approach concisely when he wrote that
"reality is seen to be grounded in a perfect jungle of concrete
expediencies."[@james_pragmatisms_1907 233] For James and other pragmatists,
truth could not be found outside of that jungle, in the abstract. It always
entailed real consequences, causes, and effects.[^ln-pragma-truth] In his
essay "Pragmatism's Conception of Truth," James asked: "How will the truth be
realized? [...] [W]hat concrete difference will its being true make in
anyone's actual life? [...] What experiences will be different from those
which would obtain if the belief were false?"[@james_pragmatisms_1907 200]
Frank Ramsey, the young British philosopher close to Ludwig Wittgenstein,
would later write in a similar vein about meaning "defined by reference to the
actions."[@ramsey_foundations_2013, 155]

For a pragmatist, truth-carrying propositions of the shape "X is Y" (as in,
"the author is dead" or "art is transcendent") beg the questions of "Where?,"
"When?," "For whom?," and "What's at stake in maintaining that?" Following the
pragmatic insight of James and Ramsey, I will proceed with the conviction that
abstract categories like "literature," "computation," and "text" cannot
possibly be reduced to a number of essential, structural features. Rather, to
borrow from Wittgenstein's *Philosophic Investigations*, categories denote a
set of related practices that share in some familial
characteristics.[^ln-witt] In our case, imagine a tree diagram where the
branches of computation and textuality intersect and diverge in ways that we
have yet to untangle.

In an approach to *doing* theory, *Plain Text* joins the experimental turn
steering the academy toward critical practice, especially in fields
long-dominated by purely speculative thought. The experimental turn represents
a generation's dissatisfaction with armchair philosophizing.  Recall the
burning armchair, the symbol of the experimental philosophy movement. Joshua
Knobe and Shaun Nichols, some of the early proponents of the movement, explain
that "many of the deepest questions of philosophy can only be properly
addressed by immersing oneself in the messy, contingent, highly variable
truths about how human beings really are" [@knobe_experimental_2008, 3]. The
emergence of spaces where research in the humanities is done exemplifies the
same trend. In naming the locations of their practice "laboratories,"
"studios," and "workshops," humanists reach for new metaphors of labor. These
metaphors aim to reorganize the relationship between body, space, artifact,
knowledge, and inscription. In my lab and elsewhere, researchers have taken to
calling this approach "experimental humanities."

As an example of what I have been calling here the "experimental turn" in the
field of early modern history consider the preface to a recent volume on *Ways
of Making and Knowing*, edited by Pamela Smith, Amy Meyers, and Harold Cook.
They write that the "history of science is not a history of concepts, or at
least not that alone, but a history of the making and using of objects to
understand the world" [@smith_ways_2014, 12]. Smith translates that insight in
the laboratory, where, together with her students, she bakes bread and smelts
iron to recreate long-lost artisanal techniques. For those who experiment,
"book knowledge" and "artifactual knowledge" connect in practice.

Artifactual knowledge---from typesetting software to e-book readers and word
processors---shapes our everyday encounter with literature. Such technologies
should not be understood as value-neutral conduits of information. I follow
Lewis Mumford and Langdon Winner to argue that technology affects the exercise
of textual politics in subtle and profound ways [@mumford_authoritarian_1964;
@winner_artifacts_1980]. Artifacts cannot hold beliefs about politics.
Political power is rather exercised through them. For example, stairs do not
discriminate against the mobility impaired. The human failure to enforce
accessibility through specific legal and architectural choices does.
Typesetting software, e-book readers, and word processors similarly embody
implicit communication models: ideas about deliberation, ethics of labor,
discursive values, and views about "natural" human aptitude for
interpretation. The maker of the electronic book encodes how the book is sold
and where, minimum and maximum font size, the visibility of marginal notation,
the possibility of sharing, the availability of the critical apparatus.
Content in that sense is meant for further processing, in a way that maximizes
its extracted value. Contemporary documents are capable of structuring the
literary encounter to these ends according to the reader's economic status,
gender, race, age, location, or physical ability.

To what extent does the book in front of you permit or enable access?
Whatever the answer, a function of understanding the text includes the
explication of its physical affordances. An experimental approach to reading
enables the critic to "lay bare" the device. A literary scholar's version of
baking bread and smelting iron is to make literal the archaeology of media at
the level of the mechanism. In *Plain Text* we will unearth and excavate
textual machines. In practicing archaeology I contend that cardinal
literary-theoretical concepts---such as word, text, narrative, discourse,
author, story, book, archive---are thoroughly enmeshed in the underlying
physical substratum of paper and pixel. It follows that any attempt to
articulate the idea cannot attain its full expressive potential without a
thick description of its base particulates.

Luckily for us, reading and writing are not esoteric activities. They are
readily available to introspection. I will therefore occasionally encourage
readers to encounter the immediate contexts of their reading anew: to put down
the book or to lean away from a screen and to look at these textual artifacts
with strange eyes. In this movement of the body, I want to disrupt the mind's
habituated intuitions, pitting them against knowledge at hand and fingertip
knowledge: as when ruffling through the pages or typing at a keyboard. How
ephemeral is an electronic text, for example? The pragmatic answer lies not in
reductive universal propositions---very, or not at all---but in contingent
technological affordances attached to specific reading devices. What can a
reader do with this text, here and now? Where is it stored? Are readers given
dispensation to copy and paste? Do they have legal permission to quote at
length, to perform publicly, or to otherwise trans-mediate? Will the text
disappear when the reader closes the book's cover?

## Plan of the Present Work

The tangled pathways of inscription winding their way through the device exist
in relation to distinct communities of computational practice. A researcher
cannot for this reason expect to discover a single theoretical framework that
captures the complexity of digital text in motion. An engineer's use of the
words "code" and "poetry" differs from that of a poet's. The changing contexts
evoke a corresponding shift in operational definitions. This book is thus
neither a total history of modern computing nor a survey of literary theory.
Rather, the argument therein progresses from the action of the alphanumerical
keyboard switch, through copper and silicon, to liquid crystal and the
floating gate, and on towards the reader and the community. It is but one of
many possible passes through a cavernous black box.

At the core of the book's **first chapter** lies the notion of a modernist
literary device, understood both as literary technique and thought experiment
about intelligent machines, directly connected to the birth of modern
computing. A section on literary technique in the work of Percy Lubbock,
Walter Benjamin, and Mikhail Bakhtin opens the discussion. Materialist poetics
rise concomitantly alongside a mechanistic, rule-based view of language. In
this chapter I reconstruct a series of thought experiments first in the
writing of Ludwig Wittgenstein and then in Alan Turing's seminal paper on an
imaginary computer capable of reading and writing. The verbs to read and to
write imply a type of cognitive processing.  What does it mean to read and to
write for a machine? What about broken mechanisms of comprehension? At once a
device and an algorithm, the Turing machine blurs the boundaries between
software and hardware, code and content, intelligence and its imitation.

The *second chapter* begins with a question. What does it mean to turn a page,
I ask, when neither pages nor the action of turning them correspond to the
implied analogy? A close reading of the metaphor leads to an intellectual
history of human-computer interaction. It progresses from "conversational
programming" to "direct manipulation" schools, the latter shaped by theories
from cognitive linguistics and immersive theater. The logic of "directness"
culminates in the rapidly developing field of brain--computer interfaces. The
chapter concludes with a moment of speculative formalism, in which I consider
the possibility of affective literature, of the kind that eschews language and
representation.

Two rich intellectual histories collide in the **third chapter**: form in
literary theory and format in computer science. I show formatting as a process
that mediates between a text's intrinsic rules for construction and its
extrinsic shape, transforming one type of structure, a series of bits arranged
into tracks and sectors, into another, letters arranged into sentences and
paragraphs. I then draw a short history of text formats. It begins with
several "control characters" limited in function to actions like "carriage
return" or "stop transmission." With time, formats begin to encompass all
manner of machine instruction, including legal instrument to enforce digital
rights management and copy protection. A manufacturer's ability to censor or
to surveil digital text is contained within the formatting layer: from
electronic books that modify themselves to suit the reader's geographic
location to "smart contracts" that contain the rules of their own execution.

The **fourth chapter** charts the emergence of screen reading. Screens restore
a measure of visibility lost to electromagnetic inscription, with one major
side-effect. Fidelity between visible and archived inscription cannot be
guaranteed. Screen reading further happens on screens that refresh themselves
at a rate of around 60 cycles per second (Hertz). The digital word is
technically an animation; it moves even as it appears to stand still. This
property attunes the reader to a particular mode of apprehension, affecting
not just the physics but also the aesthetics of digital media. Works by
philosophers Henri Bergson, John Haugeland, and Nelson Goodman construe a
phenomenology of screen-based digital perception. The digital emerges not as a
medium's intrinsic property, but structure imposed from without. In the
extreme, that means that a censored *electronic* text can form a perfectly
*analog* artifact, despite being digital in all other senses of the word.
Conversely, texts in print are already "born digital," in the sense that
literary works like Shakespeare's *Hamlet* are amenable to "reliable processes
of copying and preservation" [@haugeland_analog_1981, 213-225]. Properties
that make media "digital" or "analog" reveal themselves to be neither
universal nor essential to the medium. The medium is not the message.
"Reliability and preservation of textual copies" may mean one thing to a
literary scholar, another to a software engineer or a legal professional, and
something entirely different to a librarian, I argue in the conclusion of the
chapter. It matters not what the text is, but what we can do with it.

The **fifth and final chapter** begins with a discussion of an apparent
paradox. A camp of media theorists and textual scholars in the 1990s conceived
of electronic texts as an ephemeral, almost immaterial, phenomenon. Text
shimmered and glared: it was spoken of in terms of hypertext, light writing,
and electricity. A generation of theorists that came after insisted on the
weighty materiality of electronic media. Reading began to engage the
morphology of rare metals, media archaeology, hard drive forensics. Both
accounts, I argue, capture an aspect of the same underlying condition. The
perceived image of an archived inscription splits from its source. The sign
plausibly resides both on screen and hard drive. It fractures, in some real
sense, diverging at the site its projection from the site of the archive.
Using materials from the history of telegraphy in the late nineteenth and
early twentieth centuries, I chart the gradual fissure and ultimate
illegibility of the newly composite sign. Marks made on punch cards and ticker
tape protruded through the medium. Although difficult to read, these forms of
machine writing were readily visible and therefore amenable to analysis. The
advent of magnetic storage forced the composite inscription into an opaque
conduit. Unable to perceive magnetic polarities without the aid of a machine,
readers often manipulated text blindly. In this way a typist would type
several sentences without seeing the printed output. The chapter identifies a
milestone in the history of human textuality: the moment at which the
inscription passed from view, giving rise to the sometimes conflicting but
nevertheless consistent accounts of digital textuality.

A short *conclusion* gestures towards the contemporary political consequences
of the material covered, discussing also the possibility of machine
phenomenology in relationship to humanism. Computational poetics, I maintain,
encourages users to become active thinkers, tinkerers, and makers of
technology. It understands digital environments to be also systems of semiotic
exchange, amenable to the construction and the deconstruction of meaning. I
further encourage those who may have considered themselves mere "users" of
computation to apply the same critical acuity they employ in the close reading
of prose and poetry to the understanding of code and machine. For text to
render on screen properly it must be encoded or translated from
machine-transmittable code into human-readable shape. Encoding constitutes a
primitive field of textual activity, at the crossroads of computer science and
the study of literature. Encoding matters because how texts are encoded,
transmitted, and stored decides who gets to decode, receive, and revise.

<!--- NOTES  --->
<!--- NOTES  --->
<!--- NOTES  --->

[^ln0-amazon]: The retailer has since introduced a program that allows for
limited sharing of materials, restricted by time and geography.

[^ln-bernard]: @bernard_introduction_1957, 3,15. On Bernard see
@petit_claude_1987; @sattar_aesthetics_2013; and @mcluhan_gutenberg_1962, 4 &
206.

[^ln-brik]: @shklovksy_poetika_1919, 104. Translations are mine unless source
cited explicitly in English.

[^ln-capital]: Scholars like Alexander Galloway, David Golumbia, Bernard
Harcourt have advanced critique along similar lines. See
@galloway_protocol:_2006, @golumbia_cultural_2009, and
@harcourt_exposed:_2015.

[^ln-dead]: See @barthes_death_1977; @foucault_what_1980; @nesbit_what_1987.

[^ln-digitalliteracy]: See for example @postman_technopoly:_1992;
@negroponte_being_1995; @davidson_now_2011; @obama_2016_2016.

[^ln-dmca]: See @ku_critique_2004; @ginsburg_legal_2005; and
@fry_circumventing_2009.

[^ln-dna]: See @bok_xenotext_2011 and @bok_xenotext:_2015: "I have been
striving to write a short verse about language and genetics, whereupon I use a
'chemical alphabet' to translate this poem into a sequence of DNA for
subsequent implantation into the genome of a bacterium (in this case, a
microbe called *Deinococcus radiodurans*---an extremophile, capable of
surviving, without mutation, in even the most hostile milieus, including the
vacuum of outer space)."

[^ln-iarkho]: I borrow the term "microanalysis" from the largely forgotten in
the West Russian literary scholar and member of the Moscow Linguistic Circle,
Boris Iarkho. In his *Methodologies of Exact Literary Study* (circa 1935-6) he
wrote, in my translation: "I understand 'atomism' as a sort of an ideal
aspiration, an orientation toward the liminally small. But under no
circumstances do I advocate working with hypothetical quantities, like
molecules, atoms, positrons, and so on, which are located beyond the limits of
perception. That this applied mythology gave us such splendid results in
chemistry, should not conceal its true nature. Tomorrow, all such explanations
of visible through the invisible could give way to other hypotheses, as was
the case with their no less fertile predecessors (elemental spirits,
phlogiston, and light ether). But the cell, the nucleus, and the chromosome
endure as lasting accomplishments of microanalysis. I suggest to move as far
as a microscope can reach, and no further" [@iarkho_metodologia_2006,
363-364].

[^ln0-influences]: Works by Finn Brunton, Wendy Chun, Lisa Gitelman, Yuk Hui,
Helen Nissenbaum, John Durham Peters, Mary Poovey, and Jonathan Sterne among
many others left their mark on this text.

[^ln-kittler2]: *Gramophone, Film, Typewriter* ends as follows: "And while
professors are still reluctantly trading in their typewriters for word
processors, the NSA is preparing for the future: from nursery school
mathematics, which continues to be fully sufficient for books, to
charge-coupled devices, surface-wave filters, digital signal processors
including the four basic forms of computation. Trenches, flashes of lightning,
stars---storage, transmission, *the laying of cables*."
@kittler_gramophone_1999, 263.

[^ln0-marx]: For more on alienation see the relevant discussion in
@marx_economic_1964 and @marx_theories_1963.

[^ln-pragma-truth]: For a more thorough discussion on the topic see
@seigfried_william_1990, @pihlstrom_structuring_1996, and @putnam_jamess_1997.

[^ln0-reverse]: @kirschenbaum_mechanisms:_2008, 15. On the role of reverse
engineering in media studies see also @fuller_evil_2012, 9.

[^ln-sarab]: See also @english_economy_2008; @brouillette_wither_2015 and
@brouillette_unesco_2015.

[^ln-sartre]: Sartre would write "transcendence" and "facticity." See
@sartre_being_1993, 86-119.

[^ln-spam]: For example, in 2004 researchers estimated that spam mail makes up
40%-80% of the total email volume @cournane_analysis_2004.

[^ln-sweatshop]: See @freeman_high_2000 and @patel_working_2010.

[^ln-rhein]: I am in influenced here by the discussion of epistemic things in
@rheinberger_toward_1997, 24-37.

[^ln-varela]: See @varela_autopoiesis:_1974; @barthes_rustle_1989, 5;
@nuttall_new_2007, 6-25.

[^ln-winner]: See for example: "[w]riters concerned with with problems of
technology-out-of-control have frequently echoed Hobbes in suggesting that
such an artifact---the Leviathan of interconnected technical systems---has a
soul of its own [...] A ghost appears in the network. Unanticipated aspects of
technological structure endow the creation with an unanticipated *telos*"
[@winner_autonomous_1978, 280].

[^ln-witt]: @wittgenstein_philosophical_2001, 67-77. For more on the
connection between Wittgenstein and James see @goodman_james_2004.

\newpage
