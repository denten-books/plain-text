# Computational Poetics: An Introduction

This book is about the strange entanglement between humans, texts, and
machines. It examines key literary theoretical ideas alongside the
intellectual history of software engineering that frame contemporary reading,
writing, and interpretation practices. It is a deeply materialist work, in
which I argue that even our most ingrained intuitions about texts are
profoundly alienated from the physical contexts of intellectual production. A
new kind of poetics is therefore necessary to preserve the free play of ideas
implicit in the method of humanistic inquiry. Often, the work of literary
theory defines itself in terms of specific texts, as a series of readings. My
object of study is instead the nature of textuality itself. I am interested
here in how texts are produced; in the metaphors that guide computation; in
the forms, formulae, and formats that structure human-computer interaction; in
the literary device; and in the strange shape of contemporary inscription,
which, no longer a single mark on paper, stretches between the site of
fleeting projection, the screen, and the site of storage in its solid,
archival state. In quite another sense, this book is about more than words,
screens, and archives: it reasons through the dynamics of technological
settlement and displacement, through the comforts and the discomforts of
inhabiting our numerous extensions of self, our media homes.

While I write these introductory remarks, a ceiling-mounted smoke detector in
my kitchen begins to emit a loud noise every three minutes or so. A pleasant
female voice announces also "low battery." This is, as I learn, a precaution
stipulated by US National Fire Alarm Code 72-108 11.6.6 (2013). The clause
requiring a "distinct audible signal before the battery is incapable of
operating" is not only required by law, it is encoded into the device. The
smoke detector embodies that piece of legislation in its circuitry. We thus
obtain a condition where the two meanings of code---as governance and machine
instruction---coincide. Code equals code.

I am at home, but I also receive a notification of the alarm on my mobile
phone. Along with monitoring apps that help make my home smarter, the phone
contains most of my library. I often pick it up to read a book. However, what
I mean by "reading a book" obscures a number of metaphors for a series of odd
actions. The "book" is a small, thin black rectangle: three inches wide, five
inches tall, and barely a few millimeters thick. A slab of polished glass
covers the front of the device, where the tiny eyes of a camera and a light
sensor also protrude.  At the back, made of smooth soft plastic, we find
another, larger camera. At the foot of the device a grid of small perforations
indicate breathing room for a speaker and several microphones. To "open" a
book I touch the glass. The machine recognizes my fingerprint almost
instantly. I then tap and poke at the surface until I find a small image that
represents both my library and the book store, where I can "buy books." Buying
books does not actually involve ownership or books. Rather, I agree to a
licence that grants limited access to data, which the software then assembles
into something resembling a book on the screen. I tap again to begin reading.
The screen dims to match room ambiance as words fill the screen. One of the
passages on the first page appears underlined: a number of other readers in my
social circle must have found the passage notable. My finger slides along the
glass surface to turn a "page." The device emits a muffled rustle to reinforce
the pretense of manipulating paper. The image curls ever so slightly in a way
that resembles the printed page as another "page" slides into view. My tiny
library metaphor contains hundreds of such page metaphors.

Despite appearances, the electronic metaphor-making device next to my computer
has more in common with the smoke detector than it does with several paper
volumes scattered across my desk. The electronic book and the smoke alarm
contain printed circuit boards, capacitors, silicone chips, and resistors.
Both draw electric current. Both require firmware updates and both are
governed by codes, political and computational. The smoke alarm and the mobile
phone connect to the internet. They communicate with remote data centers and
with each other. And yet, I continue to read electronic books as if they were
familiar, immutable, and passive objects: just books. I think of them as
intimate artifacts---friends even---wholly known to me, comforting, and warm.
The electronic book is none of those things. Besides prose, it keeps my
memories, pictures, words, sounds, and thoughts. It records my reading,
sleeping, and consumption habits. It tries to sell me things, showing me
advertisements for cars, jewelry, and pills. It comes with a manual and terms
of service. It is my confidant, my dealer, my spy.

## Thesis and Scope

My aim in this book is to dispel a pervasive illusion. The electronic book
draws a compelling figure that belies material realities of reading and
writing, transformed by the advent of computation. The device on my desk is
not a book, but a simulation of a book. And everything associated with reading
this metaphor must in itself be understood under the sign of
simulation.[^ln0-manovich] What kind of a metaphor is it? How did it come into
being and how does it affect practices of literary interpretation? In *Plain
Text* I attempt to come to terms with the conditions of *simulated
textuality*.

[^ln0-manovich]: See @manovich_there_2011, 53-106.

"Software's ghostly presence produces and defies apprehension," Wendy Chun
wrote in her *Programmed Visions* [@chun_programmed_2011, 3]. But what happens
when all text is a type of software? Friedrich Kittler ends his book on a
similar note: in his vision, literature has finally been defeated by
technologies of military-grade encryption, secrecy, and obfuscation
[@kittler_gramophone_1999, 263]. Attempts to silence print through book
burning or censorship are viscerally obvious and met with nearly universal
disapproval. Unlike censorship or the burning of books, the dominion of
computation proceeds by clandestine means. The simulation-producing nature of
computed text preserves the outward appearance of printed text, while
concealing the specifics of discipline and control. I mean discipline and
control in the sense of shaping affordances: a mode of physical regulation
that structures the production, access, and the distribution of knowledge. The
challenge of *Plain Text* will be in the description of such emerging but
often occluded technological possibilities.

A concern with the material conditions of simulated textuality leads us to a
rich archive of materials from the history of literary theory, semiotics,
telegraphy, and electrical engineering from the middle of the nineteenth to
the end of the twentieth centuries. Reflecting on the development of Morse
Code in 1949 in the *Proceedings of the American Philosophical Society*, Frank
Halstead mentioned the difficulty of finding a home in either the arts or
sciences for what he calls "code development." He wrote, "it is a matter
somewhat related to the general art of cryptology, yet it is not wholly
divorced from electrical engineering nor from general philology"
[@halstead_genesis_1949, 456]. As Halstead anticipated, research in the field
of code development and computational culture has led me to a range of primary
materials: from the proceedings of the Association for Computing Machinery
(ACM) to the US Patent and Trademark Office; from Bell Labs to early Soviet
publishing houses that heralded the advance of formalism; from studies on
animal communication behavior, to Unix manuals, to textbooks on semiotics, and
to foundational texts in the philosophy of aesthetics and literary theory.

I deploy the archive to argue that extant theories of interpretation evolved
under the conditions tied to static print media. By contrast, electronic text
changes dynamically to suit its reader, political context, and geography.
Consequently, I argue for the development of what I term *computational
poetics*: a strategy of interpretation capable of reaching past surface
content to reveal the software platforms and the hardware infrastructures that
contribute to the construction of meaning. Drawing on a range of materials at
the intersection of literary thought and the history of modern computing,
*Plain Text* examines a number of key literary-theoretical constructs,
grounding contemporary practices of interpretation within the material
contexts of digital production.

I appeal to the idea of "plain text" in the title of this book to signal an
affinity with a particular mode of computational meaning-making. Plain text
identifies a file format and a frame of mind. As a file format, it contains
nothing but a "pure sequence of character codes." Plain text stands in
opposition to "fancy text," "text representation consisting of plain text plus
added information" [@unicode_consortium_unicode_1990]. In the tradition of
American textual criticism, "plain text" alludes to an editorial method of
text transcription which is both "faithful to the source" and is "easier to
read than the original document" [@cook_considerations_1988]. Combining these
two traditions, I mean ultimately to build a case for a kind of a systematic
minimalism when it comes to our use of computers---a minimalism that
privileges access to source materials, ensuring legibility and comprehension.
I do so in contrast with other available modes of human-computer interaction,
which instead privilege maximizing system-centric ideals like efficiency,
speed, performance, or security.

My use of plain text implies also a poetics of reading and writing. The title
therefore further identifies an interpretive stance one can assume in relation
to the making and the unmaking of literary artifacts. Besides visible content,
all contemporary documents carry with them a layer of hidden information.
Originally used for typesetting, that layer affects more than innocuous
document attributes like "font size" or "line spacing." Increasingly, devices
that mediate literary activity also embody structures of governance and
control. These tacitly encoded agents police intellectual property laws; they
censor and carry out surveillance operations. For example, the Digital
Millennium Copyright act, passed in the United States in 1996, goes beyond
written injunction to require in some cases the management of digital rights
(DRM) at the level of hardware. An electronic book governed by DRM may
subsequently prevent the reader from copying or sharing stored content, even
for the purposes of academic study.[^ln-dmca] In some situations, it may
report the reader's activity to the authorities. Building on the recent work
of scholars like Wendy Chun, Tung-Hui Hu, Finn Brunton, Helen Nissenbaum, and
Lisa Gitelman I make the case for an empowered *computational poetics*, a
method of inquiry that aims to bring tacit control structures once again under
the purview of interpretation and critique [@chun_programmed_2011;
@gitelman_paper_2014; @hu_prehistory_2015; @brunton_obfuscation:_2015].

My notion of poetics builds also on the long history of literary theory,
combined here with practices borrowed from software engineering and computer
science. Poetics, in the way I am using it here, concerns itself simply with
the construction of literary media artifacts. These are not however limited to
the canonical, straight-ahead structuralisms of Roman Jakobson or Jonathan
Culler. I am borrowing rather from a more peripheral tradition represented
best for me by third culture thinkers like Viktor Shklovsky and Vilém Flusser,
consummate immigrants both, who extracted a literary and a media theory
respectively out of the fabric of their emigration. The purpose of this
introduction is in part to recreate for the reader the winding path that
anticipated the making of this book. It passes first through a kind of a
productive tension between estrangement and habituation, which although
stemming from a personal experience of geographic displacement, leads to a
dialectics, that is, a method of making sense out of conflicting and often
contradictory logics of the virtual. In the section that follows, I outline
some of the methodological considerations that motivate my approach to the
study of media in general and of text in particular. Finally, I would like to
draw attention to the plan of the present work.

## Theory
### Displacement

To come to terms with the conditions of simulated textuality *Plain Text*
enacts a displacement of vocabularies. It is a response to a particular
situation of a literary scholar encountering the field of software
engineering. For a long stretch of my professional life, these two areas of
activity remained separate. I worked at one and I studied the other. At the
time, I simply did not think that code had much to do with poetry. The idea
for the book came to me in a moment of realization after I was asked one of
those seemingly naive but fundamental questions of the kind that can set
research in motion down a long and winding path. A childhood friend who loves
books asked about the difference between text in print and text on the screen.
In my struggle to answer, I realized that some of my deepest assumptions about
literature relied on the centuries-long stability of print media. Despite my
professional experience as a programmer and academic training in literary
studies, I could not readily explain the mechanisms by which keystrokes turned
into pixels, pixels into letters, and letters into words. I could recount
technical detail on some level, but my knowledge was also riddled with
unexamined gaps. It did not amount to a coherent story. I was, despite my best
efforts, surrounded by magical lanterns that cast shadows of code and poetry.

Initially, my two selves---the scholar and the engineer---spoke different
languages. Reconciling them was and continues to be a disconcerting process by
which things dear and familiar to me, in both worlds, grew strange and
unfamiliar, showing themselves to be sometimes less than, and sometimes more
than I comfortably expected. Nothing could be assumed from the start. Field
specific language, down to its foundations, had to be examined for hidden
assumptions that prevented dialog. With time, I saw that code and poetry have
much to do with one another. Writing this book has taught me to embrace the
incongruence.

Two theorists of text, media, and displacement have shaped my general approach
to computational poetics: the literary formalist Viktor Shklovsky and the
media philosopher Vilém Flusser. Flusser in particular considered the
condition of unease that comes with emigration, both physical and mental, to
be a type of information processing. His work was instrumental in making sense
of my own displacements, first as a one-time refugee fleeing the dissolution
of the former Soviet Union, then a former transplant into Silicon Valley from
a strict literary education, and now a lapsed engineer among humanists. These
vantage points offer me a singular view onto the material conditions of
contemporary intellectual life.

Both Shklovsky and Flusser wrote lucidly about the dynamics of habituation.
Their work helps us see the irresistible compromise at the heart of all
technology, a compromise by which we trade critical understanding for comfort.
Habit covers the various homes we make for ourselves in the world "like a
fluffy cotton wool blanket," Flusser wrote: "it smoothes the sharp edges of
all phenomena that it covers, so that I no longer bump against them, but I am
able to make use of them blindly." When we sit at our desks, for example, we
fail to see the "papers and the books that are lying all about." We are used
to them being there [@flusser_freedom_2003, 13 and 82]. Consequently, we do
not parse them as information. Like water that surrounds fish, the habituated
thing passes into the background of experience. Mediums become media. They
disappear into the background, cease producing meaning, become a stage for
meaning-making, and like the stage disappear from view.

The condition of exile, by contrast, allows the displaced to once again
transform habituated media into meaningful information. In exile, "everything
is unusual," Flusser wrote [@flusser_does_2011, 81]. The migrant experiences
the world as an ex-perience [*er-fahrung*], or literally a driving out.
Discovery, he concluded "begins as soon as the blanket is pulled away," where
the familiar objects can pass into view again [@flusser_does_2011, 86-7].

One could write, for example, "a field of study," without much thought about
figurative space. Shklovsky would have the reader pause to consider the
implications [@shklovksy_sborniki_1917]. In what sense do ideas resemble (or
not) a field? The poet could further make this metaphor strange. To evoke a
light-hearted illustration one could write: "to scythe a verdant field of
literary study." The verb (to scythe) and the adjective (verdant) create an
unexpected transference of new qualities not present in the original image
(intellectual field). These new qualities "overdetermine" the metaphor,
exposing its conceit. The reader discovers "intellectual fields" for what they
are: habituated metaphors, neither natural nor self-apparent. The metaphor is
made strange again through purposeful defamiliarization. To take the technique
to its logical conclusion, a writer could depict several fictional characters
in the act of scything a field of grass while discussing the relative merits
of structuralism: a discussion about the field on a field.  Such literary
artifice would make actual the implied connections between a field of grass
and a field of ideas. The writer now shows what was merely told before. The
technique of defamiliarization finally renews the figure: discarding hardened
clichés while suggesting novel linkages between constituent concepts:
intellectual chaff, leaves of mental grass, the combines of thought.

When pursuing scholarly estrangement the author "lays bare" and "makes
obvious" the metaphor by drawing attention to its inner dynamics. Metaphors,
as Lakoff and Johnson famously argued, do more than decorate---they structure
everyday human activity. The metaphor shapes one system of conceptual
relationships in terms of another. For example, the military image of
"fortification defense" implies a conceptual system structuring the "defense
of an argument." When actually defending the argument, a speaker guided by the
metaphor acts in a way that resembles combat. A different metaphor could
suggest a less combative mode of engagement between interlocutors
[@lakoff_metaphors_1980, 3-14].

The Russian formalists of the early twentieth century understood estrangement
as a matter of everyday practice, beyond linguistic analysis. Shklovsky and
his fellow travellers were concerned with the automatization of human
experience, a process by which metaphors lose their evocative power through
repeated use. Such metaphors become mere machines that convey meaning, and,
when habituated, disappear from view. According to Kantian views on the free
will, in vogue in Russia at the time, a reasoned being should proceed through
life with the assumption of personal autonomy, structuring one's own
experiences according to the principles of self-directed action. The
habituated metaphor instead guides action from without and furtively. It is
given rather than understood.  Estrangement emerges therefore as a model of
human liberation. It frees thought from the tyranny of automatism
[@shklovksy_sborniki_1917, @shklovsky_hod_1923, @boym_estrangement_1996,
@holquist_minding_2005]. By laying bare the mechanisms of the implicit
metaphor, we are thus able to recover agency lost to the blind mechanization
of thought. Through defamiliarization readers discover the principles behind
their actions: free to accept some parts of the conceptual transference (the
intellectual field *is* "verdant"!) and to reject others (but let us not "use
combines" to "harvest" it).

Our challenge today is to uproot ourselves from the comfort that rapidly
descends on the dwellings of our intellectual life. Dulling the senses,
seemingly inconspicuous conduits of agency---electronic books and
desks---acquire a sense of intelligence of their own. Devices that "watch,"
"hear," "see," and "think" give rise to object-oriented ontology and the
internet of things. A new generation of objects clamours for participatory
intelligence. Smart phones, smart light bulbs, smart thermostats, smart homes,
and smart watches, enter the networked public sphere in the role of
independent agents.[^ln-winner] A conversation begins about their personhood:
their levels of trust, friendships, rights, and accountability
[@bohn_living_2004; @jianhua_ma_towards_2005; @calverley_android_2006;
@hildebrandt_ambient_2007; @atzori_smart_2014]. Marx's "table that evolves
grotesque ideas out of its wooden brain" can now be re-branded into Surface
and PixelSense, names from the product life cycle of an actual smart table
made by Microsoft [@marx_captial_1906, 82; @wigdor_designing_2009].

I will argue here that if we hope to understand literature, to say after
Kittler, "under conditions of high technology," we can only do so from the
position of humanism. One cannot at the same time lament the systematic
erasure of the human from the literary process and advocate for post- or
anti-humanism. Unlike Kittler, who wrote that under conditions of high
technology "literature has nothing more to say," I believe that literature and
literary analysis continue to have a voice in contemporary life
[@kittler_gramophone_1999, 263]. Technology does not determine literary
silence. Rather, as the material grounds for all reflective textual activity
recede from view, readers face the prospect of selective illiteracy. The
command of technologies like networking and encryption separates those able to
read and write under the conditions of high technology from those who no
longer are.

To prevent the slide into illiteracy, instruments of literary analysis must
continue to evolve to elicit meaning under new technological contingencies.
Where texts are encrypted, we decrypt. If, as Kittler writes, automated
discourse analysis threatens to take command, we will engineer automatons that
command on our behalf. Together, small acts of resistance can mount to recover
a measure of agency from the ruling determinism of, take your pick: markets,
complex systems, unconscious drives, monistic universes, gaia science, social
networks, technology, the singularity, bureaucracy, war...  Indeed, the
possibility of human erasure---the loss of all sense---is never far, "like the
face drawn in the sand at the edge of the sea" [@foucault_order_1994, 387].
The fragility of life compels the need to mobilize whatever modest means
available for the human to persevere against daunting odds.

When we mistake things for animate actors, we ourselves become enmeshed in a
system of digital production that commodifies human experience. Objects that
surround us collect our reading habits, social interactions, and intimate
conversations. The actual living agents that benefit from the trade in
personal information are neither cyborgs nor post-human assemblages.  The
bargain that trades critical understanding for comfort benefits specific
interests, like multinational corporations and government intelligence
agencies. To address objects as if they could respond in kind shifts our
attention from the seats of power to things dumb, powerless, and indifferent
to our protestations.

The internal exile that we must undergo for smart books and smart desks to
come into view cannot compare in difficulty to the experience of physical
displacement that follows natural disaster, war, poverty, or political
instability. Yet, our systematic reluctance to take on even those small
intellectual discomforts that could lead to acts of localized dissent and
disobedience---to write using free software, to build open archives, to share
memories in private---cannot be said to exist apart from the complex systems
that perpetuate inequity and violence globally. The emotional affirmation that
accompanies exuberant social networking brings with it governing structures
invoked widely in the name of law enforcement and national security. Comfort
and security constitute the same ill-conceived bargain that leads to critical
disempowerment. But where it is difficult to imagine or to enact strategies of
digital disobedience on a universal scale, we can begin to address them
through numerous minute transactions that in aggregate brace everyday literary
exchange. This we can do now. Computational poetics begins with the machines
in the immediate proximity, those closest to the heart, thought, and touch.

To pick up an electronic book and to take it apart may be against the law in
some jurisdictions [@fry_circumventing_2009]. Given the extent to which
emergent thought-things like electronic books and smart phones participate
actively in the production of meaning, we can no longer employ strategies of
interpretation at the levels of ideology and representation alone. Close
reading, critical theory, and literary analysis must reach down to the silicon
bedrock that stages the act of interpretation. Literary theory, a discipline
fundamentally engaged in the exegesis of all figurative tropes, is therefore
crucial to the understanding of new computational environments, which have
enveloped intellectual life through metaphoric substitution.

I begin where Bernard Harcourt's recent book on digital disobedience ends:
with the possibility of localized dissent [@harcourt_exposed:_2015]. Following
itinerant theorists of the metaphor like Vilém Flusser and Viktor Shklovsky I
propose to proceed through a process of systematic estrangement of
computational metaphors; metaphors that fade into transparency as if to escape
the critical gaze. A strategy of deliberate defamiliarization reclaims the
metaphor-device for analysis. To come to terms with the book as a device; to
begin to understand the nature of the text simulation; to perceive the
particularity of the computed sign: these are the aims of *Plain Text*.

Computation advances into everyday life though metaphor. Like all tropes, such
metaphors lose their evocative power with frequent use. The task of a literary
scholar becomes then to explicate and to renew the trope, in search for
parallelisms that, as George Lakoff and Mark Johnson explain, configure one
conceptual system in terms of another [@lakoff_metaphors_1980, 3-14]. Why do
we call some software programs "applications" for example? The application of
what to what? Apple's iconic *Human Interface Guidelines*, a manual of style
that heralded the era of "what you see is what you get" interfaces, contains
explicit echoes of Lakoff's thought. The manual urges the designer to "convey
meaning through representation" and to seek the metaphor appropriate to the
task [@apple_apple_1987, 11]. Do not ask the user to throw "documents" into
"jars," for example, the manual entreats: "dragging the document icon to the
Trash means the user wants to discard that document" [@apple_apple_1987, 229]
Simulated objects must "look like they do in real world" [@apple_apple_1987].
In the words of cognitive scientists John Carroll and John Thomas, whose work
the Apple design guidelines also reference extensively, "people employ
metaphors in learning about computer systems." Using the appropriate metaphors
therefore provides "wide-ranging improvements in learning ability and ease of
use" [@carroll_metaphor_1982, 108]. What users know about trashcans in the
real world can guide interactions with virtual trashcans.

The rapid uptake of "what you see is what you get" interfaces pioneered by
Apple proved the effectiveness of metaphor-centric design. Through metaphor,
users are able to extend models of action from one domain into another.
Empirical studies have later shown the effectiveness of metaphor in the design
of human-computer interfaces [@blackwell_does_1999; @sallam_use_2009]. Flusser
would say that such figurative habituation makes experience more "smooth." The
user avoids "bumping into the sharp corners" of new and complicated virtual
environments. The metaphor conserves mental energy. Once internalized, it also
no longer attracts attention. The seminal work on figurative speech undertaken
by the Russian formalists at the turn of the twentieth century reminds us that
effective metaphoric shortcuts to learning have their cognitive downside.
Habituated experience passes into the unconscious [@shklovksy_poetika_1919,
104]. The thing "dries up" in Shklovsky's words, first in perception and then
in practice [@shklovksy_poetika_1919, 38 and 104]. The figure becomes so
familiar that we cease thinking about it---an early insight that was also
confirmed experimentally almost a century later.[^ln-cog]

The formalists understood such habituated metaphors to diminish the vitality
of experience. Shklovsky quotes from the diaries of Lev Tolstoy, who, while
dusting his room, could not remember if he had already dusted his sofa.
Tolstoy wrote:

> because actions like these are habituated and unconscious, I could not
> remember [...] whether I dusted and forgot or just did so without
> thinking---it was as if the action never happened [...] thus when life
> passes without conscious reflection, it passes as if one has not lived at
> all.

Shklovsky goes on to add that life so habituated disappears into nothingness,
when the automatization of experience "consumes things, clothing, furniture,
your spouse, and the fear of war."[^ln-brik] The formalists rarely quoted Marx
directly. Yet the echoes of Marx resonate throughout. The dead metaphor marks
the alienation of experience. The point at which material artifact disappears
from individual conciousness is the also the point where it appears within the
social sphere as fetish.

Early architects of human-computer interaction wrote their recommendations
with novice users in mind. The metaphor was supposed to ease the transition
into a virtual world. Once inside, the virtual inhabitant also began to
mistake metaphor for reality. The *Apple Design Guidelines* imply that
metaphor-based design would lead to learning and discovery. More than forty
years of computing under the guidelines have failed to produce a learned
public. This is evidenced by the frequent and urgent calls to digital literacy
on the part of our leading intellectuals, educators, and
politicians.[^ln-digitalliteracy] Instead of educating, the preference for
easy figurative tropes created shortcuts to knowledge. Once established, such
shortcuts continue to prevent users from literal engagement with computational
realities. Like Tolstoy's mindless dusting, life at the keyboard passes
without reflection. Worse yet, the trope obscures forces of capital,
governance, and control cloaked behind the innocuous figure.

Estrangement [*ostranenie*], sometimes also translated as "defamiliarization",
was the formalist answer to the ossified metaphor. Estrangement was meant to
recover the experience of the making of the thing, to name it, and to describe
it as if one encountered it for the first time [@shklovsky_voskreshenie_1914;
@shklovksy_sborniki_1917, 8]. The formalists found estrangement in art,
politics, and analysis alike [@jameson_prison-house_1972, 75-9;
@boym_estrangement_1996; @holquist_minding_2005]. In art, estrangement
proceeded through poetic experimentation: neologism, synecdoche, consonance,
or repetition, among other devices. Thus, the childlike incantation "a door
ajar" can evoke the etymological roots of the onomatopoeic "to jar" in the
sense of "to emit a harsh  sound"; the sense of the word as a vessel or a jar,
which comes from the Arabic *jarrah*; and to "ajar" which although relates to
the Old English *cyrr* or *cierr* in the meaning of "turn," as in "chore" or
"a turn of work", was in fact in the eighteenth century confused with jar in
the sense of "a harsh sound" to form the now rare "ajar" in the sense of "to
be in a jarring state; out of harmony; at odds; awry" [@_ajar_2015;
@_ajar_2015-1; @_jar_2015; @_jar_2015-1]. In this way the initial parallelism
between two usually unrelated words, a door and ajar, first creates a novel
analogy but then leads to renewed insight. Could the nonsensical *adoor* carry
the semantic weight of an adverb? Is it a chore to turn a jar? The
etymological play leads us to rediscover unexpected confluences in the words'
usage and origins.

Where estrangement in art could renew the word through suggestive, often
trans-rational [*zaum*] experience, in scholarly practice the formalists
adopted a scientific stance towards the object of their study. Unlike the
previous generation of critics who concentrated on the historical,
biographical, and philosophical aspects of literary formation, the formalists
wanted to reconstruct how the thing was made. For example, in his influential
essay on "How Gogol's *Overcoat* Was Made" Boris Eikhenbaum identified *skaz*,
or the manner of speaking, as an organizing principle for Gogol's satirical
narratives [@shklovksy_poetika_1919, 151-67]. What readers lost in having the
joke explained to them they gained in understanding of the genre.

I take a similar approach in *Plain Text* by extending formal concerns with
the mechanics of literary "device" and "technique" to literary devices and
technology proper. I too am interested in how the literary thing is made.
Computers, as I will argue throughout, are essentially machines for universal
symbolic manipulation. This property makes them particularly suitable for
figurative analysis, which aims to explicate concepts involved in the making
of the metaphor.[^ln-egturner] Influenced by the tradition of formal literary
exegesis in the work of scholars like Boris Eikhenbaum, Franco Moretti, and
Caroline Levine, my overarching aim in *Plain Text* is therefore to expose the
illusion of verisimilitude between text on paper and the simulated text on a
screen. The words may look the same, but the underlying affordances of the
medium differ in significant detail. Consider for example a news report that
alters its content based on the reader's location. Imagine also an e-book
reader that highlights popular passages of a novel in real time, shortening
the less popular passages down to their algorithmically distilled summaries.
For a literary analyst, the instability of the digital medium means analysis
cannot be confined to reading for surface meaning alone. How can close reading
persist when reading devices reconfigure the text to fit individual tastes,
mood, or politics? How would we even agree on the fact that we are reading the
same text? The very possibility of interpretation comes into question.

Estrangement cannot be practiced effectively in the mode of a monologue. To
produce meaning, Flusser reminds us, it must become dialogical practice.
Perpetual exile is otherwise uninhabitable [@flusser_freedom_2003, 81].
Estrangement thrusts the displaced into the chaos of unsettled existence. With
time, the displaced make a new home, from which they can once again "receive
noise as information" and produce meaning. "I am embedded in the familiar,"
Flusser wrote, "so that I can reach out toward the unfamiliar and create
things yet unknown" [@flusser_freedom_2003, 12]. The expellee and the settled
inhabitant need each other. The dialectics of exile lead to "informed renewal"
of shared space through what Flusser called a "creative dialogue" between the
settled and the unsettled [@flusser_freedom_2003, 84]. Without the protection
of one's home, everything turns to noise. There can no information without a
dwelling, Flusser wrote, "and without information, in a chaotic world, one can
neither feel nor think nor act" [@flusser_does_2011, 12]. By this dynamic,
displacement and habituation enter into a continuing conversation.

### Settlement

In *Plain Text*, I model the reciprocal movement to making strange on the
diverse practices of reverse engineering. Similar in method to what Matthew
Kirschenbaum calls "forensic argumentation," reverse engineering recalls the
formalist strategy of experiencing the "making of the thing" through careful,
case study-based reconstructions of textual mechanism
[@kirschenbaum_mechanisms_2008, 15]. The function of a case study in an
engineer's education, as Henry Petroski explains in his *Invention by Design*,
is to understand the ways by which one gets "from thought to thing"
[@petroski_invention_1996, 3-7]. Along with an exposition of a metaphor, each
of my chapters therefore also contains at least one literary "thought thing."
Each chapter enacts a deconstruction---a literal taking apart---of that
device.

The word processor, the operating system, and the electronic book are some of
the sites that stage the encounter between literary theory and practice today.
In *Plain Text* I introduce a method of computational poetics, which is a
form of textual analysis strongly influenced by materialist critique. Where
"distant reading" and cultural analytics perceive patterns across large-scale
copora, computational poetics breaks textuality down into its minute
constituent components. It is at this scale that I find readers and writers
becoming fundamentally alienated from the immediate material contexts of
knowledge production. Mine is not however a post-human materialism of the kind
that privileges an object's point of view. On the contrary, the book aims to
remove the aura of fetishism that attaches itself to literary--computational
artifacts and to complex systems that mediate the textual encounter.

The reverse engineering of literary devices reveals that not all texts are
created equal. In print, traditional distinctions between form and content lie
flat. The printing press firmly embeds ink into paper, leaving no space
between type and page. Media-minded critics like Johanna Drucker, Katherine
Hayles, and Jerome McGann have urged literary scholars to re-evaluate
textuality in its media-specific contexts [@drucker_digital_2001;
@mcgann_radiant_2001; @hayles_print_2004]. Their work reminds us that the
flatness of digital text endures only in the guise of an illusion. Low-level
operational intuitions governing textuality---ideas about form, content,
style, letter, and word---change profoundly as text shifts its confines from
paper to pixel. A substantial gap separates the visible text from the medium
where it is stored. In other words, pixels on a screen are literally removed
from the magnetic trace on the hard drive. The two sites of textuality---the
visible image and the archived inscription---do not come into direct contact.
Forces of capital and control exploit that gap, obscuring the workings of the
device.[^ln-capital]

Changing material conditions of textual transmission push against familiar
ideas of literary criticism. For example, the easy reproduction of digital
text weakens the material basis for the attribution of authorship. That is not
say that the author is dead; authors continue to live and to collect
royalties.[^ln-dead] The weakening of the authorship function merely makes
certain ways of talking about things like "authorial intent" and "fidelity to
the original" difficult to sustain. The emergence of community based writing
initiatives like Wikipedia and automated narrative generating machines like
spam bots further erode ideas of authorship based on individual
Autopoiesis---the idea of literature writing itself or discourse speaking
itself---does not displace the idea of the author.[^ln-varela] A discipline of
close attention to the minute particulars of encoding, transmission, storage,
and the decoding of text ultimately reclaims a measure of agency. This may
seem strange at first: to recover the subject in the physical minutiae of the
textual-technological encounter. Yet the point of contact between human, text,
and device is significant precisely because it is here, in the liminal zone of
semiotic exchange, where the subject seems to disappear into the machine and
the machine appears in the guise of an artificially intelligent actor.

Extant models of literary transmission assume movement through passive and
immutable media. Paper constitutes the document of record, which, once
archived, does not change its contents. Analytic techniques like genetic
criticism and forensic reading make it possible to reconstruct if not
"authorial intent," then at least a trace of the author's hand. In some
contexts---think manuscripts and folios---we may even ascribe properties like
"fidelity" to "original" works of art. When media are immutable, one imagines
a sort of a causal chain of custody between works and their creators, which at
some point must have occupied the same contiguous time and space. The printing
press introduced a range of structures that mediate between readers and
authors. Distance, time, and mediation subsequently weaken notions of
authorial fidelity. At the least, we understand that such intermediaries as
editors, publishing houses, and printing presses inject an element of noise
into the channel of communication.

The transition between the Gutenberg press and "Project Gutenberg," an online
library containing thousands of texts, has brought forth hitherto unexamined
possibilities. Unlike pen and paper which come in direct contact with each
other during writing, the contact between keyboard and screen passes through
another complex chain of mediation. Writing in that sense in itself becomes an
experience both programmed and simulated. We do not write in the conventional
sense of inscribing marks into a static medium. Rather, we are shown images of
inscription superimposed onto a simulation of the medium.

Neither the digital word nor the digital page exist in the way that they
appear in the word processor. At best, such composite tropes attain a measure
of similarity to the physical realities of typing, editing, and archiving
paper. Simulated erasure for example, of the kind that happens when the writer
presses the delete key, does not necessarily entail the erasure of content on
the disk. The erased word could persist and even multiply across other storage
drives and devices. In the worst case, the connection between keyboards and
screens suffers from intractable "man-in-the-middle" attacks, by which third
parties maliciously alter the content of intended communication
[@needham_using_1978].

In this book, I will argue that some of the higher-level political
afflictions of the contemporary public sphere---mass surveillance and online
censorship, for example---relate to our failure as readers and writers to come
to terms with the changing conditions of digital textuality. A society that
cares about the long-term preservation of complex discursive formations like
free speech, privacy, or online deliberation, would do well to take heed of
the textual building blocks at their foundation. The structure of discursive
formation---documents and narratives---has long been at the center of both
computer science and literary theory. Using primary sources from both
disciplines, *Plain Text* uncovers the shared history of literary machines,
bringing computation closer to its humanistic roots, and the humanities closer
to its computational realities.

*Plain Text* makes a historical case for the recovery of textual thought
latent in the machinery of contemporary computing. Just as literary
scholarship cannot survive without awareness of its computational present, the
design of computational platforms cannot advance without greater awareness of
its cultural contexts. Much is at stake in the material affordances of the
literary artifact. Affordances, as Caroline Levine explains, "describe
potential uses or actions latent in materials and designs." For example, glass
affords transparency where steel affords strength [@levine_forms:_2015, 6].
The affordances of a literary device ultimately constrain the ways in which
texts can be read and written [@hutchby_technologies_2001, 447]. The political
struggle for meaning-making, the opportunity to engage in the act of
interpretation, thus begins and ends with the material affordances of the
textual artifact.

It is easy to forget the blunt effectiveness of physical control in the global
North-west. Books that are burned or redacted cannot be read at all.
Elsewhere, inequities of access to knowledge compel readers to print their own
books and build their own libraries. Witness the so-called "shadow libraries"
of Eastern Europe and Central Asia, the street book vendors of India and
Pakistan, and the gray market presses of Nigeria arising form the country's
"book famine"[@mahmood_copyright_2005; @okiy_photocopying_2005;
@liang_piracy_2009; @bodo_short_2014; @nkiko_book_2014; @_elsevier_2015]. More
than mere piracy, such *samizdat*-like practices preserve the literary sphere
[@tenen_book_2014]. Informal book exchange networks create reading publics
that own the means of textual production and dissemination. Under duress,
readers build homemade knowledge infrastructures: they duplicate, distribute,
catalog, and archive. By contrast, in wealthier economies, such
infrastructures are commodified.  Consequently, the material contexts of
meaning-making---received passively, taken for granted---disappear from view.
For many readers, technologies that support reading, writing, and
interpretation pass from tools to fetish. No longer comprehensible by the way
of the pen or the printing press we imbue them with magical powers. Thus we
exist in the state of profound alienation from the material conditions closet
to our mental activity.

The future of reading and writing is inexorably intertwined with the
development of computer science and software engineering. Even if you are not
reading these words on a screen, my message has reached you through a long
chain of machine-mediated transformations: from the mechanical action of the
keyboard on which I am now typing, to the arrangement of electrons on magnetic
storage media, to the modulation of fiber-optic signal, to the shimmer of the
flowing liquid crystal display rendering the text. Computation occupies the
space between the keyboard and the screen, which in turn gives rise to
higher-order cultural institutions: from the architecture of social media
platforms to the formation of massive shared archives. The "cultural
techniques" that guide our use of such technologies are formative of the
society as a whole [@leroi-gourhan_gesture_1993, 83-84;
@siegert_cultural_2015]. Daily choices like choosing a text editor, a filing
system, or a social networking platform cannot therefore be addressed in
shallow instrumental, system-centric ideals. Complex computational systems
cannot give rise to ideals any more than financial markets can. From the many
available visions of human-computer interaction I argue for choosing one that
confirms to a humanist ethos, whatever the reader's politics.

Computational poetics encourages users to become active thinkers, tinkerers,
and makers of technology. It understands binary and digital environments to be
also semiotic and symbolic systems in essence, amenable to the construction
and the deconstruction of meaning. I further encourage those who may have
considered themselves mere "users" of computation to apply the same critical
acuity they employ in the close reading of prose and poetry to the
understanding of code and machine. For text to render on the screen properly
it must be encoded or translated from machine-transmittable code into
human-readable shape. Encoding constitutes a primitive field of textual
activity, at the crossroads of computer science and the study of literature.
Encoding matters because how texts are encoded, transmitted, and stored
decides who gets to decode, receive, and access.

The advent of simulated text necessitates a computational poetics, which
enables unfettered access to text, code, platform, and infrastructure.  For
now, commands like *xxd*, *pcap*, *ssh*, and *traceroute* resemble arcane
incantations that elicit hidden, symbolic action. Those who wield them gain
the metaphorical power to "hop" across, to "sniff" packets, to "survey," to
"traverse," and to "flood" network topographies. Computational poetics empower
the reader to resist hard-wired models of machine-bound interpretation.
Today, resistance remains the domain of the few. Plain text channels itinerant
streams of data back into the tidal pools of human agency and comprehension
for all. There, code can become intelligible for the very subjects whose loss
Foucault and Kittler lament.[^ln-lament] Only in such encrypted tunnels and
secure shells can anything like the digital humanities and new media studies
take root.

## Method

My approach to writing *Plain Text* stems from the desire to enact theory
capable of addressing the grim picture Friedrich Kittler paints at the end of
his influential monograph.[^ln-kittler2] Kittler was neither a technological
romantic nor a Luddite. I understand his *Gramophone, Film, Typewriter* as a
call to action. When Kittler writes that "media determine our situation," he
challenges his reader to choose between complicity and defiance
[@kittler_gramophone_1999, xxxix]. What can we do to counteract technological
determinism that Kittler warns us about? In what follows, I outline several
intellectual lineages that frame my approach to the problem, leading to a kind
of a materialist critique that is both pragmatic and experimental.

Critical theory, at its best, aims to see "the human bottom of non-human
things" [@horkheimer_critical_1982, 143]. As such, it is one of our most
powerful tools for analysis and resistance against technological determinism.
As Max Horkheimer wrote, "the issue is not simply the theory of emancipation;
it is the practice of it as well" [@horkheimer_critical_1982, 233]. Recently,
scholars like Kathleen Fitzpatrick, Tiziana Terranova, and Trebor Scholz have
began to turn the tools of critical theory towards the instrumental contexts
of knowledge production [@scholz_digital_2013; @fitzpatrick_planned_2011;
@terranova_network_2004]. I join them to argue that in treating the
instruments of intellectual production and consumption uncritically, all of
us---readers and writers---accumulate an ethical debt. For example, it is one
thing to theorize about the free movement of literary tropes across cultures
and continents, and quite another to have that theory appear in print behind
paywalls inaccessible to most global reading publics.[^ln-sarab] Similarly, a
theoretical distinction between form and content, when instantiated in
specific file formats like Microsoft Word (`.docx`) or Adobe Reader (`.pdf`),
establishes divisions of labor between editors, proofreaders, book sellers,
and offshore typesetting firms.[^ln-sweatshop] One group trades content in the
economy of prestige, another formatting in the economy of survival, and yet
another controls distribution in the market economy, for profit.

Distinctions of labor will remain in place as long as the conversation about
ideas like "form" and "content" persists in the abstract. A materialist
critique cannot achieve its stated aims without purchase on the material
world. Contemporary knowledge workers stare into rectangular black boxes for a
considerable part of their days, suspecting, in the absence of other feedback,
that their gaze is met in bad faith. Connecting theories of meaning-making to
its practices offers a way out of the conundrum. Bad faith identifies a
misalignment between thought and action.[^ln-sartre] The solution to connect
"meaning" with "operational meaning" belongs to a species of pragmatism.
William James articulated the approach concisely when he wrote that "reality
is seen to be grounded in a perfect jungle of concrete expediencies"
[@james_pragmatisms_1907]. For James and other pragmatists, truth could not
exist in the abstract alone. It also entailed causes and effects that operate
in the world.[^ln-pragma-truth] In his essay "Pragmatism's Conception of
Truth," James asked: "How will the truth be realized? What concrete difference
will its being true make in anyone's actual life? What experiences will be
different from those which would obtain if the belief were false?" Frank
Ramsey, the young British philosopher close to Ludwig Wittgenstein would later
write in a similar vein about meaning as "defined by reference to the
actions."[^ln-pragmatism]

For the pragmatist, truth-carrying propositions of the shape "X is Y" (as in,
"the author is dead" or "art is transcendent") beg the questions of "Where?,"
"When?," "For whom?," and "What's at stake in maintaining that?" Following the
pragmatic insight of James and Ramsey, I will proceed with the conviction that
abstract categories like "literature," "computation," and "text" cannot
possibly be reduced to a number of essential, structural features. Rather, to
borrow from Wittgenstein's *Philosophic Investigations*, categories denote a
set of related practices that may or may not share in any given familial
characteristic.[^ln-witt] In our case, imagine a tree diagram where the
tangled branches of computation and textuality intersect and diverge in
beautiful and yet arbitrary ways.

At the start of this project, I was inspired by the writings of Claude
Bernard, a little-known but influential ninetieth century French physician who
was one of the first researchers to incorporate experimentation into medical
practice.[^ln-bernard] Writing against the tradition of "inductive
generalizers," Bernard believed that medicine could only advance by "direct
and rigorous application of reasoning to the facts furnished us by observation
and experiment." "We cannot separate the two things, head and hand," he wrote,
continuing:

> [...] the science of life is a superb and dazzlingly lighted hall which may
> be reached only by passing through a long and ghastly kitchen [...] We shall
> reach really fruitful and luminous generalizations about vital phenomena
> only in so far as we ourselves experiment and, in hospitals, amphitheaters,
> or laboratories stir the fetid or throbbing ground of life
> [@bernard_introduction_1957, 3-15].

Today, the lighted halls of literary and media theory lead to the scholar's
workshop.

In an approach to *doing* theory, *Plain Text* joins the experimental turn
steering the academy toward critical practice, especially in fields
long-dominated by purely speculative reflection. The experimental turn
represents a generation's dissatisfaction with armchair philosophizing.
Recall the burning armchair, the symbol of the experimental philosophy
movement. Joshua Knobe and Shaun Nichols, some of the early proponents of the
movement, explain that "many of the deepest questions of philosophy can only
be properly addressed by immersing oneself in the messy, contingent, highly
variable truths about how human beings really are" [@knobe_experimental_2008,
3]. The emergence of spaces where research in the humanities is done
exemplifies the same trend. In naming the locations of their practice
"laboratories,"  "studios," and "workshops," humanists reach for new metaphors
of labor. These metaphors aim to reorganize the relationship between body,
space, artifact, knowledge, and inscription. In our lab and elsewhere,
researchers have taken to calling this approach "experimental humanities."

As an example of what I have been calling here the "experimental turn" in the
field of early modern history consider the preface to a recent volume on *Ways
of Making and Knowing*, edited by Pamela Smith, Amy Meyers, and Harold Cook.
They write that the "history of science is not a history of concepts, or at
least not that alone, but a history of the making and using of objects to
understand the world" [@smith_ways_2014, 12]. Smith translates that insight in
the laboratory, where, together with her students, she bakes bread and smelts
iron to recreate long--lost artisanal techniques. For those who experiment,
"book knowledge" and "artifactual knowledge" connect in practice.

Artifactual knowledge---from typesetting software to e-book readers and word
processors---shapes our everyday encounter with literature. Such technologies
should not be taken as value-neutral conduits of information. I follow Lewis
Mumford and Langdon Winner to argue that technology affects the exercise of
textual politics in subtle and profound ways [@mumford_authoritarian_1964;
@winner_artifacts_1980]. Artifacts cannot hold beliefs about politics.
Political power is rather exercised through them. For example, stairs do not
discriminate against the mobility impaired. The failure to enforce
accessibility through specific legal and architectural choices does.
Typesetting software, e-book readers, and word processors similarly embody
implicit communication models: ideas about deliberation, ethics of labor,
discursive values, and views about "natural" human aptitude for
interpretation. In this way, contemporary documents structure the literary
encounter according to economic conditions, location, or physical ability.

To what extent does the book in front of you permit or enable access?
Whatever the answer, a function of understanding the text must include the
explication of its physical affordances. Experimentalism enables the critic to
"lay bare" the device. A literary scholar's version of baking bread and
smelting iron is to make literal the archaeology of media at the level of the
mechanism. In *Plain Text* we will unearth and excavate textual machines. In
practicing archaeology I contend that cardinal literary-theoretical
concepts---such as word, text, narrative, discourse, author, story, book,
archive---are thoroughly enmeshed in the underlying physical substratum of
paper *and* pixel. It follows that any attempt to articulate the idea cannot
attain its full expressive potential without a thick description of its base
particulates.

Luckily for us, reading and writing are not esoteric activities. They are
readily available to introspection. I will therefore occasionally encourage
readers to encounter the immediate contexts of their reading anew: to put down
the book or to lean away from the screen and to look at these textual
artifacts with strange eyes. In this movement of the body, I want to disrupt
the mind's habituated intuitions, pitting them against knowledge at hand and
fingertip knowledge: as when ruffling through the pages or typing at a
keyboard. To what extent is electronic textually ephemeral, for example? The
pragmatic answer lies not in universal propositions, but in technological
affordances attached to specific reading devices. What can a reader do with
this text, here and now? Where is it stored? Are readers able to copy and
paste? Do they have legal permissions to quote at length, to perform publicly,
or to otherwise trans-mediate? Will the text disappear when the reader closes
the book's cover?

## Plan of the Present Work

The tangled pathways of inscription winding its way through the device exist
in relation to distinct communities of computational practice. A researcher
cannot therefore expect to discover a single theoretical framework that
captures the complexity of simulated text in motion. The inscription goes by
one name in one part of the system and by another elsewhere. What counts for
"code" and "poetry" in one domain, like computer science, may not account for
the same in another domain, like creative writing. An engineer's use of the
words "code" and "poetry" differs from that of a poet's. The changing contexts
evoke the corresponding shift in operational definitions. Consequently, this
book is neither a totalizing history of modern computing nor a survey of
literary theory. Rather, the argument therein progresses from the action of
the alphanumerical keyboard switch, through copper and silicon, to liquid
crystal and the floating gate, and on towards the reader and the community. It
is but one of many possible passes through a cavernous black box.

The passage from keystroke to pixel gives the book its shape. In the chapters
to follow, our mobile phones and laptops will come fully into view as metaphor
machines engendering ubiquitous simulation. The first three chapters are thus
concerned with the structure of the computational metaphor. The **first
chapter** begins with an explication. What does it mean to turn a page, I ask,
when neither the page nor the action of turning correspond to their implied
analogies? The analysis of the metaphor helps trace the intellectual history
of human-computer interaction, a field which progressed from "conversational
programming" to the "direct manipulation" paradigm shaped by cognitive
metaphor theory and immersive theater. The logic of "directness" leads to the
rapidly developing field of brain-to-computer interfaces. The chapter
concludes with a moment of speculative formalism, in which we consider the
possibility of affective literature that eschews language and representation.

At the core of the book's **second chapter** lies the notion of a modernist
literary device, understood both as literary technique and a thought
experiment about intelligent machines, directly connected to the birth of
modern computing. A section on literary technique in the thought of Percy
Lubbock, Walter Benjamin, and Mikhail Bakhtin opens the discussion.
Materialist poetics arise concomitantly with a mechanistic, rule-based view of
language leading to a series of thought experiments first in the writing of
Ludwig Wittgenstein, and then in the seminal paper of Alan Turing on an
imaginary computer capable of reading and writing. The verbs to read and to
write imply a type of cognitive processing. What does it mean to read and to
write for a machine? What about broken mechanisms of comprehension? At once a
device and an algorithm, the Turing machine blurs the boundaries between
software and hardware, code and content, intelligence and its imitation.

Two rich intellectual histories collide on the pages of the **third chapter**
chapter: one, the material history of formatting as a concept in computer
science and the other, the intellectual history of form in literary theory.
Format emerges as a concept that mediates between form understood as internal
"rules for construction" and form understood as "external shape." The
formatting layer transforms one type of structure, a series of bits arranged
into tracks and sectors, into another, letters arranged into sentences and
paragraphs. I draw a short history of text formats that commences with several
"control characters" limited in function to actions like "carriage return" or
"stop transmission." With time, the formatting layer encompassed all manner of
machine instruction, including structures of governance like "digital rights
management" and "copy protection." A manufacturer's ability to censor or to
surveil electronic books is contained within the formatting layer. The concept
of formatting developed in this chapter is critical therefore to our
understanding the capabilities of digital texts: from electronic books that
modify themselves to suit the reader's geographic location to "smart"
contracts that contain the rules of their own execution.

The **fourth chapter** begins with a discussion of an apparent paradox. A camp
of media theorists and textual scholars in the 1990s conceived of electronic
texts as an ephemeral, almost immaterial, phenomenon. The text shimmered and
glared: it was spoken of in terms of *hypertext*, light writing, and
electricity. A generation of theorists that came after insisted on the weighty
materiality of electronic media. Reading began to engage the morphology of
rare metals, media archeology, hard drive forensics. Both accounts, I argue,
capture an aspect of the same underlying conditions. The perceived image of an
archived inscription splits from its source. The sign plausibly resides both
on the screen and on the hard drive. It splits, in some real a sense,
diverging at the site its projection from the site of the archive. Erasing an
inscription on the screen, for example, may not elicit the corresponding
action on the disk. Using archival materials from the history of telegraphy in
the late nineteenth and early twentieth centuries, I chart the gradual
fracture and the ultimate illegibility of the computational sign. Early
computers stored human-readable text and machine instruction at the surface of
the same storage media like punch cards and ticker tape. Although difficult to
read, these forms of machine writing were readily visible and therefore
amenable to analysis. The advent of magnetic storage forced the composite
inscription into an opaque medium.  Unable to perceive magnetic polarities
without the aid of a machine, readers often manipulated text blindly. In this
way a typist would type several sentences without seeing the printed output.
The chapter identifies a milestone in the history of human textuality: the
moment at which the inscription passes from view, giving rise to the sometimes
conflicting but nevertheless consistent accounts of digital textuality.

The **fifth chapter** charts the emergence of screen reading. The screen
appears to restore a measure of visibility lost to magnetic inscription, with
one major side-effect. Fidelity between the word visible and the word archived
cannot be guaranteed. What the screen shows and what is stored on tape or hard
drive has only a contingent correlation. Screen reading further happens on
screens that refresh themselves at a rate of around 60 cycles per second
(Hertz). The digital word is technically an animation; it moves even as it
appears to stand still. This property of the medium attunes the reader to a
particular mode of apprehension, affecting not just the physics but also the
aesthetics of digital media. Works by the philosophers Henri Bergson, Jakob
von Uexküll, and John Goodman help construct a phenomenology of screen-based
digital perception. The digital emerges ultimately not as a property of the
medium, but as structure imposed onto matter from without. In the extreme,
that means that a censored *electronic* text can form a perfectly *analog*
artifact, despite being digital in all other senses of the word. Conversely,
texts in print are already "born digital," in the sense that literary works
like Shakespeare's *Hamlet* are amenable to "reliable processes of copying and
preservation" [@haugeland_analog_1981, 213-225]. Properties that make media
"digital" or "analog" reveal themselves neither to be neither universal nor
essential to the medium. The medium is not the message. "The reliability and
preservation of textual copies" may mean one thing to a literary scholar,
another to a software engineer or a legal professional, and something entirely
different to a librarian, as I argue in the conclusion of the chapter. It
matters not what the medium is, but what we can do with the text.

<!---

The **sixth and final chapter** looks to the site of storage to find the media
"homes" that house the vast archives of our private media collections. It
begins with a close reading of Beckett's *Krapp's Last Tape*. Krapp makes
yearly audio recordings of himself, only to revisit them and to enter into a
sort of dialog with his own voice from the past. I posit this archival
encounter as Krapp's "media being" and suggest that such encounters are
commonplace. Writers and book collectors regularly deposit "snapshots" of
their consciousness into files, bookshelves, and folders. Jean-Paul Sartre's
idea of an "appointment with oneself" helps to reveal this external
construction of files, folders, and library furnishings as cognitive
extension, in need of delicate pruning and arrangement. In this light, I show
that documents exist not as completed works, but as "vectors" that mutate and
move through time and space.[^ln-wark] I ask: What is being externalized,
communicated, and preserved? And answer: It is not simply a message, but the
subject itself. A close reading of the "home" folder, the default location of
personal files on many systems, concludes with the discussion of media homes.
Finally, I return to the theme of displacement, arguing for a mode of
inhabitance within media that is uncanny or un-homed [*Unheimliche*], contrary
to discourse that speaks in terms of "digital natives" and those who are "born
digital." I build on Flusser's immigrant poetics to suggest a kind of
information processing that necessitates a purposeful movement between the
polarities of settlement and expatriation.

--->

<!--

The book ends with a short conclusion expounding a theory of
microanalysis---the closest possible kind of reading---which brings the
material particulates engaged in the construction of meaning under the purview
of interpretation.[^ln-iarkho] Where distant reading and macroanalysis
constitute the study of mediation between readers and text aggregates (like
canons, genres, corpora, libraries, and archives) microanalysis examines
mediation at the level of physical minutiae. The instruments of microanalysis
coincide with algorithmic tools that reveal patterns and data structures
inaccessible to the naked eye. Microanalysis may also require facility with a
screwdriver, a binding needle, or a soldering iron: sharp tools that help to
expose structures of governance and control routinely embedded into modern
literary devices.

-->

<!--- NOTES  --->
<!--- NOTES  --->
<!--- NOTES  --->

[^ln-bernard]: On Bernard see @petit_claude_1987 and @sattar_aesthetics_2013.

[^ln-brains]: For the first view see @putnam_minds_1960 and
@fodor_language_1975. For the second view see @deutsch_quantum_1985 and
@dyson_turings_2012.

[^ln-capital]: Scholars like Alexander Galloway, David Golumbia, Bernard
Harcourt have advanced critique along similar lines. See
@galloway_protocol_2006, @golumbia_cultural_2009, and @harcourt_exposed:_2015.

[^ln-cog]: See for example @gibbs_categorization_1992; @blasko_effects_1993;
@gibbs_poetics_1994; @neal_role_1997, 441-463; @gentner_alignment_1997.

[^ln-dead]: See @barthes_death_1977; @foucault_what_1980; @nesbit_what_1987.

[^ln-digitalliteracy]: See for example @postman_technopoly:_1992;
@negroponte_being_1995; @davidson_now_2011; @obama_2016_2016.

[^ln-dissent]: See @harcourt_exposed:_2015, 251-80.

[^ln-dmca]: See @ku_critique_2004; @ginsburg_legal_2005; and @fry_circumventing_2009.

[^ln-egturner]: Mark Turner, whose work builds on Lakoff and Johnson is a
strong proponent of such an approach. See @turner_death_1987 or
@turner_language_1992.

[^ln-flusser]: The work of @flusser_does_2011 has been similarly influential.

[^ln-hegel]: I discuss the topic at length in Chapter 3.

[^ln-iarkho]: I borrow the term "microanalysis" from the largely forgotten in
the West Russian literary scholar and member of the Moscow Linguistic Circle,
Boris Iarkho. In his *Methodologies of Exact Literary Study* (circa 1935-6) he
writes: "I understand 'atomism' as a sort of an ideal aspiration, as an
orientation toward the liminally small. But under no circumstances do I
advocate working with hypothetical quantities, like molecules, atoms,
positrons, and so on, which are located beyond the limits of perception. That
this applied mythology gave us such splendid results in chemistry, should not
conceal its true nature. Tomorrow, all such explanations of visible through
the invisible could give way to other hypotheses, as was the case with their
no less fertile predecessors (elemental spirits, phlogiston, and light ether).
But the cell, the nucleus, and the chromosome endure as lasting
accomplishments of microanalysis. I suggest to move as far as a microscope can
reach, and no further" [@iarkho_metodologia_2006, 363-364]. For Iarkho, the
most quantitatively inclined of the Russian Formalists, microanalysis involved
systematic application of statistical methods to the study of literature.

[^ln-kittler2]: *Gramophone, Film, Typewriter* ends as follows: "And while
professors are still reluctantly trading in their typewriters for word
processors, the NSA is preparing for the future: from nursery school
mathematics, which continues to be fully sufficient for books, to
charge-coupled devices, surface-wave filters, digital signal processors
including the four basic forms of computation. Trenches, flashes of lightning,
stars---storage, transmission, *the laying of cables*
[@kittler_gramophone_1999, 263].

[^ln-lacan]: The evanescent absence of life that Lacan mentions as "the sign
about which Robinson Crusoe would make no mistake" [@lacan_seminar_1997, 167].

[^ln-lament]: Or perhaps celebrate, depending on your understanding of their
post-humanism. For more a more extended discussion on Kittler, Foucault, and
post-humanism see for example @winthrop-young_silicon_2000; @wolfe_what_2010,
104-128; @siegert_cultural_2013.

[^ln-pragmatism]: @ramsey_foundations_2013, 155. The intellectual legacy of
pragmatism is wide-ranging and diffuse. It is perhaps most pronounced in the
teacher colleges, where James and Dewey are still read widely, which could
explain the ascendancy of such pedagogical terms as "situated
cognition"[@brown_situated_1988, @lave_situated_1991] and "experiential
learning"[@kolb_hegel_1981]: both terms denoting some sense of necessary
synthesis between of knowing and doing. In the field of linguistics,
philosophy of language, and communication studies, pragmatics are
well-encapsulated by the "language-as-action tradition," which harkens back to
the Oxford language philosophers like J.L. Austin, Paul Grice, and John Searle
[@trueswell_approaches_2005]. Austin's *How to Do Things with Words,* is
perhaps the paradigmatic formulation of the idea that words don't just mean
things, but that they enact change in the world.

[^ln-pragma-truth]: For a more thorough discussion on the topic see
@seigfried_william_1990, @pihlstrom_structuring_1996, and @putnam_jamess_1997.

[^ln-sarab]: See also @english_economy_2008; @brouillette_wither_2015 and
@brouillette_unesco_2015.

[^ln-sartre]: Sartre would write "transcendence" and "facticity." See
@sartre_being_1993, 86-119.

[^ln-spam]: For example, in 2004 researchers estimated that spam mail makes up
40%-80% of the total email volume @cournane_analysis_2004.

[^ln-sweatshop]: See @freeman_high_2000 and @patel_working_2010.

[^ln-brik]: @shklovksy_poetika_1919, 104. Translations are mine unless source cited explicitly in
English.

[^ln-varela]: See @varela_autopoiesis_1974; @barthes_rustle_1989, 5;
@nuttall_new_2007, 6-25.

[^ln-wark]: I use the term "vector" in somewhat more limited sense than it
appears in the idea of "vectoralist class" coined by McKenzie Wark. By
"vectoralist class" Wark means something like the group of interests that
control the distribution of information. See for example
@wark_information_2006. In understanding the document as a vector I posit it
as a three-dimensional rather than a two-dimensional object, with the extra
dimension extending in time. Similar to Jerome McGann's idea of the "editorial
horizon." See @mcgann_textual_1991.

[^ln-winner]: See for example: "Writers concerned with with problems of
technology-out-of-control have frequently echoed Hobbes in suggesting that
such an artifact---the Leviathan of interconnected technical systems---has a
soul of its own [...] A ghost appears in the network.  Unanticipated aspects
of technological structure endow the creation with an anticipated *telos*"
[@winner_autonomous_1978, 280].

[^ln-witt]: @wittgenstein_philosophical_2001, 67-77. For more on the
connection between Wittgenstein and James see @goodman_james_2004.

[^ln-bookreview]: I write "supplants the function" because I do not mean to
imply that the book review disappears or becomes less vital. On massive market
platforms like Amazon Books, the book review passes from the domain of an
expert to the domain of the lay reader. Book reviews thus proliferate. Their
function changes from universal aesthetic judgement to instrumental reasoning.
In other words, we now find the book first then read the review. The review
ceases to serve as a tool for discovery--a function now addressed by the
search and recommendation engines.

[^ln-twobil]: Code metrics from @mccandless_million_2015.

\newpage
