# Computational Poetics: An Introduction

While I write these introductory remarks, a ceiling-mounted smoke detector in
my kitchen emits a loud noise every three minutes or so. A pleasant female
voice announces also "low battery." This is, I learn, a precaution stipulated
by US National Fire Alarm Code 72-108 11.6.6 (2013). The clause requiring a
"distinct audible signal before the battery is incapable of operating" is
encoded into the device. The smoke detector literally embodies that piece of
legislation in its circuitry. We thus obtain a condition where two meanings of
code---as governance and machine instruction---coincide. Code equals code.

I am at home, but I also receive a notification of the alarm on my mobile
phone. Along with monitoring apps that help make my home "smarter," the phone
contains most of my library. I often pick it up to read a book. However, the
phrase "reading a book" obscures a number of metaphors for a series of odd
actions. The "book" is a small, thin black rectangle: three inches wide, five
inches tall, and barely a few millimeters thick. A slab of polished glass
covers the front of the device, where the tiny eyes of a camera and a light
sensor also protrude. At the back, made of smooth soft plastic, we find
another, larger camera. At the foot of the device a grid of small perforations
indicates breathing room for a speaker and several microphones. To "open" a
book I touch the glass. The machine recognizes my fingerprint almost
instantly. I then tap and poke at the surface until I find a small image that
represents both my library and book store, where I can "buy books." Buying
books does not, however, involve the actual ownership of physical objects.
Rather, I agree to a licence that grants limited access to data, which the
software then assembles into something resembling a book on screen. I tap
again to begin reading. The screen dims to match room ambiance as it fills up
with words. A passage on the first page appears underlined: other readers in
my social circle must have found it notable. I swipe across the glass surface
to turn a "page." The device emits a muffled rustle to reinforce the pretense
of manipulating paper. The image curls ever so slightly as another "page"
slides into view. My tiny library metaphor contains hundreds of such page
metaphors.

Despite appearances, the electronic metaphor-making device on my desk has more
in common with smoke detectors than it does with several paper volumes
scattered on my desk. The electronic book and smoke alarm contain printed
circuit boards, capacitors, and resistors. Both draw electric current. Both
require firmware updates and both are governed by codes, political and
computational. Smoke alarms and mobile phones connect to the internet. They
communicate with distant data centers and with each other. And yet, I continue
to "read" these devices as if they were familiar, immutable, and passive
objects: just books. I think of them as intimate artifacts---friends
even---wholly known to me, comforting, and warm. The electronic book is none
of those things. Besides prose, it keeps my memories, pictures, words, sounds,
and thoughts. It records my reading, sleeping, and consumption habits. It
tries to sell me things, showing me advertisements for cars, jewelry, and
pills. It comes with a manual and terms of service. It is my confidant, my
dealer, my spy.

*Plain Text* concerns the nature of digital inscription---the material trace
that gives rise to textual phenomena, and, more broadly, to all cultural
artifacts in which computers mediate. We find ourselves today in an
unprecedented, since the Middle Ages, position of selective *asemiosis*: the
loss of signification. Many contemporary texts---like poems inscribed into
bacteria and encrypted software---exist simply beyond the reach of human
senses.[^ln-dna] Other forms of writing are illegible in ways that prevent
access or comprehension. Increasingly, we write not in the sense of making
marks on paper but in simulation. The key press leaves a lasting trace in
computer memory, which then appears on screen redoubled and ephemeral. On
disk, the mark endures in a form legible only to those who possess the
specialized tools and training necessary to decipher it.

Codes embody governance through explicit instruction. To retain a civic
potential for critique, to speak truth to power, we must perceive the
mechanisms of its codification. Critical theory cannot otherwise endure apart
from material contexts of textual production, which today emanate from the
fields of computer science and software engineering. Conversely, a tighter
coupling with the critical tradition can reveal the often occluded political
implications of technological progress. To create a novel algorithm that
predicts crime by analyzing one's reading habits, for example, is also to
invite the dystopian possibility of thought policing, unless, that is, such
algorithms remain legible, in public view, and under continual
counter-scrutiny. A vibrant discursive practice of textual exegesis is crucial
for the preservation of whatever political ideals that demand a literate
populace.

[^ln-dna]: See @bok_xenotext_2011 and @bok_xenotext:_2015: "I have been
striving to write a short verse about language and genetics, whereupon I use a
'chemical alphabet' to translate this poem into a sequence of DNA for
subsequent implantation into the genome of a bacterium (in this case, a
microbe called *Deinococcus radiodurans*---an extremophile, capable of
surviving, without mutation, in even the most hostile milieus, including the
vacuum of outer space)."

## Thesis and Scope

*Plain Text* is a response to a particular situation of a literary scholar
encountering the field of software engineering. For a long stretch of my
professional life, these two areas of activity remained separate. I worked at
one and I studied the other. At the time, I simply did not think that code had
much to do with poetry. Initially, my two selves---the scholar and the
engineer---spoke different languages. Reconciling them was and continues to be
a disconcerting process by which things dear and familiar to me, in both
worlds, grew strange and unfamiliar, showing themselves to be sometimes less
than, and sometimes more than I comfortably expected. Nothing could be assumed
from the start. Field specific language, down to its foundations, had to be
examined for hidden assumptions that prevented dialog. With time, I saw that
code and poetry have much to do with one another. Writing this book has taught
me to embrace the remaining incongruence.

The idea for this book came in a moment of realization, after I was asked one
of those seemingly naive but fundamental questions that can set research in
motion down a long and winding path.

A childhood friend who shares a love for reading asked why he could not lend
me a copy of the novel that he recently purchased from a major online
retailer.[^ln0-amazon] In my struggle to answer, I realized that some of my
deepest intuitions about literature relied on assumptions firmly attached to
print media. Despite my professional experience as a programmer and academic
training in literary studies, I could not readily explain the mechanisms by
which electromagnetic charges transformed into pixels and pixels into words.
Where to begin? To recount the passage of digital text, one had to know
something about chip architecture, operating systems, file permissions,
networking, and encryption. I could describe parts of that ecosystem, but my
knowledge was also riddled with unexamined gaps. It did not amount to a
coherent story.

Worse yet, it quickly became apparent that these technical details affect all
higher-level interpretive activity. To read together---to form a shared
understanding of the text---we had convene on the same page, which was
difficult because of imposed geographic restrictions. The text changed as it
passed hands. I now had to draw on philology and sociology of literature to
deal with textual variants, recensions, and authorship attribution. The
digital text was more obviously entwined with its reception history: reader
reviews and algorithmic recommendation engines. Despite the new copy it was
marked and highlighted. It synchronized with other media like audio books and
related television promotions. The work was pre-processed to privilege certain
meanings and modes of comprehension.

The task of "coming to terms" with these emergent contingencies entails an
expansive research program, that could only be commenced here in part. The
digital literary ecosystem is evolving rapidly. A historical approach to its
development allows us to extrapolate its trajectory into the future.
Crucially, the ecosystem is still in a nascent, formative state. Digital
knowledge architectures have not yet congealed; they are still pliable. Their
importance for our social institutions necessitate active commentary and
experimentation, particularly by those readers most reliant on their eventual
contours. Without it, we risk the dominion of what Langdon Winner has called
"autonomous technology"---a condition by which adhoc complex systems begin to
irrevocably determine our politics. "Modern people have filled the world with
the most remarkable array of contrivances," Winner wrote. We are then
surprised to find them resistant to change. "The human kind faces a woefully
permanent bondage to the power of its own inventions," he concluded. And I
hope, along with him, that it is still possible to "reconsider and
reconstruct" those outcrops that in retrospect impoverish culture, to "learn
and start again," and to retain the "prospect of liberation"
[@winner_autonomous_1978, 335].

[^ln0-amazon]: The retailer has since introduced a program that allows for
limited sharing of materials, restricted by time and geography.

To these ends, *Plain Text* tells a story of a major morphological shift
affecting culture production in general and textuality in particular. Were I
to interrupt a digital typist to ask---Where do these words reside?---I would
likely receive several conflicting answers in response. In some sense, the
words reside on screen, where they appear to view. In another sense, they live
somewhere within the machine, on remote and hermeneutically sealed surfaces:
silicone chips, hard drives, flash memory cards. Yet in another sense, visible
signs are still further removed from the contexts of their production. The
word is in the wires. It spreads across servers, routers, and data centers.
One no longer reads or writes alone. What was once apparent now takes on a
more complex shape, stretched across planes and temporalities. The book---this
book, any book---gains a new shape. Digital texts form a live lattice---a
multidimensional grid---which connects the letter's tactile response, at one's
fingertips, to its optic and electromagnetic traces. In aggregate, these
laminates incorporate the scaffolding of synthetic inscription. I cannot
consequently pass a digital note to another, in the same sense that one passes
notes in class, on paper. It is impossible to give the entire structure over.
Text is irrevocably intertwined with its stratified material contexts; it
means---it *becomes*---something else when recreated under conditions not
fully congruent to my own.

Much of contemporary anxiety about the intrusion of computational culture into
the everyday can be traced to such fundamental reshaping of the sign. Its
fracture leads to its multivalence. The lattice expands into the space between
signs, where forces of capital and control intervene to monitor and
monetize.[^ln-capital]

Reflecting on the development of Morse Code in 1949 in the *Proceedings of the
American Philosophical Society*, Frank Halstead mentioned the difficulty of
finding a home in either the arts or sciences for what he called "code
development." "It is a matter somewhat related to the general art of
cryptology," he wrote, "yet it is not wholly divorced from electrical
engineering nor from general philology" [@halstead_genesis_1949, 456]. As
Halstead anticipated, research into codification has led me to a rich
multidisciplinary archive of materials from the history of literary theory,
semiotics, telegraphy, and electrical engineering from the middle of the
nineteenth to the end of the twentieth century. That archive includes patents
and technical manuals, formalist manifestos, studies of animal communication,
human-computer interaction textbooks, as well as foundational texts in
aesthetics and literary theory.

I deploy the archive to argue that extant theories of interpretation evolved
under conditions tied to static print media. By contrast, digital text changes
dynamically to suit its reader, political context, and geography.
Consequently, I advocate for the development of *computational poetics*: a
strategy of interpretation capable of reaching past surface content to reveal
platforms and infrastructures that stage the construction of meaning. Where
"distant reading" and cultural analytics perceive patterns across large-scale
corpora, computational poetics breaks textuality down into its minute,
microscopic even, constituent components.

I appeal to the idea of "plain text" in the title of this book to signal an
affinity with a particular mode of computational meaning-making. Plain text
identifies a file format and a frame of mind. As a file format, it contains
nothing but a "pure sequence of character codes." Plain text stands in
opposition to "fancy text," "text representation consisting of plain text plus
added information" [@unicode_consortium_unicode_1990, 9-10]. In the tradition
of American textual criticism, "plain text" alludes to an editorial method of
text transcription which is both "faithful to the text of its source" and is
"easier to read than the original document" [@cook_considerations_1988].
Combining these two traditions, I mean ultimately to build a case for a kind
of a systematic minimalism when it comes to our use of computers---a
minimalism that privileges access to source materials, ensuring legibility and
comprehension. I do so in contrast with other available modes of
human-computer interaction, which instead privilege maximizing system-centric
ideals like efficiency, speed, performance, or security.

The title further identifies an interpretive stance one can assume in relation
to the making and the unmaking of literary artifacts. Besides visible content,
all contemporary documents carry with them a layer of hidden information.
Originally used for typesetting, that layer affects more than innocuous
document attributes like "font size" or "line spacing." Increasingly, devices
that mediate literary activity also embody governing structures. For example,
the Digital Millennium Copyright act, passed in the United States in 1996,
goes beyond written injunction to require in some cases the management of
digital rights (DRM) at the level of hardware. An electronic book governed by
DRM may subsequently prevent the reader from copying or sharing stored
content, even for the purposes of academic study.[^ln-dmca] In some
situations, it may report the reader's activity to the authorities. Attempts
to silence print through book burning or censorship are viscerally apparent.
Unlike these, the dominion of computation proceeds by clandestine means.
Textual composites preserve the outward appearance of print, while concealing
the material specifics of their production and distribution.

I am hence particularly aware that the history of digital text reflects the
legacy of European and later North American colonialism. The treaties that
negotiated early character encodings initially did so in the dominant
diplomatic languages, French and English
[@international_telegraph_union_documents_1865]. More modern character
encodings like the UTF-8, have since attempted to rectify historical
inequities. The challenge and consequence of the book will be in exposing such
naturalized ideological contingencies. That is not to say that epistemic
things, our phones and computers, can ever become wholly known or fully
transparent. But neither should they remain out of reach. We must insist on
dragging them into a dialectic, by which ideals reify and align with specific
technological commitments.

It is easy to forget the blunt effectiveness of physical control in the global
North-west. Books that are burned or redacted cannot be read at all.
Elsewhere, inequities of access to knowledge compel readers to print their own
books and build their own libraries. Witness the so-called "shadow libraries"
of Eastern Europe and Central Asia, the street book vendors of India and
Pakistan, and the gray market presses of Nigeria arising from the country's
"book famine"[@mahmood_copyright_2005; @okiy_photocopying_2005;
@liang_piracy_2009; @bodo_short_2014; @nkiko_book_2014; @_elsevier_2015]. More
than mere piracy, such *samizdat*-like practices preserve the literary sphere
[@tenen_book_2014]. Informal book exchange networks create reading publics
that own the means of textual production and dissemination. Under duress,
readers build homemade knowledge infrastructures: they duplicate, distribute,
catalog, and archive.

By contrast, in wealthier economies, such infrastructures are commodified.
Readers consequently receive the material contexts of their meaning-making
passively. The costs of knowledge production and barriers to its distribution
disappear from view. For many readers, technologies that support reading,
writing, and interpretation further pass from tools to fetish. No longer
comprehensible by the way of pen or printing press we imbue them with magical
powers. Thus we exist in the state of profound alienation from mechanisms
closest to our mental activity. We read electronic books as they read us,
without depth or understanding.

## Theory
### Displacement

The book stems from a productive tension between media settlement and
displacement.

I mean settlement in the way one lives among and within one's own notebooks,
bookshelves, and archives. Smart toasters and electronic heart valves are
distinct from their dumb mechanical counterparts in that they similarly give
grounds to inscription. Computers are ultimately machines that need to perform
reading and writing operations at scale. To support that activity, they
necessarily found vast, in terms of information capacity, expanses.
Commercial, private, and public interests rush in to colonize newly opened
territories. Boundaries are drawn. Areas of exclusion are created, even in our
most intimate spaces: bedsides, living rooms, kitchens, the heart and the
mind: a diabetic is not able to modify her insulin pump software; the smart
television contains proprietary firmware, controlled at a distance and without
explicit consent. The struggle is not one for virtual, but actual space.

These territories are however remote, in that they unfold at quantum scale.
Individual not privy to the mechanics of micromolecular writing are in peril
of unprecedented dispossession. I am concerned here with our basic ability to
shape discourse---to read and write---along surfaces that are not available
for immediate scrutiny. Poetics---the affordance of literary
space---physically limits the possibility of interpretation. An illegible sign
is one that never enters the hermeneutic circuit.

In making the case for a computational poetics, I am helped by recent
scholarship in the historically- and philosophically-inflected studies of
media and technology.[^ln0-influences] My notion of poetics builds also on the
long history of literary theory, in the genealogy of formalist and
structuralist schools. My approach is not however limited to the canonical,
straight-ahead structuralisms of Roman Jakobson or Jonathan Culler. I am
borrowing rather from a more peripheral tradition represented best by third
culture thinkers like Viktor Shklovsky and Vilém Flusser, consummate
immigrants both, who extracted a methodology out of the fabric of their
displacement.

Flusser in particular considered the condition of unease that comes with
migration, both physical and mental, to be a kind of information processing.
His thought was influential in making sense of my own displacements, first as
a refugee fleeing the dissolution of the former Soviet Union, then a
transplant into Silicon Valley from a strict literary education, and now a
lapsed engineer among humanists. These vantage points offer a singular view
onto the material conditions of contemporary intellectual life.

Both Shklovsky and Flusser wrote lucidly about the dynamics of settlement.
Their work sheds light onto an irresistible compromise, at the core of all
technology, by which we trade critical understanding for comfort. Habit covers
the various homes we make for ourselves in the world "like a fluffy blanket,"
Flusser wrote: "[i]t smoothes the sharp edges of all phenomena that it covers,
so that I no longer bump against them, but I am able to make use of them
blindly." When we sit at our desks, for example, we fail to see "papers and
books that are lying all about." We are used to them being there as they are
[@flusser_freedom_2003, 13; @finger_vilem_2011, 132]. We do not thereafter
parse them as information. Like water that surrounds fish, habituated things
pass into the background of experience. Mediums become media. They cease
producing meaning, become stages for meaning-making, and like a stage
disappear from view.

Losing sight of the material contexts of knowledge production is politically
perilous, because those who own the contexts set the terms of engagement.
Estrangement arrests material concealment. Exile allows the displaced to once
again transform habituated media into meaningful information. In exile,
"everything is unusual," Flusser wrote [@flusser_freedom_2003, 81]. Migrants
experience the world as ex-perience [*er-fahrung*], or literally a driving
out. Discovery, he concluded "begins as soon as the blanket is pulled away,"
where familiar objects can pass into view again [@flusser_freedom_2003, 82-3].

One could write, to take a simple example, "a field of study," without much
thought about figurative space. Shklovsky would have readers pause to consider
the implications [@shklovksy_sborniki_1917]. In what sense do ideas resemble
(or not) a field? The poet could take things further and elaborate: "to scythe
a verdant field of literary study." The verb (to scythe) and the adjective
(verdant) create an unexpected transference of new qualities not present in
the original image (intellectual field). These qualities "overdetermine" or
"saturate" the metaphor, exposing its conceit. One can do to fields of grass
what one cannot to ideas. Subsequently, we realize that the two
domains---intellectual and horticultural---do not map onto each other
perfectly, leaving a semantic remainder: the chaff. Readers discover
intellectual "fields" for what they are: habituated metaphors, neither natural
nor self-apparent. Metaphor are made strange again through purposeful
defamiliarization. To take the technique to its logical conclusion, a writer
could depict several fictional characters in the act of scything a field of
grass while discussing the relative merits of structuralism: a discussion
about the field on a field. Such literary artifice would make actual the
implied connections between fields of grass and ideas. The writer now shows
what was merely told before. The technique of defamiliarization finally renews
the figure: discarding hardened clichés while suggesting novel linkages
between constituent concepts: ideational chaff, leaves of mental grass,
combines of thought.

The formalists understood habituated metaphors to diminish the vitality of
experience. Shklovsky quotes from the diaries of Lev Tolstoy, who, while
dusting his room, could not remember if he had already dusted his sofa.
Tolstoy wrote:

> because actions like these are habituated and unconscious, I could not
> remember [...] whether I dusted and forgot or just did so without
> thinking---it was as if the action never happened [...] thus when life
> passes without conscious reflection, it passes as if one has not lived at
> all.

Shklovsky adds that life so habituated disappears into nothingness, when the
automatization of experience "consumes things, clothing, furniture, your
spouse, and the fear of war."[^ln-brik]

The formalists rarely quoted Marx directly. Yet Marx resonates throughout.
For Marx, dead metaphors mark the alienation from humanity.[^ln0-marx] The
point at which material artifacts disappear from conciousness is also the
point where they appear within the social sphere as fetishes.

Shklovksy changes Marx's German alienation [*Entfremdung*], which for Marx
always denies life, into the Russian estrangement [*ostranenie*], literally an
"othering," of the kind that affirms it. The difference is one of agency. In
the first case, subjects are treated like objects by others. In the second,
they recognize and reject the objectified within. Formalist
estrangement---same as defamiliarization---arrests the momentum of tacitly
received habit. Once othered, the human experience can be revitalized.

Our challenge today is to uproot ourselves from the comforts that rapidly
descend on the dwellings of our intellectual life. Dulling the senses,
seemingly inconspicuous conduits of agency---electronic books and smart
desks---acquire a sense of intelligence of their own. Devices that "watch,"
"hear," "see," and "think" give rise to object-oriented ontology and the
internet of things. A new generation of objects clamours for participatory
intelligence. They claim space in the home, near bed and hearth. Smart phones,
smart light bulbs, smart thermostats, smart homes, and smart watches, enter
the networked public sphere in the role of independent agents.[^ln-winner] A
conversation begins about their personhood: their levels of trust,
friendships, rights, and accountability [@bohn_living_2004;
@jianhua_ma_towards_2005; @calverley_android_2006; @hildebrandt_ambient_2007;
@atzori_smart_2014]. Marx's table that "evolves out of its wooden brain
grotesque ideas" now becomes Surface and PixelSense---product names of actual
smart tables, available for purchase [@marx_capital:_1906, 82;
@wigdor_designing_2009].

If we hope to understand digital culture and especially literature, as
Friedrich Kittler would write, "under conditions of high technology," we can
only do so from the position of humanism. One cannot otherwise lament the
systematic erasure of the human from the literary process and, at the same
time, advocate for a post- or anti-humanism. Unlike Kittler, who wrote that
under conditions of high technology "literature has nothing more to say," I
believe that literature and literary analysis continue to have a voice in
contemporary life [@kittler_gramophone_1999, 263]. Technology does not
determine literary silence. Rather, as the material grounds for all reflective
textual activity recede from view, readers face the prospect of selective
illiteracy. The command of technologies like networking and encryption
separates those able to read and write under conditions of high technology
from those who no longer are: another dispossession.

When we mistake things for animate actors, we ourselves become enmeshed in a
system of digital production that commodifies human experience. Objects that
surround us collect our reading habits, social interactions, and intimate
conversations. Agents that benefit from trade in personal data are neither
cyborgs nor post-human assemblages. The bargain that trades critical
understanding for comfort benefits specific, individual interests. To address
objects as if they could respond in kind shifts our attention from seats of
power to things powerless, inarticulate, and indifferent to our protestations.
One can no more extract justice from a smart desk than hold a bureaucracy
accountable. Notions of justice and accountability presuppose a robust model
of agency, absent in the assemblage.

The internal exile that we must undergo for smart books and smart desks to
come into view cannot compare in difficulty to the experience of physical
displacement that follows natural disaster, war, poverty, or political
instability. Yet, our systematic reluctance to take on even those small
intellectual discomforts that could lead to acts of localized dissent and
disobedience---to write using free software, to build open archives, or to
share memories in private---cannot be said to exist outside the complex
systems that perpetuate inequity and violence globally. The emotional
affirmation that accompanies exuberant social networking brings with it
governing structures evoked in the name of law enforcement and national
security. Comfort and security constitute the same ill-conceived bargain that
leads to critical disempowerment. But where it is difficult to imagine or to
enact strategies of digital disobedience on a universal scale, we can begin to
address them through numerous minute transactions that in aggregate brace
everyday literary exchange. This we can do now. Computational poetics begins
with machines in our immediate proximity, closest to thought and touch.

To pick up an electronic book and to take it apart may be against the law in
some jurisdictions [@fry_circumventing_2009]. Given the extent to which
emergent thought-things---epistemic artifacts like electronic books and smart
phones---participate actively in the production of meaning, we can no longer
employ strategies of interpretation at the level of ideology or representation
alone.[^ln-rhein] The praxis of close reading must reach down to the silicon
bedrock: material entities and physical structures that bear the weight of
interpretation. Literary theory, a discipline fundamentally engaged in the
exegesis of figurative trope, is therefore crucial to the understanding of new
computational environments, which have enveloped intellectual life through
metaphoric substitution. To read the machine is to learn how it is made, but
also to unpack the rich metaphors that guide our tactical engagement with the
word: the boot in rebooting, the wares in software, the bug and the joystick,
the interpreter and the shell.

### Settlement

Estrangement cannot be practiced effectively in monologue. To produce meaning,
Flusser reminds us, it needs to become a dialogical practice.  Perpetual exile
is otherwise uninhabitable [@flusser_freedom_2003, 81]. Estrangement thrusts
the displaced into the chaos of unsettled existence. With time, they make a
new home, from which they can once again "receive noise as information" and
produce meaning. "I am embedded in the familiar," Flusser wrote, "so that I
can reach out toward the unfamiliar and create things yet unknown"
[@flusser_freedom_2003, 12]. A dialectics of exile leads to "informed renewal"
of shared space, through what Flusser called a "creative dialogue" between the
settled and the displaced [@flusser_freedom_2003, 84]. Without the shelter of
one's home, everything turns to noise. Information cannot exist without
dwelling, Flusser wrote, "and without information, in a chaotic world, one can
neither feel nor think nor act" [@flusser_freedom_2003, 12]. By this dynamic,
displacement and settlement enter into a continuing dialectic.

In *Plain Text*, I model the reciprocal movement to "making strange" on the
diverse practices of reverse engineering. Similar in method to what Matthew
Kirschenbaum calls "forensic argumentation," reverse engineering recalls the
formalist strategy of experiencing the making of the thing through careful,
case study-based reconstructions of textual artifact.[^ln0-reverse] The
function of case studies in an engineer's education, as Henry Petroski
explains in his *Invention by Design*, is to understand the ways by which one
gets "from thought to thing" [@petroski_invention_1996, 3-7]. From thought to
thing would be another apt definition of poetics and an alternative subtitle
to this book. Along with literary and historical exposition, each of my
chapters contain at least one literary thought-thing. Each chapter enacts a
deconstruction---a literal taking apart---of that device. The epistemic object
is present to challenge my and the reader's theoretical intuitions.

The reverse engineering of literary devices reveals that not all texts are
created equal. In print, traditional distinctions between form and content lie
flat. The printing press firmly embeds ink into paper, leaving no space
between type and page. Materially-minded critics like Johanna Drucker,
Katherine Hayles, and Jerome McGann have urged literary scholars to
re-evaluate textuality in its media-specific contexts [@drucker_digital_2001;
@mcgann_radiant_2001; @hayles_print_2004]. Their work reminds us that the
flatness of digital text is an illusion. Low-level operational intuitions
governing textuality---ideas about form, content, style, letter, and
word---change profoundly as text shifts its confines from paper to pixel. A
substantial gap separates visible text from its storage medium. The two sites
of inscription---screen and electromagnetic storage---are physically
incongruent. One must be translated into the other. Control codes govern the
process, which brings with it physical control at the level of infrastructure.
This is where, for example, we can find spyware and censorship filters.

I propose we begin with this obvious sense of difference between paper and
pixel: where print is governed by law from without, think for example of
England's Obscene Publication Acts, digital text is governed by code, from
within [On Obscene Publication Acts see @mccalman_unrespectable_1984;
@roberts_morals_1985]. I will go further than others to maintain that digital
text *is* code, in the sense that it is always parsed and potentially
executable [See discussion in @manovich_language_2002, 48;
@chun_software_2004, 27-8; @galloway_anti-language_2010]. Control thus binds
to content inextricably, to become an organ in the same unified corpus.

Changing material conditions of textual transmission push against familiar
ideas of literary criticism. For example, the easy reproduction of digital
text weakens the material basis for authorship attribution. Text that is easy
to copy is easy to cite and plagiarize. The weakening of the authorship
function makes certain ways of talking about ideas like "authorial intent" and
"fidelity to the original" difficult to sustain. The emergence of massive,
community-based writing initiatives like Wikipedia along with algorithms that
write spam or summarize news automatically, further erode notions of
authorship based on individual genius. The author did not die, however.
Authors continue to live and collect royalties.[^ln-dead]
Autopoiesis---literature writing or discourse speaking itself---did not
displace authorship as a social institution.[^ln-varela] Code merely makes the
flows of poiesis less apparent. It is difficult, but not impossible, to find
the programmer responsible for sending spam or to credit writers based on
Wikipedia contribution history. Spammers are sentenced just as notable
Wikipedia contributors receive barn stars in recognition of their efforts.

Poetics reconstructs a sequence of willful delegation: from thought to thing.
A discipline of close attention to the minute particulars of encoding,
transmission, storage, and the decoding of texts ultimately reclaims a measure
of intent and thereby authorial responsibility. In many cases, we may not care
to speak of it. One would hardly find Tolstoy "at fault" for his *War and
Peace*. In other contexts, as when unsolicited advertisement clutters the
bandwidth to the exclusion of other forms of speech, we must. That may seem
strange at first: to recover the subject in the physical minutiae of the
encounter between text and machine. The point of contact between human, text,
and device is significant because it is here, in the liminal zone of semiotic
exchange, where subjects disappear into machines and where machines step forth
as animated and seemingly intelligent actors. Our ability to apprehend the
politics of smart objects therefore depends on the formulation of their
poetics: how they were made.

Extant models of literary transmission assume movement through passive and
immutable media. Paper constitutes the document of record, which, once
archived, does not change its contents. Philological techniques like genetic
criticism and forensic reading make it possible to reconstruct if not
"authorial intent," then at least a trace of an author's hand. In some
cases---think manuscripts and folios---we may even ascribe properties like
"fidelity" to "original" works of art. When media are immutable, one imagines
a causal chain of custody between works and their creators, who at some point
must have occupied the same contiguous time and space: the closer a parchment
to Shakespeare, the higher its evidentiary (and market) value.

The transition between Gutenberg press and Project Gutenberg, an online
library containing thousands of texts, complicates the linkage. Unlike pen and
paper, which come in direct contact with each other during writing, the bridge
between keyboard and screen passes through multiple mediating filters.
Writing in that sense in itself becomes a programmed experience. We do not
write in the conventional sense of etching marks into a static host. The act
is a simulation. We neither touch nor see the textual conduit. The visible
does not correspond to the actual. Simulated erasure for example, of the kind
that happens when a writer presses the backspace key, does not necessarily
entail the corresponding erasure of content on disk. The "erased" word could
persist and even multiply across other storage drives and devices. The sign's
fracture entails such palpable consequences.

In *Plain Text*, I will argue that some of contemporary public sphere's
ideological afflictions---the acquiescence to routine surveillance and
censorship, for example---relate to our failure as readers and writers to come
to terms with the changing material conditions of digital text. A society that
cares about the long-term preservation of complex discursive formations like
free speech, privacy, or online deliberation, would do well to take heed of
the textual building blocks at their foundation. The structure of discursive
formation---documents and narratives---has long been at the center of both
computer science and literary theory. Using primary sources from both
disciplines, *Plain Text* uncovers the shared history of literary machines,
bringing computation closer to its humanistic roots, and the humanities closer
to its computational realities.

*Plain Text* makes a historical case for the recovery of textual thought
latent in the machinery of contemporary computing. Just as literary
scholarship cannot survive without awareness of its computational present, the
design of computational platforms cannot advance without greater awareness of
its cultural contexts. The political struggle for meaning-making, the very
opportunity to engage in the act of interpretation, thus begins and ends with
the material affordances of the epistemic artifact.[^ln0-levine]

[^ln0-levine]: Affordances, as Caroline Levine explains, "describe the
potential uses or actions latent in materials and designs." For example,
"[g]lass affords transparency" where "[s]teel affords strength"
[@levine_forms:_2015, 6].  See also @hutchby_technologies_2001, 447.

The future of reading and writing is inexorably intertwined with the
development of computer science and software engineering. Even if you are not
reading these words on a screen, my message has reached you through a long
chain of machine-mediated transformations: from the mechanical action of the
keyboard on which I am now typing, to the arrangement of electrons on magnetic
storage media, to the modulation of fiber-optic signal, to the shimmer of the
flowing liquid crystal display rendering the text. Computation occupies the
space between keyboard and screen, which in turn gives rise to higher-order
cultural institutions: from the architecture of social media platforms to the
formation of massive shared archives. The "cultural techniques" that guide our
use of such technologies are formative of the society as a whole
[@leroi-gourhan_gesture_1993, 83-84; @siegert_cultural_2015]. Daily choices
like choosing a text editor, a filing system, or a social networking platform
cannot therefore be addressed in shallow instrumental, system-centric ideals.
Complex computational systems cannot give rise to ideals any more than
financial markets can. From the many available visions of human-computer
interaction I argue for choosing one that confirms to a humanist ethos,
whatever the reader's politics.

Computational poetics encourages users to become active thinkers, tinkerers,
and makers of technology. It understands binary and digital environments to be
also semiotic and symbolic systems in essence, amenable to the construction
and the deconstruction of meaning. I further encourage those who may have
considered themselves mere "users" of computation to apply the same critical
acuity they employ in the close reading of prose and poetry to the
understanding of code and machine. For text to render on screen properly it
must be encoded or translated from machine-transmittable code into
human-readable shape. Encoding constitutes a primitive field of textual
activity, at the crossroads of computer science and the study of literature.
Encoding matters because how texts are encoded, transmitted, and stored
decides who gets to decode, receive, and access.

The advent of simulated text necessitates a computational poetics, which
enables unfettered access to text, code, platform, and infrastructure. For
now, commands like *xxd*, *pcap*, *ssh*, and *traceroute* resemble arcane
incantations that elicit hidden, symbolic action. Those who wield them gain
the metaphorical power to "hop" across, to "sniff" packets, to "survey," to
"traverse," and to "flood" network topographies. Computational poetics empower
the reader to resist hard-wired models of machine-bound interpretation.
Today, resistance remains in the purview of the few. Plain text channels
itinerant streams of data back into the tidal pools of human agency and
comprehension for all. There, code can become intelligible for the very
subjects whose loss Foucault and Kittler lament.[^ln-lament] Only in such
encrypted tunnels and secure shells can anything like the digital humanities
and new media studies take root.

## Method

> We cannot separate the two things: head and hand [...] the science of life
> [...] is a superb and dazzlingly lighted hall which may be reached only by
> passing through a long and ghastly kitchen [...] [W]e shall reach really
> fruitful and luminous generalizations about vital phenomena only in so far as
> we ourselves experiment and, in hospitals, amphitheaters, or laboratories,
> stir the fetid or throbbing ground of life [@bernard_introduction_1957,
> 3,15].

My approach to writing *Plain Text* stems from the desire to enact theory
capable of addressing the grim picture Friedrich Kittler painted at the end of
his influential monograph.[^ln-kittler2] By all accounts, Kittler was neither
a technological romantic nor Luddite. I hence understand his *Gramophone,
Film, Typewriter* as a call to action. When Kittler wrote that "media
determine our situation," he challenged his reader to choose between
complicity and defiance [@kittler_gramophone_1999, xxxix]. It was not a
statement of fact but the articulation of a question: What can one do to
counteract technological determinism? In what follows, I outline several
intellectual lineages, materialist and experimental, which frame my answer.

Critical theory at its best aims to see "the human bottom of nonhuman things"
[@horkheimer_critical_1982, 143]. As such, it is one of our most powerful
tools for analysis and resistance against technological determinism. Max
Horkheimer wrote that the issue "is not simply the theory of emancipation; it
is the practice of it as well" [@horkheimer_critical_1982, 233]. Recently,
scholars like Kathleen Fitzpatrick, Tiziana Terranova, and Trebor Scholz have
began to turn the tools of critical theory towards the instrumental contexts
of knowledge production [@scholz_digital_2013; @fitzpatrick_planned_2011;
@terranova_network_2004]. I join them to argue that in treating the
instruments of intellectual production and consumption uncritically, all of
us---readers and writers---accumulate an ethical debt. It is one thing to
theorize about the free movement of literary tropes across cultures and
continents, and quite another to have that theory appear in print behind
paywalls inaccessible to most global reading publics.[^ln-sarab] Similarly, a
theoretical distinction between form and content, when instantiated in
specific file formats like Microsoft Word (`.docx`) or Adobe Reader (`.pdf`),
establishes divisions of labor between editors, book sellers, and offshore
typesetting firms.[^ln-sweatshop] One group trades content in the economy of
prestige, another formatting in the economy of survival, yet another controls
distribution in economy of the market.

Distinctions of labor will remain in place as long as the conversation about
ideas like "form" and "content" persists in the abstract. Similarly, a
materialist critique cannot achieve its stated aims without purchase on the
material world. Contemporary knowledge workers stare into rectangular black
boxes for a considerable part of their days, suspecting, in the absence of
other feedback, that their gaze is met in bad faith. Connecting theories of
meaning-making to their practice offers a way out of the conundrum. Bad faith
identifies a misalignment between thought and action.[^ln-sartre] The solution
to connect "meaning" with "operational meaning" belongs to a species of
pragmatism. William James articulated the approach concisely when he wrote
that "reality is seen to be grounded in a perfect jungle of concrete
expediencies."[@james_pragmatisms_1907 233] For James and other pragmatists,
truth could not exist in the abstract alone. It also entailed causes and
effects that operate in the world.[^ln-pragma-truth] In his essay
"Pragmatism's Conception of Truth," James asked: "How will the truth be
realized? [...] [W]hat concrete difference will its being true make in
anyone's actual life? [...] What experiences will be different from those
which would obtain if the belief were false?"[@james_pragmatisms_1907 200]
Frank Ramsey, the young British philosopher close to Ludwig Wittgenstein,
would later write in a similar vein about meaning "defined by reference to the
actions."[@ramsey_foundations_2013, 155]

For a pragmatist, truth-carrying propositions of the shape "X is Y" (as in,
"the author is dead" or "art is transcendent") beg the questions of "Where?,"
"When?," "For whom?," and "What's at stake in maintaining that?" Following the
pragmatic insight of James and Ramsey, I will proceed with the conviction that
abstract categories like "literature," "computation," and "text" cannot
possibly be reduced to a number of essential, structural features. Rather, to
borrow from Wittgenstein's *Philosophic Investigations*, categories denote a
set of related practices that may or may not share in any given familial
characteristic.[^ln-witt] In our case, imagine a tree diagram where the
branches of computation and textuality intersect and diverge in tangled and
convoluted ways.

In an approach to *doing* theory, *Plain Text* joins the experimental turn
steering the academy toward critical practice, especially in fields
long-dominated by purely speculative thought. The experimental turn represents
a generation's dissatisfaction with armchair philosophizing.  Recall the
burning armchair, the symbol of the experimental philosophy movement. Joshua
Knobe and Shaun Nichols, some of the early proponents of the movement, explain
that "many of the deepest questions of philosophy can only be properly
addressed by immersing oneself in the messy, contingent, highly variable
truths about how human beings really are" [@knobe_experimental_2008, 3]. The
emergence of spaces where research in the humanities is done exemplifies the
same trend. In naming the locations of their practice "laboratories,"
"studios," and "workshops," humanists reach for new metaphors of labor. These
metaphors aim to reorganize the relationship between body, space, artifact,
knowledge, and inscription. In my lab and elsewhere, researchers have taken to
calling this approach "experimental humanities."

As an example of what I have been calling here the "experimental turn" in the
field of early modern history consider the preface to a recent volume on *Ways
of Making and Knowing*, edited by Pamela Smith, Amy Meyers, and Harold Cook.
They write that the "history of science is not a history of concepts, or at
least not that alone, but a history of the making and using of objects to
understand the world" [@smith_ways_2014, 12]. Smith translates that insight in
the laboratory, where, together with her students, she bakes bread and smelts
iron to recreate long-lost artisanal techniques. For those who experiment,
"book knowledge" and "artifactual knowledge" connect in practice.

Artifactual knowledge---from typesetting software to e-book readers and word
processors---shapes our everyday encounter with literature. Such technologies
should not be understood as value-neutral conduits of information. I follow
Lewis Mumford and Langdon Winner to argue that technology affects the exercise
of textual politics in subtle and profound ways [@mumford_authoritarian_1964;
@winner_artifacts_1980]. Artifacts cannot hold beliefs about politics.
Political power is rather exercised through them. For example, stairs do not
discriminate against the mobility impaired. The human failure to enforce
accessibility through specific legal and architectural choices does.
Typesetting software, e-book readers, and word processors similarly embody
implicit communication models: ideas about deliberation, ethics of labor,
discursive values, and views about "natural" human aptitude for
interpretation. The maker of the electronic book encodes how the book is sold
and where, minimum and maximum font size, the visibility of marginal notation,
the possibility of sharing, the availability of the critical apparatus.
Content in that sense is meant for further processing, in a way that maximizes
its extracted value. Contemporary documents are capable of structuring the
literary encounter to these ends according to the reader's economic status,
gender, race, age, location, or physical ability.

To what extent does the book in front of you permit or enable access?
Whatever the answer, a function of understanding the text includes the
explication of its physical affordances. An experimental approach to reading
enables the critic to "lay bare" the device. A literary scholar's version of
baking bread and smelting iron is to make literal the archaeology of media at
the level of the mechanism. In *Plain Text* we will unearth and excavate
textual machines. In practicing archaeology I contend that cardinal
literary-theoretical concepts---such as word, text, narrative, discourse,
author, story, book, archive---are thoroughly enmeshed in the underlying
physical substratum of paper and pixel. It follows that any attempt to
articulate the idea cannot attain its full expressive potential without a
thick description of its base particulates.

Luckily for us, reading and writing are not esoteric activities. They are
readily available to introspection. I will therefore occasionally encourage
readers to encounter the immediate contexts of their reading anew: to put down
the book or to lean away from a screen and to look at these textual artifacts
with strange eyes. In this movement of the body, I want to disrupt the mind's
habituated intuitions, pitting them against knowledge at hand and fingertip
knowledge: as when ruffling through the pages or typing at a keyboard. How
ephemeral is an electronic text, for example? The pragmatic answer lies not in
reductive universal propositions---very, or not at all---but in contingent
technological affordances attached to specific reading devices. What can a
reader do with this text, here and now? Where is it stored? Are readers given
dispensation to copy and paste? Do they have legal permission to quote at
length, to perform publicly, or to otherwise trans-mediate? Will the text
disappear when the reader closes the book's cover?

## Plan of the Present Work

The tangled pathways of inscription winding their way through the device exist
in relation to distinct communities of computational practice. A researcher
cannot for this reason expect to discover a single theoretical framework that
captures the complexity of digital text in motion. An engineer's use of the
words "code" and "poetry" differs from that of a poet's. The changing contexts
evoke a corresponding shift in operational definitions. This book is thus
neither a total history of modern computing nor a survey of literary theory.
Rather, the argument therein progresses from the action of the alphanumerical
keyboard switch, through copper and silicon, to liquid crystal and the
floating gate, and on towards the reader and the community. It is but one of
many possible passes through a cavernous black box.

At the core of the book's **first chapter** lies the notion of a modernist
literary device, understood both as literary technique and a thought
experiment about intelligent machines, directly connected to the birth of
modern computing. A section on literary technique in the thought of Percy
Lubbock, Walter Benjamin, and Mikhail Bakhtin opens the discussion.
Materialist poetics rise concomitantly alongside a mechanistic, rule-based
view of language. In this chapter I reconstruct a series of thought
experiments first in the writing of Ludwig Wittgenstein, and then in Alan
Turing's seminal paper on an imaginary computer capable of reading and
writing. The verbs to read and to write imply a type of cognitive processing.
What does it mean to read and to write for a machine? What about broken
mechanisms of comprehension? At once a device and an algorithm, the Turing
machine blurs the boundaries between software and hardware, code and content,
intelligence and its imitation.

The passage from keystroke to pixel gives this book its shape. In the chapters
to follow, our mobile phones and laptops will come fully into view as metaphor
machines engendering ubiquitous simulation. The **second chapter** begins with
an explication. What does it mean to turn a page, I ask, when neither the page
nor the action of turning it correspond to their implied analogies? The
analysis of the metaphor helps trace the intellectual history of
human-computer interaction, a field which progressed from "conversational
programming" to the "direct manipulation" paradigm shaped by theories of
cognitive metaphor and immersive theater. The logic of "directness" leads to
the rapidly developing field of brain-computer interfaces. The chapter
concludes with a moment of speculative formalism, in which I consider the
possibility of affective literature, of the kind that eschews language and
representation.

Two rich intellectual histories collide in the **third chapter**: one, the
material history of format as a concept in computer science and the other, the
intellectual history of form in literary theory. I show formatting as a
process that mediates between the text's intrinsic rules for construction and
its extrinsic shape, transforming one type of structure, a series of bits
arranged into tracks and sectors, into another, letters arranged into
sentences and paragraphs. I then draw a short history of text formats. It
begins with several "control characters" limited in function to actions like
"carriage return" or "stop transmission." With time, formats begin to
encompass all manner of machine instruction, including legal instrument to
enforce digital rights management and copy protection. A manufacturer's
ability to censor or to surveil digital text is contained within the
formatting layer: from electronic books that modify themselves to suit the
reader's geographic location to "smart contracts" that contain the rules of
their own execution.

The **fourth chapter** charts the emergence of screen reading. Screens appear
to restore a measure of visibility lost in electromagnetic inscription, with
one major side-effect. They cannot guarantee fidelity between the word visible
and the word archived. The inscription shown can only attain a arbitrary
correlation to the inscription archived. Screen reading further happens on
screens that refresh themselves at a rate of around 60 cycles per second
(Hertz). The digital word is technically an animation; it moves even as it
appears to stand still. This property of the medium attunes the reader to a
particular mode of apprehension, affecting not just the physics but also the
aesthetics of digital media. Works by the philosophers Henri Bergson, John
Haugeland, and Nelson Goodman help construct a phenomenology of screen-based
digital perception. The digital emerges ultimately not as an intrinsic
property of the medium, but as structure imposed from without. In the extreme,
that means that a censored *electronic* text can form a perfectly *analog*
artifact, despite being digital in all other senses of the word. Conversely,
texts in print are already "born digital," in the sense that literary works
like Shakespeare's *Hamlet* are amenable to "reliable processes of copying and
preservation" [@haugeland_analog_1981, 213-225]. Properties that make media
"digital" or "analog" reveal themselves to be neither universal nor essential
to the medium. The medium is not the message. "The reliability and
preservation of textual copies" may mean one thing to a literary scholar,
another to a software engineer or a legal professional, and something entirely
different to a librarian, I argue in the conclusion of the chapter. It matters
not what the medium is, but what we can do with the text.

The **fifth and final chapter** begins with a discussion of an apparent
paradox. A camp of media theorists and textual scholars in the 1990s conceived
of electronic texts as an ephemeral, almost immaterial, phenomenon. Text
shimmered and glared: it was spoken of in terms of *hypertext*, light writing,
and electricity. A generation of theorists that came after insisted on the
weighty materiality of electronic media. Reading began to engage the
morphology of rare metals, media archaeology, hard drive forensics. Both
accounts, I argue, capture an aspect of the same underlying condition. The
perceived image of an archived inscription splits from its source. The sign
plausibly resides both on screen and on hard drive. It fractures, in some real
sense, diverging at the site its projection from the site of the archive.
Using archival materials from the history of telegraphy in the late nineteenth
and early twentieth centuries, I chart the gradual fracture and the ultimate
illegibility of the newly composite sign. Early computers stored
human-readable text and machine instruction at the surface of the same storage
media like punch cards and ticker tape. Although difficult to read, these
forms of machine writing were readily visible and therefore amenable to
analysis. The advent of magnetic storage forced the composite inscription into
an opaque medium. Unable to perceive magnetic polarities without the aid of a
machine, readers often manipulated text blindly. In this way a typist would
type several sentences without seeing the printed output. The chapter
identifies a milestone in the history of human textuality: the moment at which
the inscription passed from view, giving rise to the sometimes conflicting but
nevertheless consistent accounts of digital textuality.

A short *conclusion* gestures towards the contemporary political consequences
of the material covered, discussing also the possibility of machine
phenomenology in relationship to humanism.

<!--- NOTES  --->
<!--- NOTES  --->
<!--- NOTES  --->

[^ln-bernard]: On Bernard see @petit_claude_1987; @sattar_aesthetics_2013; and
@mcluhan_gutenberg_1962, 4 & 206.

[^ln-bookreview]: I write "supplants the function" because I do not mean to
imply that the book review disappears or becomes less vital. On massive market
platforms like Amazon Books, the book review passes from the domain of an
expert to the domain of the lay reader. Book reviews thus proliferate. Their
function changes from universal aesthetic judgement to instrumental reasoning.
In other words, we now find the book first then read the review. The review
ceases to serve as a tool for discovery--a function now addressed by the
search and recommendation engines.

[^ln-brains]: For the first view see @putnam_minds_1960 and
@fodor_language_1975. For the second view see @deutsch_quantum_1985 and
@dyson_turings_2012.

[^ln-brik]: @shklovksy_poetika_1919, 104. Translations are mine unless source cited explicitly in
English.

[^ln-capital]: Scholars like Alexander Galloway, David Golumbia, Bernard
Harcourt have advanced critique along similar lines. See
@galloway_protocol:_2006, @golumbia_cultural_2009, and @harcourt_exposed:_2015.

[^ln-cog]: See for example @gibbs_categorization_1992; @blasko_effects_1993;
@gibbs_poetics_1994; @neal_role_1997, 441-463; @gentner_alignment_1997.

[^ln-dead]: See @barthes_death_1977; @foucault_what_1980; @nesbit_what_1987.

[^ln-digitalliteracy]: See for example @postman_technopoly:_1992;
@negroponte_being_1995; @davidson_now_2011; @obama_2016_2016.

[^ln-dissent]: See @harcourt_exposed:_2015, 251-80.

[^ln-dmca]: See @ku_critique_2004; @ginsburg_legal_2005; and @fry_circumventing_2009.

[^ln-egturner]: Mark Turner, whose work builds on Lakoff and Johnson is a
strong proponent of such an approach. See @turner_death_1987 or
@turner_language_1992.

[^ln-flusser]: The work of @flusser_does_2011 has been similarly influential.

[^ln-hegel]: I discuss the topic at length in Chapter 3.

[^ln-iarkho]: I borrow the term "microanalysis" from the largely forgotten in
the West Russian literary scholar and member of the Moscow Linguistic Circle,
Boris Iarkho. In his *Methodologies of Exact Literary Study* (circa 1935-6) he
writes: "I understand 'atomism' as a sort of an ideal aspiration, as an
orientation toward the liminally small. But under no circumstances do I
advocate working with hypothetical quantities, like molecules, atoms,
positrons, and so on, which are located beyond the limits of perception. That
this applied mythology gave us such splendid results in chemistry, should not
conceal its true nature. Tomorrow, all such explanations of visible through the
invisible could give way to other hypotheses, as was the case with their no
less fertile predecessors (elemental spirits, phlogiston, and light ether).
But the cell, the nucleus, and the chromosome endure as lasting accomplishments
of microanalysis. I suggest to move as far as a microscope can reach, and no
further" [@iarkho_metodologia_2006, 363-364]. For Iarkho, the most
quantitatively inclined of the Russian Formalists, microanalysis involved
systematic application of statistical methods to the study of literature.

[^ln0-influences]: Works by Finn Brunton, Wendy Chun, Matthew Fuller, Alexander
Galloway, Lisa Gitelman, Yuk Hui, Helen Nissenbaum, Lev Manovich, John Durham
Peters, Mary Poovey, and Jonathan Sterne among many others left their mark on
this text.

[^ln-kittler2]: *Gramophone, Film, Typewriter* ends as follows: "And while
professors are still reluctantly trading in their typewriters for word
processors, the NSA is preparing for the future: from nursery school
mathematics, which continues to be fully sufficient for books, to
charge-coupled devices, surface-wave filters, digital signal processors
including the four basic forms of computation. Trenches, flashes of lightning,
stars---storage, transmission, *the laying of cables*."
@kittler_gramophone_1999, 263.

[^ln-lacan]: The evanescent absence of life that Lacan mentions as "the sign
about which Robinson Crusoe would make no mistake" [@lacan_seminar_1997, 167].

[^ln-lament]: Or perhaps celebrate, depending on your understanding of their
post-humanism. For more a more extended discussion on Kittler, Foucault, and
post-humanism see for example @winthrop-young_silicon_2000; @wolfe_what_2010,
104-128; @siegert_cultural_2013.

[^ln0-manovich]: See @manovich_there_2011, 53-106.

[^ln0-marx]: For more on alienation see the relevant discussion in
@marx_economic_1964 and @marx_theories_1963.

[^ln-pragma-truth]: For a more thorough discussion on the topic see
@seigfried_william_1990, @pihlstrom_structuring_1996, and @putnam_jamess_1997.

[^ln0-reverse]: @kirschenbaum_mechanisms:_2008, 15. On the role of reverse
engineering in media studies see also @fuller_evil_2012, 9.

[^ln-sarab]: See also @english_economy_2008; @brouillette_wither_2015 and
@brouillette_unesco_2015.

[^ln-sartre]: Sartre would write "transcendence" and "facticity." See
@sartre_being_1993, 86-119.

[^ln-spam]: For example, in 2004 researchers estimated that spam mail makes up
40%-80% of the total email volume @cournane_analysis_2004.

[^ln-sweatshop]: See @freeman_high_2000 and @patel_working_2010.

[^ln-rhein]: I am in influenced here by the discussion of epistemic things in
@rheinberger_toward_1997, 24-37.

[^ln-varela]: See @varela_autopoiesis:_1974; @barthes_rustle_1989, 5;
@nuttall_new_2007, 6-25.

[^ln-wark]: I use the term "vector" in somewhat more limited sense than it
appears in the idea of "vectoralist class" coined by McKenzie Wark. By
"vectoralist class" Wark means something like the group of interests that
control the distribution of information. See for example
@wark_information_2006. In understanding the document as a vector I posit it as
a three-dimensional rather than a two-dimensional object, with the extra
dimension extending in time, similar to Jerome McGann's idea of the "editorial
horizon." See @mcgann_textual_1991.

[^ln-winner]: See for example: "[w]riters concerned with with problems of
technology-out-of-control have frequently echoed Hobbes in suggesting that
such an artifact---the Leviathan of interconnected technical systems---has a
soul of its own [...] A ghost appears in the network. Unanticipated aspects of
technological structure endow the creation with an unanticipated *telos*"
[@winner_autonomous_1978, 280].

[^ln-witt]: @wittgenstein_philosophical_2001, 67-77. For more on the
connection between Wittgenstein and James see @goodman_james_2004.

[^ln-twobil]: Code metrics from @mccandless_million_2015.

\newpage
