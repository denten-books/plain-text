# Computational Poetics: An Introduction

While I write these introductory remarks, a ceiling-mounted smoke detector in
my kitchen emits a loud noise every three minutes or so. A pleasant female
voice announces also "low battery." This is, I learn, a precaution stipulated
by US National Fire Alarm Code 72-108 11.6.6 (2013). The clause requiring a
"distinct audible signal before the battery is incapable of operating" is
encoded into the device. The smoke detector literally embodies that piece of
legislation in its circuitry. We thus obtain a condition where two meanings of
code---as governance and machine instruction---coincide. Code equals code.

I am at home, but I also receive a notification of the alarm on my mobile
phone. Along with monitoring apps that help make my home "smarter," the phone
contains most of my library. I often pick it up to read a book. However, the
phrase "reading a book" obscures a number of metaphors for a series of odd
actions. The "book" is a small, thin black rectangle: three inches wide, five
inches tall, and barely a few millimeters thick. A slab of polished glass
covers the front of the device, where the tiny eyes of a camera and a light
sensor also protrude. At the back, made of smooth soft plastic, we find
another, larger camera. At the foot of the device a grid of small perforations
indicates breathing room for a speaker and several microphones. To "open" a
book I touch the glass. The machine recognizes my fingerprint almost
instantly. I then tap and poke at the surface until I find a small image that
represents both my library and a book store, where I can "buy books." Buying
books does not, however, involve the actual ownership of physical objects.
Rather, I agree to a licence that grants limited access to data, which the
software then assembles into something resembling a book on the screen. I tap
again to begin reading. The screen dims to match room ambiance as it fills up
with words. A passage on the first page appears underlined: a number of other
readers in my social circle must have found it notable. My finger slides along
the glass surface to turn a "page." The device emits a muffled rustle to
reinforce the pretense of manipulating paper. The image curls ever so slightly
as another "page" slides into view. My tiny library metaphor contains hundreds
of such page metaphors.

Despite appearances, the electronic metaphor-making device on my desk has more
in common with the smoke detector than it does with several paper volumes
scattered across my desk. The electronic book and the smoke alarm contain
printed circuit boards, capacitors, and resistors. Both draw electric current.
Both require firmware updates and both are governed by codes, political and
computational. The smoke alarm and the mobile phone connect to the internet.
They communicate with remote data centers and with each other. And yet, I
continue to read electronic books as if they were familiar, immutable, and
passive objects: just books. I think of them as intimate artifacts---friends
even---wholly known to me, comforting, and warm. The electronic book is none
of those things. Besides prose, it keeps my memories, pictures, words, sounds,
and thoughts. It records my reading, sleeping, and consumption habits. It
tries to sell me things, showing me advertisements for cars, jewelry, and
pills. It comes with a manual and terms of service. It is my confidant, my
dealer, my spy.

*Plain Text* concerns the nature of digital inscription---the material trace
that gives rise to textual phenomena, and, more broadly, to all cultural
artifacts in which the computer mediates. We find ourselves today in an
unprecedented, since the Middle Ages, position of selective *asemiosis*: the
loss of signification. Many contemporary texts---like poems inscribed into
bacteria and encrypted software---exist simply beyond the reach of human
senses.[^ln-dna] Other forms of writing are illegible in ways that prevent
access or comprehension. Increasingly, we write not in the sense of making
marks on paper but in simulation. The key press leaves a trace in computer
memory, which then appears on the screen as its representation. There, the
trace is visible but ephemeral. On disk, the mark endures in a form legible
only to those who possess the specialized tools and the training necessary to
decipher it. A vibrant discursive practice of textual exegesis---commentary,
interpretation, dialog---is crucial to whatever political ideals that demand
an engaged populace. Codes embody governance through explicit instruction. It
stands to reason that to retain the civic potential for critique---to speak
truth to power---one must be able to perceive its codification. Traditional
literary theory must therefore connect to the material contexts of textual
production which emanate from the fields of computer science and software
engineering. Conversely, a tighter coupling with the critical tradition in the
humanities can reveal the often occluded political implications of
technological progress, which so often appears in the guise of the apolitical.
To create a novel algorithm that predicts crime by analyzing one's reading
habits, for example, is also to invite the dystopian possibility of thought
policing, unless, that is, such algorithms remain legible, in public view, and
under continual counter-scrutiny.

[^ln-dna]: See @bok_xenotext:_2015 and @bok_xenotext_2011: "I have been
striving to write a short verse about language and genetics, whereupon I use a
'chemical alphabet' to translate this poem into a sequence of DNA for
subsequent implantation into the genome of a bacterium (in this case, a
microbe called *Deinococcus radiodurans*---an extremophile, capable of
surviving, without mutation, in even the most hostile milieus, including the
vacuum of outer space)."

## Thesis and Scope

More narrowly, *Plain Text* tells a story of a major morphological shift
affecting culture production in general and textuality in particular. If I
were to interrupt someone in the process of writing something on a computer
and ask---Where do these words reside?---I would likely receive several
conflicting answers in response. In some sense, the words reside on the
screen, where they appear to view. In another sense, they live somewhere
within the machine, on remote and often hermeneutically sealed surfaces:
silicone chips, hard drives, flash memory cards. In yet another sense, the
visible sign is still further removed from the contexts of its production. The
word is in the wires. It spreads across servers, routers, and data centers.
One no longer reads or writes alone. What was once apparent now takes on a
more complex shape, stretched between surfaces, across time and space. The
book---this book, any book---gains a new structure. I do not mean the above
figuratively. In the case of my writing words on a screen, using a keyboard,
the text forms a kind of a live lattice---a multidimensional grid---which
connects the tactile sense of the letter beneath my fingers to its optic and
electromagnetic traces. All of these sensualities are present at once. They
incorporate the totality of the synchronic text only in aggregate. I cannot
consequently pass a note to the reader digitally in the same sense that one
passes notes in class, on paper. It is impossible to give the entire structure
over to another. My text is irrevocably intertwined with my material contexts;
it literally gains another shape when recreated under system configurations
not fully congruent with my own.

Much of the contemporary anxiety about the intrusion of computational culture
into the everyday points to this fundamental reshaping of the sign, without
naming it. The physical fracture of the overall inscription leads to its
multivalence. The lattice opens a depth between the words, where forces of
capital and control intervene to monitor, monetize, censor, or
correct.[^ln-capital]

To come to terms with the novel conditions of text so fractured and refracted
*Plain Text* enacts a displacement of vocabularies. It is a response to a
particular situation of a literary scholar encountering the field of software
engineering. For a long stretch of my professional life, these two areas of
activity remained separate. I worked at one and I studied the other. At the
time, I simply did not think that code had much to do with poetry. The idea
for this book came to me in a moment of realization after I was asked one of
those seemingly naive but fundamental questions that can set research in
motion down a long and winding path. A childhood friend who loves books asked
about the difference between text in print and text on the screen.  In my
struggle to answer, I realized that some of my deepest assumptions about
literature relied on the centuries-long stability of print media. Despite my
professional experience as a programmer and academic training in literary
studies, I could not readily explain the mechanisms by which keystrokes turned
into pixels, and pixels into words. I could recount technical detail on some
level, but my knowledge was riddled with unexamined gaps. It did not amount to
a coherent story. I was, despite my best efforts, surrounded by magical
lanterns that cast shadows of code and poetry.

Initially, my two selves---the scholar and the engineer---spoke different
languages. Reconciling them was and continues to be a disconcerting process by
which things dear and familiar to me, in both worlds, grew strange and
unfamiliar, showing themselves to be sometimes less than, and sometimes more
than I comfortably expected. Nothing could be assumed from the start. Field
specific language, down to its foundations, had to be examined for hidden
assumptions that prevented dialog. With time, I saw that code and poetry have
much to do with one another. Writing this book has taught me to embrace the
incongruence.

Reflecting on the development of Morse Code in 1949 in the *Proceedings of the
American Philosophical Society*, Frank Halstead mentioned the difficulty of
finding a home in either the arts or sciences for what he called "code
development." "It is a matter somewhat related to the general art of
cryptology," he wrote, "yet it is not wholly divorced from electrical
engineering nor from general philology" [@halstead_genesis_1949, 456]. As
Halstead anticipated, research in the field of computational culture has led
me to a rich multidisciplinary archive of materials from the history of
literary theory, semiotics, telegraphy, and electrical engineering from the
middle of the nineteenth to the end of the twentieth century. That archive
includes documents from the proceedings of the Association for Computing
Machinery (ACM) and the US Patent and Trademark Office, from Bell Labs and
early Soviet publishing houses that heralded the advance of formalism, from
studies on animal communication behavior, to Unix manuals, to textbooks on
semiotics, and to foundational texts in the philosophy of aesthetics and
literary theory.

I deploy the archive to argue that extant theories of interpretation evolved
under conditions tied to static print media. By contrast, digital text changes
dynamically to suit its reader, political context, and geography.
Consequently, I advocate for the development of computational poetics: a
strategy of interpretation capable of reaching past surface content to reveal
platforms and infrastructures that stage the construction of meaning. A
computational poetics differentiates within the apparent unity of digital
text. In the chapters that follow, I will trace a figure and describe its
anatomy. If the physics of the word have changed---qualitatively,
materially---I would like to ask: How? and How do these changes affect the
diversity of interpretive practices? I draw on the annals of literary theory
and software engineering to buttress the historical bases for a possible
answer. In the process, I argue that even our most basic practices of
intellectual production are profoundly alienated from their physical contexts.
The object of study is the nature of that alienation.

I appeal to the idea of "plain text" in the title of this book to signal an
affinity with a particular mode of computational meaning-making. Plain text
identifies a file format and a frame of mind. As a file format, it contains
nothing but a "pure sequence of character codes." Plain text stands in
opposition to "fancy text," "text representation consisting of plain text plus
added information" [@unicode_consortium_unicode_1990]. In the tradition of
American textual criticism, "plain text" alludes to an editorial method of
text transcription which is both "faithful to the source" and is "easier to
read than the original document" [@cook_considerations_1988]. Combining these
two traditions, I mean ultimately to build a case for a systematic minimalism
when it comes to our use of computers---a minimalism that privileges access to
source materials, ensuring legibility and comprehension.  I do so in contrast
with other available modes of human-computer interaction, which instead
privilege maximizing system-centric ideals like efficiency, speed,
performance, or security.

The title further identifies an interpretive stance one can assume in relation
to the making and the unmaking of literary artifacts. Besides visible content,
all contemporary documents carry with them a layer of hidden information.
Originally used for typesetting, that layer affects more than innocuous
document attributes like "font size" or "line spacing." Increasingly, devices
that mediate literary activity also embody governing structures. For example,
the Digital Millennium Copyright act, passed in the United States in 1996,
goes beyond written injunction to require in some cases the management of
digital rights (DRM) at the level of hardware. An electronic book governed by
DRM may subsequently prevent the reader from copying or sharing stored
content, even for the purposes of academic study.[^ln-dmca] In some
situations, it may report the reader's activity to the authorities. Attempts
to silence print through book burning or censorship are viscerally apparent.
Unlike these, the dominion of computation proceeds by clandestine means.
Simulated text preserves the outward appearance of print, while concealing the
material specifics of digital production and distribution. The challenge of
*Plain Text* will be in the description of such emerging but often occluded
technological possibilities.

## Theory
### Displacement

*Plain Text* stems from a productive tension between estrangement and
habituation. In the background of a historical and materialist critique of
computational media there lies also an existential argument about inhabiting
media. I mean inhabiting in the way one lives with and within one's own
bookshelves, closets, hard drives, and archives. The dialectics of media
displacement constitute a method of making sense out of the often
contradictory logics of the virtual object. We are confronted by spaces that
are not spaces, or rather ersatz expanses that dissimulate: glass that looks
like paper, liquid crystal that flows to imitate ink. By such means, the
electronic book delineates a qualitatively new grounds for textual
inscription. Because *Plain Text* deals with the structure of intimate space,
it is a project theoretically contiguous with the philosophical poetics of
Gaston Bachelard and Henri Lefebvre, extended into the realm of everyday
computation [@lefebvre_production_1991; @bachelard_poetics_1994].

Writing surfaces multiply and establish themselves firmly among the
furnishings of home, body, and mind. Think here of commercial products that
occupy a central place in the living room: devices that listen, talk, and
answer questions, smart personal assistants, pacemakers and brain implants,
portable gadgets close to head and heart. One can call them computers, but
what is a computer but a machine for the reading and writing---input and
output---of information? The smart toaster and the electronic pacemaker alike
are distinct from their dumb mechanical counterparts in that they give grounds
to inscription. A contest for that space---the right to access and
ownership---is therefore crucial to the future of a literate humanities. I do
not mean to suggest that everyone needs to learn how to code, although that
would not be a bad thing. I mean to view computational culture apart from its
instrumental uses, in the context of literary and civic thought. I am
concerned here with the preservation of the basic possibility to form
discourse---to read and write---along surfaces that are not available for
immediate scrutiny. Poetics---the affordance of literary space---physically
limits the possibility of interpretation. A sign invisible or rendered white
on a white background is ultimately illegible. It never makes it into the
hermeneutic circuit.

In making the case for a computational poetics, I am helped by recent
scholarship in the historically- and philosophically-inflected studies of
media and technology.[^ln0-influences] My notion of poetics builds also on the
long history of literary theory, in the genealogy of formalist and
structuralist schools. My approach is not however limited to the canonical,
straight-ahead structuralisms of Roman Jakobson or Jonathan Culler. I am
borrowing rather from a more peripheral tradition represented best by third
culture thinkers like Viktor Shklovsky and Vilém Flusser, consummate
immigrants both, who extracted a methodology out of the fabric of their
migration.

Flusser in particular considered the condition of unease that comes with
migration, both physical and mental, to be a kind of information processing.
His thought was influential in making sense of my own displacements, first as
a refugee fleeing the dissolution of the former Soviet Union, then a
transplant into Silicon Valley from a strict literary education, and now a
lapsed engineer among humanists. These vantage points offer a singular view
onto the material conditions of contemporary intellectual life.

Both Shklovsky and Flusser wrote lucidly about the dynamics of habituation.
Their work sheds light onto the irresistible compromise at the core of all
technology---a compromise by which we trade critical understanding for
comfort. Habit covers the various homes we make for ourselves in the world
"like a fluffy cotton wool blanket," Flusser wrote: "[i]t smoothes the sharp
edges of all phenomena that it covers, so that I no longer bump against them,
but I am able to make use of them blindly." When we sit at our desks, for
example, we fail to see the "papers and the books that are lying all about."
We are used to them being there [@flusser_freedom_2003, 13 and 82].
Consequently, we do not parse them as information. Like water that surrounds
fish, the habituated thing passes into the background of experience. Mediums
become media. They disappear into the background, cease producing meaning,
become a stage for meaning-making, and like the stage disappear from view.

Losing sight of the material contexts of knowledge production is politically
perilous, because those who own the contexts set the terms of engagement.
Estrangement arrests the process of material concealment. The condition of
exile allows the displaced to once again transform habituated media into
meaningful information. In exile, "everything is unusual," Flusser wrote
[@flusser_does_2011, 81]. The migrant experiences the world as an ex-perience
[*er-fahrung*], or literally a driving out. Discovery, he concluded "begins as
soon as the blanket is pulled away," where the familiar objects can pass into
view again [@flusser_does_2011, 86-7].

<!-- perhaps more or less on exile, this is why i am bringing it in and how i
want you think about it -->

One could write, to take a simple example, "a field of study," without much
thought about figurative space. Shklovsky would have the reader pause to
consider the implications [@shklovksy_sborniki_1917]. In what sense do ideas
resemble (or not) a field? The poet could further make this metaphor strange.
One could write, for example: "to scythe a verdant field of literary study."
The verb (to scythe) and the adjective (verdant) create an unexpected
transference of new qualities not present in the original image (intellectual
field). These qualities "overdetermine" or "saturate" the metaphor, exposing
its conceit. One can do to fields of grass what one cannot to ideas.
Subsequently, we realize that the two domains---intellectual and
horticultural---do not map onto each other perfectly, leaving a semantic
remainder: the stuff that does not fit. The reader discovers intellectual
"fields" for what they are: habituated metaphors, neither natural nor
self-apparent. The metaphor is made strange again through purposeful
defamiliarization. To take the technique to its logical conclusion, a writer
could depict several fictional characters in the act of scything a field of
grass while discussing the relative merits of structuralism: a discussion
about the field on a field. Such literary artifice would make actual the
implied connections between fields of grass and fields of ideas. The writer
now shows what was merely told before. The technique of defamiliarization
finally renews the figure: discarding hardened clichés while suggesting novel
linkages between constituent concepts: intellectual chaff, leaves of mental
grass, the combines of thought.

The formalists understood habituated metaphors to diminish the vitality of
experience. Shklovsky quotes from the diaries of Lev Tolstoy, who, while
dusting his room, could not remember if he had already dusted his sofa.
Tolstoy wrote:

> because actions like these are habituated and unconscious, I could not
> remember [...] whether I dusted and forgot or just did so without
> thinking---it was as if the action never happened [...] thus when life
> passes without conscious reflection, it passes as if one has not lived at
> all.

Shklovsky goes on to add that life so habituated disappears into nothingness,
when the automatization of experience "consumes things, clothing, furniture,
your spouse, and the fear of war."[^ln-brik] The formalists rarely quoted Marx
directly. Yet the echoes of Marx resonate throughout. The dead metaphor marks
alienation from humanity.[^ln0-marx] The point at which material artifact
disappears from individual conciousness is also the point where it appears
within the social sphere as fetish. Shklovksy however inverts the Marxist idea
of alienation [*Entfremdung*], which for Marx always denies life, into a
technique of estrangement---literally othering [*ostranenie*]---of the kind
that affirms it. The difference is between one's own alienation---the forced
perception of self as fixed other---and the ability to externalize the other,
lodged deeply within and calcified. Formalist defamiliarization arrests the
momentum of tacitly received habit. Once extracted, it can be revitalized.

Our challenge today is to uproot ourselves from the comfort that rapidly
descends on the dwellings of our intellectual life. Dulling the senses,
seemingly inconspicuous conduits of agency---electronic books and smart
desks---acquire a sense of intelligence of their own. Devices that "watch,"
"hear," "see," and "think" give rise to object-oriented ontology and the
internet of things. A new generation of objects clamours for participatory
intelligence. They claim space in the home, near bed and hearth. Smart phones,
smart light bulbs, smart thermostats, smart homes, and smart watches, enter
the networked public sphere in the role of independent agents.[^ln-winner] A
conversation begins about their personhood: their levels of trust,
friendships, rights, and accountability [@bohn_living_2004;
@jianhua_ma_towards_2005; @calverley_android_2006; @hildebrandt_ambient_2007;
@atzori_smart_2014]. Marx's "table that evolves grotesque ideas out of its
wooden brain" now becomes Surface and PixelSense, product names of actual
smart tables made by Microsoft [@marx_captial_1906, 82;
@wigdor_designing_2009].

If we hope to understand digital culture and especially literature, as
Friedrich Kittler would write, "under conditions of high technology," we can
only do so from the position of humanism. One cannot otherwise lament the
systematic erasure of the human from the literary process and, at the same
time, advocate for a post- or anti-humanism. Unlike Kittler, who wrote that
under conditions of high technology "literature has nothing more to say," I
believe that literature and literary analysis continue to have a voice in
contemporary life [@kittler_gramophone_1999, 263]. Technology does not
determine literary silence. Rather, as the material grounds for all reflective
textual activity recede from view, readers face the prospect of selective
illiteracy. The command of technologies like networking and encryption
separates those able to read and write under conditions of high technology
from those who no longer are: a true suppression of voice.

When we mistake things for animate actors, we ourselves become enmeshed in a
system of digital production that commodifies human experience. Objects that
surround us collect our reading habits, social interactions, and intimate
conversations. The actual living agents that benefit from trade in personal
data are neither cyborgs nor post-human assemblages. The bargain that trades
critical understanding for comfort benefits specific interests, like
multinational corporations and government intelligence agencies. To address
objects as if they could respond in kind shifts our attention from the seats
of power to things powerless, inarticulate, and indifferent to our
protestations.

The internal exile that we must undergo for smart books and smart desks to
come into view cannot compare in difficulty to the experience of physical
displacement that follows natural disaster, war, poverty, or political
instability. Yet, our systematic reluctance to take on even those small
intellectual discomforts that could lead to acts of localized dissent and
disobedience---to write using free software, to build open archives, to share
memories in private---cannot be said to exist apart from the complex systems
that perpetuate inequity and violence globally. The emotional affirmation that
accompanies exuberant social networking brings with it governing structures
evoked in the name of law enforcement and national security. Comfort and
security constitute the same ill-conceived bargain that leads to critical
disempowerment. But where it is difficult to imagine or to enact strategies of
digital disobedience on a universal scale, we can begin to address them
through numerous minute transactions that in aggregate brace everyday literary
exchange. This we can do now. Computational poetics begins with the machines
in the immediate proximity, closest to thought and touch.

To pick up an electronic book and to take it apart may be against the law in
some jurisdictions [@fry_circumventing_2009]. Given the extent to which
emergent thought-things---epistemic artifacts---like electronic books and
smart phones participate actively in the production of meaning, we can no
longer employ strategies of interpretation at the level of ideology or
representation alone.[^ln-rhein] The praxis of close reading must reach down
to the silicon bedrock: material entities and physical structures that bear
the weight of interpretation. Literary theory, a discipline fundamentally
engaged in the exegesis of figurative trope, is therefore crucial to the
understanding of new computational environments, which have enveloped
intellectual life through metaphoric substitution. To read the machine is to
learn how it is made, but also to unpack the rich metaphors that guide our
tactical engagement with the word: the boot in rebooting, the wares in
software, the bug and the joystick, the interpreter and the shell.

### Settlement

Estrangement cannot be practiced effectively in the mode of a monologue. To
produce meaning, Flusser reminds us, it needs to become a dialogical practice.
Perpetual exile is otherwise uninhabitable [@flusser_freedom_2003, 81].
Estrangement thrusts the displaced into the chaos of unsettled existence. With
time, the displaced make a new home, from which they can once again "receive
noise as information" and produce meaning. "I am embedded in the familiar,"
Flusser wrote, "so that I can reach out toward the unfamiliar and create
things yet unknown" [@flusser_freedom_2003, 12]. The displaced and the settled
need each other. The dialectics of exile lead to "informed renewal" of shared
space through what Flusser called a "creative dialogue" between the settled
and the displaced [@flusser_freedom_2003, 84]. Without the protection of one's
home, everything turns to noise. Information cannot exist without a dwelling,
Flusser wrote, "and without information, in a chaotic world, one can neither
feel nor think nor act" [@flusser_does_2011, 12]. By this dynamic,
displacement and settlement enter into a continuing dialectic.

In *Plain Text*, I model the reciprocal movement to "making strange" on the
diverse practices of reverse engineering. Similar in method to what Matthew
Kirschenbaum calls "forensic argumentation," reverse engineering recalls the
formalist strategy of experiencing the "making of the thing" through careful,
case study-based reconstructions of textual mechanism.[^ln0-reverse] The
function of a case study in an engineer's education, as Henry Petroski
explains in his *Invention by Design*, is to understand the ways by which one
gets "from thought to thing" [@petroski_invention_1996, 3-7]. From thought to
thing would be another apt definition of poetics and an alternative subtitle
to this book. Along with literary and historical exposition, each of my
chapters contains at least one literary thought-thing. Each chapter enacts a
deconstruction---a literal taking apart---of that device. The epistemic object
is present to challenge the reader's and the author's theoretical intuitions.

Computational poetics, a mode of materialist critique, is concerned with the
transition of theory into practice. Where "distant reading" and cultural
analytics perceive patterns across large-scale corpora, computational poetics
breaks textuality down into its minute constituent components. It is at this
scale that I find readers and writers becoming fundamentally alienated from
the immediate material contexts of knowledge production. Mine is not however a
post-human materialism of the kind that privileges an object's point of view.
On the contrary, the book aims to remove the aura of fetishism that attaches
itself to literary--computational artifacts and to complex systems that
mediate in the textual encounter. That is not to say that epistemic things can
ever become wholly known or fully transparent. But neither should they remain
forever out of reach. We must insist on entering them into a dialectic, by
which ideals reify and align with specific technological commitments.

The reverse engineering of literary devices reveals that not all texts are
created equal. In print, traditional distinctions between form and content lie
flat. The printing press firmly embeds ink into paper, leaving no space
between type and page. Materially-minded critics like Johanna Drucker,
Katherine Hayles, and Jerome McGann have urged literary scholars to
re-evaluate textuality in its media-specific contexts [@drucker_digital_2001;
@mcgann_radiant_2001; @hayles_print_2004]. Their work reminds us that the
flatness of digital text endures only in the guise of an illusion. Low-level
operational intuitions governing textuality---ideas about form, content,
style, letter, and word---change profoundly as text shifts its confines from
paper to pixel. A substantial gap separates the visible text from the medium
where it is stored. Pixels on a screen are literally removed from the
electromagnetic trace on the hard drive. The two sites of textuality---the
visible image and the archived inscription---do not come into direct contact.
The space between gives ground to more text, of the kind that specifies rules
for transformation: from one medium, solid state storage, to another, the
liquid crystal display. These rules contain the essence of control, before
ideology, at the level of infrastructure. Censorship filters and surveilling
apparatus are some of the starkest examples of governance that occupy the
space between storage and presentation: what the text is and what it appears
to be. I propose we begin with this obvious sense of difference between paper
and digital text: where print is governed by law from without, think for
example of the Obscene Publication Acts in Victorian England, digital text is
governed by code, capable of executing its edicts from within
[@mccalman_unrespectable_1984; @roberts_morals_1985]. In this way governance
intertwines with text to become an organ in the same unified corpus.

Changing material conditions of textual transmission push against familiar
ideas of literary criticism. For example, the easy reproduction of digital
text weakens the material basis for authorship attribution. Text that is easy
to copy is easy to cite and plagiarize. The weakening of the authorship
function makes certain ways of talking about ideas like "authorial intent" and
"fidelity to the original" difficult to sustain. The emergence of community
based writing initiatives like Wikipedia and narrative generating machines
that write spam and summarize news automatically further erode notions of
authorship based on individual genius. The author is not dead; authors
continue to live and to collect royalties.[^ln-dead] Autopoiesis---a
theoretical model of literature writing itself or discourse speaking
itself---does not displace the social institution of authorship.[^ln-varela]
It merely makes the flows of poiesis less apparent. A discipline of close
attention to the minute particulars of encoding, transmission, storage, and
the decoding of text ultimately reclaims a measure of intent and therefore
responsibility for creation. The algorithmically derived advertisement (spam)
nevertheless stems from specific economic interests, to take a pedestrian
example. Another goal of computational poetics is to trace the flows of agency
through the long sequence of authorial delegation. The author's responsibility
passes from the issuing agency to its instrument. The spammer writes code to
spam on his behalf, yet he is still at fault. Under many circumstances I may
not care to speak in this way: it seems ridiculous, for example, to find
Tolstoy "at fault" for his *War and Peace*. At the same time, the work *is
his*. Under differing circumstances we must hold the author accountable, as
when unsolicited advertisement clutters the airways at the expense of other
forms of speech. This may seem strange at first: to recover the subject in the
physical minutiae of the encounter between text and machine. The point of
contact between human, text, and device is significant precisely because it is
here, in the liminal zone of semiotic exchange, where the subject disappears
into the machine and where the machine steps forth, an animated and seemingly
intelligent actor.

Extant models of literary transmission assume movement through passive and
immutable media. Paper constitutes the document of record, which, once
archived, does not change its contents. Philological techniques like genetic
criticism and forensic reading make it possible to reconstruct if not
"authorial intent," then at least a trace of the author's hand. In some
contexts---think manuscripts and folios---we may even ascribe properties like
"fidelity" to "original" works of art. When media are immutable, one imagines
a causal chain of custody between works and their creators, who at some point
must have occupied the same contiguous time and space. The printing press
introduces a range of structures that mediate between readers and authors.
These subsequently weaken notions of authorial fidelity. In the least, we
understand that such intermediaries as copy machines and printing presses
inject an element of noise into the channel of communication.

The transition between the Gutenberg press and Project Gutenberg, an online
library containing thousands of texts, further lengthens linkages. Unlike pen
and paper which come in direct contact with each other during writing, the
contact between keyboard and screen passes through multiple mediating filters.
Writing in that sense in itself becomes a programmed experience. We do not
write in the conventional sense of inscribing marks into a static host.
Rather, we are shown images of inscription superimposed onto a simulation of
the medium. Neither the digital word nor digital page exist in the way they
appear in the word processor or on the pages of an electronic book. At best,
such composite tropes attain a measure of similarity to the physical realities
of typing, editing, and archiving paper. Simulated erasure for example, of the
kind that happens when the writer presses the delete key, does not necessarily
entail the corresponding erasure of content on the disk. The erased word could
persist and even multiply across other storage drives and devices. In the
worst case, the connection between keyboards and screens suffers from
intractable "man-in-the-middle" attacks, by which third parties maliciously
alter the content of intended communication [@needham_using_1978].

In this book, I will argue that some of the higher-level political afflictions
of the contemporary public sphere---mass surveillance and online censorship,
for example---relate to our failure as readers and writers to come to terms
with the changing conditions of digital textuality. A society that cares about
the long-term preservation of complex discursive formations like free speech,
privacy, or online deliberation, would do well to take heed of the textual
building blocks at their foundation. The structure of discursive
formation---documents and narratives---has long been at the center of both
computer science and literary theory. Using primary sources from both
disciplines, *Plain Text* uncovers the shared history of literary machines,
bringing computation closer to its humanistic roots, and the humanities closer
to its computational realities.

*Plain Text* makes a historical case for the recovery of textual thought
latent in the machinery of contemporary computing. Just as literary
scholarship cannot survive without awareness of its computational present, the
design of computational platforms cannot advance without greater awareness of
its cultural contexts. Much is at stake in the material affordances of the
literary artifact.[^ln0-levine] The political struggle for meaning-making, the
very opportunity to engage in the act of interpretation, thus begins and ends
with the material affordances of the epistemic artifact.

[^ln0-levine]: Affordances, as Caroline Levine explains, "describe potential
uses or actions latent in materials and designs." For example, glass affords
transparency where steel affords strength [@levine_forms:_2015, 6].  See also
@hutchby_technologies_2001, 447.

It is easy to forget the blunt effectiveness of physical control in the global
North-west. Books that are burned or redacted cannot be read at all.
Elsewhere, inequities of access to knowledge compel readers to print their own
books and build their own libraries. Witness the so-called "shadow libraries"
of Eastern Europe and Central Asia, the street book vendors of India and
Pakistan, and the gray market presses of Nigeria arising from the country's
"book famine"[@mahmood_copyright_2005; @okiy_photocopying_2005;
@liang_piracy_2009; @bodo_short_2014; @nkiko_book_2014; @_elsevier_2015]. More
than mere piracy, such *samizdat*-like practices preserve the literary sphere
[@tenen_book_2014]. Informal book exchange networks create reading publics
that own the means of textual production and dissemination. Under duress,
readers build homemade knowledge infrastructures: they duplicate, distribute,
catalog, and archive. By contrast, in wealthier economies, such
infrastructures are commodified. Consequently, readers receive the material
contexts of their meaning-making passively. The costs of knowledge production
and barriers to its distribution disappear from view. For many readers,
technologies that support reading, writing, and interpretation further pass
from tools to fetish. No longer comprehensible by the way of pen or printing
press we imbue them with magical powers. Thus we exist in the state of
profound alienation from the material conditions closest to our mental
activity. We read electronic books as they read us, without depth or
comprehension.

The future of reading and writing is inexorably intertwined with the
development of computer science and software engineering. Even if you are not
reading these words on a screen, my message has reached you through a long
chain of machine-mediated transformations: from the mechanical action of the
keyboard on which I am now typing, to the arrangement of electrons on magnetic
storage media, to the modulation of fiber-optic signal, to the shimmer of the
flowing liquid crystal display rendering the text. Computation occupies the
space between the keyboard and the screen, which in turn gives rise to
higher-order cultural institutions: from the architecture of social media
platforms to the formation of massive shared archives. The "cultural
techniques" that guide our use of such technologies are formative of the
society as a whole [@leroi-gourhan_gesture_1993, 83-84;
@siegert_cultural_2015]. Daily choices like choosing a text editor, a filing
system, or a social networking platform cannot therefore be addressed in
shallow instrumental, system-centric ideals. Complex computational systems
cannot give rise to ideals any more than financial markets can. From the many
available visions of human-computer interaction I argue for choosing one that
confirms to a humanist ethos, whatever the reader's politics.

Computational poetics encourages users to become active thinkers, tinkerers,
and makers of technology. It understands binary and digital environments to be
also semiotic and symbolic systems in essence, amenable to the construction
and the deconstruction of meaning. I further encourage those who may have
considered themselves mere "users" of computation to apply the same critical
acuity they employ in the close reading of prose and poetry to the
understanding of code and machine. For text to render on the screen properly
it must be encoded or translated from machine-transmittable code into
human-readable shape. Encoding constitutes a primitive field of textual
activity, at the crossroads of computer science and the study of literature.
Encoding matters because how texts are encoded, transmitted, and stored
decides who gets to decode, receive, and access.

The advent of simulated text necessitates a computational poetics, which
enables unfettered access to text, code, platform, and infrastructure. For
now, commands like *xxd*, *pcap*, *ssh*, and *traceroute* resemble arcane
incantations that elicit hidden, symbolic action. Those who wield them gain
the metaphorical power to "hop" across, to "sniff" packets, to "survey," to
"traverse," and to "flood" network topographies. Computational poetics empower
the reader to resist hard-wired models of machine-bound interpretation.
Today, resistance remains in the purview of the few. Plain text channels
itinerant streams of data back into the tidal pools of human agency and
comprehension for all. There, code can become intelligible for the very
subjects whose loss Foucault and Kittler lament.[^ln-lament] Only in such
encrypted tunnels and secure shells can anything like the digital humanities
and new media studies take root.

## Method

> We cannot separate the two things, head and hand [...] the science of life
> is a superb and dazzlingly lighted hall which may be reached only by passing
> through a long and ghastly kitchen [...] We shall reach really fruitful and
> luminous generalizations about vital phenomena only in so far as we
> ourselves experiment and, in hospitals, amphitheaters, or laboratories stir
> the fetid or throbbing ground of life [@bernard_introduction_1957, 3-15].

My approach to writing *Plain Text* stems from the desire to enact theory
capable of addressing the grim picture Friedrich Kittler paints at the end of
his influential monograph.[^ln-kittler2] By all accounts, Kittler was neither
a technological romantic nor Luddite. I therefore understand his *Gramophone,
Film, Typewriter* as a call to action. When Kittler writes that "media
determine our situation," he challenges his reader to choose between
complicity and defiance [@kittler_gramophone_1999, xxxix]. It is not a
statement of fact but the articulation of a question: What can one do to
counteract technological determinism? In what follows, I outline several
intellectual lineages, materialist and experimental, which frame my answer.

Critical theory at its best aims to see "the human bottom of non-human things"
[@horkheimer_critical_1982, 143]. As such, it is one of our most powerful
tools for analysis and resistance against technological determinism. As Max
Horkheimer wrote, "the issue is not simply the theory of emancipation; it is
the practice of it as well" [@horkheimer_critical_1982, 233]. Recently,
scholars like Kathleen Fitzpatrick, Tiziana Terranova, and Trebor Scholz have
began to turn the tools of critical theory towards the instrumental contexts
of knowledge production [@scholz_digital_2013; @fitzpatrick_planned_2011;
@terranova_network_2004]. I join them to argue that in treating the
instruments of intellectual production and consumption uncritically, all of
us---readers and writers---accumulate an ethical debt. It is one thing to
theorize about the free movement of literary tropes across cultures and
continents, and quite another to have that theory appear in print behind
paywalls inaccessible to most global reading publics.[^ln-sarab] Similarly, a
theoretical distinction between form and content, when instantiated in
specific file formats like Microsoft Word (`.docx`) or Adobe Reader (`.pdf`),
establishes divisions of labor between editors, book sellers, and offshore
typesetting firms.[^ln-sweatshop] One group trades content in the economy of
prestige, another formatting in the economy of survival, and yet another
controls distribution in the market economy.

<!-- insert materialist critique sentence elsewhere -->

Distinctions of labor will remain in place as long as the conversation about
ideas like "form" and "content" persists in the abstract, apart from their
material contexts. Similarly, a materialist critique cannot achieve its stated
aims without purchase on the material world. Contemporary knowledge workers
stare into rectangular black boxes for a considerable part of their days,
suspecting, in the absence of other feedback, that their gaze is met in bad
faith. Connecting theories of meaning-making to their practice offers a way
out of the conundrum. Bad faith identifies a misalignment between thought and
action.[^ln-sartre] The solution to connect "meaning" with "operational
meaning" belongs to a species of pragmatism.  William James articulated the
approach concisely when he wrote that "reality is seen to be grounded in a
perfect jungle of concrete expediencies" [@james_pragmatisms_1907]. For James
and other pragmatists, truth could not exist in the abstract alone. It also
entailed causes and effects that operate in the world.[^ln-pragma-truth] In
his essay "Pragmatism's Conception of Truth," James asked: "How will the truth
be realized? What concrete difference will its being true make in anyone's
actual life? What experiences will be different from those which would obtain
if the belief were false?" Frank Ramsey, the young British philosopher close
to Ludwig Wittgenstein would later write in a similar vein about meaning
"defined by reference to the actions."[^ln-pragmatism]

For a pragmatist, truth-carrying propositions of the shape "X is Y" (as in,
"the author is dead" or "art is transcendent") beg the questions of "Where?,"
"When?," "For whom?," and "What's at stake in maintaining that?" Following the
pragmatic insight of James and Ramsey, I will proceed with the conviction that
abstract categories like "literature," "computation," and "text" cannot
possibly be reduced to a number of essential, structural features. Rather, to
borrow from Wittgenstein's *Philosophic Investigations*, categories denote a
set of related practices that may or may not share in any given familial
characteristic.[^ln-witt] In our case, imagine a tree diagram where the
tangled branches of computation and textuality intersect and diverge in
beautiful yet arbitrary ways.

In an approach to *doing* theory, *Plain Text* joins the experimental turn
steering the academy toward critical practice, especially in fields
long-dominated by purely speculative thought. The experimental turn represents
a generation's dissatisfaction with armchair philosophizing.  Recall the
burning armchair, the symbol of the experimental philosophy movement. Joshua
Knobe and Shaun Nichols, some of the early proponents of the movement, explain
that "many of the deepest questions of philosophy can only be properly
addressed by immersing oneself in the messy, contingent, highly variable
truths about how human beings really are" [@knobe_experimental_2008, 3]. The
emergence of spaces where research in the humanities is done exemplifies the
same trend. In naming the locations of their practice "laboratories,"
"studios," and "workshops," humanists reach for new metaphors of labor. These
metaphors aim to reorganize the relationship between body, space, artifact,
knowledge, and inscription. In my lab and elsewhere, researchers have taken to
calling this approach the "experimental humanities."

As an example of what I have been calling here the "experimental turn" in the
field of early modern history consider the preface to a recent volume on *Ways
of Making and Knowing*, edited by Pamela Smith, Amy Meyers, and Harold Cook.
They write that the "history of science is not a history of concepts, or at
least not that alone, but a history of the making and using of objects to
understand the world" [@smith_ways_2014, 12]. Smith translates that insight in
the laboratory, where, together with her students, she bakes bread and smelts
iron to recreate long-lost artisanal techniques. For those who experiment,
"book knowledge" and "artifactual knowledge" connect in practice.

Artifactual knowledge---from typesetting software to e-book readers and word
processors---shapes our everyday encounter with literature. Such technologies
should not be understood as value-neutral conduits of information. I follow
Lewis Mumford and Langdon Winner to argue that technology affects the exercise
of textual politics in subtle and profound ways [@mumford_authoritarian_1964;
@winner_artifacts_1980]. Artifacts cannot hold beliefs about politics.
Political power is rather exercised through them. For example, stairs do not
discriminate against the mobility impaired. The human failure to enforce
accessibility through specific legal and architectural choices does.
Typesetting software, e-book readers, and word processors similarly embody
implicit communication models: ideas about deliberation, ethics of labor,
discursive values, and views about "natural" human aptitude for
interpretation. The maker of the electronic book encodes how the book is sold
and where, minimum and maximum font size, the visibility of marginal notation,
the possibility of sharing, the availability of the critical apparatus.
Content in that sense is meant for further processing, in a way that maximizes
its extracted value. Contemporary documents are capable of structuring the
literary encounter to these ends according to the reader's economic status,
gender, race, age, location, or physical ability.

To what extent does the book in front of you permit or enable access?
Whatever the answer, a function of understanding the text must include the
explication of its physical affordances. An experimental approach to reading
enables the critic to "lay bare" the device. A literary scholar's version of
baking bread and smelting iron is to make literal the archaeology of media at
the level of the mechanism. In *Plain Text* we will unearth and excavate
textual machines. In practicing archaeology I contend that cardinal
literary-theoretical concepts---such as word, text, narrative, discourse,
author, story, book, archive---are thoroughly enmeshed in the underlying
physical substratum of paper and pixel. It follows that any attempt to
articulate the idea cannot attain its full expressive potential without a
thick description of its base particulates.

Luckily for us, reading and writing are not esoteric activities. They are
readily available to introspection. I will therefore occasionally encourage
readers to encounter the immediate contexts of their reading anew: to put down
the book or to lean away from the screen and to look at these textual
artifacts with strange eyes. In this movement of the body, I want to disrupt
the mind's habituated intuitions, pitting them against knowledge at hand and
fingertip knowledge: as when ruffling through the pages or typing at a
keyboard. How ephemeral is an electronic text, for example? The pragmatic
answer lies not in reductive universal propositions---very, or not at
all---but in contingent technological affordances attached to specific reading
devices.  What can a reader do with this text, here and now? Where is it
stored? Are readers given dispensation to copy and paste? Do they have legal
permission to quote at length, to perform publicly, or to otherwise
trans-mediate? Will the text disappear when the reader closes the book's
cover?

## Plan of the Present Work

The tangled pathways of inscription winding their way through the device exist
in relation to distinct communities of computational practice. A researcher
cannot therefore expect to discover a single theoretical framework that
captures the complexity of simulated text in motion. An engineer's use of the
words "code" and "poetry" differs from that of a poet's. The changing contexts
evoke the corresponding shift in operational definitions. Consequently, this
book is neither a total history of modern computing nor a survey of literary
theory. Rather, the argument therein progresses from the action of the
alphanumerical keyboard switch, through copper and silicon, to liquid crystal
and the floating gate, and on towards the reader and the community. It is but
one of many possible passes through a cavernous black box.

The passage from keystroke to pixel gives this book its shape. In the chapters
to follow, our mobile phones and laptops will come fully into view as metaphor
machines engendering ubiquitous simulation. The **first chapter** begins with
an explication. What does it mean to turn a page, I ask, when neither the page
nor the action of turning it correspond to their implied analogies? The
analysis of the metaphor helps trace the intellectual history of
human-computer interaction, a field which progressed from "conversational
programming" to the "direct manipulation" paradigm shaped by theories of
cognitive metaphor and immersive theater. The logic of "directness" leads to
the rapidly developing field of brain-computer interfaces. The chapter
concludes with a moment of speculative formalism, in which I consider the
possibility of affective literature, of the kind that eschews language and
representation.

At the core of the book's **second chapter** lies the notion of a modernist
literary device, understood both as literary technique and a thought
experiment about intelligent machines, directly connected to the birth of
modern computing. A section on literary technique in the thought of Percy
Lubbock, Walter Benjamin, and Mikhail Bakhtin opens the discussion.
Materialist poetics rise concomitantly alongside a mechanistic, rule-based
view of language. In this chapter I reconstruct a series of thought
experiments first in the writing of Ludwig Wittgenstein, and then in Alan
Turing's seminal paper on an imaginary computer capable of reading and
writing. The verbs to read and to write imply a type of cognitive processing.
What does it mean to read and to write for a machine? What about broken
mechanisms of comprehension? At once a device and an algorithm, the Turing
machine blurs the boundaries between software and hardware, code and content,
intelligence and its imitation.

Two rich intellectual histories collide in the **third chapter**: one, the
material history of format as a concept in computer science and the other, the
intellectual history of form in literary theory. I show formatting as a
process that mediates between the text's intrinsic rules for construction and
its extrinsic shape, transforming one type of structure, a series of bits
arranged into tracks and sectors, into another, letters arranged into
sentences and paragraphs. I then draw a short history of text formats. It
begins with several "control characters" limited in function to actions like
"carriage return" or "stop transmission." With time, formats begin to
encompass all manner of machine instruction, including legal instrument to
enforce digital rights management and copy protection. A manufacturer's
ability to censor or to surveil digital text is contained within the
formatting layer: from electronic books that modify themselves to suit the
reader's geographic location to "smart contracts" that contain the rules of
their own execution.

The **fourth chapter** charts the emergence of screen reading. The screen
appears to restore a measure of visibility lost in electromagnetic
inscription, with one major side-effect. The screen cannot guarantee fidelity
between the word visible and the word archived. The inscription shown can only
attain a contingent correlation to the inscription archived. Screen reading
further happens on screens that refresh themselves at a rate of around 60
cycles per second (Hertz). The digital word is technically an animation; it
moves even as it appears to stand still. This property of the medium attunes
the reader to a particular mode of apprehension, affecting not just the
physics but also the aesthetics of digital media. Works by the philosophers
Henri Bergson, John Haugeland, and Nelson Goodman help construct a
phenomenology of screen-based digital perception. The digital emerges
ultimately not as an intrinsic property of the medium, but as structure
imposed from without. In the extreme, that means that a censored *electronic*
text can form a perfectly *analog* artifact, despite being digital in all
other senses of the word. Conversely, texts in print are already "born
digital," in the sense that literary works like Shakespeare's *Hamlet* are
amenable to "reliable processes of copying and preservation"
[@haugeland_analog_1981, 213-225]. Properties that make media "digital" or
"analog" reveal themselves to be neither universal nor essential to the
medium. The medium is not the message. "The reliability and preservation of
textual copies" may mean one thing to a literary scholar, another to a
software engineer or a legal professional, and something entirely different to
a librarian, I argue in the conclusion of the chapter. It matters not what the
medium is, but what we can do with the text.

The **fifth chapter** begins with a discussion of an apparent paradox. A camp
of media theorists and textual scholars in the 1990s conceived of electronic
texts as an ephemeral, almost immaterial, phenomenon. Text shimmered and
glared: it was spoken of in terms of *hypertext*, light writing, and
electricity. A generation of theorists that came after insisted on the weighty
materiality of electronic media. Reading began to engage the morphology of
rare metals, media archeology, hard drive forensics. Both accounts, I argue,
capture an aspect of the same underlying condition. The perceived image of an
archived inscription splits from its source. The sign plausibly resides both
on the screen and on the hard drive. It fractures, in some real sense,
diverging at the site its projection from the site of the archive. Erasing an
inscription on the screen, for example, may not elicit the corresponding
action on the disk. Using archival materials from the history of telegraphy in
the late nineteenth and early twentieth centuries, I chart the gradual
fracture and the ultimate illegibility of the newly composite sign. Early
computers stored human-readable text and machine instruction at the surface of
the same storage media like punch cards and ticker tape. Although difficult to
read, these forms of machine writing were readily visible and therefore
amenable to analysis. The advent of magnetic storage forced the composite
inscription into an opaque medium. Unable to perceive magnetic polarities
without the aid of a machine, readers often manipulated text blindly. In this
way a typist would type several sentences without seeing the printed output.
The chapter identifies a milestone in the history of human textuality: the
moment at which the inscription passed from view, giving rise to the sometimes
conflicting but nevertheless consistent accounts of digital textuality.

The **sixth and final chapter** looks to the site of storage to find the media
"homes" that house vast archives of our private media collections. It begins
with a close reading of Beckett's *Krapp's Last Tape*. Krapp makes yearly
audio recordings of himself, only to revisit them and to enter into a sort of
dialog with his own voice from the past. I posit this archival encounter as
Krapp's "media being" and suggest that such encounters are commonplace.
Writers and book collectors regularly deposit "snapshots" of their
consciousness into books and onto bookshelves. Jean-Paul Sartre's idea of an
"appointment with oneself" helps to reveal this external construction of
files, folders, and library furnishings as cognitive extension, in need of
delicate pruning and arrangement. In this light, I show that documents exist
not as completed works, but as "vectors" that mutate and move through time and
space.[^ln-wark] I ask: What is being externalized, communicated, and
preserved? And answer: It is not simply a message, but the subject itself. A
close reading of the "home" folder, the default location of personal files on
many systems, concludes with a discussion about our media homes. Finally, I
return to the theme of displacement, arguing for a mode of inhabitance within
media that is uncanny or un-homed [*Unheimliche*], contrary to discourse that
speaks in terms of "digital natives" and those who are "born digital." I build
on the immigrant poetics of Flusser and Franz Fanon to suggest a kind of
information processing that necessitates a purposeful movement between the
polarities of settlement and expatriation.

<!--- NOTES  --->
<!--- NOTES  --->
<!--- NOTES  --->

[^ln-bernard]: On Bernard see @petit_claude_1987; @sattar_aesthetics_2013; and
@mcluhan_gutenberg_1962, 4 & 206.

[^ln-bookreview]: I write "supplants the function" because I do not mean to
imply that the book review disappears or becomes less vital. On massive market
platforms like Amazon Books, the book review passes from the domain of an
expert to the domain of the lay reader. Book reviews thus proliferate. Their
function changes from universal aesthetic judgement to instrumental reasoning.
In other words, we now find the book first then read the review. The review
ceases to serve as a tool for discovery--a function now addressed by the
search and recommendation engines.

[^ln-brains]: For the first view see @putnam_minds_1960 and
@fodor_language_1975. For the second view see @deutsch_quantum_1985 and
@dyson_turings_2012.

[^ln-brik]: @shklovksy_poetika_1919, 104. Translations are mine unless source cited explicitly in
English.

[^ln-capital]: Scholars like Alexander Galloway, David Golumbia, Bernard
Harcourt have advanced critique along similar lines. See
@galloway_protocol_2006, @golumbia_cultural_2009, and @harcourt_exposed:_2015.

[^ln-cog]: See for example @gibbs_categorization_1992; @blasko_effects_1993;
@gibbs_poetics_1994; @neal_role_1997, 441-463; @gentner_alignment_1997.

[^ln-dead]: See @barthes_death_1977; @foucault_what_1980; @nesbit_what_1987.

[^ln-digitalliteracy]: See for example @postman_technopoly:_1992;
@negroponte_being_1995; @davidson_now_2011; @obama_2016_2016.

[^ln-dissent]: See @harcourt_exposed:_2015, 251-80.

[^ln-dmca]: See @ku_critique_2004; @ginsburg_legal_2005; and @fry_circumventing_2009.

[^ln-egturner]: Mark Turner, whose work builds on Lakoff and Johnson is a
strong proponent of such an approach. See @turner_death_1987 or
@turner_language_1992.

[^ln-flusser]: The work of @flusser_does_2011 has been similarly influential.

[^ln-hegel]: I discuss the topic at length in Chapter 3.

[^ln-iarkho]: I borrow the term "microanalysis" from the largely forgotten in
the West Russian literary scholar and member of the Moscow Linguistic Circle,
Boris Iarkho. In his *Methodologies of Exact Literary Study* (circa 1935-6) he
writes: "I understand 'atomism' as a sort of an ideal aspiration, as an
orientation toward the liminally small. But under no circumstances do I
advocate working with hypothetical quantities, like molecules, atoms,
positrons, and so on, which are located beyond the limits of perception. That
this applied mythology gave us such splendid results in chemistry, should not
conceal its true nature. Tomorrow, all such explanations of visible through
the invisible could give way to other hypotheses, as was the case with their
no less fertile predecessors (elemental spirits, phlogiston, and light ether).
But the cell, the nucleus, and the chromosome endure as lasting
accomplishments of microanalysis. I suggest to move as far as a microscope can
reach, and no further" [@iarkho_metodologia_2006, 363-364]. For Iarkho, the
most quantitatively inclined of the Russian Formalists, microanalysis involved
systematic application of statistical methods to the study of literature.

[^ln0-influences]: Works by Finn Brunton, Wendy Chun, Matthew Fuller,
Alexander Galloway, Lisa Gitelman, Yuk Hui, Helen Nissenbaum, Lev Manovich,
John Durham Peters, Mary Poovey, and Jonathan Sterne among many others left
their mark on this text.

[^ln-kittler2]: *Gramophone, Film, Typewriter* ends as follows: "And while
professors are still reluctantly trading in their typewriters for word
processors, the NSA is preparing for the future: from nursery school
mathematics, which continues to be fully sufficient for books, to
charge-coupled devices, surface-wave filters, digital signal processors
including the four basic forms of computation. Trenches, flashes of lightning,
stars---storage, transmission, *the laying of cables*."
@kittler_gramophone_1999, 263.

[^ln-lacan]: The evanescent absence of life that Lacan mentions as "the sign
about which Robinson Crusoe would make no mistake" [@lacan_seminar_1997, 167].

[^ln-lament]: Or perhaps celebrate, depending on your understanding of their
post-humanism. For more a more extended discussion on Kittler, Foucault, and
post-humanism see for example @winthrop-young_silicon_2000; @wolfe_what_2010,
104-128; @siegert_cultural_2013.

[^ln0-manovich]: See @manovich_there_2011, 53-106.

[^ln0-marx]: For more on alienation see the relevant discussion in
@marx_economic_1964 and @marx_theories_1963.

[^ln-pragmatism]: @ramsey_foundations_2013, 155. The intellectual legacy of
pragmatism is wide-ranging and diffuse. It is perhaps most pronounced in the
teacher colleges, where James and Dewey are still read widely, which could
explain the ascendancy of such pedagogical terms as "situated
cognition"[@brown_situated_1988, @lave_situated_1991] and "experiential
learning"[@kolb_hegel_1981]: both terms denoting some sense of necessary
synthesis between of knowing and doing. In the field of linguistics,
philosophy of language, and communication studies, pragmatics are
well-encapsulated by the "language-as-action tradition," which harkens back to
the Oxford language philosophers like J.L. Austin, Paul Grice, and John Searle
[@trueswell_approaches_2005]. Austin's *How to Do Things with Words,* is
perhaps the paradigmatic formulation of the idea that words don't just mean
things, but that they enact change in the world.

[^ln-pragma-truth]: For a more thorough discussion on the topic see
@seigfried_william_1990, @pihlstrom_structuring_1996, and @putnam_jamess_1997.

[^ln0-reverse]: @kirschenbaum_mechanisms:_2008, 15. On the role of reverse
engineering in media studies see also @fuller_evil_2012, 9.

[^ln-sarab]: See also @english_economy_2008; @brouillette_wither_2015 and
@brouillette_unesco_2015.

[^ln-sartre]: Sartre would write "transcendence" and "facticity." See
@sartre_being_1993, 86-119.

[^ln-spam]: For example, in 2004 researchers estimated that spam mail makes up
40%-80% of the total email volume @cournane_analysis_2004.

[^ln-sweatshop]: See @freeman_high_2000 and @patel_working_2010.

[^ln-rhein]: I am in influenced here by the discussion of epistemic things in
@rheinberger_toward_1997, 24-37.

[^ln-varela]: See @varela_autopoiesis:_1974; @barthes_rustle_1989, 5;
@nuttall_new_2007, 6-25.

[^ln-wark]: I use the term "vector" in somewhat more limited sense than it
appears in the idea of "vectoralist class" coined by McKenzie Wark. By
"vectoralist class" Wark means something like the group of interests that
control the distribution of information. See for example
@wark_information_2006. In understanding the document as a vector I posit it
as a three-dimensional rather than a two-dimensional object, with the extra
dimension extending in time. Similar to Jerome McGann's idea of the "editorial
horizon." See @mcgann_textual_1991.

[^ln-winner]: See for example: "Writers concerned with with problems of
technology-out-of-control have frequently echoed Hobbes in suggesting that
such an artifact---the Leviathan of interconnected technical systems---has a
soul of its own [...] A ghost appears in the network.  Unanticipated aspects
of technological structure endow the creation with an anticipated *telos*"
[@winner_autonomous_1978, 280].

[^ln-witt]: @wittgenstein_philosophical_2001, 67-77. For more on the
connection between Wittgenstein and James see @goodman_james_2004.

[^ln-twobil]: Code metrics from @mccandless_million_2015.

\newpage
