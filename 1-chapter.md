---
title: "Plain Text: The Poetics of Human-Computer Interaction (Sample Chapters)"
subtitle: "Chapter 1: Laying Bare the Device"
author: "Dennis Tenen"
style: csl/chicago-note.csl
bibliography: plain-text.bib
toc: true
documentclass: article
cover-image: images/steno.png
header-includes:
- \usepackage{ftnxtra}
- \usepackage{titlesec}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \newcommand{\sectionbreak}{\clearpage}
- \rhead{DRAFT | do not circulate }
- \lhead{}

---

# Chapter 1: Laying Bare the Device

"The weakest point in our present day universe is the incapacity of man to meet
the machine, the culture conserve, or the robot, other than through submission,
actual destruction, and social revolution" [@moreno_who_1953, 233]. So wrote
the Austrian-American psychiatrist, Jacob L. Moreno between the years of 1934
and 1953, in his now seldom read classic, *Who Shall Survive?* He is remembered
today as a pioneer of group therapy, an early critic of Freud and socialism.
Sociologists also occasionally mention his work as precursor to network
analysis. His books contain beautiful diagrams, sprouting nodes and edges, with
titles like "Structure of a Cottage Family," "A Handicraft Group," and "The
Civilian Social Atom." Yet Moreno was also a humanist and a philosopher of
technology and culture. In opposition to eugenics, popular at the time, his
answer to "Who Shall Survive?" was "everyone" [@moreno_who_1953, 245].

Humanity, according to Moreno, faced two major threats: first embodied in the
aggression from other human beings, and second, in the aggression of robots or,
what Moreno called alternatively the "cultural conserve" and the "zootechnical
animal" [@moreno_who_1953, 237]. Robots, for Moreno, were more than mechanized
automatons. "Machine rule" encompassed all devices, social structures, and
products of the mind that diminished creativity. He wrote: "these methods have
always amounted simply to this---to neglect and abandon the genuine and
outstanding creative process [...] to extinguish all the active, living
moments, and to strive towards one unchangeable goal: the illusion of the
finished, perfected product whose assumed perfectibility was an excuse [...]
for forsaking its past, for preferring one partial phenomenon to the whole
reality" [@moreno_who_1953, 233]. The "illusion of the perfected product"
reduces humans to "machine-addicts," residing in a "jungle of robots" that
threatens to suffocate all spotanious activity. Through robots, life becomes a
script.

In the name of comfort, safety, and prolonged life, technologists and
population planners disempower the very subjects whose lives they claim to
preserve. The zootechnical animal substitutes human ability to set goals for
the promised certainty of a better future. "The eugenic dreamer and the
technological dreamer have one idea in common," Moreno wrote, "to substitute
and hasten the slow process of nature:"

> Once the creative process is encapsulated in a book it is *given*; it can be
recapitulated eternally by everybody without the effort of creating anew.  Once
a machine for a certain pattern of performance is invented a certain produce
can be turned out in infinite numbers practically without effort [...] Once
that miraculous eugenic formula will be found a human society will be given
prefect and smooth at birth, like a book of a press [@moreno_who_1953, 236].

Like Socrates from Plato's *Phaedrus*, Moreno distrusts the rote mechanization
of thought itself. All forms of externalized algorithmic rule fall under
suspicion: from central planning, to corporate governance, to machine code, and
legal codex. Such mechanisms serve to externalize and to "conserve" volition,
at a given point of time. With time, mechanized volition governs without
consensus or comprehension. Splintered from its source, externalized volition
staggers forth, *golem*-like, through laws, books, and social institutions.  With
life-spans that span generations, images of the past proliferate and crowd out
the present. Moreno writes:

> Once off the press, the parent, the producer, the author is immaterial; the
> book goes to all places and to all people, it does not care where it is read
> and by whom. Many robots have further in common the attribute of comparative
> immortality. A book, a film, an atomic bomb, they do not perish in the human
> sense, the same capacity is always there, they can be reproduced *ad
> infinitum* [...] Our human world is increasingly filled with robots and there
> seems to be no end to new forms and new developments [@moreno_who_1953, 239].

In the aftermath of World War II, Moreno expanded the first edition of his book
to consider the ultimate automaton, the atomic bomb. "Mankind has been awakened
from a dream," he writes. The atomic bomb gives humanity a glimpse of its
common enemy. Technology, for Moreno, does not determine the present situation.
Rather, a mindless actor in possession of fossilized volition, it competes, in
Darwinian sense, with living actors. Once set in motion, voluntarily, by
humans, the war machine and the book alike continue to do their bidding. These
structures may no longer be needed or wanted, but because they are inorganic,
they persist to shape the social and the mental worlds to come. Moreno
explains:

> Many of the domesticated robots are blessed with the attribute of becoming
labor-saving devices, which has, however the unpleasant consequence that they
at time reduce the need for creating, promoting with leisure also inertia.
[...] Many of the robots have also the attribute in common of being able to
affect human beings or other "targets at a distance," a book, a radio or a
television sender can entertain or teach at a distance, like a gun, a rocket
and an atomic bomb can kill people and destroy at a distance. The book is a
robot par excellence [@moreno_who_1953, 238].

The inertia of past decisions embodied in extant mechanisms ultimately poses a
threat for human survival. For Moreno, the real competition for survival
happens not between persons, sects, races, or nations, but between humanity and
its automatons from the past. The only way to compete with the robot was for
him to expand the human cultural capacity for creation. The biological being
has only this one advantage over the zootechnical animal: spontaneity. But the
capacity to free will and to creation has to be continuously guarded against
lethargy and advanced through training. The machines of yore ease the burden of
creation. In reducing labor, they enfeeble the creative capacity. Moreno's
therapy practice was therefore built on the principle of spontaneity training,
aimed at the construction of communities that acknowledge and preserve
individual agency. As far as I can tell from the records, the practice involved
group improvisation, in what Moreno called the "techniques of freedom," which
aimed to "balance spontaneous social forces to the greatest possible harmony an
unity of all" [@moreno_who_1953, 8].

I leave Moreno here, with thoughts of hydrogen bombs and books occupying the
same plane of mechanization. The book does make for an excellent robot. If a
conversation is a temporary communicative link between two people, a book is a
device for delayed conversation. It affects targets at a distance, decoupling
readers and writers in time and space. We are habituated to see the book as a
simple thing made of ink, cloth, and paper. It was never that simple. In this
chapter, my aim is to encounter the book anew as a complex system. The
device-like property of computed text especially, when compared to print, holds
severe consequences for the practices of reading, writing, and interpretation.

When in the 1930s one could view Moreno book--bombs as a
fanciful---technophobic even---view of literary technology, a century later his
concern appears pressing and prescient. The unintended consequences of
disembodied and automated agency, from artificially intelligent personal
assistants to market trading algorithms, worry scientists, legislators, and
media theorists. What looks like a book indeed functions as a gun and a
trigger. I mean this literally: it comprises a part of the same computational
platform that powers drones and aircraft carriers. Today, the "servers" that
serve the world's largest purveyors of literature service also air traffic
control and the National Security Administration [@soyata_combat:_2012;
@logicworks_government_2015].

In these conditions we---humanists, historians, philologists---must reconsider
the easy relationship we enjoyed with pen and paper, the material conditions of
textuality. The simulated book no longer plays by the same rules as print. The
bibliographic illusion veils device internals. The universal Turing machine,
from which all computational devices inherit, reveals itself ultimately as a
species of control mechanisms. Yet the Turing machine, and subsequently all
computers, belong also, in part, to the long history of the book. In this
chapter, I draw several pre-histories of the literary device, first as a formal
technique, then as an thought experiment, and finally as a control mechanism.
To preserve agency and to break the inertia of leisurely reading, we must
rediscover the book as a device; to call it forth for what it is and always
was---a robot for effecting thought at a distance; and to bring it back under
the purview of interpretation.

## 1.1 Technique

What is a literary device? The formal concept of a "device," widely used in
literary studies, is an artifact of an unfortunate translation from Russian.
The word *priem* would be much better translated as "technique," in the sense
of "method," "approach," or "procedure." The word "device" contains these
meanings as well, but in modern usage, it usually carries a more concrete
connotation, as "an object, machine, or piece of equipment that has been made
for a special purpose" (Merriam-Webster). "Laying bare the device," for Viktor
Shklovsky, the Russian formalist critic who coined the phrase, meant making
explicit the implied mechanism of the metaphor, particularly in cases where
such metaphors turn "stale," "automatic," and "naturalized," that is, bereft of
their original poetic and evocative power.

One could write, for example, "a field of study," without much thought about
figurative space. Shklovsky would have the reader pause to consider the
implications [@shklovksy_sborniki_1917]. In what sense do ideas resemble (or
not) a field? The poet could further make the metaphor strange. To evoke a
light-hearted illustration one could write: "to scythe a verdant field of
literary study." The verb (to scythe) and the adjective (verdant) create an
unexpected transference of new qualities not present in the original image
(intellectual field). The introduced qualities "break" or "overdetermine" the
metaphor, exposing its conceit. The reader can discover "intellectual fields"
for what they are: habituated metaphors, neither natural nor self-apparent. The
metaphor is made strange again through purposeful defamiliarization. To take
the technique to its logical conclusion, a writer could depict several
fictional characters in the act of scything a field of grass while discussing
the relative merits of structuralism: a discussion about the field on a field.
Such literary artifice would make actual the implied connections between a
fields of grass and fields of ideas. The writer now shows what was merely told
before. The technique of defamiliarization finally renews the figure:
discarding hardened clichÃ©s while suggesting novel linkages between constituent
concepts: intellectual chaff, leaves of mental grass, the combines of thought.

When pursuing estrangement the author "lays bare" and "makes obvious" the
metaphor by drawing attention to its inner dynamics. Metaphors, as Lakoff and
Johnson famously argued, do more than decorate---they structure everyday human
activity. The metaphor shapes one system of conceptual relationships in terms
of another. For example, the military image of "fortification defence" implies
a conceptual system structuring the "defence of an argument"
[@lakoff_metaphors_1980, 3-14]. When defending the argument, a speaker acts in
the way that resembles combat. A different metaphor would suggest a less
combative mode of engagement between interlocutors.

Russian formalists of the early twentieth century did not quite have the
contemporary cognitive vocabulary to connect mind and symbol, but they did
understand estrangement as a matter of everyday practice, beyond linguistic
analysis. One of Shklovsky's central concerns was with the automatization of
human experience, by which metaphors lose their evocative power through
repeated use. Such metaphors become mere machines that convey meaning, and,
when habituated, disappear from view. According to the Kantian view, in vogue
in Russia at the time, a reasoned being should proceed through life with the
assumption of agency, structuring one's own experiences according to the
principles of free will. The habituated metaphor instead structures furtively,
obscuring the relationships involved. Consequently, estrangement emerges as a
model of human liberation. It frees thought from the tyranny of automatism
[@shklovksy_sborniki_1917, @shklovsky_hod_1923, @boym_estrangement_1996,
@holquist_minding_2005]. Laying bare the mechanisms of the implicit metaphor
recovers agency lost to the blind mechanization of thought. Through
estrangement, readers discover the principles governing their actions: free to
accept some parts of the conceptual transference (the intellectual field *is*
"verdant"!) and to reject others (but let us not "use combines" to "harvest"
it). And perhaps the field should not be a field at all: it could be a meadow
or a forest.

Vladimir Nabokov, a writer conspicuously aware of his literary--theoretical
heritage, used defamiliarization in the formalist vein often and with
relentless clinical precision. In the short story "A Guide to Berlin," to which
D. Barton Johnson attributes our first glimpse at Nabokov's "mature virtuoso
style [@johnson_guide_1979, 354]," Nabokov writes:

> In front of the house where I live, a gigantic black pipe lies along the
outer edge of the sidewalk. A couple of feet away, in the same file, lies
another, then a third and a fourth---the street's iron entrails, still idle,
not yet lowered into the ground, deep under the asphalt. For the first few days
after they were unloaded, with a hollow clanging, from trucks, little boys
would run on them, up and down, and crawl on all fours through those round
tunnels, but a week later nobody was playing anymore and thick snow was falling
instead; and now when, cautiously probing the treacherous glaze of the sidewalk
with my thick rubber-heeled stick, I go out in the flat gray light of the
morning, an even stripe of fresh snow stretches along the upper side of each
black pipe [...] Today someone wrote "Otto" with his finger on the strip of
virgin snow, and I thought how beautifully that name, with its two soft o's
flanking the pair of gentle consonants suited the silent layer of snow upon
that pipe with its two orifices and its tacit tunnel [@nabokov_guide_1976, 27].

The tightly wound vignette takes the formalist programmatic concern with
"laying bare the device" to its logical and recursively structured conclusion.
The pipes can be read as a metaphor for the literary device. Usually found
beneath the street, they now sit idle and visible above the surface. Yet even
when exposed, the device fails to captivate for long. Disused, it once again
passes out sight, covered in snow. Concerned with surfaces, the narrator
"probes the glaze" of the street. He finds a palindrome written in snow. The
inscription "OTTO" not only resembles the pipes visually, but is in itself a
surface-revealing inscription that makes the pipes visible again. Although the
metaphoric pipe does not reach beyond the page, the mimetic surface inscription
draws attention to the word's visual shape and acoustics. It invites readers to
perform the symmetry of its assonance and consonance as they pronounce the
word. The round vowels and the interrupting obstruents of "OTTO" contort the
body in accordance with the sound image: reverse mimesis, the body as sound
pipe. The moment of corporeal reenactment transcends representational and
paper-bound confines of the medium. The pipes appear briefly on this side of
the page. The performance makes the "making of the literary technique obvious,"
obvious. In this, lies the prevalent characteristic of Nabokov's mature work,
which often seeks to rise above the word through sheer recursion of literary
technique, where each successive turn of abstraction brings the buried symbol
closer to the reader.

Inspired by the formalists, I would like to extend the technique of
estrangement to books and documents as literal devices. When asked in the
context of media and book history, the question of literary surfaces gains an
instrumental dimension. Habit hides the peculiarity of our everyday interfaces
with the word. We read at the surface. We etch inscriptions deep within the
bowels of a machine. When enacted on the level of the physical device,
estrangement parallels the practice of literary theory and reverse engineering.
Both aim to reveal internals that structure experience, made opaque through
artifice and habituation. I imagine here a kind of critical practice that
reverses the principles of good interface design. What design aims to make easy
and ordinary, defamiliarization makes difficult and strange. Materialist
poetics expose the price paid for literary facility.

For example, we know that physical affordances of liquid crystal displays
(LCDs) and magnetic storage differ drastically from those of goat skins or
parchment. Yet digital surface representation maintains the illusion of
self-similarity. We are faced with what is called *skeuomorphic* design, by
which screen reading resembles print. In this way, an electronic book reader
simulates the bent corner of a well-thumbed book. The skeuomorphic resemblance
itself constitutes a metaphor worthy of critical examination. The principles of
skeuomorphic design extend a visual metaphor from one medium to another. The
reader already knows how to turn pages of a book. A book device therefore
simulates pages to ease the burden of cognitive transition from one medium to
another. Instead of pushing unfamiliar buttons (yet another metaphor) to turn
the page, readers perform the more habituated motion of swiping across the
screen. The gliding motion enacts a kinetic metaphor, transposing properties of
paper to glass.

Readers bear the burden of conceptual transference (like the turning of pages).
In pretending to turn "pages," a reader loses sight of the structures producing
the simulation. Some would object that such structures are irrelevant or not
interesting: "one does not need to be a mechanic to drive a car," as the saying
goes. Yet, particularly in the case of literary devices, the concealed
mechanisms concern the structuring of privileged cognitive, as opposed to
other, let us say more pedestrian, facilities. If an automobile extends the
foot, the book extends the brain. It shapes mental activity. The simulated text
ultimately enacts a number of cognitive metaphors. If we are to value anything
like interpretation or critical reason, we must certainly value them at the
physical site of mental extension.

More than superficial embellishment, the skeuomorphic metaphor structures all
meaning-carrying units from letters, to words, paragraphs, chapters, books, and
pages. In our example, we know that there is nothing inherently page-like about
stiff slabs of glass and silicone. The metaphor of "turing the page by swiping
across the screen" conceals the structural rift between media. Why would
readers engage in such a charade? Why not simply make use of novel interfaces
afforded by new technology? The literature from the field of human--computer
interaction suggests a formalist answer: habituation [@carroll_metaphor_1982;
@carroll_interface_1987; @spolsky_user_2001]. The initial effort it takes to
learn to read in a new environment may discourage many potential readers from
adopting a new technology. Smart designers therefore rely on habituated
practice, the turning of pages in our case, to minimize the "friction" of
adoption. Although an "electronic book reader" contains no pages as such, it
extends the metaphor of pages to electronic reading. The usability metaphor
comes at a cost of concealment. A digital poem, a novel, a physician's script,
or a legal contract may resemble their paper counterparts. But the metaphor of
"turing pages" is but one simulation among the device's many possibilities.
When imitating pages, the reading *appliance* also monitors, adjusts, warns,
and controls. In return for usability it simulates and dissembles. The
exposition of the metaphor reminds us of the compromise between two conceptual
systems. It reveals real material affordances behind the symbol.

The simulation conceals structuring principles large and small. Some of the
concealed details may remain inconsequential, like the limit on how many keys
can be pressed at once without overwhelming the circuitry of the keyboard.
Other concealed details are of paramount importance, like digital rights
management chips and censorship filters. Like the smoke alarm, literary gadgets
are governed and internalize government structures in ways that we have only
begun to comprehend. The material affordances of device--bound textuality
influence all higher-level functions of interpretation.[^ln1-rmedium] Yet,
available theories of interpretation build on properties and assumptions
attached to print media. For example, in Hans-Georg Gadamer's seminal
conception of art, the free play of the artistic mind transforms into material
structure (*Gebilde*) that is both "repeatable" and "permanent"
[@gadamer_truth_1975, 110]. Similarly, in *Interpretation Theory*, Paul Ricoeur
writes about the "range of social and political changes" related to the
invention of writing. For Ricoeur, human discourse is "fixed" and thereby
"preserved from destruction" in writing [@ricur_interpretation_1976, 26-8].

The literary device offers no such permanence, neither in simulation nor in
diffusion. The very meanings of "fixed," "permanent," and "repeatable" change
with the medium. The engineering of literary artifacts conceals a number of
design choices, obscuring the flows of code and codex under the familiar guise
of surface representation. The digital book does not just simulate a book.
Being a type of a Turing machine, it holds the potential to embody all possible
metaphors.[^ln1-notquite] The task of the literary scholar reading on the level
of the device becomes to make the figure available for interpretation. It is to
apprehend its revealed mechanics. What happens in the metaphorical
transference between the book and the apparatus simulating the book?
Estrangement, the exegesis of the metaphor, reveals mechanisms of governance
shaping mental experience. Device hermeneutics allow one to consent, or,
conversely, to resist elements of imposed structure.

What sort of a thing is a literary device? It is tempting to think of personal
computers as glorified calculators. That is often the popular image of
computing, one that highlights the machine's ability to calculate. The computer
reduces culture to ones and zeroes (or so goes the story), thereby diminishing
the human experience.[^ln1-pop] There is some truth to that position, but I
would like to argue here that the connection between computing and calculation
is but a piece of a larger story. The personal computer governing the
production of textuality today emerged from an amalgamation of automated
equipment: among them the telegraph, the typewriter, and the calculator. Add to
that list the loom, the music box, the radio, and the film camera
[^ln1-ceruzzi]. Each of these machines left an imprint on our everyday
engagement with computational devices.

It is important to keep the intertwined material lineages of computation in
mind because each brings with it a different set of values and priorities. As
complex computational systems continue to play an ever greater part in our
lives, from affecting family relations to health and nutrition (think social
media and personal activity trackers), we are increasingly faced with a host of
conflicting choices. When building systems that give form to human experience,
should we privilege agency or efficiency, privacy or connectivity, elegance or
complexity? These are not choices that can be left to a calculator. Systems,
left to their own devices, cannot produce values. Rather, values are imposed
from without. The question then becomes one of ends and means. A calculator is
most "efficient" when operating on binary data. Efficiency and complexity are
goods for the task of calculation. Humans prefer to manipulate texts and
images. A democratic vision of a just society places value on open deliberation
and consensus building. Undeniably, computers participate in social
transformation: used to make war and to create art. What are our machines
optimized for? The passive voice points to the root of the problem. A
computational mechanism that extends agency should embody values that
correspond to the agent of the action. In other words, we must be able to
project our values through the machine, and not the other way around. What
seems like a technologically determined inevitability is often simply the
projection of values from without. It is social and political, not
technological determinism.

[^ln1-notquite]: To what extent a personal computer is a Turing machine is
matter of contention. The Turing machine is a *thought experiment* that
imagines a machine. The PC is a machine emulating the thought experiment. See
@putnam_representation_1988, 121-5; @chalmers_does_1996; @petzold_code:_2000. A
more detailed discussion follows in 1.2.

[^ln1-kant]: Or at least proceeding as if one has agency to structure one's own
experience, despite the overwhelming evidence for determinism.

## 1.2 Thought Experiment

To confront the computer as a *literary* device, optimized for symbolic
exchange, one must first understand its peculiar relationship to universal
Turing machines. And to understand the history of the Turing machine, we must
see it in a wider cultural context, beyond the mathematical literature where it
was first discussed. In what follows, I shall draw two as yet unexplored
lineages that lead to Turing's seminal essay on computable numbers: the first
intellectual, stemming back to his tutelage under Ludwig Wittgenstein, and the
second material, highlighting the physical similarities between Turing's design
and a number of concomitant developments in printing and communication. This
history is important because it allows us to see the simulated book in a new
light: not as byproduct of quantification, but as a metaphor machine,
capable of universal symbol manipulation.

More than any other mechanism, the Turing machine defined the very limits of
computation. Yet it is also a source of considerable debate, misunderstanding,
and controversy, because it poses a fundamental paradox. Turing imagined his
machine as a physical mechanism solving a theoretical problem. Actual
computers, in turn, simulate hypothetical Turing machines. You can see how this
may get confusing. Computation traces a figure stuck in the loop between the
ideal and the physical worlds. It is part real mechanism and part unattainable
idea; part physics and part metaphysics. The indeterminacy of computation blurs
the boundaries between hardware and software. And no matter how hard computer
science tries to escape into the realm of pure mathematics, the limits of
physical engineering pull it back to the sphere of the applied.[^ln1-cs]

In his seminal 1937 paper on computable numbers, Alan Turing, then a student at
King's College, proposed a peculiar solution to appear in mathematical journal.
He imagined a mechanism that solves a theoretical problem. What that problem
was (in the field of elementary number theory) is not as important as how he
proposed to solve it. Turing begins suggestively: "we may compare a man in the
process of computing a real number to a machine that is only capable of a
finite number of conditions." [@turing_computable_1937, 231]. In effect, he
asks his readers to compare computation, a human mental process, to the
mechanical action of a machine. As Charles Petzold explained it in his
book-length annotation on Turing's paper, Turing "makes reference to 'states of
mind' that are analogous to machine states" [@petzold_annotated_2008, 67]. But
the analogy itself leads to contention. Neither mathematicians nor cognitive
scientists agree on the extent to which states of mind can be compared to
discrete machine states.

Turing further imagines a machine "supplied with a 'tape' (the analogue of
paper) running through it, and divided into sections (called 'squares') each
capable of bearing a 'symbol'" [@turing_computable_1937, 231]. Much like a
movie reel, the tape moves through the mechanism one section at a time. At each
point only one section bearing one symbol can be said to be "in the machine."
"We may call this square the 'scanned square,'" Turing writes,

> The symbol on the scanned square may be called the "scanned symbol." The
> "scanned symbol" is the only one of which the machine is, so to speak,
> "directly aware" [@turing_computable_1937, 231].

The scanned symbols become a part of the machine's internal configuration. In
Turing's words, "the machine can effectively remember some of the symbols which
it has 'seen' (scanned) previously" [@turing_computable_1937, 231]. The
machine's "behavior" is therefore determined by its initial configuration (in
the arrangement of tape and scanning apparatus) plus the scanned symbol.

We imagine then a device not unlike a telegraph or a film projector, which
ingests reels of tape. But unlike telegraphs or film projectors, the ingested
symbolic representation becomes effectively, by definition, a part of the
machine's internal configuration. Remember that in constructing his
contraption, Turing continually appeals to the model of human cognition. A child
in the process of reading or doing mathematics similarly "ingests" symbols.
These symbols really do become a part of the child's mental apparatus,
affecting a change in brain states on some real and empirically observable
neurological level. Turing's machine is capable of similar internalization.

Where the child converts symbol into brain states, the machine transforms
software (symbol) into hardware (configuration). The machine does not just
scan, it "reads" in the Platonic sense. It internalizes and becomes "aware."
Consider by contrast the action of a film projector. Unlike a Turing machine,
the projector does not internalize film reels. The film reel passes through
without leaving a trace within the mechanism.[^ln1-reading]

In addition to "reading," Turing's machine must be able to write. Turing wrote
that "in some configurations in which the scanned square is blank (*i.e.* bears
no symbol) the machine writes down a new symbol on the scanned square"
[@turing_computable_1937, 231]. The machine can also erase and move symbols to
adjacent squares, one square at a time. Reading, writing, and symbolic
manipulation are thus mechanical actions at the core of Turing's computation.

The configuration state of the machine determines the movement of the "reading"
and "writing" apparatus along the surface of the tape. At its simplest
incarnation, the tape moves along one dimension only: left or right. Thus some
of the scanned symbols are meant to represent computable numbers (the whole
point of Turing's paper). Yet other symbols are meant as machine instructions.
They direct the movement of the reading and writing head. They tell the machine
to "write," "scan," or "erase" symbols. Today, we would call such instructions
"programs" or "control codes." The control codes and the computed data form a
part of the same continuous stream of information.

Just as the Turing machine is able to convert symbolic representation into
internal configuration states, it can conversely enact the opposite movement, by
representing internal configuration states symbolically. This remarkable
property allows for the creation of what Turing calls a class of universal
machines. Specific Turing machines could be configured to preform actions like
addition or multiplication. But the multiplication machine could not, for
example, be reconfigured for another purpose, because the physical movement of
its internals is fixed. In addition to scanning symbols, the universal Turing
machine has the ability to internalize *other machine configurations*. Turing
explains that "it is possible to invent a single machine which can compute any
computable sequence" [@turing_computable_1937, 241]. In being able to
internalize configuration as symbol, the *universal* Turing machine can
simulate all other special-purpose Turing machines.

The transition of symbols into machine states (and the other way around)
defines modern programming. A universal machine, unlike other, definitive,
single-purpose and limited-state mechanisms (a clock for example), contains the
ability to take on differing internal symbolic configurations. It can imitate a
clock, an abacus, a scale, a book. In a later paper linking computing machinery
and intelligence, Turing implies it could eventually simulate human thought as
well [@turing_computing_1950].[^ln1-compete]

The universal Turing machine (UTM) finally encapsulates a model of computation
itself. The UTM can compute anything computable. In substituting the concept of
computability with "effective computability" Turing's paper belongs to the
annals of mathematical theory. But, it continues to elicit response widely
because much of it contains tantalizing possibilities that bare on symbolic
manipulation more generally. The paper is riddled with metaphors of cognition,
for example. From the beginning we are asked to consider the similarity between
humans and machines in the process of computation. Turing consistently
describes machine states in terms of "states of mind," "awareness," and
"memory." Without confronting the nature of human cognition directly, Turing
hints at the idea of computation as a model for human thought. The literature
on the so-called "computational theory of mind" cites Turing's work extensively
for this reason [@fodor_language_1975; @putnam_representation_1988].

Turing's paper should hold interest for literary scholars because it presents a
minimally viable model for generalized symbolic manipulation: reading and
writing. Although the thought experiment it describes solves a mathematical
problem, the thought experiment itself has roots in a more general conversation
about the nature of interpretation, central to the questions of meaning-making
in art and culture. The conversations between Alan Turing and Ludwig
Wittgenstein are instructive in this regard. Wittgenstein broached the problem
of reading machines first in *The Blue and Brown Books* along with
*Philosophical Grammar* (all compiled in the early 1930s), then in his lectures
and remarks on the foundations of psychology and mathematics from the late
1930s, and finally in *Philosophical Investigations*, (written between 1945 and
1949). To give you a sense of the timeline: Alan Turing's paper on computable
numbers appeared in print in 1936 and his "Computing Machinery and
Intelligence" in 1950. A historical reconstruction of that conversation, across
both writers' notes and publications, will help us perceive the extent to which
Turing's machines were conceived as a type of intelligent reading and writing
simulators.[^ln1-notes]

### *The Blue and Brown Notebooks*

The *Blue and Brown Notebooks* comprise "some notes to my pupils, so that they
may have something to carry home with them, in their hands if not their brains"
[@wittgenstein_blue_1965, vii]. "The Blue Book" begins with a question of
interpretation: "What is a meaning of a word?" From the start, Wittgenstein
cautions his students against choosing the easy answer, which holds that
meaning resides in the head. Wittgenstein writes:

> It is misleading then to talk of thinking as of a "mental activity". We may
> say that thinking is essentially the activity of operating with signs. This
> activity is performed by the hand, when we think by writing; by the mouth and
> larynx, when we think by speaking; and if we think by imaging signs or
> pictures, I can give you no agent that thinks. If then you say that in such
> cases the mind thinks, I would only draw your attention to the fact that you
> are using metaphor, that here the mind is the agent in a different sense from
> that in which the hand can be said to be the agent in writing.

The "locality of thought" poses a problem of analogy. Wittgenstein explains
that when we see a sentence on paper, the external manifestation of a thought,
we assume that some analogous structure exists somewhere in the brain. Perhaps,
Wittgenstein speculates, we could even observe the brain directly, in the
process of writing. Both phenomena, brain- and paper- bound, could properly be
called the *expression* of thought. Yet neither can offer the definitive
location where thinking happens. Rather, Wittgenstein suggests, we are
witnessing a metaphor: some set of correlations between two distinct
activities. And it may be that the correlations themselves are what we mean by
"thought." Neither brain nor paper make sense as *the* site of cognition by
itself, just like it would not make sense to interrupt a metaphor---"memory the
warder of the ~brain~ (from *Macbeth)---and then look for it in the remaining
snippet.

Our difficulty in locating the definitive site of thought points to the
inadequacy of Cartesian dualism between body and mind. Neither physical nor
mental descriptions of thought are sufficient to locate the site of cognition,
Wittgenstein argues. As an example of such a difficulty and likely having a
passage from Descartes in mind[^ln1-descartes] Wittgenstein asks, "Can a
machine think" [@wittgenstein_blue_1965, 16]? The problem, as he explains, is
not one of finding a machine that can do the job---of manipulating signs, for
example. It lies in the ability of a machine to enact the both sides of the
metaphoric equation. "Doing the job," the manipulation of signs, must
correspond to something else. Severed from some other analogical structure, the
"blind" manipulation of signs is a meaningless actvity. Meaning, Wittgenstein
seems to suggest, resides simply in this analogy between something (symbol) and
something else (mechanism).

Wittgenstein extends his thought experiments about reading machines in his
*Brown Notebook.* Let us study the word "reading," he suggests early on. By
reading, he means the activity of "translating script into sounds," "of writing
according to dictation," or "of copying in writing a page of print"
[@wittgenstein_blue_1965, 119]. Reading once again is "mechanical" reading,
without a sense of "understanding" or interpretation. What happens when an
average child reads a newspaper, for example? "His eyes glide along the printed
words, he pronounces them aloud or to himself, but other words he pronounces
after having seen their first few letters only, other again he reads out letter
by letter." The child acts as a "reading machine" when he pays no attention to
what he reads, even when he speaks the words out loud. Yet he reads
"faultlessly like a reliable machine." Another child merely pretends to read.
He guesses at the words, and on occasion repeats things "by heart", without
actually seeing them on the page [@wittgenstein_blue_1965, 121-22].

Wittgenstein continues to complicate such edge cases, challenging his
audience's intuitions of what it means to read and to understand. He gives also
the example of a hallucinating patient, who "reads" what to us looks like
gibberish, and the case of man who fakes reading Cyrillic by memorizing the
lines phonetically. He talks of machines too, which produce random sounds that
occasionally, by accident, correspond to some existing texts. In each case, we
envision two mechanisms, Wittgenstein writes, one visible and external and one
hidden and internal. To read, the reader must do more than go through the
motions of reading. Instead, we privilege the inward-facing signs of
comprehension as the "real criterion for a person's reading or not reading."
The physical motions, of gliding one's eyes across the page and saying the
words out loud, must connect in some way with appropriate internal, mental
representations.

But in fact no such internal mechanisms can be known to us or communicated to
others properly [@wittgenstein_blue_1965, 120]. We can only intuit the reader's
private experience of reading, or whether such reading attains the desired
correspondence between inward state and outward sign. A reading pupil must
convince his teacher that the scanned sign had the intended effect. This
requires more words in a sort of a broken hermeneutic spiral, stuck in a
communication feedback loop that cannot quite complete the circuit.

Wittgenstein finally describes the mechanisms of reading as an "indirect way
of transmitting a feeling." "Something that we can never know happens at the
other end" of the communication act. Communication, as we would say today, is
always mediated.  In conclusion of the notebooks, Wittgenstein imagines the
possibility of unmediated, "direct" modes communication, capable of
transmitting feelings from one person to another [@wittgenstein_blue_1965,
185].

Thought experiments in *The Blue and Brown Notebooks* do not amount to a
cohesive model of communication, semiotics, or the mind. They do however
contain the seeds of the reading and writing machines later imagined by Alan
Turing and subsequently passed into the foundations of computer science.
Wittgenstein's experimental thought machines prefigure the modern computer.
Wittgenstein conquers these fantastical broken machines ultimately to address
the problem of symbolic interpretation.

### *Philosophical Grammar*

*Philosophical Grammar,* written around the same time as the *Blue and Brown
Notebooks*, gives us another into the pre-history of the literary device. It
begins a gain with a problem of "understanding" and "not understanding." "To
understand language," Wittgenstein writes, "is take in symbolism as a whole"
[@wittgenstein_philosophical_1974, 5]. From the very first passages,
Wittgenstein envisions understanding as a type of trans-mediation. In comparing
the understanding of propositions to music, he writes, "I can only translate
the musical picture into a picture in another medium"
[@wittgenstein_philosophical_1974, 5]. Consequently, Wittgenstein continually
returns to the pianola, a type of a player piano, to illustrate key concepts in
his lectures and writing of the "middle" period (between his *Tractatus* and
*Philosophical Investigations*).

For example, in the early passages of *Philosophical Grammar*, Wittgenstein
writes: "Aren't our sentences parts of a mechanism? A in a pianola? But suppose
it is in bad condition?  So it is not the effect but the purpose of the signs
(the holes in the pianola roll). Their purpose *within* the mechanism"
[@wittgenstein_philosophical_1974, 10]. Wittgenstein elaborates a few pages
later:

> The sentences that we utter have a particular purpose, they are to produce
certain effects. They are parts of a mechanism, perhaps a psychological
mechanism, and the words of the sentences are also parts of the mechanism
(levers, cogwheels, and so on). The example that seems to illustrate what we're
thinking of here is an automatic music player, a pianola. It contains a roll,
rollers, etc., on which the piece of music is written is some kind of notation
(the position of holes, pegs, and so on). It's as if the written sign gave
orders which are carried out by keys and hammers
[@wittgenstein_philosophical_1974, 69].

As was the case with reading automata in *The Blue and Brown Notebooks*,
Wittgenstein again substitute a physical mechanism for the process of symbolic
interpretation. On this view, words and music notation alike, have "a purpose"
to elicit some "effects" in the reader/player. But as before, we cannot always
expect the mechanism of interpretation to function properly, nor do we have a
reliable way to check its operation. "Suppose the pianola is in bad condition,"
Wittgenstein repeats. The signs on the roll could produce "hisses and bangs"
instead of music, for example. One could object that notes are always meant
to play on a mechanism in perfect working order. By analogy, "the sense of
an order is its effect on an obedient man" [@wittgenstein_philosophical_1974,
60-70]. The pianola exemplifies what will come into a much starker contrast
later in this chapter: that the mechanisms of symbolic communication ultimately
belong to a class of controlling devices and that through them it becomes
impossible to isolate anything like an order (code, instruction, etc.) from
content (message, information, etc.).

When drawing the analogy between mental and mechanical precesses, Wittgenstein
explicitly rejects the model of language as a "psychophysical" mechanism.
Rather, as the title of the work suggests, Wittgenstein is in search for the
"grammar" governing the engagement: between speakers and listeners, readers and
writers, player pianos and musical scores. By the end of the work, grammar
emerges as a set of "conventions." Wittgenstein complicates the mechanism by
inserting an extra layer of "rules" that mediate between symbol and machine or
mental state. A convention could be included in a chart, for example. And it is
possible that "there is a part of the mechanism which resembles the chart, and
is inserted between the language-part of the mechanism and the rest of it"
[@wittgenstein_philosophical_1974, 190]. "Imagine a language consisting of
commands," Wittgenstein writes in conclusion.  It is to direct a human
"forwards," "back," "right," and "left," "quickly" and "slowly"
[@wittgenstein_philosophical_1974, 197] The grammar, like a table of
correspondences, explains the meaning of the signs. Today, we would call it a
"program." The translates arbitrary symbolic notion into physical action.  In
this way, we can move away from speaking of "intended effects" or "proper
abidance," and rather concentrate on this mediating layer that describes the
rules of engagement.

### Lectures and Remarks

Alan Turing attended Wittgenstein's Lectures on the Foundations of Mathematics
at Cambridge University in 1939 [@wittgenstein_wittgensteins_1976, 7]. From the
notes complied and published by Cora Diamond, it is clear that Turing was a
vociferous presence in the class. His name is mentioned 86 times in the text,
more than any other student by a wide margin. At some point of the course
Wittgenstein concludes his lecture in saying: "Unfortunately, Turing will be
away from the next lecture, and therefore that lecture will have to be somewhat
parenthetical. For it is not good my getting the rest to agree to something
that Turing would not agree to" [@wittgenstein_wittgensteins_1976, 67-68].

Like the notebooks beforehand, Wittgenstein structures his lectures around the
problem of symbolic interpretation. "I am going to talk about the interrelation
of mathematical symbols," Wittgenstein begins. We imagine that logical laws
represent some sort of "fixed" mechanisms "behind" the symbols used to express
them. "I am speaking against the idea of logical machinery," Wittgenstein says
in lecture XX. "The idea of logical machinery would suppose that there was
something behind our symbols" [@wittgenstein_wittgensteins_1976, 194]. We
imagine logic to be a sort of a "rigid mechanism" that can only turn this way
or the other. "Any rule can be imagined to be a description of a
mechanism---even the rule which says a pawn must not be moved in a certain
way," Wittgenstein writes. The parts of the mechanism subsequently exist in a
causal relationship to one another. Pushing this or that lever will *always*
result in such and such movement, because of the way the mechanical parts are
connected. We say that the mechanism is rigid or the law is inexorable, when
the results of an action are absolutely fixed. Wittgenstein calls such a
relationships "super-hardness." Where a judge can be lenient, he explains, the
law is compulsory. What we would now call "an algorithm" compels predictable
execution.

We are tempted, as before, to privilege the inner workings of the symbolic
mechanism, also at the core of meaning making in mathematics. "If I show you
the mechanism behind the [watch] dial, you will be able to predict the movement
of the hour hand for any given movement of the minute hand," Wittgenstein
writes.  "And you will not be sceptical." Yet even there, we would be making an
assumption about a mechanism that functions well. "For instance, I may drop the
clock" Wittgenstein explains, "so that the machinery is broken, or a lighting
may strike it [@wittgenstein_wittgensteins_1976, 195]. How are we to know if
the mechanism functions properly or not? For that we would need "a picture" or
some sort of schematics that describe what the proper mechanism should look
like. The mechanism is in fact itself a type of "a symbol" for the perfected
behaviour of the sort that we expect. Where we tried to find the mechanism
behind the symbol, we found also the symbol behind the mechanism. Once again we
encounter the spiral between intent and effect, which never quite manage to
explain each other.

In his lectures on mathematics, Wittgenstein never finds a way out of this
recursive conundrum. The foundations of mathematics rely on some such mutually
dependent relationship between the physical and the symbolic worlds. Whether it
is in math or in ordinary language, some magic happens at the coupling of the
matter and sign. The precise point of contact concerns Wittgenstein in all
fields of human activity, from literature to psychology and mathematics.

In all of these fields, Wittgenstein finds an implicit analogy between "symbol"
and "mechanism." A type of metaphor, the analogy itself is atomic. It cannot be
split further into something like "sign" and "referent" or the "signifier" and
the "signified." In his lectures on aesthetics, Wittgenstein describes such a
semiotic relationship as the "concomitance between mechanism and its trace"
[@wittgenstein_lectures_1966, 16]. In giving an account of one's aesthetic
judgment, the best we can do is to "trace a mechanism"
[@wittgenstein_lectures_1966, 13].

It would be a mistake to reduce Wittgenstein's semiotics to the mechanichal
theory of the mind. Rather, in presenting his students and readers with a
number of hypothetical machines, Wittgenstein attempts to discover the rule
book of what he later calls the language game. Much has been written on this
aspect of Wittgenstein's thought. In the context of our conversation,
Wittgenstein's "middle period" is important for its direct influence on
Turing's model of computation. Several prominent charactheristics pass from
Wittgenstein's reading machines to Turing's universals. First, the symbolic
machine emerges from the metaphor-like corrspondance between internal machine
states and external symbolic representations. Second, Wittgenstein discusses
symbolic representation in terms of desired effects, that is, ultimately a type
of a remote control mechanism. And finally, Wittgestein imagines a mediating
layer that holds the rules for translation between state and symbol. All of
these features, along with a penchant for ambigusous thought experimentation,
pass directly from Wittgestein's to Turing. Turing, in effect, attepts to clean
up after his teacher's profusion of broken interpretation machines. Instead, he
gives us one thought experiment, encompossing all possible center and edge
cases. In addition, Turing describes the minimal physical requirements needed
to actually build such a contraption.

## 1.3 Mechanism

So far, we have confronted the literary device as an idea: imagined first as in
the methodological contexts of formalist literary analysis and then as a
thought experiment about generalized symbolic manipulation about generalized
symbolic manipulation. When viewed in the context of book history, the
universal Turing machine signifies a consummation of several broad, long-term
trends that begin with the invention of writing itself.

The God of the Hebrew Bible etched his commandments into stone (Exodus 34:1).
Moses broke the first set of tablets, but the word remained, for a time,
immutable. The material history of literary computing begins with petrified
words that endure forever, and ends with word as an electrical charge:
animated, radiant, fluid, and iridescent [@mcgann_radiant_2001;
@bryant_fluid_2002].

The long history of the word proceeds in stages, from the immutable sign to the
universal implement, capable of reproducing all symbolic representation
dynamically. The universal Turing machine culminates the development of the
symbol. Through it, the symbol gains its ideal form, capable of representing
everything that can be represented. All further symbolic engines constitute
lesser versions of the universal archetype.[^ln1-brain] Yet the archetype
machine itself is also limited to an ideal. It can only exist as a thought
experiment. All real-world Turing machines must contain non-representational
elements, dispelling the illusion of immateriality.

Although much of contemporary popular discourse on computation speaks the
language of disruption, the history of computational symbolism, of the sort I
am suggesting here, must be seen as an evolutionary trajectory.

If a symbol, something used to represent something else, elicits a type of an
illusion, the universal symbolic machine enacts the ultimate illusion. It
creates a phantasmal image of symbolism itself. The history of computing is
thus a history of symbolism in the broadest possible meaning of the word, which
includes lyric poetry and symbolic logic.  In this chapter I would like to
convince the reader to view text, in all its computationally-mediated
forms---files, "print outs, "web pages," electronic books---as a device.
All Turing machines, however imperfect, occupy that ambiguous space between
theory and practice. The personal computer, the hand-held "mobile" telephone,
and the electronic book "reader" share in the legacy of Turing's computation.
They are ideas and devices.[^ln1-caveat]

The ambiguity between hardware and software leads to some controversy in the
critical literature, as evidenced by Lev Manovich's playful response to
Kittler's "there is no software" argument. If I understand it correctly,
Kittler's short but often cited essay picks up the thread of Kittler's earlier
work to posit what he calls a "postmodern writing scene." "We do not write
anymore," writes Kittler: "human-made writing passes through microscopically
written inscriptions which, in contrast to all historical writing tools, are
able to read and write by themselves" [@kittler_there_1995]. According to this
schema, Kittler sees the paper-bound design blueprints of the first integrated
microprocessor as the last "real" piece of writing. Everything written after
that point is hardware (because software is hardware at that "microscopic"
level).

Manovich inverts Kittler's argument into "there is only software," by which he
means that in a pragmatic sense, the affordances of a given medium are
determined by software. A printed page begins to differ from a screen only when
the readers are able to effect something on the screen that they could not on
paper. To this end, Manovich encourages his readers to become active developers
of software, rather than its passive consumers [@manovich_there_2011, 274]. In
that, Manovich reasserts the possibility of writing in the silicon age. Kittler
(who passed in 2011) could perhaps object to that line of reasoning in
maintaining that chip architecture (the last written work) still determines (as
foundation) all higher levels of textuality "floating" above the silicon
bedrock. And no amount of learning to code would give an ordinary subject the
resources required to write in silicon---a process so advanced and expensive as
to be limited to a handful of international chip manufacturers. In opening a
successive nested series of black boxes, the post-silicon writer hits the
impenetrable bedrock of chip architecture. In such conditions, is it even
worthwhile to follow Manovich's call for new literacies? Is writing still
possible?

The question of where do brains end and minds begin remains unresolved in
cognitive science, for example. Similarly, at some imperceptible point software
disappears into hardware. But before we ourselves get lost in that liminal
space between matter and idea, let us recover a measure of oddity found in the
now ubiquitous operation of Turing machines. First, note that Turing's original
formulation happens at the level of a thought experiment. (Turing does not
begin to build actual machines until his move to Princeton in 1936.) A
universal Turing machine comes to life initially as an idea that can take on
the structure of other ideas expressed symbolically. Second, note that though
Turing describes his machine in the language of mathematics (where his most
significant contribution lies), his description also contains the bare minimum
of a mechanical device. No matter how symbolic a Turing machine aspires to be,
no matter how ascendant to the realm of the ideal, it still needs a bare
minimum of physical matter to function. And Turing's paper does contain the
canonical description of that bare physical minimum.

With the above two observations in mind, we can view abstracted universal
Turing machines, as implemented in the Wireworld universe (a cellular automaton
simulation), for example, or in Minecraft (a procedurally generated sand-box
world-exploration game), as recursive, second-order ideational constructs,
built on top of first-order physical mechanisms (a personal computer, in the
case of Wireworld and Minecraft). We know this, because all *n+* order Turing
machines are limited in computational power by the physical capabilities of
that bottom-most device (the physical machine writing the simulation). The
simulated UTM cannot outperform (in terms of cycles per second, instructions
per cycle, or its capacity to hold a number of instructions) the machine doing
the simulation. If we disregard the dizzying levels of recursion (a Turing
machine, simulating a Turing machine, simulating a Turing machine and so on),
we can begin to examine the turtle at the bottom, which has its head in the
symbolic and its feet firmly in the material world.

Literature in computer science tends to see universal Turing machines as
algorithms: in other words, as virtual, second-order symbolic representations.
As consummate thinkers on the level of the symbol, computer scientists and
literary scholars (unlike, say, electrical engineers or book binders) rarely
need to pay heed to that strange bottom-most turtle.[^ln1-bottom] Yet it is
impossible to entirely disassociate the implementation from the idea. In his
review of Turing's "On Computable Numbers" paper, Alonzo Church, the American
mathematician whose work anticipated Turing's (independently) in several
important aspects, wrote that "a human calculator, provided with pencil and
paper and explicit instructions can be regarded as a kind of a Turing machine"
[@church_computable_1937, 42-3; also cited in @petzold_annotated_2008, 63].
Disregarding the broader, metaphysical implications of that statement, note for
now the persistence of two essential implements required for the minimally
viable operation of the Church--Turing human and machine calculators. Pen and
paper persevere and assert themselves through the
abstraction.[^ln1-abstraction]

Forced to confront the universal Turing machine *as a mechanism*, the
historian must acknowledge that it borrows from a number of extant designs,
which, together and incrementally, give the UTM its physical form. A media
history of the Turing machine as device differs from its intellectual history
as symbolic, mathematical abstraction in interesting and instructive
ways.[^ln1-turing]

![Universal Turing machine as an idea. "Nick Gardner's Wireworld multiplier,
via a Turing machine."](images/turing-idea.png)

Bracketing for the moment the mathematical and cognitive implications of
Turing's work, I want to approach the Turing machine from the perspective of a
book historian and a media scholar. If the Turing machine is to be taken at
face value, not as an algorithm, but as an instrument, what kind of a machine
would it be? What are its antecedents?

Most of the minimal physical requirements to build a universal Turing machine
were within reach in the 1930s, at the time Turing authored his influential
paper. In practice, his proposal would require first, an apparatus capable of
"scanning" and "erasing" a "finite number of symbols." Second, we would need
what Turing calls "one-dimensional paper," divided into discrete squares "like
a child's arithmetic book" [@turing_computable_1937, 249].[^ln1-infinite]
Furthermore, we would need some sort of mechanism to advance tape through the
machine, or, alternatively, to propel the scanning mechanism along the length
of the tape. Having assembled these elements, our creation would look roughly
like a cross between a telegraph, a film projector, and a
typewriter.[^ln1-davey]

Were we to patent the Turing machine at the time of its theoretical inception
(1936-37) in the United States, the above elements would find prior art in
mechanisms such as the "Numeral adding or subtracting attachment for
type-writing machines" [@daugherty_numeral_1894], "Combined Type-writing and
Computing Machine" [@degener_combined_1911], "Computing Attachment for
Typewriters" [@wright_computing_1914], "Computing Mechanism"
[@wright_computing_1915], and "Combined Type-writing and Adding Machine"
[@ellis_combined_1914] among others. All of these machines contain some
combination of a reading and writing "head," storage tape, and movement
mechanism.

By the end of the nineteenth century a number of lesser contraptions anticipate
the functional elements of Turing's machine. And by 1936, when Turing publishes
his paper on computable numbers, these inventions not only anticipate the
modern computer, but are brought to mass market in the widespread manufacture
of computing scales, dial recorders, electric tabulating machines, and
computing typewriters made by companies like Underwood Computing Machine,
Electromatic, and International Business Machines (IBM). Rather than a single
eureka moment, the invention of the universal machine should be viewed as a
gradual historical process that culminates in Turing's universal (and minimally
viable) specifications.

A number of inventions at the end of the nineteenth century pertain
specifically to "circuit-controlling devices controlled by a traveling
perforated strip or tape" [@cuttriss_telegraphy_1893]. Prior to perforated
tape, the transmission of messages by telegraph required the presence of a
skilled operator, able to transcribe messages from text to Morse code, and into
the physical motion of a lever-operated circuit. In the operation of early
telegraphy, the human operator acted as a mute interpreter between text and
telegraph. The transcription of text into signal, and back onto paper, required
the real-time presence of human encoders and decoders.

The perforated tape decoupled the human from the machine. In US1187035 (1916)
on "Telegraphy", Albert and Ralph Bumstead explain: "the object of our
invention is to provide a system of telegraphy which does not require skilled
operators for the transmission and reception of messages"
[@bumstead_telegraphy_1916]. Instead, the message was transcribed into
perforation via mechanical means and then fed into the mechanism. The tape
mechanics of the typewriter could then be coupled with the electrics of the
telegraph, with perforated tape acting as a mediator between the two "worlds"
of mechanics and electricity.

A number of contraptions emerged at the time with the aim of transforming the
mechanical action of the typewriter into perforation, and, consequently,
perforation into script, completing the circuit between automated "encoding"
and "decoding." As one machine converted human input into mechanical states,
and into signal, another machine converted signals into mechanical states and
thereon into human-legible messages.

What began as a trickle at the end of the nineteenth century ended in a flood
at the beginning of the twentieth. A multitude of inventions capitalized on the
control capabilities of removable storage media. These included machines for
tape-controlled telegraphic transmission [@wheatstone_improvement_1874;
@murray_tape-controlled_1905; @bumstead_telegraphy_1916], tape-controlled
printing [@creed_printing_1911], printing telegraphs
[@hallden_printing-telegraph_1929], and remote broadcast programming devices
for radio and television content [@vriendt_program_1934; @brown_automatic_1936;
@brown_selective_1936]. With the invention of punch cards and perforated tape
(also used in textile looms, as early as 1725), a message meant for another
human became also a physical medium---bumps and holes---used to animate the
mechanical movement of the transmission apparatus.

For example, of the 33 asserted claims in the Bumstead brothers' "Telegraphy"
patent, the first 13 relate to the "transmission of intelligence,"

> [...] adapted to initiate a succession of electrical impulses all of which
> have a character representing significance, a receiver adapted to detect
> variations in time intervals elapsing between successive impulses, a
> plurality of interpreting relays selectively actuated by said receiver, and a
> printed mechanism responsive for the combined action
> [@bumstead_telegraphy_1916, 12-13].

What begins as a description of a mechanism for information transmittal, ends
with a claim about hermeneutics of control. Starting with clause 14, the
brothers begin to describe "a telegraph system" that capable of "transmitting
impulses" at varying time intervals. In the language of the patent, the length
of the time interval "represents significance," involving an automated receiver
responsible for "distributing, interpreting, and recording." The printing
mechanism is further "arranged to print the interpretation of the signals which
is made by the interpreting relays" [@bumstead_telegraphy_1916, 6]. The
interpreting relays transform time intervals into a "typographical form"
representing "a letter, a figure, or other characters," "in accordance with a
code" [@bumstead_telegraphy_1916, 13]. Initially, the telegraph prints to
"transmit intelligence." But the authors also understand that the varying time
intervals could also signify other information, meant to actuate a variety of
devices.

By the middle of their patent, they begin to describe their telegraph as a
general "controlling medium," which can power everything from typesetting
machines to more general "sunflower switches." "Indeed the detector and the
interpreting relay could be made to actuate a set of sunflower switches for an
indicator without including a printer at all," the authors conclude
[@bumstead_telegraphy_1916, 12]. For the automated telegraph, control code and
the message are one. The mechanism interprets some signals as figure and
character and other signals as control code affecting the internal mechanical
configuration of the device. The first type of code holds "significance" for
humans, where the second for the mechanism itself. It is "transmitting
intelligence" in a sense of externalizing machine states and "interpreting" in
the sense of mechanical reconfiguration of internal parts.

Along with dozens of similar inventions patented around the turn of the
twentieth century, Bumstead brothers describe a mechanism that functions as a
Turing machine with little modification. The automated telegraph, driven by
ticker tape, and connected to a printer contain all the necessary requirements
set out by Turing: a discrete symbolic language, the removable storage medium,
and a device that can alter its internal states based on the reading and
writing of scanned symbols. Like the Turing machine, the Bumstead telegraph is
capable of recursion. Ultimately, it can produce and interpret its own control
codes.

By 1905, Donald Murray, the inventor of the popular Murray telegraph, could
write that "if we disregard the small class of telegrams that merely express
emotions, *the essence of telegraphy is control* [emphasis mine]." He went on
to write that "telegraph systems, therefore, belong not to the class of
producing or distributing, but to the class of controlling mechanisms"
[@murray_setting_1905, 556].

That history begins with the human capacity to externalize images. It proceeds
with the invention of writing: a formal constraint on the image, adding a level
of non-mimetic abstraction. A picture of the horse that looks like a horse can
now be represented in five characters that can further be recombined to form
other images. The constraint on the number of symbolic "building blocks"
proceeds with the diffusion of movable type in China and Europe, circa 1040
(China) and 1450 (Germany) [@mcluhan_gutenberg_1962; @he_diffusion_1994;
@needham_shorter_1994, 1-34; @febvre_coming_2010].

With the invention of movable type and the typewriter, the variability of
hand-written script was further normalized to a set of discrete and
reproducible characters.[^ln1-normal] A key stipulation for the Turing machine
requires that "the number of symbols which can be printed is finite"
[@turing_computable_1937, 249]. The mechanization of print begins to "lift" the
letter from its medium, enabling the development of distant writing
(telegraphy) and remote communications, which, although extant in many early
societies (as smoke and mirror signals, for example) accelerates dramatically
at the beginning of the nineteenth century [@shaffner_telegraph_1859;
@beauchamp_history_2001; @standage_victorian_2014]. When combined with the
mechanization of type, telegraphy amplifies the range and the speed of
geographical displacement enabled by the circulation of printed matter. I do
not pause much for these developments because they are well described in the
literature.

Finally, the rise of universal Turing machines in the late nineteenth and early
twentieth centuries definitely severs the symbol from its material contexts.
Textuality splits into simulated surface representation and underlying control
code. Computation changes the nature of print from an intelligence-conveying
medium to one of communication and control. "Content" intended for humans is
now routinely mixed with "control codes" intended to alter the operation of the
receiving device. The Turing machine achieves the bifurcation of the sign,
intertwining the histories of telecommunications and code control. A
computational document or a book arises as a subset of control devices: the
essence of distant writing is control.

[^ln1-pop]: See for example  @drucker_digital_2001; @golumbia_cultural_2009;
@marche_literature_2012.

[^ln1-ceruzzi]: See @ceruzzi_computing_2012, 11 who writes that "the modern
computer is a convergence of separate streams of information handling, each
with its own rich tradition of technological history." "One could add other
antecedents such as the development of radio, motion pictures, and photography"
[@ceruzzi_computing_2012, 11].

[^ln1-compete]: "We may hope that machines will eventually compete with men in
all purely intellectual fields" [@turing_computing_1950, 460].

[^ln1-infinite]: A true universal Turing machine would require a tape that is
infinitely long.

[^ln1-davey]: Mike Davey built and displayed a similar instrument at Harvard
Universitiy's Collection of Historical Scientific Instruments in 2012. He
writes, "my goal in building this project was to create a machine that embodied
the classic look and feel of the machine presented in Turingâs paper.  I wanted
to build a machine that would be immediately recognizable as a Turing machine
to someone familiar with Turing's work" [@davey_turing_2012].

[^ln1-reading]:The Turing machine in effect gives us a concise minimally viable
definition of "reading" and "becoming aware." Proper reading involves the
appropriate internalization of the symbol, for both human and machine.

[^ln1-cs]: Two separate departments offersing competing degrees in software
engineering and computer science is a common occurance in North American
universities.

[^ln1-caveat]: The institutional distinctions between software engineering and
computer science often hinge on the extent to which the discipline pays heed to
the physical limitations of computing. As usual the situation on the ground is
much more complicated, and the boundaries between software engineering and
computer science are fast eroding. Still, North American students often have
the choice to major in Computer Science or Software Engineering. It would not
be unusual for the one faculty to be located in the School for Liberal Arts and
Science and the other in the School of Engineering. Consider also the two major
professional organizations: Institute for Electrical and Electronics Engineers
(IEEE) and Association for Computing Machinery (ACM). See
@glass_comparative_1992; @parnas_software_1999; @glass_analysis_2004;
@vessey_unified_2005.

