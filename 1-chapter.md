---
title: "Plain Text: The Poetics of Human-Computer Interaction (Sample Chapters)"
subtitle: "Chapter 1: Laying Bare the Device"
author: "Dennis Tenen"
style: csl/chicago-note.csl
bibliography: plain-text.bib
toc: true
documentclass: article
cover-image: images/steno.png
header-includes:
- \usepackage{ftnxtra}
- \usepackage{titlesec}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \newcommand{\sectionbreak}{\clearpage}
- \rhead{DRAFT | do not circulate }
- \lhead{}

---

# Chapter 1: Laying Bare the Device

"The weakest point in our present day universe is the incapacity of man to meet
the machine, the culture conserve, or the robot, other than through submission,
actual destruction, and social revolution" [@moreno_who_1953, 233]. So wrote
the Austrian-American psychiatrist, Jacob L. Moreno between the years of 1934
and 1953, in his now seldomly read classic, *Who Shall Survive?* He is
remembered today as a pioneer of group therapy. Sociologists also occasionally
mention his work as an early precursor to network analysis. His books contains
beautiful diagrams, sprouting nodes and edges, with titles like "Structure of a
Cottage Family," "A Handicraft Group," and "The Civilian Social Atom." Yet
Moreno was also a philosopher of technology and culture. Human relationship to
mechanized "dead" thought was at the center of his practice.

"Many of the domesticated robots are blessed with the attribute of become
labor-saving devices, which has, however the unpleasant consequence that they
at time reduce the need for creating, promoting with leisure also intertia.
[...] Many of the robots have also the attribute in common of bewing able to
affect human beings or other "targets at a distance," a book, a radio or a
television sender can entertain or teach at a distance, like a gun, a rocket
and an atomic bomb can kill people and destroy at a distance. The book is a
robot par excellence. Once off the press, the parent, the producer, the author
is immaterial; the book goes to all places and to all people, it doe not care
where it is read and by whom. Many robots have further in common the attribute
of comparative immortality. A book, a film, an atomic bomb, they do not perish
in the human sense, the same capacity is always there, they can be reproduced *ad
infinitum. [...] Our human world is incresingly filled with robots there there
seems to be no ned to new forms and new developments. Since man cam outof the
jungle, its master, he did not have a similar maze of threats to face---the
jungle of robots" [@moreno_who_1953, 239].

universal Turing machine as a book---an instrument for symbolic
exchange---means to recover the physical roots of computation.  When viewed in
the context of book history, the universal Turing machine signifies a
consummation of several broad, long-term trends that begin with the invention
of writing itself. The God of the Hebrew Bible etched his commandments into
stone (Exodus 34:1). Moses broke the first set of tablets, but the word
remained, for a time, immutable. The material history of literary computing
begins with petrified words that endure forever, and ends with word as an
electrical charge: animated, radiant, fluid, and iridescent
[@mcgann_radiant_2001; @bryant_fluid_2002].

The long history of the word proceeds in stages, from the immutable sign to the
universal implement, capable of reproducing all symbolic representation
dynamically. The universal Turing machine culminates the development of the
symbol. Through it, the symbol gains its ideal form, capable of representing
everything that can be represented. All further symbolic engines constitute
lesser versions of the universal archetype.[^ln1-brain] Yet the archetype
machine itself is also limited to an ideal. It can only exist as a thought
experiment. All real-world Turing machines must contain non-representational
elements, dispelling the illusion of immateriality.

Although much of contemporary popular discourse on computation speaks the
language of disruption, the history of computational symbolism, of the sort I
am suggesting here, must be seen as an evolutionary trajectory.

If a symbol, something used to represent something else, elicits a type of an
illusion, the universal symbolic machine enacts the ultimate illusion. It
creates a phantasmal image of symbolism itself. The history of computing is
thus a history of symbolism in the broadest possible meaning of the word, which
includes lyric poetry and symbolic logic. 
In this chapter I would like to convince the reader to view text, in all its
computationally-mediated forms---files, "print outs, "web pages," electronic
books---as a device.

## 1.1 Literary Device as Gadget and Technique

What is a literary device? The formal concept of a "device," widely used in
literary studies, is an artifact of an unfortunate translation from Russian.
The word *priem* would be much better translated as "technique," in the sense
of "method," "approach," or "procedure." The word "device" contains these
meanings as well, but in modern usage, it usually carries a more concrete
connotation, as "an object, machine, or piece of equipment that has been made
for a special purpose" (Merriam-Webster). "Laying bare the device," for Viktor
Shklovsky, the Russian formalist critic who coined the phrase, meant making
explicit the implied mechanism of the metaphor, particularly in cases where
such metaphors turn "stale," "automatic," and "naturalized," that is, bereft of
their original poetic and evocative power.

One could write, for example, "a field of study," without much thought about
figurative space. Shklovsky would have the reader pause to consider the
implications [@shklovksy_sborniki_1917]. In what sense do ideas resemble (or
not) a field? The poet could further make the metaphor strange. To evoke a
light-hearted illustration one could write: "to scythe a verdant field of
literary study." The verb (to scythe) and the adjective (verdant) create an
unexpected transference of new qualities not present in the original image
(intellectual field). The introduced qualities "break" or "overdetermine" the
metaphor, exposing its conceit. The reader can discover "intellectual fields"
for what they are: habituated metaphors, neither natural nor self-apparent. The
metaphor is made strange again through purposeful defamiliarization. To take
the technique to its logical conclusion, a writer could depict several
fictional characters in the act of scything a field of grass while discussing
the relative merits of structuralism: a discussion about the field on a field.
Such literary artifice would make actual the implied connections between a
fields of grass and fields of ideas. The writer now shows what was merely told
before. The technique of defamiliarization finally renews the figure:
discarding hardened clichÃ©s while suggesting novel linkages between constituent
concepts: intellectual chaff, leaves of mental grass, the combines of thought.

When pursuing estrangement the author "lays bare" and "makes obvious" the
metaphor by drawing attention to its inner dynamics. Metaphors, as Lakoff and
Johnson famously argued, do more than decorate---they structure everyday human
activity. The metaphor shapes one system of conceptual relationships in terms
of another. For example, the military image of "fortification defence" implies
a conceptual system structuring the "defence of an argument"
[@lakoff_metaphors_1980, 3-14]. When defending the argument, a speaker acts in
the way that resembles combat. A different metaphor would suggest a less
combative mode of engagement between interlocutors.

Russian formalists of the early twentieth century did not quite have the
contemporary cognitive vocabulary to connect mind and symbol, but they did
understand estrangement as a matter of everyday practice, beyond linguistic
analysis. One of Shklovsky's central concerns was with the automatization of
human experience, by which metaphors lose their evocative power through
repeated use. Such metaphors become mere machines that convey meaning, and,
when habituated, disappear from view. According to the Kantian view, in vogue
in Russia at the time, a reasoned being should proceed through life with the
assumption of agency, structuring one's own experiences according to the
principles of free will. The habituated metaphor instead structures furtively,
obscuring the relationships involved. Consequently, estrangement emerges as a
model of human liberation. It frees thought from the tyranny of automatism
[@shklovksy_sborniki_1917, @shklovsky_hod_1923, @boym_estrangement_1996,
@holquist_minding_2005]. Laying bare the mechanisms of the implicit metaphor
recovers agency lost to the blind mechanization of thought. Through
estrangement, readers discover the principles governing their actions: free to
accept some parts of the conceptual transference (the intellectual field *is*
"verdant"!) and to reject others (but let us not "use combines" to "harvest"
it). And perhaps the field should not be a field at all: it could be a meadow
or a forest.

Vladimir Nabokov, a writer conspicuously aware of his literary--theoretical
heritage, used defamiliarization in the formalist vein often and with
relentless clinical precision. In the short story "A Guide to Berlin," to which
D. Barton Johnson attributes our first glimpse at Nabokov's "mature virtuoso
style [@johnson_guide_1979, 354]," Nabokov writes:

> In front of the house where I live, a gigantic black pipe lies along the
outer edge of the sidewalk. A couple of feet away, in the same file, lies
another, then a third and a fourth---the street's iron entrails, still idle,
not yet lowered into the ground, deep under the asphalt. For the first few days
after they were unloaded, with a hollow clanging, from trucks, little boys
would run on them, up and down, and crawl on all fours through those round
tunnels, but a week later nobody was playing anymore and thick snow was falling
instead; and now when, cautiously probing the treacherous glaze of the sidewalk
with my thick rubber-heeled stick, I go out in the flat gray light of the
morning, an even stripe of fresh snow stretches along the upper side of each
black pipe [...] Today someone wrote "Otto" with his finger on the strip of
virgin snow, and I thought how beautifully that name, with its two soft o's
flanking the pair of gentle consonants suited the silent layer of snow upon
that pipe with its two orifices and its tacit tunnel [@nabokov_guide_1976, 27].

The tightly wound vignette takes the formalist programmatic concern with
"laying bare the device" to its logical and recursively structured conclusion.
The pipes can be read as a metaphor for the literary device. Usually found
beneath the street, they now sit idle and visible above the surface. Yet even
when exposed, the device fails to captivate for long. Disused, it once again
passes out sight, covered in snow. Concerned with surfaces, the narrator
"probes the glaze" of the street. He finds a palindrome written in snow. The
inscription "OTTO" not only resembles the pipes visually, but is in itself a
surface-revealing inscription that makes the pipes visible again. Although the
metaphoric pipe does not reach beyond the page, the mimetic surface inscription
draws attention to the word's visual shape and acoustics. It invites readers to
perform the symmetry of its assonance and consonance as they pronounce the
word. The round vowels and the interrupting obstruents of "OTTO" contort the
body in accordance with the sound image: reverse mimesis, the body as sound
pipe. The moment of corporeal reenactment transcends representational and
paper-bound confines of the medium. The pipes appear briefly on this side of
the page. The performance makes the "making of the literary technique obvious,"
obvious. In this, lies the prevalent characteristic of Nabokov's mature work,
which often seeks to rise above the word through sheer recursion of literary
technique, where each successive turn of abstraction brings the buried symbol
closer to the reader.

Inspired by the formalists, I would like to extend the technique of
estrangement to books and documents as literal devices. When asked in the
context of media and book history, the question of literary surfaces gains an
instrumental dimension. Habit hides the peculiarity of our everyday interfaces
with the word. We read at the surface. We etch inscriptions deep within the
bowels of a machine. When enacted on the level of the physical device,
estrangement parallels the practice of literary theory and reverse engineering.
Both aim to reveal internals that structure experience, made opaque through
artifice and habituation. I imagine here a kind of critical practice that
reverses the principles of good interface design. What design aims to make easy
and ordinary, defamiliarization makes difficult and strange. Materialist
poetics expose the price paid for literary facility.

For example, we know that physical affordances of liquid crystal displays
(LCDs) and magnetic storage differ drastically from those of goat skins or
parchment. Yet digital surface representation maintains the illusion of
self-similarity. We are faced with what is called *skeuomorphic* design, by
which screen reading resembles print. In this way, an electronic book reader
simulates the bent corner of a well-thumbed book. The skeuomorphic resemblance
itself constitutes a metaphor worthy of critical examination. The principles of
skeuomorphic design extend a visual metaphor from one medium to another. The
reader already knows how to turn pages of a book. A book device therefore
simulates pages to ease the burden of cognitive transition from one medium to
another. Instead of pushing unfamiliar buttons (yet another metaphor) to turn
the page, readers perform the more habituated motion of swiping across the
screen. The gliding motion enacts a kinetic metaphor, transposing properties of
paper to glass.

Readers bear the burden of conceptual transference (like the turning of pages).
In pretending to turn "pages," a reader loses sight of the structures producing
the simulation. Some would object that such structures are irrelevant or not
interesting: one does not need to be a mechanic to drive a car, as the saying
goes. Yet, particularly in the case of literary devices, the concealed
mechanisms concern the structuring of privileged cognitive, as opposed to
other, let us say more pedestrian, facilities. If an automobile extends the
foot, the book extends the brain. It shapes mental activity. The simulated text
ultimately enacts a number of cognitive metaphors. If we are to value anything
like interpretation or critical reason, we must certainly value them at the
physical site of mental extension.

More than superficial embellishment, the skeuomorphic metaphor structures all
meaning-carrying units from letters, to words, paragraphs, chapters, books, and
pages. In our example, we know that there is nothing inherently page-like about
stiff slabs of glass and silicone. The metaphor of "turing the page by swiping
across the screen" conceals the structural rift between media. Why would
readers engage in such a charade? Why not simply make use of novel interfaces
afforded by new technology? The literature from the field of human--computer
interaction suggests a formalist answer: habituation [@carroll_metaphor_1982;
@carroll_interface_1987; @spolsky_user_2001]. The initial effort it takes to
learn to read in a new environment may discourage many potential readers from
adopting a new technology. Smart designers therefore rely on habituated
practice, the turning of pages in our case, to minimize the "friction" of
adoption. Although an "electronic book reader" contains no pages as such, it
extends the metaphor of pages to electronic reading. The usability metaphor
comes at a cost of concealment. A digital poem, a novel, a physician's script,
or a legal contract may resemble their paper counterparts. But the metaphor of
"turing pages" is but one simulation among the device's many possibilities.
When imitating pages, the reading *appliance* also monitors, adjusts, warns,
and controls. In return for usability it simulates and dissembles. The
exposition of the metaphor reminds us of the compromise between two conceptual
systems. It reveals real material affordances behind the symbol.

The simulation conceals structuring principles large and small. Some of the
concealed details may remain inconsequential, like the limit on how many keys
can be pressed at once without overwhelming the circuitry of the keyboard.
Other concealed details are of paramaount importance, like digital rights
management chips and censorship filters. Like the smoke alarm, literary gadgets
are governed and internalize government structures in ways that we have only
begun to comprehend. The material affordances of device--bound textuality
influence all higher-level functions of interpretation.[^ln1-rmedium] Yet,
available theories of interpretation build on properties and assumptions
attached to print media. For example, in Hans-Georg Gadamer's seminal
conception of art, the free play of the artistic mind transforms into material
structure (*Gebilde*) that is both "repeatable" and "permanent"
[@gadamer_truth_1975, 110]. Similarly, in *Interpretation Theory*, Paul Ricoeur
writes about the "range of social and political changes" related to the
invention of writing. For Ricoeur, human discourse is "fixed" and thereby
"preserved from destruction" in writing [@ricur_interpretation_1976, 26-8].

The literary device offers no such permanence, neither in sumulation nor in
diffusion. The very meanings of "fixed," "permanent," and "repeatable" change
with the medium. The engineering of literary artifacts conceals a number of
design choices, obscuring the flows of code and codex under the familiar guise
of surface representation. The digital book does not just simulate a book.
Being a type of a Turing machine, it holds the potential to embody all possible
metaphors.[^ln1-notquite] The task of the literary scholar reading on the level
of the device becomes to make the figure available for interpretation. It is to
apprehend its revealed mechanics.  What happens in the metaphorical
transference between the book and the apparatus simulating the book?
Estrangement, the exegesis of the metaphor, reveals mechanisms of governance
shaping mental experience. Device hermeneutics allow one to consent, or,
conversely, to resist elements of imposed structure.

What sort of a thing is a literary device? It is tempting to think of personal
computers as glorified calculators. That is often the popular image of
computing, one that highlights the machine's ability to calculate. The computer
reduces culture to ones and zeroes (or so goes the story), thereby diminishing
the human experience.[^ln1-pop] There is some truth to that position, but I
would like to argue here that the connection between computing and calculation
is but a piece of a larger story. The personal computer governing the
production of textuality today emerged from an amalgamation of automated
equipment: among them the telegraph, the typewriter, and the calculator. Add to
that list the loom, the music box, the radio, and the film camera
[^ln1-ceruzzi]. Each of these machines left an imprint on our everyday
engagement with computational devices.

It is important to keep the intertwined material lineages of computation in
mind because each brings with it a different set of values and priorities. As
complex computational systems continue to play an ever greater part in our
lives, from affecting family relations to health and nutrition (think social
media and personal activity trackers), we are increasingly faced with a host of
conflicting choices. When building systems that give form to human experience,
should we privilege agency or efficiency, privacy or connectivity, elegance or
complexity? These are not choices that can be left to a calculator. Systems,
left to their own devices, cannot produce values. Rather, values are imposed
from without. The question then becomes one of ends and means. A calculator is
most "efficient" when operating on binary data. Efficiency and complexity are
goods for the task of calculation. Humans prefer to manipulate texts and
images. A democratic vision of a just society places value on open deliberation
and consensus building. Undeniably, computers participate in social
transformation: used to make war and to create art. What are our machines
optimized for? The passive voice points to the root of the problem. A
computational mechanism that extends agency should embody values that
correspond to the agent of the action. In other words, we must be able to
project our values through the machine, and not the other way around. What
seems like a technologically determined inevitability is often simply the
projection of values from without. It is social and political, not
technological determinism.

[^ln1-notquite]: To what extent a personal computer is a Turing machine is
matter of contention. The Turing machine is a *thought experiment* that
imagines a machine. The PC is a machine emulating the thought experiment. See
@putnam_representation_1988, 121-5; @chalmers_does_1996; @petzold_code:_2000. A
more detailed discussion follows in 1.2.

[^ln1-kant]: Or at least proceeding as if one has agency to structure one's own
experience, despite the overwhelming evidence for determinism.

## 1.2 The Nature of the Simulation

To confront the computer as a *literary* device, optimized for symbolic
exchange, one must first understand its peculiar relationship to universal
Turing machines. And to understand the history of the Turing machine, we must
see it in a wider cultural context, beyond the mathematical literature where it
was first discussed. In what follows, I shall draw two as yet unexplored
lineages that lead to Turing's seminal essay on computable numbers: the first
intellectual, stemming back to his tutelage under Ludwig Wittgenstein, and the
second material, highlighting the physical similarities between Turing's design
and a number of concomitant developments in printing and communication. This
history is important because it allows us to see the simulated book in a new
light: not as byproduct of quantification, but as a universal symbol
manipulator, a metaphor machine: a machine for the ingesting and regurgitating
metaphors.

## 1.3 What It Is

More than any other mechanism, the Turing machine defined the very limits of
computation. Yet it is also a source of considerable debate, misunderstanding,
and controversy, because it poses a fundamental paradox. Turing imagined his
machine as a physical mechanism solving a theoretical problem. Actual
computers, in turn, simulate hypothetical Turing machines. You can see how
this may get confusing. Computation emerges as a figure stuck in the loop
between the ideal and the physical worlds. It is part real mechanism and part
unattainable idea; part physics and part metaphysics. The indeterminacy of
computation blurs the boundaries between hardware and software. And no matter
how hard computer science tries to escape into the realm of pure mathematics,
the limits of physical engineering pull it back to the sphere of the
applied.[^ln1-cs]

In his seminal 1937 paper on computable numbers, Alan Turing, then a student at
King's College, proposed a peculiar solution to appear in mathematical journal.
He imagined a mechanism that solves a theoretical problem. What that problem
was (in the field of elementary number theory) is not as important as how he
proposed to solve it. Turing begins suggestively: "we may compare a man in the
process of computing a real number to a machine that is only capable of a
finite number of conditions." [@turing_computable_1937, 231]. In effect, he
asks his readers to compare computation, a human mental process, to the
mechanical action of a machine. As Charles Petzold explained it in his
book-length annotation on Turing's paper, Turing "makes reference to 'states of
mind' that are analogous to machine states" [@petzold_annotated_2008, 67]. But
the analogy itself leads to contention. Neither mathematicians nor cognitive
scientists agree on the extent to which states of mind can be compared to
discrete machine states.

Turing further imagines a machine "supplied with a 'tape' (the analogue of
paper) running through it, and divided into sections (called 'squares') each
capable of bearing a 'symbol'" [@turing_computable_1937, 231]. Much like a
movie reel, the tape moves through the mechanism one section at a time. At each
point only one section bearing one symbol can be said to be "in the machine."
"We may call this square the 'scanned square,'" Turing writes,

> The symbol on the scanned square may be called the "scanned symbol." The
> "scanned symbol" is the only one of which the machine is, so to speak,
> "directly aware" [@turing_computable_1937, 231].

The scanned symbols become a part of the machine's internal configuration. In
Turing's words, "the machine can effectively remember some of the symbols which
it has 'seen' (scanned) previously" [@turing_computable_1937, 231]. The
machine's "behavior" is therefore determined by its initial configuration (in
the arrangement of tape and scanning apparatus) plus the scanned symbol.

We imagine then a device not unlike a telegraph or a film projector, which
ingests reels of tape. But unlike telegraphs or film projectors, the ingested
symbolic representation becomes effectively, by definition, a part of the
machine's internal configuration. Remember that in constructing his
contraption, Turing continually appeals to the model of human cognition. A child
in the process of reading or doing mathematics similarly "ingests" symbols.
These symbols really do become a part of the child's mental apparatus,
affecting a change in brain states on some real and empirically observable
neurological level. Turing's machine is capable of similar internalization.

Where the child converts symbol into brain states, the machine transforms
software (symbol) into hardware (configuration). The machine does not just
scan, it "reads" in the Platonic sense. It internalizes and becomes "aware."
Consider by contrast the action of a film projector. Unlike a Turing machine,
the projector does not internalize film reels. The film reel passes through
without leaving a trace within the mechanism.[^ln1-reading]

In addition to "reading," Turing's machine must be able to write. Turing wrote
that "in some configurations in which the scanned square is blank (*i.e.* bears
no symbol) the machine writes down a new symbol on the scanned square"
[@turing_computable_1937, 231]. The machine can also erase and move symbols to
adjacent squares, one square at a time. Reading, writing, and symbolic
manipulation are thus mechanical actions at the core of Turing's computation.

The configuration state of the machine determines the movement of the "reading"
and "writing" apparatus along the surface of the tape. At its simplest
incarnation, the tape moves along one dimension only: left or right. Thus some
of the scanned symbols are meant to represent computable numbers (the whole
point of Turing's paper). Yet other symbols are meant as machine instructions.
They direct the movement of the reading and writing head. They tell the machine
to "write," "scan," or "erase" symbols. Today, we would call such instructions
"programs" or "control codes." The control codes and the computed data form a
part of the same continuous stream of information.

Just as the Turing machine is able to convert symbolic representation into
internal configuration states, it can conversely enact the opposite movement, by
representing internal configuration states symbolically. This remarkable
property allows for the creation of what Turing calls a class of universal
machines. Specific Turing machines could be configured to preform actions like
addition or multiplication. But the multiplication machine could not, for
example, be reconfigured for another purpose, because the physical movement of
its internals is fixed. In addition to scanning symbols, the universal Turing
machine has the ability to internalize *other machine configurations*. Turing
explains that "it is possible to invent a single machine which can compute any
computable sequence" [@turing_computable_1937, 241]. In being able to
internalize configuration as symbol, the *universal* Turing machine can
simulate all other special-purpose Turing machines.

The transition of symbols into machine states (and the other way around)
defines modern programming. A universal machine, unlike other, definitive,
single-purpose and limited-state mechanisms (a clock for example), contains the
ability to take on differing internal symbolic configurations. It can imitate a
clock, an abacus, a scale, a book. In a later paper linking computing machinery
and intelligence, Turing implies it could eventually simulate human thought as
well [@turing_computing_1950].[^ln1-compete]

The universal Turing machine (UTM) emerges, finally, as a model of computation
itself. It can compute anything computable. In substituting the concept of
computability with "effective computability" Turing's paper belongs to the
annals of mathematical theory. But, it continues to elicit response widely
because much of it contains tantalizing possibilities that bare on symbolic
manipulation more generally. The paper is riddled with metaphors of cognition,
for example. From the beginning we are asked to consider the similarity between
humans and machines in the process of computation. Turing consistently
describes machine states in terms of "states of mind," "awareness," and
"memory." Without confronting the nature of human cognition directly, Turing
hints at the idea of computation as a model for human thought. The literature
on the so-called "computational theory of mind" cites Turing's work extensively
for this reason [@fodor_language_1975; @putnam_representation_1988].

## 1.4 Intellectual Context (intellectual history)

Turing's paper should hold interest for literary scholars because it presents a
minimally viable model for generalized symbolic manipulation: reading and
writing. Although the thought experiment it describes solves a mathematical
problem, the thought experiment itself has its roots in a more general
conversation about the nature of interpretation, central to the questions of
meaning-making in art and culture. The conversations between Alan Turing and
Ludwig Wittgenstein are instructive in this regard. A reconstruction of that
conversation will help us perceive the extent to which Turing's machines were
conceived as a type of intelligent reading and writing simulators.

Wittgenstein first introduces the problem of reading machines in his
*Philosophical Grammar*, written in the period between 1931 and 1933
[@wittgenstein_remarks_1978, 1-33]. Wittgenstein gives the example of a child
who is asked to read, but who instead regurgitates the text from memory.
Intuitively, we feel that this is not "reading" proper. In a similar case,
Wittgenstein asks his readers to imagine an experimental "human reading
machine" (his words, not mine), which like the child in the previous example
can produce sounds upon seeing a text, but these sounds often do not correspond
with the words on the page. Such an automaton cannot read per se, although
occasionally the sounds it produces do coincide with the printed word. Suppose
then that upon seeing such an experiment, a newcomer comments: "This person is
reading." The scientist who has set up the experiment would respond: "No he is
not. It is a mere accident." But what shall we say when such a biological
machine begins to consistently correspond letters to appropriate sounds. Has it
learned to read? And at what point does mere coincidence pass into conscious
action (120-121)? In his characteristically cryptic manner, Wittgenstein defers
the question by the means of yet another analogy. "If A tries to make B believe
that he is able to read Cyrillic script, cheating him by learning a Russian
sentence by heart and then saying it while looking at the printed sentence, we
may certainly say that A knows he is pretending, and that his not reading is
characterized by a particular personal experience" (121).  But suppose the man
really does know how to read Russian, although when he reads he has a peculiar
feeling of knowing the words by heart.  Should we regard his personal
experience as the criterion distinguishing between reading and not reading in
that case? And again, Wittgenstein expects us to answer in the negative.  It
seems then, that the external presentation alone is not sufficient to determine
whether the person is reading or not.  In each case, we had to check for the
appropriate mental state.  Wittgenstein writes, "We here envision two
mechanisms, the internal workings of which we can see, and this internal
working is the real criterion for a person's reading or not reading.  But in
fact no such mechanisms are known to us in these cases" (120).  And it turns
out that the appropriate mental state alone is also insufficient to describe
thought definitively. Here, Wittgenstein asks us to imagine a person under the
influence of drugs who is shown a set of discrete strings composed of
nonsensical characters. When shown the string $%^&* for example, the drugged
patient reads "above," as if the typographical characters were meaningful and
in English.  As far as the patient is concerned, she is reading.  All the
formal attributes of the action are thereâthe proper region of her brain is
receiving stimulation, she follows the text with her eyes from left to right,
silently mouthing the words, and so on.  But this cannot be reading as we know
it: the woman is simply imagining that she is reading (122).  Thus, neither the
internal nor the external  descriptions of the action seem adequate to
encompass everything we mean by reading. And yet we do have a relatively clear
picture of what reading properly entails, what it looks like, what it sounds
like, how to do it, and how to teach others to do it.  In building this chain
of deferring analogies (from the reading child to the drug-induced reading
hallucination) we are acting as though "we had tried to find the real artichoke
by stripping it of its leaves," writes Wittgenstein (125). The moral of the
story is that the leaves, taken together, are the artichoke. The explication of
the word "reading' for Wittgenstein involves describing a set of characteristic
features, some of which may be mutated, deformed, or missing altogether. What
we are dealing with here is a family or a genus of behaviors that fall under a
particular rubric. Our work then, similar to a botanist's, is to describe
rather than to explain such features. "Suppose I wish to produce in someone a
mental image of the inside of a particular eighteenth-century room which he is
prevented from entering," Wittgenstein writes. "I therefore adopt this method:
I show him the house from the outside, pointing out the windows of the room in
question, I further lead him into other rooms of the same period" and so on
(125). No single feature defines the room, it seems. Instead, we observe a
range of facades, a range of decors, a range of configurations. Taken together
these serve as an instrumental categoryârooms of the 18th centuryâthat is
useful in talking about, visiting, preserving, or living in 18th-century rooms.
By analogy, the mind is hermeneutically sealed to outside observers.  The best
we can do is to examine other, similar minds in similar situations. To think,
to read, to write, is to play a particular part in the appropriate cultural and
linguistic contextâa part that we learn as a result of continuing practice and
acculturation. "Could a machine think?" Wittgenstein asks again in the
Philosophical Investigations, "Could it be in pain?" Well, is the human body to
be called such a machine? It surely comes as close as possible to being such a
machine. But a machine surely cannot think!âIs that an empirical statement? No.
We only say it about human beings and about those similar to them, 'they
think.' We also say it of dolls and no doubt of spirits too. Look at the word
'to think' as a tool (2003, 359-360).

Wittgenstein seems here to be offering a pragmatic answer to the question of
machine intelligence: we are more likely to ascribe thought to an
anthropomorphic machine. But that tells us more about human psychology than
machine cognition (or cognition in general). From the onset of the conversation
that question was deferred by a chain of analogies, which took us from thinking
machines, to eloquent amoebas, and to human reading automata. For those
familiar with Wittgenstein's thought, we arrive then at a fairly expected
conclusion: cognitive processes like thinking and reading are defined through
usage, in a descriptive rather than a proscriptive manner. In that sense, we
can already anticipate the pragmatic attitude towards artificial intelligence
of those, who like Alan Turing, have advocated a set of purely functional
litmus tests as criteria for ascertaining intelligence of non-human entities.
On that view, the given activity does not have to correspond to any state or a
definition. It must merely enter the stream of appropriate social practice.
Unexpected however, are several odd and persistent features of Wittgensteinâs
thought on artificial intelligence. The first is a willful blurring of the
boundary between the human and the mechanical. From Philosophical Grammar to
Philosophical Investigations Wittgenstein speaks of the human body as a kind of
a machine, and of machines as a type of a body.3 To what extent do such
statements function as a metaphor or as a provocation is unclear in the context
of our discussion, though the second feature comes into a much sharper relief.
In almost every passage I have examined here Wittgenstein's thought experiments
appeal to our intuitions about specifically discursive (rather than generally
cognitive) actions.  What began as a general discussion concerning the
Cartesian mind-body dualism, unfolded almost entirely through examples that
involve reading and writing automata.  As we shall see later, such a slide from
the cognitive to the discursive will come to define the conversation about
machine intelligence. This strain of thought in the literature on the
(artificial) mind takes thinking machines to be primarily machines that read
and write, with the hope that what holds true for reading and writing will also
hold true for thinking in general. But, nothing has been said so far about the
connection between thinking, reading, and writing. That elision has passed on
from Wittgenstein to his students, in a line of reasoning that is particularly
prevalent in Alan Turing's foundational work on artificial intelligence (the
subject of the next section).  Turing attended Wittgenstein's Lectures on the
Foundations of Mathematics at Cambridge University in 1939
[@wittgenstein_wittgensteins_1976, 7]. From the notes complied and published by
Cora Diamond, it is clear that Turing was a vociferous presence in the class.
His name is mentioned 86 times in the text, more than any other student by a
wide margin. At some point of the course Wittgenstein concludes his lecture in
saying: "Unfortunately, Turing will be away from the next lecture, and
therefore that lecture will have to be somewhat parenthetical. For it is not
good my getting the rest to agree to something that Turing would not agree to"
[@wittgenstein_wittgensteins_1976, 67-68].

The lectures touch upon the subject of "logical machinery" obliquely.
Wittgenstein believes the term itself to be misleading. He writes:

> The idea of logical machinery would suppose that there was something behind
> our symbols. Thus, there are certain cogwheels behind the dial of a clock
> which produce the following movement [...] Similarly, one might think that
> there is a machinery behind the symbols---that behind '(x). Æx' and 'Æa' is a
> machinery which explains why one must follow from the other. A Chinese man
> who just sees the symbols wouldn't see this machinery.[^ln1-chinese] But we
> who see the machinery see that if there is (x). Æx, there must must be Æa
> [@wittgenstein_wittgensteins_1976, 194].

In the period of 1942--44, Wittgenstein's oblique references to a mechanistic
theory of the mind gain a more concrete shape. "Does a calculating machine
calculate?" he asks in his *Remarks on the Foundations of Mathematics*
[@wittgenstein_remarks_1978, 257]. The question of discursive reading machines
of the earlier period, becomes here a question of mathematics.  And in a
similar fashion to his earlier examples, Wittgenstein imagines a human
calculating machine that could be trained to follow the rules of inference
blindly, and which is able to "nod its head after every correctly drawn
conclusion" and to "shake its head at a mistake and stopped calculating."
Outside of this capacity this creature would otherwise be a perfect imbecile,
writes Wittgenstein (258). The possibility of such automata hints not only at
the mechanization of mathematics (only an enigmatic fragment of the sentence
here from Wittgenstein on 372), but also at mechanization of thought in
general.  But could such an automaton be calculating (and by extension,
thinking)? What if it feels like it is, but is not (420)?  Conversely, what if
we ourselves calculate properly, and yet feel like so many automatons, under
spell of an unknown deity (422)? This line of questioning was certainly already
familiar to those students of Wittgenstein who attended his earlier lectures at
Cambridge, and who undoubtedly have participated in his reading-related thought
experiments.  Wittgenstein's reading and calculating machines were meant to
challenge the very notions of reading and calculating.  But, in his seminal
1936 essay On Computable Numbers,2 

Turing returned to the problem of machine and human intelligence explicitly
(Turing 1950). Here, Turing proposes to reformulate Wittgenstein's original
question (Can machines think?) into what he calls the "imitation game." The
format would surely please his former professor: three peopleâa man, a woman,
and an interrogator of either sexâwould communicate by teletype. The object of
the game for the interrogator is to determine the gender of the individual
behind the screen.  The object of the game for the other two participants is to
fool the interrogator. And here is the twist: the part of one of the
participants (not the interrogator) would be played by a machine.  The question
"Can a machine think?" becomes then, "Will the interrogator decide wrongly as
often when the game is played like this as he does when the game is played
between a man and a woman?" (Turing 1950, 433).  The striking transposition of
the cognitive activity (thinking) into its functional discursive equivalent
(misrepresenting one's identity in writing) echoes Wittgenstein's playful
thought experiments.  The machine that thinks is a machine that tells
tall-tales. On this view, a convincing imitation of thought is thought. We
would simply not be able to prove otherwise, without peeking behind the
teletype screen to see who or what is doing the typing. In that sense, Turing
returns to Wittgenstein's refusal to locate the mark of the cognitive within
any given organ or activity. Thought is simply that which looks (sounds, reads)
like thoughtâit is a game that we play, and a game that could conceivably be
played by other entities, mechanical or otherwise. For our purposes, it is
interesting to note that Turing's chatbot does not simply compute or calculate.
It is a literary machine. It does not just imitate human logic or speech.
Instead, it imitates (performs!) fibbing.  It is able to imagine a fictional
story about an alternative identity, and ultimately to convince its reader of
the story's veracity. In this shift from the cognitive to the discursive,
Turing follows the trajectory of Wittgenstein's thought experimentation.
Moreover, the game is tinged with distinctly sexual overtones, and in the
context of an interrogation. It is a game in which winning means transgressing
either one's gender or one's species, all the while maintaining a straight
face. The proposed language game is not simply conversational, it is
suspenseful and subversive, having the force of a mystery, a detective novel,
or a legal drama.6 At one point of the essay Turing answers what he calls "the
argument from consciousness," quoting one Professor Jefferson in saying that it
is not "until a machine can write a sonnet or compose a concerto because of
thoughts and emotions felt, and not by the chance fall of symbols, could we
agree that machine equals brainâthat is, not only write it but know that it had
written it. No mechanism could feel (and not merely artificially signal, an
easy contrivance) pleasure at its successes, grieve when its valves fuse, be
warmed by flattery, be made miserable by its mistakes, be charmed by sex, be
angry or depressed when it cannot get what it wants" (446). In response Turing
scripts the following conversation: Interrogator: In the first line of your
sonnet which reads 'Shall I compare thee to 	a summer's day' would not 'a
spring day' do as well or better?  Witness: It would not scan.  Interrogator:
How about 'a winter's day.' That would scan all right.  Witness: Yes, but
nobody want to be compared to a winter's day.  Interrogator: Would you say Mr.
Pickwick reminded you of Christmas?  Witness: In a way.  Interrogator: Yet
Christmas is a winter's day, and I do not think Mr. Pickwick would mind the
comparison.  Witness: I don't think you're serious. By a winter's day one means
a typical winter's day, rather than a special one like Christmas. (447)

Imitation game == mimesis, simulation.

[^ln1-chinese]: This line is a likely source for John Searle's famouse "Chinese
Room" experiment [@searle_minds_1980].

## 1.5 Content and Control (material history)

All Turing machines, however imperfect, occupy that ambiguous space between
theory and practice. The personal computer, the hand-held "mobile" telephone,
and the electronic book "reader" share in the legacy of Turing's computation.
They are ideas and devices.[^ln1-caveat]

The ambiguity between hardware and software leads to some controversy in the
critical literature, as evidenced by Lev Manovich's playful response to
Kittler's "there is no software" argument. If I understand it correctly,
Kittler's short but often cited essay picks up the thread of Kittler's earlier
work to posit what he calls a "postmodern writing scene." "We do not write
anymore," writes Kittler: "human-made writing passes through microscopically
written inscriptions which, in contrast to all historical writing tools, are
able to read and write by themselves" [@kittler_there_1995]. According to this
schema, Kittler sees the paper-bound design blueprints of the first integrated
microprocessor as the last "real" piece of writing. Everything written after
that point is hardware (because software is hardware at that "microscopic"
level).

Manovich inverts Kittler's argument into "there is only software," by which he
means that in a pragmatic sense, the affordances of a given medium are
determined by software. A printed page begins to differ from a screen only when
the readers are able to effect something on the screen that they could not on
paper. To this end, Manovich encourages his readers to become active developers
of software, rather than its passive consumers [@manovich_there_2011, 274]. In
that, Manovich reasserts the possibility of writing in the silicon age. Kittler
(who passed in 2011) could perhaps object to that line of reasoning in
maintaining that chip architecture (the last written work) still determines (as
foundation) all higher levels of textuality "floating" above the silicon
bedrock. And no amount of learning to code would give an ordinary subject the
resources required to write in silicon---a process so advanced and expensive as
to be limited to a handful of international chip manufacturers. In opening a
successive nested series of black boxes, the post-silicon writer hits the
impenetrable bedrock of chip architecture. In such conditions, is it even
worthwhile to follow Manovich's call for new literacies? Is writing still
possible?

The question of where do brains end and minds begin remains unresolved in
cognitive science, for example. Similarly, at some imperceptible point software
disappears into hardware. But before we ourselves get lost in that liminal
space between matter and idea, let us recover a measure of oddity found in the
now ubiquitous operation of Turing machines. First, note that Turing's original
formulation happens at the level of a thought experiment. (Turing does not
begin to build actual machines until his move to Princeton in 1936.) A
universal Turing machine comes to life initially as an idea that can take on
the structure of other ideas expressed symbolically. Second, note that though
Turing describes his machine in the language of mathematics (where his most
significant contribution lies), his description also contains the bare minimum
of a mechanical device. No matter how symbolic a Turing machine aspires to be,
no matter how ascendant to the realm of the ideal, it still needs a bare
minimum of physical matter to function. And Turing's paper does contain the
canonical description of that bare physical minimum.

With the above two observations in mind, we can view abstracted universal
Turing machines, as implemented in the Wireworld universe (a cellular automaton
simulation), for example, or in Minecraft (a procedurally generated sand-box
world-exploration game), as recursive, second-order ideational constructs,
built on top of first-order physical mechanisms (a personal computer, in the
case of Wireworld and Minecraft). We know this, because all *n+* order Turing
machines are limited in computational power by the physical capabilities of
that bottom-most device (the physical machine writing the simulation). The
simulated UTM cannot outperform (in terms of cycles per second, instructions
per cycle, or its capacity to hold a number of instructions) the machine doing
the simulation. If we disregard the dizzying levels of recursion (a Turing
machine, simulating a Turing machine, simulating a Turing machine and so on),
we can begin to examine the turtle at the bottom, which has its head in the
symbolic and its feet firmly in the material world.

Literature in computer science tends to see universal Turing machines as
algorithms: in other words, as virtual, second-order symbolic representations.
As consummate thinkers on the level of the symbol, computer scientists and
literary scholars (unlike, say, electrical engineers or book binders) rarely
need to pay heed to that strange bottom-most turtle.[^ln1-bottom] Yet it is
impossible to entirely disassociate the implementation from the idea. In his
review of Turing's "On Computable Numbers" paper, Alonzo Church, the American
mathematician whose work anticipated Turing's (independently) in several
important aspects, wrote that "a human calculator, provided with pencil and
paper and explicit instructions can be regarded as a kind of a Turing machine"
[@church_computable_1937, 42-3; also cited in @petzold_annotated_2008, 63].
Disregarding the broader, metaphysical implications of that statement, note for
now the persistence of two essential implements required for the minimally
viable operation of the Church--Turing human and machine calculators. Pen and
paper persevere and assert themselves through the
abstraction.[^ln1-abstraction]

Forced to confront the universal Turing machine *as a mechanism*, the
historian must acknowledge that it borrows from a number of extant designs,
which, together and incrementally, give the UTM its physical form. A media
history of the Turing machine as device differs from its intellectual history
as symbolic, mathematical abstraction in interesting and instructive
ways.[^ln1-turing]

![Universal Turing machine as an idea. "Nick Gardner's Wireworld multiplier,
via a Turing machine."](images/turing-idea.png)

[^ln1-caveat]: The institutional distinctions between software engineering and
computer science often hinge on the extent to which the discipline pays heed to
the physical limitations of computing. As usual the situation on the ground is
much more complicated, and the boundaries between software engineering and
computer science are fast eroding. Still, North American students often have
the choice to major in Computer Science or Software Engineering. It would not
be unusual for the one faculty to be located in the School for Liberal Arts and
Science and the other in the School of Engineering. Consider also the two major
professional organizations: Institute for Electrical and Electronics Engineers
(IEEE) and Association for Computing Machinery (ACM). See
@glass_comparative_1992; @parnas_software_1999; @glass_analysis_2004;
@vessey_unified_2005.

Bracketing for the moment the mathematical and cognitive implications of
Turing's work, I want to approach the Turing machine from the perspective of a
book historian and a media scholar. If the Turing machine is to be taken at
face value, not as an algorithm, but as an instrument, what kind of a machine
would it be? What are its antecedents?

Most of the minimal physical requirements to build a universal Turing machine
were within reach in the 1930s, at the time Turing authored his influential
paper. In practice, his proposal would require first, an apparatus capable of
"scanning" and "erasing" a "finite number of symbols." Second, we would need
what Turing calls "one-dimensional paper," divided into discrete squares "like
a child's arithmetic book" [@turing_computable_1937, 249].[^ln1-infinite]
Furthermore, we would need some sort of mechanism to advance tape through the
machine, or, alternatively, to propel the scanning mechanism along the length
of the tape. Having assembled these elements, our creation would look roughly
like a cross between a telegraph, a film projector, and a
typewriter.[^ln1-davey]

Were we to patent the Turing machine at the time of its theoretical inception
(1936-37) in the United States, the above elements would find prior art in
mechanisms such as the "Numeral adding or subtracting attachment for
type-writing machines" [@daugherty_numeral_1894], "Combined Type-writing and
Computing Machine" [@degener_combined_1911], "Computing Attachment for
Typewriters" [@wright_computing_1914], "Computing Mechanism"
[@wright_computing_1915], and "Combined Type-writing and Adding Machine"
[@ellis_combined_1914] among others. All of these machines contain some
combination of a reading and writing "head," storage tape, and movement
mechanism.

By the end of the nineteenth century a number of lesser contraptions anticipate
the functional elements of Turing's machine. And by 1936, when Turing publishes
his paper on computable numbers, these inventions not only anticipate the
modern computer, but are brought to mass market in the widespread manufacture
of computing scales, dial recorders, electric tabulating machines, and
computing typewriters made by companies like Underwood Computing Machine,
Electromatic, and International Business Machines (IBM). Rather than a single
eureka moment, the invention of the universal machine should be viewed as a
gradual historical process that culminates in Turing's universal (and minimally
viable) specifications.

A number of inventions at the end of the nineteenth century pertain
specifically to "circuit-controlling devices controlled by a traveling
perforated strip or tape" [@cuttriss_telegraphy_1893]. Prior to perforated
tape, the transmission of messages by telegraph required the presence of a
skilled operator, able to transcribe messages from text to Morse code, and into
the physical motion of a lever-operated circuit. In the operation of early
telegraphy, the human operator acted as a mute interpreter between text and
telegraph. The transcription of text into signal, and back onto paper, required
the real-time presence of human encoders and decoders.

The perforated tape decoupled the human from the machine. In US1187035 (1916)
on "Telegraphy", Albert and Ralph Bumstead explain: "the object of our
invention is to provide a system of telegraphy which does not require skilled
operators for the transmission and reception of messages"
[@bumstead_telegraphy_1916]. Instead, the message was transcribed into
perforation via mechanical means and then fed into the mechanism. The tape
mechanics of the typewriter could then be coupled with the electrics of the
telegraph, with perforated tape acting as a mediator between the two "worlds"
of mechanics and electricity.

A number of contraptions emerged at the time with the aim of transforming the
mechanical action of the typewriter into perforation, and, consequently,
perforation into script, completing the circuit between automated "encoding"
and "decoding." As one machine converted human input into mechanical states,
and into signal, another machine converted signals into mechanical states and
thereon into human-legible messages.

What began as a trickle at the end of the nineteenth century ended in a flood
at the beginning of the twentieth. A multitude of inventions capitalized on the
control capabilities of removable storage media. These included machines for
tape-controlled telegraphic transmission [@wheatstone_improvement_1874;
@murray_tape-controlled_1905; @bumstead_telegraphy_1916], tape-controlled
printing [@creed_printing_1911], printing telegraphs
[@hallden_printing-telegraph_1929], and remote broadcast programming devices
for radio and television content [@vriendt_program_1934; @brown_automatic_1936;
@brown_selective_1936]. With the invention of punch cards and perforated tape
(also used in textile looms, as early as 1725), a message meant for another
human became also a physical medium---bumps and holes---used to animate the
mechanical movement of the transmission apparatus.

For example, of the 33 asserted claims in the Bumstead brothers' "Telegraphy"
patent, the first 13 relate to the "transmission of intelligence,"

> [...] adapted to initiate a succession of electrical impulses all of which
> have a character representing significance, a receiver adapted to detect
> variations in time intervals elapsing between successive impulses, a
> plurality of interpreting relays selectively actuated by said receiver, and a
> printed mechanism responsive for the combined action
> [@bumstead_telegraphy_1916, 12-13].

What begins as a description of a mechanism for information transmittal, ends
with a claim about hermeneutics of control. Starting with clause 14, the
brothers begin to describe "a telegraph system" that capable of "transmitting
impulses" at varying time intervals. In the language of the patent, the length
of the time interval "represents significance," involving an automated receiver
responsible for "distributing, interpreting, and recording." The printing
mechanism is further "arranged to print the interpretation of the signals which
is made by the interpreting relays" [@bumstead_telegraphy_1916, 6]. The
interpreting relays transform time intervals into a "typographical form"
representing "a letter, a figure, or other characters," "in accordance with a
code" [@bumstead_telegraphy_1916, 13]. Initially, the telegraph prints to
"transmit intelligence." But the authors also understand that the varying time
intervals could also signify other information, meant to actuate a variety of
devices.

By the middle of their patent, they begin to describe their telegraph as a
general "controlling medium," which can power everything from typesetting
machines to more general "sunflower switches." "Indeed the detector and the
interpreting relay could be made to actuate a set of sunflower switches for an
indicator without including a printer at all," the authors conclude
[@bumstead_telegraphy_1916, 12]. For the automated telegraph, control code and
the message are one. The mechanism interprets some signals as figure and
character and other signals as control code affecting the internal mechanical
configuration of the device. The first type of code holds "significance" for
humans, where the second for the mechanism itself. It is "transmitting
intelligence" in a sense of externalizing machine states and "interpreting" in
the sense of mechanical reconfiguration of internal parts.

Along with dozens of similar inventions patented around the turn of the
twentieth century, Bumstead brothers describe a mechanism that functions as a
Turing machine with little modification. The automated telegraph, driven by
ticker tape, and connected to a printer contain all the necessary requirements
set out by Turing: a discrete symbolic language, the removable storage medium,
and a device that can alter its internal states based on the reading and
writing of scanned symbols. Like the Turing machine, the Bumstead telegraph is
capable of recursion. Ultimately, it can produce and interpret its own control
codes.

By 1905, Donald Murray, the inventor of the popular Murray telegraph, could
write that "if we disregard the small class of telegrams that merely express
emotions, *the essence of telegraphy is control* [emphasis mine]." He went on
to write that "telegraph systems, therefore, belong not to the class of
producing or distributing, but to the class of controlling mechanisms"
[@murray_setting_1905, 556].

[^ln1-pop]: See for example  @drucker_digital_2001; @golumbia_cultural_2009;
@marche_literature_2012.

[^ln1-ceruzzi]: See @ceruzzi_computing_2012, 11 who writes that "the modern
computer is a convergence of separate streams of information handling, each
with its own rich tradition of technological history." "One could add other
antecedents such as the development of radio, motion pictures, and photography"
[@ceruzzi_computing_2012, 11].

[^ln1-compete]: "We may hope that machines will eventually compete with men in
all purely intellectual fields" [@turing_computing_1950, 460].

[^ln1-infinite]: A true universal Turing machine would require a tape that is
infinitely long.

[^ln1-davey]: Mike Davey built and displayed a similar instrument at Harvard
Universitiy's Collection of Historical Scientific Instruments in 2012. He
writes, "my goal in building this project was to create a machine that embodied
the classic look and feel of the machine presented in Turingâs paper.  I wanted
to build a machine that would be immediately recognizable as a Turing machine
to someone familiar with Turing's work" [@davey_turing_2012].

[^ln1-reading]:The Turing machine in effect gives us a concise minimally viable
definition of "reading" and "becoming aware." Proper reading involves the
appropriate internalization of the symbol, for both human and machine.

[^ln1-cs]: Two separate departments offersing competing degrees in software
engineering and computer science is a common occurance in North American
universities.

## 1.6 Splitting the Sign

That history begins with the human capacity to externalize images. It proceeds
with the invention of writing: a formal constraint on the image, adding a level
of non-mimetic abstraction. A picture of the horse that looks like a horse can
now be represented in five characters that can further be recombined to form
other images. The constraint on the number of symbolic "building blocks"
proceeds with the diffusion of movable type in China and Europe, circa 1040
(China) and 1450 (Germany) [@mcluhan_gutenberg_1962; @he_diffusion_1994;
@needham_shorter_1994, 1-34; @febvre_coming_2010].

With the invention of movable type and the typewriter, the variability of
hand-written script was further normalized to a set of discrete and
reproducible characters.[^ln1-normal] A key stipulation for the Turing machine
requires that "the number of symbols which can be printed is finite"
[@turing_computable_1937, 249]. The mechanization of print begins to "lift" the
letter from its medium, enabling the development of distant writing
(telegraphy) and remote communications, which, although extant in many early
societies (as smoke and mirror signals, for example) accelerates dramatically
at the beginning of the nineteenth century [@shaffner_telegraph_1859;
@beauchamp_history_2001; @standage_victorian_2014]. When combined with the
mechanization of type, telegraphy amplifies the range and the speed of
geographical displacement enabled by the circulation of printed matter. I do
not pause much for these developments because they are well described in the
literature.

Finally, the rise of universal Turing machines in the late nineteenth and early
twentieth centuries definitely severs the symbol from its material contexts.
Textuality splits into simulated surface representation and underlying control
code. Computation changes the nature of print from an intelligence-conveying
medium to one of communication and control. "Content" intended for humans is
now routinely mixed with "control codes" intended to alter the operation of the
receiving device. The Turing machine achieves the bifurcation of the sign,
intertwining the histories of telecommunications and code control. A
computational document or a book arises as a subset of control devices: the
essence of distant writing is control.

