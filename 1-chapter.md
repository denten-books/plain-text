---
title: "Plain Text: The Poetics of Human-Computer Interaction (Sample Chapters)"
subtitle: "Chapter 1: Laying Bare the Device"
author: "Dennis Tenen"
style: csl/chicago-note.csl
bibliography: plain-text.bib
toc: true
documentclass: article
cover-image: images/steno.png
header-includes:
- \usepackage{ftnxtra}
- \usepackage{titlesec}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \newcommand{\sectionbreak}{\clearpage}
- \rhead{DRAFT | do not circulate }
- \lhead{}

---

# Chapter 1: Laying Bare the Device

## 1.1 Prelude

"The weakest point in our present day universe is the incapacity of man to meet
the machine, the culture conserve, or the robot, other than through submission,
actual destruction, and social revolution" [@moreno_who_1953, 233]. So wrote
the Austrian-American psychiatrist, Jacob L. Moreno between the years of 1934
and 1953, in his now seldom read classic, *Who Shall Survive?* He is remembered
today as a pioneer of group therapy, an early critic of Freud and socialism.
Sociologists also occasionally mention his work as precursor to network
analysis. His books contain beautiful diagrams, sprouting nodes and edges, with
titles like "Structure of a Cottage Family," "A Handicraft Group," and "The
Civilian Social Atom." Yet Moreno was also a humanist and a philosopher of
technology and culture. In opposition to eugenics, popular at the time, his
answer to "Who Shall Survive?" was "everyone" [@moreno_who_1953, 245].

Humanity, according to Moreno, faced two major threats: first embodied in the
aggression from other human beings, and second, in the aggression of robots or,
what Moreno called alternatively the "cultural conserve" and the "zootechnical
animal" [@moreno_who_1953, 237]. Robots, for Moreno, were more than mechanized
automatons. "Machine rule" encompassed all devices, social structures, and
products of the mind that diminished creativity. He wrote: "these methods have
always amounted simply to this---to neglect and abandon the genuine and
outstanding creative process [...] to extinguish all the active, living
moments, and to strive towards one unchangeable goal: the illusion of the
finished, perfected product whose assumed perfectibility was an excuse [...]
for forsaking its past, for preferring one partial phenomenon to the whole
reality" [@moreno_who_1953, 233]. The "illusion of the perfected product"
reduces humans to "machine-addicts," residing in a "jungle of robots" that
threatens to crowd out all spotanious activity. Through robots, life becomes a
script.

In the name of comfort, safety, and prolonged life, technologists and
population planners disempower the very subjects whose lives they claim to
preserve. The zootechnical animal substitutes human ability to set goals for
the promised certainty of a better future. "The eugenic dreamer and the
technological dreamer have one idea in common," Moreno wrote, "to substitute
and hasten the slow process of nature:"

> Once the creative process is encapsulated in a book it is *given*; it can be
recapitulated eternally by everybody without the effort of creating anew.  Once
a machine for a certain pattern of performance is invented a certain produce
can be turned out in infinite numbers practically without effort [...] Once
that miraculous eugenic formula will be found a human society will be given
prefect and smooth at birth, like a book of a press [@moreno_who_1953, 236].

Like Socrates from Plato's *Phaedrus*, Moreno distrusts the rote mechanization
of thought itself. All forms of externalized algorithmic rule fall under
suspicion: from central planning, to corporate governance, to machine code, and
legal codex. All such mechanisms serve to externalize and to "conserve"
volition, at a given point of time. With time, such volition governs without
consensus or comprehension. Such shards of externalized volition, embodied in
laws, books, and institutions, proliferate and multiply. Moreno writes:

> Once off the press, the parent, the producer, the author
is immaterial; the book goes to all places and to all people, it does not care
where it is read and by whom. Many robots have further in common the attribute
of comparative immortality. A book, a film, an atomic bomb, they do not perish
in the human sense, the same capacity is always there, they can be reproduced
*ad infinitum* [...] Our human world is increasingly filled with robots and
there seems to be no end to new forms and new developments [@moreno_who_1953,
239].

In the aftermath of World War II, Moreno expanded the first edition of his book
to include the ultimate automaton, the atomic bomb. "Mankind has been awakened
form a dream," he writes. The atomic bomb gives humanity a glimpse of its
common enemy. Technology, for Moreno, does not determine the present situation.
Rather, a mindless actor in possession of fossilized volition, it competes, in
Darwinian sense, with living actors. Once set in motion, voluntarily, by
humans, the war machine and the book alike, as all cultural conserves, continue
to do their bidding. These structures may no longer be needed or wanted, but
because they are inorganic, they persist to shape the social and the mental
worlds to come. Moreno explains:

> Many of the domesticated robots are blessed with the attribute of become
labor-saving devices, which has, however the unpleasant consequence that they
at time reduce the need for creating, promoting with leisure also inertia.
[...] Many of the robots have also the attribute in common of being able to
affect human beings or other "targets at a distance," a book, a radio or a
television sender can entertain or teach at a distance, like a gun, a rocket
and an atomic bomb can kill people and destroy at a distance. The book is a
robot par excellence [@moreno_who_1953, 238].

The inertia of past decisions embodied in extant mechanisms ultimately poses a
threat for human survival. For Moreno, the real competition for survival
happens not between persons, sects, races, or nations, but between humanity and
its zombie-like automatons from the past. The only way to compete with the
robot was for him to expand the human cultural capacity for creation. The
biological being has only this one advantage over the zootechnical animal:
spontaneity. But the capacity to free will and to creation has to be
continuously guarded against lethargy and advanced through training. The
machines of yore ease the burden of creation. In reducing labor, they enfeeble
the creative capacity. Moreno's therapy practice was therefoe built on the
principle of spontaneity training, aimed at the construction of communities
that acknowledge and preserve individual agency. As far as I can tell from the
records, the practice involved group improvisation, in what Moreno called the
"techniques of freedom," which aimed to "balance spontaneous social forces to
the greatest possible harmony an unity of all" [@moreno_who_1953, 8].

I leave Moreno here, with thoughts of hydrogen bombs and books, considered as
part of the same mechanized plane. The book does make for an excellent robot.
If a conversation is a temporary communicative link between two people, a book
is a device for delayed conversation. It affects targets at a distance,
decoupling readers and writers in time and space. We are habituated to see the
book as a simple thing made of ink, cloth, and paper. It never was so. In this
chapter, my aim is to convince the reader to encounter the book anew as a
complex system. The device-like property of computed text especially, when
compared to print, holds severe consequences for the practices of reading,
writing, and interpretation.

Where in the 1930s one could view Moreno book--bomb as a fanciful, technophobic
even, view of literary technology, a century later his concern seems pressing
and prescient. The unintended consequences of disembodied and automated agency,
from artificially intelligent personal assistants to market trading algorithms,
are beginning to worry prominent scientists, businessmen, and media theorists.
What looks like a book really is also a gun and a trigger. I mean this
literally: it comprises a part of the same computational platform that powers
drones and aircraft carriers. Today, the "servers" that serve the world's
largest purveyors of literature service also air traffic control and the
National Security Administration.

In these conditions we---humanists, historians, philologists---must reconsider
the easy relationship we enjoyed with pen and paper, the material conditions of
textuality. The siumlated book no longer plays by the same rules as print. The
bibliographic illusion veils device internals. The universal Turing machine,
from which all computational devices inherit, reveals itself ultimately as a
species of control mechanisms. Yet the Turing machine, and subsequently all
computers, belong also, in part, to the long history of the book. To preserve
agency and to break the inertia of leisurely reading, we must rediscover the
book as a device; to call it forth for what it is and always was---a robot for
effecting thought at a distance; and to bring it back under the purview of
interpretation.

I offer two pre-histories in this chapter, one that uncovers the universal
machine as an idea closely related to books and reading, and another that sees
it as sharing in the lineage of control devices.

## 1.2 Literary Device as Gadget and Technique

What is a literary device? The formal concept of a "device," widely used in
literary studies, is an artifact of an unfortunate translation from Russian.
The word *priem* would be much better translated as "technique," in the sense
of "method," "approach," or "procedure." The word "device" contains these
meanings as well, but in modern usage, it usually carries a more concrete
connotation, as "an object, machine, or piece of equipment that has been made
for a special purpose" (Merriam-Webster). "Laying bare the device," for Viktor
Shklovsky, the Russian formalist critic who coined the phrase, meant making
explicit the implied mechanism of the metaphor, particularly in cases where
such metaphors turn "stale," "automatic," and "naturalized," that is, bereft of
their original poetic and evocative power.

One could write, for example, "a field of study," without much thought about
figurative space. Shklovsky would have the reader pause to consider the
implications [@shklovksy_sborniki_1917]. In what sense do ideas resemble (or
not) a field? The poet could further make the metaphor strange. To evoke a
light-hearted illustration one could write: "to scythe a verdant field of
literary study." The verb (to scythe) and the adjective (verdant) create an
unexpected transference of new qualities not present in the original image
(intellectual field). The introduced qualities "break" or "overdetermine" the
metaphor, exposing its conceit. The reader can discover "intellectual fields"
for what they are: habituated metaphors, neither natural nor self-apparent. The
metaphor is made strange again through purposeful defamiliarization. To take
the technique to its logical conclusion, a writer could depict several
fictional characters in the act of scything a field of grass while discussing
the relative merits of structuralism: a discussion about the field on a field.
Such literary artifice would make actual the implied connections between a
fields of grass and fields of ideas. The writer now shows what was merely told
before. The technique of defamiliarization finally renews the figure:
discarding hardened clichÃ©s while suggesting novel linkages between constituent
concepts: intellectual chaff, leaves of mental grass, the combines of thought.

When pursuing estrangement the author "lays bare" and "makes obvious" the
metaphor by drawing attention to its inner dynamics. Metaphors, as Lakoff and
Johnson famously argued, do more than decorate---they structure everyday human
activity. The metaphor shapes one system of conceptual relationships in terms
of another. For example, the military image of "fortification defence" implies
a conceptual system structuring the "defence of an argument"
[@lakoff_metaphors_1980, 3-14]. When defending the argument, a speaker acts in
the way that resembles combat. A different metaphor would suggest a less
combative mode of engagement between interlocutors.

Russian formalists of the early twentieth century did not quite have the
contemporary cognitive vocabulary to connect mind and symbol, but they did
understand estrangement as a matter of everyday practice, beyond linguistic
analysis. One of Shklovsky's central concerns was with the automatization of
human experience, by which metaphors lose their evocative power through
repeated use. Such metaphors become mere machines that convey meaning, and,
when habituated, disappear from view. According to the Kantian view, in vogue
in Russia at the time, a reasoned being should proceed through life with the
assumption of agency, structuring one's own experiences according to the
principles of free will. The habituated metaphor instead structures furtively,
obscuring the relationships involved. Consequently, estrangement emerges as a
model of human liberation. It frees thought from the tyranny of automatism
[@shklovksy_sborniki_1917, @shklovsky_hod_1923, @boym_estrangement_1996,
@holquist_minding_2005]. Laying bare the mechanisms of the implicit metaphor
recovers agency lost to the blind mechanization of thought. Through
estrangement, readers discover the principles governing their actions: free to
accept some parts of the conceptual transference (the intellectual field *is*
"verdant"!) and to reject others (but let us not "use combines" to "harvest"
it). And perhaps the field should not be a field at all: it could be a meadow
or a forest.

Vladimir Nabokov, a writer conspicuously aware of his literary--theoretical
heritage, used defamiliarization in the formalist vein often and with
relentless clinical precision. In the short story "A Guide to Berlin," to which
D. Barton Johnson attributes our first glimpse at Nabokov's "mature virtuoso
style [@johnson_guide_1979, 354]," Nabokov writes:

> In front of the house where I live, a gigantic black pipe lies along the
outer edge of the sidewalk. A couple of feet away, in the same file, lies
another, then a third and a fourth---the street's iron entrails, still idle,
not yet lowered into the ground, deep under the asphalt. For the first few days
after they were unloaded, with a hollow clanging, from trucks, little boys
would run on them, up and down, and crawl on all fours through those round
tunnels, but a week later nobody was playing anymore and thick snow was falling
instead; and now when, cautiously probing the treacherous glaze of the sidewalk
with my thick rubber-heeled stick, I go out in the flat gray light of the
morning, an even stripe of fresh snow stretches along the upper side of each
black pipe [...] Today someone wrote "Otto" with his finger on the strip of
virgin snow, and I thought how beautifully that name, with its two soft o's
flanking the pair of gentle consonants suited the silent layer of snow upon
that pipe with its two orifices and its tacit tunnel [@nabokov_guide_1976, 27].

The tightly wound vignette takes the formalist programmatic concern with
"laying bare the device" to its logical and recursively structured conclusion.
The pipes can be read as a metaphor for the literary device. Usually found
beneath the street, they now sit idle and visible above the surface. Yet even
when exposed, the device fails to captivate for long. Disused, it once again
passes out sight, covered in snow. Concerned with surfaces, the narrator
"probes the glaze" of the street. He finds a palindrome written in snow. The
inscription "OTTO" not only resembles the pipes visually, but is in itself a
surface-revealing inscription that makes the pipes visible again. Although the
metaphoric pipe does not reach beyond the page, the mimetic surface inscription
draws attention to the word's visual shape and acoustics. It invites readers to
perform the symmetry of its assonance and consonance as they pronounce the
word. The round vowels and the interrupting obstruents of "OTTO" contort the
body in accordance with the sound image: reverse mimesis, the body as sound
pipe. The moment of corporeal reenactment transcends representational and
paper-bound confines of the medium. The pipes appear briefly on this side of
the page. The performance makes the "making of the literary technique obvious,"
obvious. In this, lies the prevalent characteristic of Nabokov's mature work,
which often seeks to rise above the word through sheer recursion of literary
technique, where each successive turn of abstraction brings the buried symbol
closer to the reader.

Inspired by the formalists, I would like to extend the technique of
estrangement to books and documents as literal devices. When asked in the
context of media and book history, the question of literary surfaces gains an
instrumental dimension. Habit hides the peculiarity of our everyday interfaces
with the word. We read at the surface. We etch inscriptions deep within the
bowels of a machine. When enacted on the level of the physical device,
estrangement parallels the practice of literary theory and reverse engineering.
Both aim to reveal internals that structure experience, made opaque through
artifice and habituation. I imagine here a kind of critical practice that
reverses the principles of good interface design. What design aims to make easy
and ordinary, defamiliarization makes difficult and strange. Materialist
poetics expose the price paid for literary facility.

For example, we know that physical affordances of liquid crystal displays
(LCDs) and magnetic storage differ drastically from those of goat skins or
parchment. Yet digital surface representation maintains the illusion of
self-similarity. We are faced with what is called *skeuomorphic* design, by
which screen reading resembles print. In this way, an electronic book reader
simulates the bent corner of a well-thumbed book. The skeuomorphic resemblance
itself constitutes a metaphor worthy of critical examination. The principles of
skeuomorphic design extend a visual metaphor from one medium to another. The
reader already knows how to turn pages of a book. A book device therefore
simulates pages to ease the burden of cognitive transition from one medium to
another. Instead of pushing unfamiliar buttons (yet another metaphor) to turn
the page, readers perform the more habituated motion of swiping across the
screen. The gliding motion enacts a kinetic metaphor, transposing properties of
paper to glass.

Readers bear the burden of conceptual transference (like the turning of pages).
In pretending to turn "pages," a reader loses sight of the structures producing
the simulation. Some would object that such structures are irrelevant or not
interesting: "one does not need to be a mechanic to drive a car," as the saying
goes. Yet, particularly in the case of literary devices, the concealed
mechanisms concern the structuring of privileged cognitive, as opposed to
other, let us say more pedestrian, facilities. If an automobile extends the
foot, the book extends the brain. It shapes mental activity. The simulated text
ultimately enacts a number of cognitive metaphors. If we are to value anything
like interpretation or critical reason, we must certainly value them at the
physical site of mental extension.

More than superficial embellishment, the skeuomorphic metaphor structures all
meaning-carrying units from letters, to words, paragraphs, chapters, books, and
pages. In our example, we know that there is nothing inherently page-like about
stiff slabs of glass and silicone. The metaphor of "turing the page by swiping
across the screen" conceals the structural rift between media. Why would
readers engage in such a charade? Why not simply make use of novel interfaces
afforded by new technology? The literature from the field of human--computer
interaction suggests a formalist answer: habituation [@carroll_metaphor_1982;
@carroll_interface_1987; @spolsky_user_2001]. The initial effort it takes to
learn to read in a new environment may discourage many potential readers from
adopting a new technology. Smart designers therefore rely on habituated
practice, the turning of pages in our case, to minimize the "friction" of
adoption. Although an "electronic book reader" contains no pages as such, it
extends the metaphor of pages to electronic reading. The usability metaphor
comes at a cost of concealment. A digital poem, a novel, a physician's script,
or a legal contract may resemble their paper counterparts. But the metaphor of
"turing pages" is but one simulation among the device's many possibilities.
When imitating pages, the reading *appliance* also monitors, adjusts, warns,
and controls. In return for usability it simulates and dissembles. The
exposition of the metaphor reminds us of the compromise between two conceptual
systems. It reveals real material affordances behind the symbol.

The simulation conceals structuring principles large and small. Some of the
concealed details may remain inconsequential, like the limit on how many keys
can be pressed at once without overwhelming the circuitry of the keyboard.
Other concealed details are of paramount importance, like digital rights
management chips and censorship filters. Like the smoke alarm, literary gadgets
are governed and internalize government structures in ways that we have only
begun to comprehend. The material affordances of device--bound textuality
influence all higher-level functions of interpretation.[^ln1-rmedium] Yet,
available theories of interpretation build on properties and assumptions
attached to print media. For example, in Hans-Georg Gadamer's seminal
conception of art, the free play of the artistic mind transforms into material
structure (*Gebilde*) that is both "repeatable" and "permanent"
[@gadamer_truth_1975, 110]. Similarly, in *Interpretation Theory*, Paul Ricoeur
writes about the "range of social and political changes" related to the
invention of writing. For Ricoeur, human discourse is "fixed" and thereby
"preserved from destruction" in writing [@ricur_interpretation_1976, 26-8].

The literary device offers no such permanence, neither in simulation nor in
diffusion. The very meanings of "fixed," "permanent," and "repeatable" change
with the medium. The engineering of literary artifacts conceals a number of
design choices, obscuring the flows of code and codex under the familiar guise
of surface representation. The digital book does not just simulate a book.
Being a type of a Turing machine, it holds the potential to embody all possible
metaphors.[^ln1-notquite] The task of the literary scholar reading on the level
of the device becomes to make the figure available for interpretation. It is to
apprehend its revealed mechanics.  What happens in the metaphorical
transference between the book and the apparatus simulating the book?
Estrangement, the exegesis of the metaphor, reveals mechanisms of governance
shaping mental experience. Device hermeneutics allow one to consent, or,
conversely, to resist elements of imposed structure.

What sort of a thing is a literary device? It is tempting to think of personal
computers as glorified calculators. That is often the popular image of
computing, one that highlights the machine's ability to calculate. The computer
reduces culture to ones and zeroes (or so goes the story), thereby diminishing
the human experience.[^ln1-pop] There is some truth to that position, but I
would like to argue here that the connection between computing and calculation
is but a piece of a larger story. The personal computer governing the
production of textuality today emerged from an amalgamation of automated
equipment: among them the telegraph, the typewriter, and the calculator. Add to
that list the loom, the music box, the radio, and the film camera
[^ln1-ceruzzi]. Each of these machines left an imprint on our everyday
engagement with computational devices.

It is important to keep the intertwined material lineages of computation in
mind because each brings with it a different set of values and priorities. As
complex computational systems continue to play an ever greater part in our
lives, from affecting family relations to health and nutrition (think social
media and personal activity trackers), we are increasingly faced with a host of
conflicting choices. When building systems that give form to human experience,
should we privilege agency or efficiency, privacy or connectivity, elegance or
complexity? These are not choices that can be left to a calculator. Systems,
left to their own devices, cannot produce values. Rather, values are imposed
from without. The question then becomes one of ends and means. A calculator is
most "efficient" when operating on binary data. Efficiency and complexity are
goods for the task of calculation. Humans prefer to manipulate texts and
images. A democratic vision of a just society places value on open deliberation
and consensus building. Undeniably, computers participate in social
transformation: used to make war and to create art. What are our machines
optimized for? The passive voice points to the root of the problem. A
computational mechanism that extends agency should embody values that
correspond to the agent of the action. In other words, we must be able to
project our values through the machine, and not the other way around. What
seems like a technologically determined inevitability is often simply the
projection of values from without. It is social and political, not
technological determinism.

[^ln1-notquite]: To what extent a personal computer is a Turing machine is
matter of contention. The Turing machine is a *thought experiment* that
imagines a machine. The PC is a machine emulating the thought experiment. See
@putnam_representation_1988, 121-5; @chalmers_does_1996; @petzold_code:_2000. A
more detailed discussion follows in 1.2.

[^ln1-kant]: Or at least proceeding as if one has agency to structure one's own
experience, despite the overwhelming evidence for determinism.

## 1.3 The Nature of the Simulation

To confront the computer as a *literary* device, optimized for symbolic
exchange, one must first understand its peculiar relationship to universal
Turing machines. And to understand the history of the Turing machine, we must
see it in a wider cultural context, beyond the mathematical literature where it
was first discussed. In what follows, I shall draw two as yet unexplored
lineages that lead to Turing's seminal essay on computable numbers: the first
intellectual, stemming back to his tutelage under Ludwig Wittgenstein, and the
second material, highlighting the physical similarities between Turing's design
and a number of concomitant developments in printing and communication. This
history is important because it allows us to see the simulated book in a new
light: not as byproduct of quantification, but as a metaphor machine,
capable of universal symbol manipulation.

More than any other mechanism, the Turing machine defined the very limits of
computation. Yet it is also a source of considerable debate, misunderstanding,
and controversy, because it poses a fundamental paradox. Turing imagined his
machine as a physical mechanism solving a theoretical problem. Actual
computers, in turn, simulate hypothetical Turing machines. You can see how
this may get confusing. Computation emerges as a figure stuck in the loop
between the ideal and the physical worlds. It is part real mechanism and part
unattainable idea; part physics and part metaphysics. The indeterminacy of
computation blurs the boundaries between hardware and software. And no matter
how hard computer science tries to escape into the realm of pure mathematics,
the limits of physical engineering pull it back to the sphere of the
applied.[^ln1-cs]

In his seminal 1937 paper on computable numbers, Alan Turing, then a student at
King's College, proposed a peculiar solution to appear in mathematical journal.
He imagined a mechanism that solves a theoretical problem. What that problem
was (in the field of elementary number theory) is not as important as how he
proposed to solve it. Turing begins suggestively: "we may compare a man in the
process of computing a real number to a machine that is only capable of a
finite number of conditions." [@turing_computable_1937, 231]. In effect, he
asks his readers to compare computation, a human mental process, to the
mechanical action of a machine. As Charles Petzold explained it in his
book-length annotation on Turing's paper, Turing "makes reference to 'states of
mind' that are analogous to machine states" [@petzold_annotated_2008, 67]. But
the analogy itself leads to contention. Neither mathematicians nor cognitive
scientists agree on the extent to which states of mind can be compared to
discrete machine states.

Turing further imagines a machine "supplied with a 'tape' (the analogue of
paper) running through it, and divided into sections (called 'squares') each
capable of bearing a 'symbol'" [@turing_computable_1937, 231]. Much like a
movie reel, the tape moves through the mechanism one section at a time. At each
point only one section bearing one symbol can be said to be "in the machine."
"We may call this square the 'scanned square,'" Turing writes,

> The symbol on the scanned square may be called the "scanned symbol." The
> "scanned symbol" is the only one of which the machine is, so to speak,
> "directly aware" [@turing_computable_1937, 231].

The scanned symbols become a part of the machine's internal configuration. In
Turing's words, "the machine can effectively remember some of the symbols which
it has 'seen' (scanned) previously" [@turing_computable_1937, 231]. The
machine's "behavior" is therefore determined by its initial configuration (in
the arrangement of tape and scanning apparatus) plus the scanned symbol.

We imagine then a device not unlike a telegraph or a film projector, which
ingests reels of tape. But unlike telegraphs or film projectors, the ingested
symbolic representation becomes effectively, by definition, a part of the
machine's internal configuration. Remember that in constructing his
contraption, Turing continually appeals to the model of human cognition. A child
in the process of reading or doing mathematics similarly "ingests" symbols.
These symbols really do become a part of the child's mental apparatus,
affecting a change in brain states on some real and empirically observable
neurological level. Turing's machine is capable of similar internalization.

Where the child converts symbol into brain states, the machine transforms
software (symbol) into hardware (configuration). The machine does not just
scan, it "reads" in the Platonic sense. It internalizes and becomes "aware."
Consider by contrast the action of a film projector. Unlike a Turing machine,
the projector does not internalize film reels. The film reel passes through
without leaving a trace within the mechanism.[^ln1-reading]

In addition to "reading," Turing's machine must be able to write. Turing wrote
that "in some configurations in which the scanned square is blank (*i.e.* bears
no symbol) the machine writes down a new symbol on the scanned square"
[@turing_computable_1937, 231]. The machine can also erase and move symbols to
adjacent squares, one square at a time. Reading, writing, and symbolic
manipulation are thus mechanical actions at the core of Turing's computation.

The configuration state of the machine determines the movement of the "reading"
and "writing" apparatus along the surface of the tape. At its simplest
incarnation, the tape moves along one dimension only: left or right. Thus some
of the scanned symbols are meant to represent computable numbers (the whole
point of Turing's paper). Yet other symbols are meant as machine instructions.
They direct the movement of the reading and writing head. They tell the machine
to "write," "scan," or "erase" symbols. Today, we would call such instructions
"programs" or "control codes." The control codes and the computed data form a
part of the same continuous stream of information.

Just as the Turing machine is able to convert symbolic representation into
internal configuration states, it can conversely enact the opposite movement, by
representing internal configuration states symbolically. This remarkable
property allows for the creation of what Turing calls a class of universal
machines. Specific Turing machines could be configured to preform actions like
addition or multiplication. But the multiplication machine could not, for
example, be reconfigured for another purpose, because the physical movement of
its internals is fixed. In addition to scanning symbols, the universal Turing
machine has the ability to internalize *other machine configurations*. Turing
explains that "it is possible to invent a single machine which can compute any
computable sequence" [@turing_computable_1937, 241]. In being able to
internalize configuration as symbol, the *universal* Turing machine can
simulate all other special-purpose Turing machines.

The transition of symbols into machine states (and the other way around)
defines modern programming. A universal machine, unlike other, definitive,
single-purpose and limited-state mechanisms (a clock for example), contains the
ability to take on differing internal symbolic configurations. It can imitate a
clock, an abacus, a scale, a book. In a later paper linking computing machinery
and intelligence, Turing implies it could eventually simulate human thought as
well [@turing_computing_1950].[^ln1-compete]

The universal Turing machine (UTM) emerges, finally, as a model of computation
itself. It can compute anything computable. In substituting the concept of
computability with "effective computability" Turing's paper belongs to the
annals of mathematical theory. But, it continues to elicit response widely
because much of it contains tantalizing possibilities that bare on symbolic
manipulation more generally. The paper is riddled with metaphors of cognition,
for example. From the beginning we are asked to consider the similarity between
humans and machines in the process of computation. Turing consistently
describes machine states in terms of "states of mind," "awareness," and
"memory." Without confronting the nature of human cognition directly, Turing
hints at the idea of computation as a model for human thought. The literature
on the so-called "computational theory of mind" cites Turing's work extensively
for this reason [@fodor_language_1975; @putnam_representation_1988].

## 1.4 Intellectual Context

Turing's paper should hold interest for literary scholars because it presents a
minimally viable model for generalized symbolic manipulation: reading and
writing. Although the thought experiment it describes solves a mathematical
problem, the thought experiment itself has roots in a more general conversation
about the nature of interpretation, central to the questions of meaning-making
in art and culture. The conversations between Alan Turing and Ludwig
Wittgenstein are instructive in this regard. Wittgenstein broached the problem
of reading machines first in *The Blue and Brown Books* along with
*Philosophical Grammar* (all compiled in the early 1930s), then in his lectures
and remarks on the foundations of psychology and mathematics from the late
1930s, and finally in *Philosophical Investigations*, (written between 1945 and
1949). To give you a sense of the timeline: Alan Turing's paper on computable
numbers appeared in print in 1936 and his "Computing Machinery and
Intelligence" in 1950. A historical reconstruction of that conversation, across
both writers' notes and publications, will help us perceive the extent to which
Turing's machines were conceived as a type of intelligent reading and writing
simulators.[^ln1-notes]

### *The Blue and Brown Notebooks*

The *Blue and Brown Notebooks* comprise "some notes to my pupils, so that they
may have something to carry home with them, in their hands if not their brains"
[@wittgenstein_blue_1965, vii]. "The Blue Book" begins with a question of
interpretation: "What is a meaning of a word?" From the start, Wittgenstein
cautions his students against choosing the easy answer, which holds that
meaning resides in the head. Wittgenstein writes:

> It is misleading then to talk of thinking as of a "mental activity". We may
> say that thinking is essentially the activity of operating with signs. This
> activity is performed by the hand, when we think by writing; by the mouth and
> larynx, when we think by speaking; and if we think by imaging signs or
> pictures, I can give you no agent that thinks. If then you say that in such
> cases the mind thinks, I would only draw your attention to the fact that you
> are using metaphor, that here the mind is the agent in a different sense from
> that in which the hand can be said to be the agent in writing.

The "locality of thought" poses a problem of analogy. Wittgenstein explains
that when we see a sentence on paper, the external manifestation of a thought,
we assume that some analogous structure exists somewhere in the brain. Perhaps,
Wittgenstein speculates, we could even observe the brain directly, in the
process of writing. Both phenomena, brain- and paper- bound, could properly be
called the *expression* of thought. Yet neither can offer the definitive
location where thinking happens. Rather, Wittgenstein suggests, we are
witnessing a metaphor: some set of correlations between two distinct
activities. And it may be that the correlations themselves are what we mean by
"thought." Neither brain nor paper make sense as *the* site of cognition in
isolation, just like it would not make sense to interrupt a metaphor---"memory
the warder of the ~brain~ (from *Macbeth)---and then look for it in the
remaining snippet.

Our difficulty in locating the definitive site of thought points to the
inadequacy of Cartesian dualism between body and mind. Neither physical nor
mental descriptions of thought are sufficient to locate the site of cognition,
Wittgenstein argues. As an example of such a difficulty and likely having a
passage from Descartes in mind[^ln1-descartes] Wittgenstein asks, "Can a
machine think" [@wittgenstein_blue_1965, 16]? The problem, as he explains, is
not one of finding a machine that can do the job---of manipulating signs, for
example. It lies in the ability of a machine to enact the both sides of the
metaphor. The manipulation of signs must correspond to something else. Severed
from some other analogical structure the "blind" manipulation of signs is a
meaningless actvity. Meaning, Wittgenstein seems to suggest, resides simply in
this analogy between something (symbol) and something else (mechanism).

Wittgenstein extends his thought experiments about reading machines in his
*Brown Notebook.* Let us study the word "reading," he suggests. By reading, he
means the activity of "translating script into sounds," "of writing according
to dictation," or "of copying in writing a page of print"
[@wittgenstein_blue_1965, 119]. Reading once again is "mechanical" reading,
without a sense of "understanding" or interpretation. What happens when an
average child reads a newspaper, for example? "His eyes glide along the printed
words, he pronounces them aloud or to himself, but other words he pronounces
after having seen their first few letters only, other again he reads out letter
by letter." The child acts as a "reading machine" when he pays no attention to
what he reads, even when he speaks the words out loud. Yet he reads
"faultlessly like a reliable machine." Another child merely pretends to read.
He guesses at the words, and on occasion repeats things "by heart", without
actually seeing them on the page [@wittgenstein_blue_1965, 121-22].

Wittgenstein continues to complicate such edge cases, challenging his
audience's intuitions of what it means to read and to understand. He gives also
the example of the hallucinating patient, who "reads" what to us looks like
gibberish, and the case of man who fakes reading Cyrillic by memorizing the
lines phonetically. He talks of machines too, which produce random sounds that
occasionally, by accident, correspond to some existing texts. In each case, we
envision two mechanisms, one visible and external and one hidden and internal.
To read, it seems that the reader must do more than act out the action of
reading. Instead, we privelege some notion of inward-facing signs of
comprehension as the "real criterion for a person's reading or not reading."
But in fact no such internal, private mechanisms can be known to us or
communicated to others properly [@wittgenstein_blue_1965, 120]. Once again, we
only intuit some "correct" correspondence between internal states and external
signs. A reading pupil must convince his teacher that the words had the
intended effect. But, paradoxically, that state cannot be communicated but
through more words.

In the conclusion to his notebooks, Wittgenstein ultimately describes the
mechanisms of reading as an "indirect way of transmitting a feeling."
"Something that we can never know happens at the other end" of the
communication act. Communication, as we would say today, is always mediated.
In conclusion, Wittgenstein imagines the possibility of unmediated, "direct"
modes communication, capable of transmitting feelings from one person to
another [@wittgenstein_blue_1965, 185].

Thought experiments in *The Blue and Brown Notebooks* do not amount to a
cohesive theory of communication, semiotics, or the mind. They do however
contain the seeds of the reading and writing machines later imagined by Alan
Turing and subsequently passed into the foundations of computer science. The
notebooks begin and end aslo with the interpretation of text. Wittgentein's
experimental thought machines prefigure the modern computer.

### *Philosophical Grammar*

In *Philosophical Grammar,* written around the same time as the *Blue and Brown
Notebooks*,

"'To understand language'---to take in symbolism as a whole"
[@wittgenstein_philosophical_1974, 5].

"In our study of symbolism, there is no foreground and background; it isn't a
matter of a tangible sign, with an accomponying intangible power of
understanding [@wittgenstein_philosophical_1974, 86].

"But if thinking consists only in writing or speaking, why shuldn't a machine
do it? Could a machine be in pain" [@wittgenstein_philosophical_1974, 17]?
Could it have internal states? "It is a travesty of the truth to say: thinking
is an activity of our mind, as writing is an activity of the
hand" [@wittgenstein_philosophical_1974, 17].

"'Intention seen from outside' is connected with the question whether a machine
can think [@wittgenstein_philosophical_1974, 144]

"The intention seems to interpret, to give final interpretation" 23

"By intention I mean here what uses a sign as a thought. The intention seems to
interpret, to give final interpretation; which is not a further sign or
picture, but something else, the thing that cannot be further interpretated" 145

"Though we speak of thought and its expression, the thought is not a kind of a
condition that the sentence produces as a potion might. And communication by
language is not a process by which I use a drug to produce in others the same
pains I have in myself. 

Parenthetical: "What sort of process might be called "thought transference" or
"thought reading." 107.

Lots of stuff on keyboard and pianola.

### Lectures and Remarks

Alan Turing attended Wittgenstein's Lectures on the Foundations of Mathematics
at Cambridge University in 1939 [@wittgenstein_wittgensteins_1976, 7]. From the
notes complied and published by Cora Diamond, it is clear that Turing was a
vociferous presence in the class. His name is mentioned 86 times in the text,
more than any other student by a wide margin. At some point of the course
Wittgenstein concludes his lecture in saying: "Unfortunately, Turing will be
away from the next lecture, and therefore that lecture will have to be somewhat
parenthetical. For it is not good my getting the rest to agree to something
that Turing would not agree to" [@wittgenstein_wittgensteins_1976, 67-68].

Like in the notebooks beforehand, in his lectures, Wittgenstein is concerned
primarily with symbolic interpretation. "I am going to talk about the
interrelation of mathematical symbols," Wittgenstein begins. We imagine that
logical laws represent some sort of "fixed" mechanisms "behind" the symbols
used to express them.  "I am speaking against the idea of logical machinery,"
Wittgenstein says in lecture XX. "The idea of logical machinery would suppose
that there was something behind our symbols" [@wittgenstein_wittgensteins_1976,
194]. We imagine logic to be a sort of a "rigid mechanism" that can only turn
this way or the other. "Any rule can be imagined to be a description of a
mechanism---even the rule which says a pawn must not be moved in a certain
way," Wittgenstein writes. The parts of the mechanism subsequently exist in a
causal relationship to one another. Pushing this or that lever will *always*
result in such and such movement, because of the way the mechanical parts are
connected. We say that the mechanism is rigid or the law is inexorable, when
the results of an action are absolutely fixed. Wittgenstein calls such a
relationships "super-hardness." Where a judge can be lenient, he explains, the
law is compulsory. What we would now call "an algorithm" compels predictable
execution.

Like the internal mental states in the previous example, the inner workings of
the mechanism seem to be at the core of meaning making in mathematics.
"If I show you the mechanism behind the [watch] dial, you will be able to
predict the movement of the hour hand for any given movement of the minute
hand," Wittgenstein writes. "And you will not be sceptical." Yet even there,
you are making an assumption about a perfectly functioning mechanism. "For
instance, I may drop the clock" Wittgenstein explains, "so that the machinery
is broken, or a lighting may strike it [@wittgenstein_wittgensteins_1976, 195].
The mechanism then is in fact itself "a symbol" for the perfected behaviour of
the sort we needed to describe. Where we tried to find the mechanism behind the
symbol, we found also a symbol behind the mechanism.

In his lectures on mathematics, Wittgenstein never finds a way out of this
recursive conundrum. The foundations of mathematics rely on some such mutually
dependent relationship between the physical and the symbolic worlds. Whether it
is in math or in ordinary language, some magic happens at the coupling of the
matter and sign. The precise point of contact concerns Wittgenstein in all
fields of human activity, from literature to psychology and mathematics.

In all of these fields, Wittgenstein finds an implicit analagy between "symbol"
and "mechanism." A type of metaphor, the analagy itself is atomic. It cannot be
split furthe into something like "sign" and "refferent" or the "signifier" and
the "signified." In his lectures on aesthetics, Wittgenstein describes such a
semiotic relationship as the "concomitance between mechanism and its trace"
[@wittgenstein_lectures_1966, 16]. In giving an account of one's aesthetic
juedgement you ultimately "trace a mechanism" [@wittgenstein_lectures_1966,
13].

### Turing's *Computing Machinery and Intelligence*

Wittgenstein's conversations with Turing about the ways by which physical
states pass into the symbolic ones and the other way around, prefigure the
operation of the universal Turing machine.  The Turing machine occupies exactly
the described ambiguous state between symbol and mechanism.

This line of questioning was certainly already familiar to those students of
Wittgenstein who attended his earlier lectures at Cambridge, and who
undoubtedly have participated in his reading-related thought experiments.
Wittgenstein's reading and calculating machines were meant to challenge the
very notions of reading and calculating.

Turing returned to the problem of machine and human intelligence explicitly
[@turing_computing_1950]. Here, Turing proposes to reformulate Wittgenstein's
original question (Can machines think?) into what he calls the "imitation
game." The format would surely please his former professor: three people---a
man, a woman, and an interrogator of either sex---would communicate by
teletype. The object of the game for the interrogator is to determine the
gender of the individual behind the screen. The object of the game for the
other two participants is to fool the interrogator. And here is the twist: the
part of one of the participants (not the interrogator) would be played by a
machine.

The question "Can a machine think?" becomes then, "Will the interrogator decide
wrongly as often when the game is played like this as he does when the game is
played between a man and a woman?" [@turing_computing_1950, 433]. The striking
transposition of the cognitive activity (thinking) into its functional
discursive equivalent (misrepresenting one's identity in writing) echoes
Wittgenstein's playful thought experiments. The machine that thinks is a
machine that tells tall-tales. On this view, a convincing imitation of thought
is thought. We would simply not be able to prove otherwise, without peeking
behind the teletype screen to see who or what is doing the typing. In that
sense, Turing returns to Wittgenstein's refusal to locate the mark of the
cognitive within any given organ or activity. Thought is simply that which
looks (sounds, reads) like thought---it is a game that we play, and a game that
could conceivably be played by other entities, mechanical or otherwise. For our
purposes, it is interesting to note that Turing's chat-bot does not simply
compute or calculate.  It is a literary machine. It does not just imitate human
logic or speech.  Instead, it imitates (performs!) fibbing. It is able to
imagine a fictional story about an alternative identity, and ultimately to
convince its reader of the story's veracity.

In the shift from the cognitive to the discursive, Turing follows the
trajectory of Wittgenstein's thought experimentation. Moreover, the game is
tinged with distinctly sexual overtones, and in the context of an
interrogation. It is a game in which winning means transgressing either one's
gender or one's species, all the while maintaining a straight face. The
proposed language game is not simply conversational, it is suspenseful and
subversive, having the force of a mystery, a detective novel, or a legal
drama. At one point of the essay Turing answers what he calls "the argument
from consciousness," quoting one Professor Jefferson in saying that it is not
"until a machine can write a sonnet or compose a concerto because of thoughts
and emotions felt, and not by the chance fall of symbols, could we agree that
machine equals brainâthat is, not only write it but know that it had written
it. No mechanism could feel (and not merely artificially signal, an easy
contrivance) pleasure at its successes, grieve when its valves fuse, be warmed
by flattery, be made miserable by its mistakes, be charmed by sex, be angry or
depressed when it cannot get what it wants" [@turing_computing_1950, 446].

In response Turing scripts the following conversation: 

> Interrogator: In the first line of your sonnet which reads 'Shall I compare
thee to a summer's day' would not 'a spring day' do as well or better?

> Witness: It would not scan.

> Interrogator: How about 'a winter's day.' That
would scan all right.

> Witness: Yes, but nobody want to be compared to a
winter's day.

> Interrogator: Would you say Mr.  Pickwick reminded you of Christmas?

> Witness: In a way.

> Interrogator: Yet Christmas is a winter's day, and I do not think
Mr. Pickwick would mind the comparison.

> Witness: I don't think you're serious.
By a winter's day one means a typical winter's day, rather than a special one
like Christmas [@turing_computing_1950, 447].

Add Plato. Reading is proper internalization. Interpretation is the scanned
symbol + state of the machine.

Literature as imitation game == mimesis, simulation.

[^ln1-chinese]: This line is a likely source for John Searle's famous "Chinese
Room" experiment [@searle_minds_1980].

[^ln1-notes]: As always, working with Wittgenstein is complicated by the
inherently ad-hoc nature of his published work. Much of it comes to us in the
form of disjointed second-hand notes and dictations. As if to anticipate this
difficulty, in a letter to Bertrand Russell accompanying the manuscript of *The
Blue and Brown Books*, a collection of notes that form the basis for his
*Philosophical Investigations*, Wittgenstein writes: "I think it's very
difficult to understand [these notes], as so many points are just hinted at.
They are meant only for the people who heard the lectures"
[@wittgenstein_blue_1965, vii].

[^ln1-descartes]: Descartes writes in his 1637 *Discourse on Method*: "If there
were such machines having the organs and the shape of a monkey or some other
animal that lacked reason, we would have no way of recognizing that they were
not entirely of the same nature as these animals; whereas if there were any
such machines that bore a resemblance to our bodies and imitated our action as
far as this is practically feasible, we would always have two very certain
means of recognizing that they were not at all, for that reason, true men."
Also quoted in @dennett_can_2004, 297.

[^ln1-enigma]: See the enigmatic fragment on @wittgenstein_remarks_1978, 372.

## 1.5 Content and Control (Material Context)

exchange---means to recover the physical roots of computation.  When viewed in
the context of book history, the universal Turing machine signifies a
consummation of several broad, long-term trends that begin with the invention
of writing itself.

The God of the Hebrew Bible etched his commandments into stone (Exodus 34:1).
Moses broke the first set of tablets, but the word remained, for a time,
immutable. The material history of literary computing begins with petrified
words that endure forever, and ends with word as an electrical charge:
animated, radiant, fluid, and iridescent [@mcgann_radiant_2001;
@bryant_fluid_2002].

The long history of the word proceeds in stages, from the immutable sign to the
universal implement, capable of reproducing all symbolic representation
dynamically. The universal Turing machine culminates the development of the
symbol. Through it, the symbol gains its ideal form, capable of representing
everything that can be represented. All further symbolic engines constitute
lesser versions of the universal archetype.[^ln1-brain] Yet the archetype
machine itself is also limited to an ideal. It can only exist as a thought
experiment. All real-world Turing machines must contain non-representational
elements, dispelling the illusion of immateriality.

Although much of contemporary popular discourse on computation speaks the
language of disruption, the history of computational symbolism, of the sort I
am suggesting here, must be seen as an evolutionary trajectory.

If a symbol, something used to represent something else, elicits a type of an
illusion, the universal symbolic machine enacts the ultimate illusion. It
creates a phantasmal image of symbolism itself. The history of computing is
thus a history of symbolism in the broadest possible meaning of the word, which
includes lyric poetry and symbolic logic.  In this chapter I would like to
convince the reader to view text, in all its computationally-mediated
forms---files, "print outs, "web pages," electronic books---as a device.
All Turing machines, however imperfect, occupy that ambiguous space between
theory and practice. The personal computer, the hand-held "mobile" telephone,
and the electronic book "reader" share in the legacy of Turing's computation.
They are ideas and devices.[^ln1-caveat]

The ambiguity between hardware and software leads to some controversy in the
critical literature, as evidenced by Lev Manovich's playful response to
Kittler's "there is no software" argument. If I understand it correctly,
Kittler's short but often cited essay picks up the thread of Kittler's earlier
work to posit what he calls a "postmodern writing scene." "We do not write
anymore," writes Kittler: "human-made writing passes through microscopically
written inscriptions which, in contrast to all historical writing tools, are
able to read and write by themselves" [@kittler_there_1995]. According to this
schema, Kittler sees the paper-bound design blueprints of the first integrated
microprocessor as the last "real" piece of writing. Everything written after
that point is hardware (because software is hardware at that "microscopic"
level).

Manovich inverts Kittler's argument into "there is only software," by which he
means that in a pragmatic sense, the affordances of a given medium are
determined by software. A printed page begins to differ from a screen only when
the readers are able to effect something on the screen that they could not on
paper. To this end, Manovich encourages his readers to become active developers
of software, rather than its passive consumers [@manovich_there_2011, 274]. In
that, Manovich reasserts the possibility of writing in the silicon age. Kittler
(who passed in 2011) could perhaps object to that line of reasoning in
maintaining that chip architecture (the last written work) still determines (as
foundation) all higher levels of textuality "floating" above the silicon
bedrock. And no amount of learning to code would give an ordinary subject the
resources required to write in silicon---a process so advanced and expensive as
to be limited to a handful of international chip manufacturers. In opening a
successive nested series of black boxes, the post-silicon writer hits the
impenetrable bedrock of chip architecture. In such conditions, is it even
worthwhile to follow Manovich's call for new literacies? Is writing still
possible?

The question of where do brains end and minds begin remains unresolved in
cognitive science, for example. Similarly, at some imperceptible point software
disappears into hardware. But before we ourselves get lost in that liminal
space between matter and idea, let us recover a measure of oddity found in the
now ubiquitous operation of Turing machines. First, note that Turing's original
formulation happens at the level of a thought experiment. (Turing does not
begin to build actual machines until his move to Princeton in 1936.) A
universal Turing machine comes to life initially as an idea that can take on
the structure of other ideas expressed symbolically. Second, note that though
Turing describes his machine in the language of mathematics (where his most
significant contribution lies), his description also contains the bare minimum
of a mechanical device. No matter how symbolic a Turing machine aspires to be,
no matter how ascendant to the realm of the ideal, it still needs a bare
minimum of physical matter to function. And Turing's paper does contain the
canonical description of that bare physical minimum.

With the above two observations in mind, we can view abstracted universal
Turing machines, as implemented in the Wireworld universe (a cellular automaton
simulation), for example, or in Minecraft (a procedurally generated sand-box
world-exploration game), as recursive, second-order ideational constructs,
built on top of first-order physical mechanisms (a personal computer, in the
case of Wireworld and Minecraft). We know this, because all *n+* order Turing
machines are limited in computational power by the physical capabilities of
that bottom-most device (the physical machine writing the simulation). The
simulated UTM cannot outperform (in terms of cycles per second, instructions
per cycle, or its capacity to hold a number of instructions) the machine doing
the simulation. If we disregard the dizzying levels of recursion (a Turing
machine, simulating a Turing machine, simulating a Turing machine and so on),
we can begin to examine the turtle at the bottom, which has its head in the
symbolic and its feet firmly in the material world.

Literature in computer science tends to see universal Turing machines as
algorithms: in other words, as virtual, second-order symbolic representations.
As consummate thinkers on the level of the symbol, computer scientists and
literary scholars (unlike, say, electrical engineers or book binders) rarely
need to pay heed to that strange bottom-most turtle.[^ln1-bottom] Yet it is
impossible to entirely disassociate the implementation from the idea. In his
review of Turing's "On Computable Numbers" paper, Alonzo Church, the American
mathematician whose work anticipated Turing's (independently) in several
important aspects, wrote that "a human calculator, provided with pencil and
paper and explicit instructions can be regarded as a kind of a Turing machine"
[@church_computable_1937, 42-3; also cited in @petzold_annotated_2008, 63].
Disregarding the broader, metaphysical implications of that statement, note for
now the persistence of two essential implements required for the minimally
viable operation of the Church--Turing human and machine calculators. Pen and
paper persevere and assert themselves through the
abstraction.[^ln1-abstraction]

Forced to confront the universal Turing machine *as a mechanism*, the
historian must acknowledge that it borrows from a number of extant designs,
which, together and incrementally, give the UTM its physical form. A media
history of the Turing machine as device differs from its intellectual history
as symbolic, mathematical abstraction in interesting and instructive
ways.[^ln1-turing]

![Universal Turing machine as an idea. "Nick Gardner's Wireworld multiplier,
via a Turing machine."](images/turing-idea.png)

[^ln1-caveat]: The institutional distinctions between software engineering and
computer science often hinge on the extent to which the discipline pays heed to
the physical limitations of computing. As usual the situation on the ground is
much more complicated, and the boundaries between software engineering and
computer science are fast eroding. Still, North American students often have
the choice to major in Computer Science or Software Engineering. It would not
be unusual for the one faculty to be located in the School for Liberal Arts and
Science and the other in the School of Engineering. Consider also the two major
professional organizations: Institute for Electrical and Electronics Engineers
(IEEE) and Association for Computing Machinery (ACM). See
@glass_comparative_1992; @parnas_software_1999; @glass_analysis_2004;
@vessey_unified_2005.

Bracketing for the moment the mathematical and cognitive implications of
Turing's work, I want to approach the Turing machine from the perspective of a
book historian and a media scholar. If the Turing machine is to be taken at
face value, not as an algorithm, but as an instrument, what kind of a machine
would it be? What are its antecedents?

Most of the minimal physical requirements to build a universal Turing machine
were within reach in the 1930s, at the time Turing authored his influential
paper. In practice, his proposal would require first, an apparatus capable of
"scanning" and "erasing" a "finite number of symbols." Second, we would need
what Turing calls "one-dimensional paper," divided into discrete squares "like
a child's arithmetic book" [@turing_computable_1937, 249].[^ln1-infinite]
Furthermore, we would need some sort of mechanism to advance tape through the
machine, or, alternatively, to propel the scanning mechanism along the length
of the tape. Having assembled these elements, our creation would look roughly
like a cross between a telegraph, a film projector, and a
typewriter.[^ln1-davey]

Were we to patent the Turing machine at the time of its theoretical inception
(1936-37) in the United States, the above elements would find prior art in
mechanisms such as the "Numeral adding or subtracting attachment for
type-writing machines" [@daugherty_numeral_1894], "Combined Type-writing and
Computing Machine" [@degener_combined_1911], "Computing Attachment for
Typewriters" [@wright_computing_1914], "Computing Mechanism"
[@wright_computing_1915], and "Combined Type-writing and Adding Machine"
[@ellis_combined_1914] among others. All of these machines contain some
combination of a reading and writing "head," storage tape, and movement
mechanism.

By the end of the nineteenth century a number of lesser contraptions anticipate
the functional elements of Turing's machine. And by 1936, when Turing publishes
his paper on computable numbers, these inventions not only anticipate the
modern computer, but are brought to mass market in the widespread manufacture
of computing scales, dial recorders, electric tabulating machines, and
computing typewriters made by companies like Underwood Computing Machine,
Electromatic, and International Business Machines (IBM). Rather than a single
eureka moment, the invention of the universal machine should be viewed as a
gradual historical process that culminates in Turing's universal (and minimally
viable) specifications.

A number of inventions at the end of the nineteenth century pertain
specifically to "circuit-controlling devices controlled by a traveling
perforated strip or tape" [@cuttriss_telegraphy_1893]. Prior to perforated
tape, the transmission of messages by telegraph required the presence of a
skilled operator, able to transcribe messages from text to Morse code, and into
the physical motion of a lever-operated circuit. In the operation of early
telegraphy, the human operator acted as a mute interpreter between text and
telegraph. The transcription of text into signal, and back onto paper, required
the real-time presence of human encoders and decoders.

The perforated tape decoupled the human from the machine. In US1187035 (1916)
on "Telegraphy", Albert and Ralph Bumstead explain: "the object of our
invention is to provide a system of telegraphy which does not require skilled
operators for the transmission and reception of messages"
[@bumstead_telegraphy_1916]. Instead, the message was transcribed into
perforation via mechanical means and then fed into the mechanism. The tape
mechanics of the typewriter could then be coupled with the electrics of the
telegraph, with perforated tape acting as a mediator between the two "worlds"
of mechanics and electricity.

A number of contraptions emerged at the time with the aim of transforming the
mechanical action of the typewriter into perforation, and, consequently,
perforation into script, completing the circuit between automated "encoding"
and "decoding." As one machine converted human input into mechanical states,
and into signal, another machine converted signals into mechanical states and
thereon into human-legible messages.

What began as a trickle at the end of the nineteenth century ended in a flood
at the beginning of the twentieth. A multitude of inventions capitalized on the
control capabilities of removable storage media. These included machines for
tape-controlled telegraphic transmission [@wheatstone_improvement_1874;
@murray_tape-controlled_1905; @bumstead_telegraphy_1916], tape-controlled
printing [@creed_printing_1911], printing telegraphs
[@hallden_printing-telegraph_1929], and remote broadcast programming devices
for radio and television content [@vriendt_program_1934; @brown_automatic_1936;
@brown_selective_1936]. With the invention of punch cards and perforated tape
(also used in textile looms, as early as 1725), a message meant for another
human became also a physical medium---bumps and holes---used to animate the
mechanical movement of the transmission apparatus.

For example, of the 33 asserted claims in the Bumstead brothers' "Telegraphy"
patent, the first 13 relate to the "transmission of intelligence,"

> [...] adapted to initiate a succession of electrical impulses all of which
> have a character representing significance, a receiver adapted to detect
> variations in time intervals elapsing between successive impulses, a
> plurality of interpreting relays selectively actuated by said receiver, and a
> printed mechanism responsive for the combined action
> [@bumstead_telegraphy_1916, 12-13].

What begins as a description of a mechanism for information transmittal, ends
with a claim about hermeneutics of control. Starting with clause 14, the
brothers begin to describe "a telegraph system" that capable of "transmitting
impulses" at varying time intervals. In the language of the patent, the length
of the time interval "represents significance," involving an automated receiver
responsible for "distributing, interpreting, and recording." The printing
mechanism is further "arranged to print the interpretation of the signals which
is made by the interpreting relays" [@bumstead_telegraphy_1916, 6]. The
interpreting relays transform time intervals into a "typographical form"
representing "a letter, a figure, or other characters," "in accordance with a
code" [@bumstead_telegraphy_1916, 13]. Initially, the telegraph prints to
"transmit intelligence." But the authors also understand that the varying time
intervals could also signify other information, meant to actuate a variety of
devices.

By the middle of their patent, they begin to describe their telegraph as a
general "controlling medium," which can power everything from typesetting
machines to more general "sunflower switches." "Indeed the detector and the
interpreting relay could be made to actuate a set of sunflower switches for an
indicator without including a printer at all," the authors conclude
[@bumstead_telegraphy_1916, 12]. For the automated telegraph, control code and
the message are one. The mechanism interprets some signals as figure and
character and other signals as control code affecting the internal mechanical
configuration of the device. The first type of code holds "significance" for
humans, where the second for the mechanism itself. It is "transmitting
intelligence" in a sense of externalizing machine states and "interpreting" in
the sense of mechanical reconfiguration of internal parts.

Along with dozens of similar inventions patented around the turn of the
twentieth century, Bumstead brothers describe a mechanism that functions as a
Turing machine with little modification. The automated telegraph, driven by
ticker tape, and connected to a printer contain all the necessary requirements
set out by Turing: a discrete symbolic language, the removable storage medium,
and a device that can alter its internal states based on the reading and
writing of scanned symbols. Like the Turing machine, the Bumstead telegraph is
capable of recursion. Ultimately, it can produce and interpret its own control
codes.

By 1905, Donald Murray, the inventor of the popular Murray telegraph, could
write that "if we disregard the small class of telegrams that merely express
emotions, *the essence of telegraphy is control* [emphasis mine]." He went on
to write that "telegraph systems, therefore, belong not to the class of
producing or distributing, but to the class of controlling mechanisms"
[@murray_setting_1905, 556].

That history begins with the human capacity to externalize images. It proceeds
with the invention of writing: a formal constraint on the image, adding a level
of non-mimetic abstraction. A picture of the horse that looks like a horse can
now be represented in five characters that can further be recombined to form
other images. The constraint on the number of symbolic "building blocks"
proceeds with the diffusion of movable type in China and Europe, circa 1040
(China) and 1450 (Germany) [@mcluhan_gutenberg_1962; @he_diffusion_1994;
@needham_shorter_1994, 1-34; @febvre_coming_2010].

With the invention of movable type and the typewriter, the variability of
hand-written script was further normalized to a set of discrete and
reproducible characters.[^ln1-normal] A key stipulation for the Turing machine
requires that "the number of symbols which can be printed is finite"
[@turing_computable_1937, 249]. The mechanization of print begins to "lift" the
letter from its medium, enabling the development of distant writing
(telegraphy) and remote communications, which, although extant in many early
societies (as smoke and mirror signals, for example) accelerates dramatically
at the beginning of the nineteenth century [@shaffner_telegraph_1859;
@beauchamp_history_2001; @standage_victorian_2014]. When combined with the
mechanization of type, telegraphy amplifies the range and the speed of
geographical displacement enabled by the circulation of printed matter. I do
not pause much for these developments because they are well described in the
literature.

Finally, the rise of universal Turing machines in the late nineteenth and early
twentieth centuries definitely severs the symbol from its material contexts.
Textuality splits into simulated surface representation and underlying control
code. Computation changes the nature of print from an intelligence-conveying
medium to one of communication and control. "Content" intended for humans is
now routinely mixed with "control codes" intended to alter the operation of the
receiving device. The Turing machine achieves the bifurcation of the sign,
intertwining the histories of telecommunications and code control. A
computational document or a book arises as a subset of control devices: the
essence of distant writing is control.

Return to Moreno.

[^ln1-pop]: See for example  @drucker_digital_2001; @golumbia_cultural_2009;
@marche_literature_2012.

[^ln1-ceruzzi]: See @ceruzzi_computing_2012, 11 who writes that "the modern
computer is a convergence of separate streams of information handling, each
with its own rich tradition of technological history." "One could add other
antecedents such as the development of radio, motion pictures, and photography"
[@ceruzzi_computing_2012, 11].

[^ln1-compete]: "We may hope that machines will eventually compete with men in
all purely intellectual fields" [@turing_computing_1950, 460].

[^ln1-infinite]: A true universal Turing machine would require a tape that is
infinitely long.

[^ln1-davey]: Mike Davey built and displayed a similar instrument at Harvard
Universitiy's Collection of Historical Scientific Instruments in 2012. He
writes, "my goal in building this project was to create a machine that embodied
the classic look and feel of the machine presented in Turingâs paper.  I wanted
to build a machine that would be immediately recognizable as a Turing machine
to someone familiar with Turing's work" [@davey_turing_2012].

[^ln1-reading]:The Turing machine in effect gives us a concise minimally viable
definition of "reading" and "becoming aware." Proper reading involves the
appropriate internalization of the symbol, for both human and machine.

[^ln1-cs]: Two separate departments offersing competing degrees in software
engineering and computer science is a common occurance in North American
universities.

