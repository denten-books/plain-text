# Chapter 1: Device

Laying Bare the Device

"The weakest point in our present day universe is the incapacity of man to meet
the machine, the culture conserve, or the robot, other than through submission,
actual destruction, and social revolution" [@moreno_who_1953, 233]. So wrote
the Austrian-American psychiatrist, Jacob L. Moreno between the years of 1934
and 1953, in his idiosyncratic, sprawling, and now seldom read volume, *Who
Shall Survive?* He is remembered today as a pioneer of group therapy and an
early critic of Freud and socialism. Sociologists have also recently
rediscovered his work as precursor to network analysis. His books contain
beautiful diagrams, sprouting nodes and edges, with titles like "Structure of a
Cottage Family," "A Handicraft Group," and "The Civilian Social Atom." Yet
Moreno was also a humanist and a philosopher of technology and culture. In
opposition to eugenics, popular at the time, his answer to "Who Shall Survive?"
was "everyone" [@moreno_who_1953, 245].

Humanity, according to Moreno, faces two major threats: first embodied in the
aggression from other human beings, and second, in the aggression of robots or,
what Moreno called alternatively the "cultural conserve" and the "zootechnical
animal" [@moreno_who_1953, 237]. Robots, for Moreno, were more than mechanized
automatons. "Machine rule" encompasses all devices, social structures, and
products of the mind that diminished creativity. He wrote: "these methods have
always amounted simply to this---to neglect and abandon the genuine and
outstanding creative process [...] to extinguish all the active, living
moments, and to strive towards one unchangeable goal: the illusion of the
finished, perfected product whose assumed perfectibility was an excuse [...]
for forsaking its past, for preferring one partial phenomenon to the whole
reality" [@moreno_who_1953, 233]. The "illusion of the perfected product"
reduces humans to "machine-addicts," residing in a "jungle of robots" that
threatens to suffocate all spontaneous activity. Through robots, life becomes a
script.

In the name of comfort, safety, and prolonged life, technologists and
population planners disempower the very subjects whose lives they claim to
preserve. The zootechnical animal substitutes human ability to set goals for
the promised certainty of a better future. "The eugenic dreamer and the
technological dreamer have one idea in common," Moreno wrote, "to substitute
and hasten the slow process of nature":

> Once the creative process is encapsulated in a book it is *given*; it can be
recapitulated eternally by everybody without the effort of creating anew.  Once
a machine for a certain pattern of performance is invented a certain produce
can be turned out in infinite numbers practically without effort [...] Once
that miraculous eugenic formula will be found a human society will be given
prefect and smooth at birth, like a book of a press [@moreno_who_1953, 236].

Like Socrates from Plato's *Phaedrus*, Moreno distrusted rote mechanization of
thought itself. All forms of externalized algorithmic rule fell under
suspicion: from central planning, to corporate governance, to machine code, and
legal codex. For Moreno, such mechanisms served to externalize and to
"conserve" volition, at a given point of time. With time, mechanized volition
governs without consensus or comprehension. Splintered from its source, it
staggers forth, *golem*-like, through laws, books, and social institutions.
Near immortal, images of the past proliferate and crowd out the present. Moreno
wrote:

> Once off the press, the parent, the producer, the author is immaterial; the
> book goes to all places and to all people, it does not care where it is read
> and by whom. Many robots have further in common the attribute of comparative
> immortality. A book, a film, an atomic bomb, they do not perish in the human
> sense, the same capacity is always there, they can be reproduced *ad
> infinitum* [...] Our human world is increasingly filled with robots and there
> seems to be no end to new forms and new developments [@moreno_who_1953, 239].

In the aftermath of World War II, Moreno expanded the first edition of his book
to consider the ultimate automaton, the atomic bomb. "Mankind has been awakened
from a dream," he wrote. The atomic bomb gives humanity a glimpse of its common
enemy. Technology, for Moreno, does not determine the present situation.
Rather, a mindless actor in possession of fossilized volition, it competes, in
Darwinian sense, with living actors. Once set in motion, voluntarily, by
humans, the war machine and the book alike continue to do their bidding
blindly. Such structures persist to shape the social and the mental worlds to
come. Moreno explained:

> Many of the domesticated robots are blessed with the attribute of becoming
labor-saving devices, which has, however the unpleasant consequence that they
at time reduce the need for creating, promoting with leisure also inertia.
[...] Many of the robots have also the attribute in common of being able to
affect human beings or other "targets at a distance," a book, a radio or a
television sender can entertain or teach at a distance, like a gun, a rocket
and an atomic bomb can kill people and destroy at a distance. The book is a
robot par excellence [@moreno_who_1953, 238].

For Moreno, the inertia of past decisions embodied in extant mechanisms
ultimately posed a threat for human survival. On this view, the real
competition for survival happens not between persons, sects, races, or nations,
but between humanity and its automatons from the past. The only way to compete
with the robot was for him was to expand the human cultural capacity for
creation. The biological being has only this one advantage over the
zootechnical animal: spontaneity. But the capacity for freedom has to be
continuously guarded against lethargy, Moreno argued. The machines of yore ease
the burden of creativity. In reducing labor, they enfeeble the capacity for
poiesis. Moreno's therapy practice was therefore built on the principle of
spontaneity training, aimed at the construction of communities that acknowledge
and preserve individual agency. As far as I can tell from the records, the
practice involved group improvisation and role-play, in what Moreno called the
"techniques of freedom," which aimed to "balance spontaneous social forces to
the greatest possible harmony an unity of all" [@moreno_who_1953, 8].

I leave Moreno's text here, with perplexing thoughts of hydrogen bombs and
books occupying the same plane of analysis. How can a book be compared to a
gun: one an instrument of peace and edification, the other of war and
destruction? When considered in the contemporary context, several features of
Moreno's provocation come into a sharper relief.

I locate first in the symbolic, representational nature of robotics. It is an
odd way to phrase it, but we would reasonably say that a bomb signifies
malicious intent. Following the new critics, it has become unfashionable to
speak of similarly of intention in literary studies. When it comes to books,
the critical intuition is to treat any conjecture about authorial intent as a
fallacy [@wimsatt_verbal_1954]. But when it comes to war, our intuitions are
reversed. To understand an act of aggression is to assign responsibility and to
draw inference about its intentions. Moreno asks us to confront the book once
again as a volitional object. Even if we cannot "read" the author's mind, we
can similarly assign a measure of agency to the author. Failing an account of
causes and effects involved we are left to ascribe volition to inanimate
objects and meaning making to chance. The intentional fallacy frees the critic
to concentrate on the pertinent and readily observable attributes of the text.
But it also obscures agency, imbuing the letter with an anthropomorphic
quality, sliding into active voice, where texts mean and languages "speak
themselves."[^ln1-auto]

The above is not meant to buoy the notion of authorial intent. Rather, Moreno's
jarring parallelism between books and bombs reminds the reader that both
constitute a species of displaced agency, a problem long in the background of
Western liberal thought.[^ln1-consensus] In this light, the contemporary
cultural anxiety about artificial intelligence and robotics comprises a part of
larger problematics related to action delayed in time an space by symbolic
means. The technology of the word decouples readers from writers. Once
decoupled, seemingly autonomous actors---books and robots---clutter the social
sphere, continuing to structure human experience in the absence of the
originating accord. It is again a curious way of putting things, but not
unusual in the larger context of post-Kantian humanism at the turn of the
twentieth century.  In Moreno's words we hear more than an echo of Marx's
fetishism of commodities, by which "definite social relation between men"
assumes "the fantastic form of a relation between things" [@marx_capital_1967,
72]. Moreno arrives at a similar conclusion by another logic. In creating some
of the earliest examples of social network graphs, he finds (and objects to)
the presence of things in the position of social actors.

Moreno helps us see the book in a new light. If it was always, as he writes, a
a robot for enacting action at a distance, it is all the more robotic as a
device that draws electricity. When in the 1930s one could view Moreno
book-bombs as a fanciful---technophobic even---view of literary technology, a
century later his concern appears pressing and prescient. The unintended
consequences of disembodied and automated agency, from artificially intelligent
personal assistants to market trading algorithms, worry scientists,
legislators, and media theorists. What looks like a book today indeed takes on
the functions of gun and trigger. I mean this literally: the simulated text
comprises a part of the same computational platform that powers drones and
aircraft carriers. Today, "servers" that serve the world's largest purveyors of
literature service also air traffic control and covert intelligence
[@soyata_combat:_2012; @logicworks_government_2015].

These conditions compel us---humanists, historians, philologists---to
reconsider the easy relationship we have enjoyed with the material conditions
of textuality since the Gutenberg press. "Simulated text," as I have been
calling it here, and, alternatively, the "computed literary artifact," no
longer plays by the same rules as print. The bibliographic illusion veils
machine internals. The universal Turing machine, from which all computational
devices inherit, will reveal itself ultimately as a form of governance. To make
the particulars of computational governance comprehensible, I will also argue
that the Turing machine, and subsequently all computers, belong to the long
history of the book. They gain meaning for us not as mathematical abstraction,
but as mechanisms of generalized symbolic manipulation: related to pen, paper,
typewriter, and telegraph.

In this chapter, I draw several pre-histories of the literary device, first as
a formal technique, then as an thought experiment, and finally as a control
mechanism. To preserve a sense of human agency and to break the inertia of
leisurely reading, we must rediscover the book as a device; to call it forth
for what it is and always was---a robot for effecting thought at a distance;
and to bring it back under the purview of interpretation. My approach to the
problem of "digital" literature lies the dual movement between making strange
and making familiar. To discover the object again is to strip it of its
ideational content---to dispel the fetish. To understand it is to imbue it with
new meaning and subjectivity. In this chapter, we shall encounter the book anew
as a mechanism and complex system.

[^ln1-auto]: See for example @heidegger_pathmarks_1998, 57: "For the phenomenon
most worthy of thought and questioning remains the mystery of
language---wherein our entire reflection has to gather itself---above all when
it dawns on us that language is not a work of human beings: language speaks."
See also @blanchot_work_1995, 41.

[^ln1-consensus]: The literature on consensual governance, for example, going
back to Hobbes, Locke, and Mill, often touches on the problem of lapsed
consent. Roughly: What makes whatever compacts made by past generations still
valid today?

## 1.1 Technique

What sort of a thing is a literary device? The formal concept of a "device,"
widely used in literary studies, is an artifact of an unfortunate translation
from Russian. The word *priem* would be much better translated as "technique,"
in the sense of "method," "approach," or "procedure." The word "device"
contains these meanings as well, but in modern usage, it usually carries a more
concrete connotation, as "an object, machine, or piece of equipment that has
been made for a special purpose" (Merriam-Webster). "Laying bare the device,"
for Viktor Shklovsky, the Russian formalist critic who coined the phrase, meant
making explicit the implied mechanism of the metaphor, particularly in cases
where such metaphors turn "stale," "automatic," and "naturalized," that is,
bereft of their original poetic and evocative power.

One could write, for example, "a field of study," without much thought about
figurative space. Shklovsky would have the reader pause to consider the
implications [@shklovksy_sborniki_1917]. In what sense do ideas resemble (or
not) a field? The poet could further make the metaphor strange. To evoke a
light-hearted illustration one could write: "to scythe a verdant field of
literary study." The verb (to scythe) and the adjective (verdant) create an
unexpected transference of new qualities not present in the original image
(intellectual field). The introduced qualities "break" or "overdetermine" the
metaphor, exposing its conceit. The reader can discover "intellectual fields"
for what they are: habituated metaphors, neither natural nor self-apparent. The
metaphor is made strange again through purposeful defamiliarization. To take
the technique to its logical conclusion, a writer could depict several
fictional characters in the act of scything a field of grass while discussing
the relative merits of structuralism: a discussion about the field on a field.
Such literary artifice would make actual the implied connections between a
fields of grass and fields of ideas. The writer now shows what was merely told
before. The technique of defamiliarization finally renews the figure:
discarding hardened clichés while suggesting novel linkages between constituent
concepts: intellectual chaff, leaves of mental grass, the combines of thought.

When pursuing estrangement the author "lays bare" and "makes obvious" the
metaphor by drawing attention to its inner dynamics. Metaphors, as Lakoff and
Johnson famously argued, do more than decorate---they structure everyday human
activity. The metaphor shapes one system of conceptual relationships in terms
of another. For example, the military image of "fortification defence" implies
a conceptual system structuring the "defence of an argument"
[@lakoff_metaphors_1980, 3-14]. When defending the argument, a speaker acts in
the way that resembles combat. A different metaphor would suggest a less
combative mode of engagement between interlocutors.

Russian formalists of the early twentieth century did not quite have the
contemporary cognitive vocabulary to connect mind and symbol, but they did
understand estrangement as a matter of everyday practice, beyond linguistic
analysis. Similarly to Moreno, one of Shklovsky's central concerns was with the
automatization of human experience, by which metaphors lose their evocative
power through repeated use. Such metaphors become mere machines that convey
meaning, and, when habituated, disappear from view. According to the Kantian
view, in vogue in Russia at the time, a reasoned being should proceed through
life with the assumption of agency, structuring one's own experiences according
to the principles of free will. The habituated metaphor instead structures
furtively, obscuring the relationships involved. Consequently, estrangement
emerges as a model of human liberation. It frees thought from the tyranny of
automatism [@shklovksy_sborniki_1917, @shklovsky_hod_1923,
@boym_estrangement_1996, @holquist_minding_2005]. Laying bare the mechanisms of
the implicit metaphor recovers agency lost to the blind mechanization of
thought. Through estrangement, readers discover the principles governing their
actions: free to accept some parts of the conceptual transference (the
intellectual field *is* "verdant"!) and to reject others (but let us not "use
combines" to "harvest" it). And perhaps the field should not be a field at all:
it could be a meadow or a forest.

Vladimir Nabokov, a writer conspicuously aware of his literary--theoretical
heritage, used defamiliarization in the formalist vein often and with
relentless clinical precision. In the short story "A Guide to Berlin," to which
D. Barton Johnson attributes our first glimpse at Nabokov's "mature virtuoso
style [@johnson_guide_1979, 354]," Nabokov writes:

> In front of the house where I live, a gigantic black pipe lies along the
outer edge of the sidewalk. A couple of feet away, in the same file, lies
another, then a third and a fourth---the street's iron entrails, still idle,
not yet lowered into the ground, deep under the asphalt. For the first few days
after they were unloaded, with a hollow clanging, from trucks, little boys
would run on them, up and down, and crawl on all fours through those round
tunnels, but a week later nobody was playing anymore and thick snow was falling
instead; and now when, cautiously probing the treacherous glaze of the sidewalk
with my thick rubber-heeled stick, I go out in the flat gray light of the
morning, an even stripe of fresh snow stretches along the upper side of each
black pipe [...] Today someone wrote "Otto" with his finger on the strip of
virgin snow, and I thought how beautifully that name, with its two soft o's
flanking the pair of gentle consonants suited the silent layer of snow upon
that pipe with its two orifices and its tacit tunnel [@nabokov_guide_1976, 27].

The tightly wound vignette takes the formalist programmatic concern with
"laying bare the device" to its logical and recursively structured conclusion.
The pipes can be read as a metaphor for the literary device. Usually found
beneath the street, they now sit idle and visible above the surface. Yet even
when exposed, the device fails to captivate for long. Disused, it once again
passes out sight, covered in snow. Concerned with surfaces, the narrator
"probes the glaze" of the street. He finds a palindrome written in snow. The
inscription "OTTO" not only resembles the pipes visually, but is in itself a
surface-revealing inscription that makes the pipes visible again. Although the
metaphoric pipe does not reach beyond the page, the mimetic surface inscription
draws attention to the word's visual shape and acoustics. It invites readers to
perform the symmetry of its assonance and consonance as they pronounce the
word. The round vowels and the interrupting obstruents of "OTTO" contort the
body in accordance with the sound image: reverse mimesis, the body as sound
pipe. The moment of corporeal reenactment transcends representational and
paper-bound confines of the medium. The pipes appear briefly on this side of
the page. The performance makes the "making of the literary technique obvious,"
obvious. In this, lies the prevalent characteristic of Nabokov's mature work,
which often seeks to rise above the word through sheer recursion of literary
technique, where each successive turn of abstraction brings the buried symbol
closer to the reader.

Inspired by the formalists, I would like to extend the technique of
estrangement to books and documents as literal devices. When asked in the
context of media and book history, the question of literary surfaces gains an
instrumental dimension. Habit hides the peculiarity of our everyday interfaces
with the word. We read at the surface; we etch inscriptions deep within the
bowels of a machine. When enacted on the level of the physical device,
estrangement parallels the practice of literary theory and reverse engineering.
Both aim to reveal internals that structure experience, made opaque through
artifice and habituation. I imagine here a kind of critical practice that
reverses the principles of good interface design. What design aims to make easy
and ordinary, defamiliarization makes difficult and strange. Materialist
poetics expose the price paid for the facility of computed text.

For example, we know that physical affordances of liquid crystal displays
(LCDs) and magnetic storage differ drastically from those of goat skins or
parchment. Yet digital surface representation maintains the illusion of
self-similarity. We are faced with what is called *skeuomorphic* design, by
which screen reading resembles print. In this way, an electronic book reader
simulates the bent corner of a well-thumbed book. The skeuomorphic resemblance
itself constitutes a metaphor worthy of critical examination. The principles of
skeuomorphic design extend a visual metaphor from one medium to another. The
reader already knows how to turn pages of a book. A book device therefore
simulates pages to ease the burden of cognitive transition from one medium to
another. Instead of pushing unfamiliar buttons (yet another analogy) to turn
the page, readers perform the more habituated motion of swiping across the
screen. The gliding motion enacts a kinetic metaphor, transposing properties of
paper to glass.

Readers bear the burden of conceptual transference. In pretending to turn
"pages," a reader loses sight of the structures producing the simulation. Some
would object that such structures are irrelevant or not interesting: "one does
not need to be a mechanic to drive a car," as the saying goes. Yet,
particularly in the case of literary devices, the concealed mechanisms concern
the structuring of privileged cognitive, as opposed to other, let us say more
pedestrian, facilities. If an automobile extends the foot, the book extends the
brain. It shapes mental activity. The simulated text ultimately enacts a number
of cognitive metaphors. If we are to value anything like interpretation or
critical reason, we must certainly value them at the physical site of mental
extension.

More than superficial embellishment, the skeuomorphic metaphor structures all
meaning-carrying units: from letters, to words, paragraphs, chapters, books,
and pages. In our example, we know that there is nothing inherently page-like
about stiff slabs of glass and silicone. The metaphor of "turning the page by
swiping across the screen" conceals the structural rift between media. Why
would readers engage in such a charade? Why not simply make use of novel
interfaces afforded by new technology? The literature from the field of
human--computer interaction suggests a formalist answer: habituation
[@carroll_metaphor_1982; @carroll_interface_1987; @spolsky_user_2001]. The
initial effort it takes to learn to read in a new environment may discourage
many potential readers from adopting a new technology. Smart designers
therefore rely on acculturated practice, the turning of pages in our case, to
minimize the "friction" of adoption. Although an "electronic book reader"
contains no pages as such, it extends the metaphor of pages to electronic
reading.

The usability metaphor comes at a cost of concealment. A digital poem, a novel,
a physician's script, or a legal contract may resemble their paper
counterparts. But the metaphor of "turning pages" is but one simulation among
the device's many possibilities. When imitating pages, the reading *appliance*
also monitors, adjusts, warns, and controls. In return for usability it
simulates and dissembles. The exposition of the metaphor reminds us of the
compromise between two conceptual systems. It reveals real material affordances
behind the symbol.

The simulation conceals structuring principles large and small. Some of the
concealed details may remain inconsequential, like the limit on how many keys
can be pressed at once without overwhelming the circuitry of keyboard when
typing. Other concealed details are of paramount importance, like digital
rights management chips and censorship filters. Like the smoke alarm, literary
gadgets are governed and internalize government structures in ways that we have
only begun to comprehend. The material affordances of device--bound textuality
influence all higher-level functions of interpretation.[^ln1-rmedium] Yet,
available theories of interpretation build on properties and assumptions
attached to print media. For example, in Hans-Georg Gadamer's seminal
conception of art, the free play of the artistic mind transforms into material
structure (*Gebilde*) that is both "repeatable" and "permanent"
[@gadamer_truth_1975, 110]. Similarly, in *Interpretation Theory*, Paul Ricoeur
writes about the "range of social and political changes" related to the
invention of writing. For Ricoeur, human discourse is "fixed" and thereby
"preserved from destruction" in writing [@ricur_interpretation_1976, 26-8].

The literary device offers no such permanence. The very meanings of the words
"fixed," "permanent," and "repeatable" change with the medium. The engineering
of literary artifacts conceals a number of design choices, obscuring the flows
of code and codex under the familiar guise of surface representation. The
digital book does not just simulate a book.  Being a type of a Turing machine,
it holds the potential to embody all possible metaphors.[^ln1-notquite] The
task of the literary scholar reading on the level of the device becomes to make
the figure available for interpretation. It is to apprehend its revealed
mechanics. What happens in the metaphorical transference between the book and
the apparatus simulating the book?  Estrangement, the exegesis of the metaphor,
reveals mechanisms of governance shaping mental experience. Device hermeneutics
allow one to consent, or, conversely, to resist elements of imposed structure.

It is tempting to think of personal computers as glorified calculators. That is
often the popular image of computing, one that highlights the machine's ability
to calculate. The computer reduces culture to ones and zeroes (or so goes the
story), thereby diminishing the human experience.[^ln1-pop] There is some truth
to that position, but I would like to argue here that the connection between
computing and calculation is but a piece of a larger story. The personal
computer governing the production of textuality today emerged from an
amalgamation of automated equipment: among them the telegraph, the typewriter,
and the calculator. Add to that list the loom, the music box, the radio, and
the film camera [^ln1-ceruzzi]. Each of these machines left an imprint on our
everyday engagement with computational devices.

It is important to keep the intertwined material lineages of computation in
mind because each brings with it a different set of values and priorities. As
complex computational systems continue to play an ever greater part in our
lives, from affecting family relations to health and nutrition (think social
media and personal activity trackers), we are increasingly faced with a host of
conflicting choices. When building systems that give form to human experience,
should we privilege agency or efficiency, privacy or connectivity, elegance or
complexity? These are not choices that can be left to a calculator. Systems,
left to their own devices, cannot produce values. Rather, values are imposed
from without. The question then becomes one of ends and means. A calculator is
most "efficient" when operating on binary data. Efficiency and complexity are
goods for the task of calculation. Humans prefer to manipulate texts and
images. A democratic vision of a just society places value on open deliberation
and consensus building. Undeniably, computers participate in social
transformation: used to make war and to create art. What are our machines
optimized for? The passive voice points to the root of the problem. A
computational mechanism that extends agency should embody values that emanate
from the agent. In other words, one should be able to project values through
the machine, and not the other way around. What seems like a technologically
determined inevitability is often simply the imposition of another's will from
without. It is an attempt to social and political, not technological
determinism. In most cases, it is possible to trace the root of imposition to
specific governing agents, agencies, or incorporations.

[^ln1-notquite]: To what extent a personal computer is a Turing machine is
matter of contention. The Turing machine is a *thought experiment* that
imagines a machine. The PC is a machine emulating the thought experiment. See
@putnam_representation_1988, 121-5; @chalmers_does_1996; @petzold_code:_2000. A
more detailed discussion follows in 1.2.

[^ln1-kant]: Or at least proceeding as if one has agency to structure one's own
experience, despite the overwhelming evidence for determinism.

[^ln1-rmedium]: For example, see Paul Ricoeur writing on the change in media
from speaking to writing: "The most obvious change from speaking to writing
concerns the relation between message and its medium or channel. At first
glance, it concerns only this relation, but upon closer examination, the first
alteration irradiates in every direction, affecting in decisive manner all the
factors and functions" [@ricur_interpretation_1976, 25].

## 1.2 Thought Experiment

To confront the computer as a *literary* device, optimized for symbolic
exchange, one must first understand its peculiar relationship to universal
Turing machines. And to understand the history of Turing machines, it is best
we view them in a wider cultural context, beyond the mathematical literature
where they were first introduced.

In what follows, I shall draw two as yet unexplored lineages that lead to
Turing's seminal essay on computable numbers: the first intellectual, stemming
back to his tutelage under Ludwig Wittgenstein, and the second material,
highlighting the physical similarities between Turing's design and a number of
concomitant developments in printing and communication. To read Turing and
Wittgenstein together is to recover a legacy of humanities computing that often
gets overlooked in the critical literature on the subject. This history is
important because it allows us to see the simulated book in a new light: not as
byproduct of quantification, but as a metaphor machine, capable of universal
symbolic manipulation.

Turing machines should hold interest for literary scholars because they present
a minimally viable model for generalized symbolic manipulation: reading and
writing. Although the thought experiment they embody solves a mathematical
problem, the thought experiment itself has roots in a more general discussion
about the nature of interpretation, central to questions of meaning-making in
art and culture.

In his seminal 1936 paper on computable numbers, Alan Turing, then a student at
King's College, proposed a peculiar thought experiment to appear on the pages
of mathematical journal. The experiment addressed a problem in the field of
elementary number theory. But the problem turned out to be less important than
the general shape of the solution.[^ln1-anticipate] Turing imagined a mechanism
that solves a theoretical problem. His solution thus touched upon not just the
theory of mathematics, but on the *action* of symbolic thought in the world.
His imagined machine could read, write, and in some sense, understand symbols.
In other words, it was able to transition from some form of representational,
external shape of the symbol into the corresponding non-representational
internal state of the mechanism. The outlines of that mechanism will come into
focus in his section.[^ln1-turingcog]

Let us be clear about one point at the outset: Turing did not "invent" the
computer. Rather I see his hypothetical machine as the culmination of a
long-standing thought experiment concerning the nature of interpretation,
passed to him through Wittgenstein's lectures. It presents a minimally viable
blueprint for a class of already existing devices, used for communication and
control. Turing's minimally viable schematics gave a succinct formula to what
we now call simply "programming" and "computers."

Consider the essence of programming devices as a practice related to the
general deferment of volition by symbolic means, as in "last will and
testament" or a to-do list or a legal injunction. Someone wants you to do
something: turn left then right, buy milk, invest into real estate, or, in the
case of literature, feel compassion. Machines can be thought of as an extension
of that same practice. To "program" a rudimentary toaster, for example, is to
displace some measure of volition (I want toast) to an inanimate object. Should
I die in the process of toast-making, the toaster will still carry the action
of making toast to its logical conclusion. Common to all of these examples is a
lengthening of the cause an effect chain. Under regular circumstances, the
desire to do something produces an immediate corresponding action in the world.
You reach for an apple. You take a bite. "Programming" in that sense delays the
execution of desire. I want toast now, but I will program a toaster to make it
tomorrow. The toaster acts as an executor of my will.

In Moreno's language, we could say that a programmed machine symbolizes that
"conserved" fraction of the will to do something. It represents and enacts the
originating desire, able to continue performing an action independently, in the
absence of the "programmer." In that way the machine could be said to
"conserve" volition. Delay and displacement of that sort resides at the center
of humanity's unease with automata, robotics, and computation. The worry is not
only that the machine will begin to act independently---the plot of many a
science fiction novel---but that it will continue acting without cessation.
Note however that such remote volitional properties are not confined to the
autonomous movement of a mechanism. Moreno's initially disconcerting
proposition to treat books and robots on the same plane of analysis makes sense
if viewed in the context of---what should we call it?---history of symbolism
and representation.

The problem of symbolic displacement already presents itself in the invention
of writing. Recall for example the famous *pharmakon* passage from Plato's
*Phaedrus*, discussed eloquently in Jacques Derrida's *Dissemination*. At the
conclusion of the dialog, King Thamus objects to the technology (*ta tekhnēs*)
of the written word, as he believes it will foster forgetfulness in the people
who use it.  Plato writes: "Their faith in extrinsic writing [*graphō
exōthen*], by means of foreign impressions [*allotrion tupōn*] will diminish
their intrinsic [*endothen autous*] capacity to remember"
[@plato_plato:_1999].[^ln1-platotr] Plato thus contrasts the exterior figure
[*graphō exōthen*] with the intrinsic [*endothen*] human capacity to remember.
The Greek *tupōn*, related to the English "type," literally means an
impression. And in this case it is "foreign" or "othered" [*allotrion*].  It
comes from without. Like Moreno after him, Thamus finds such remote thought
typography problematic. True memory and thought for them both must come from
within. It must be autopoietic not allopoietic. This is why Socrates asks
Phaedrus to stop reciting a speech the young man heard earlier and memorized.
Mechanical reproduction by rote does not in any sense equate to what we would
today call "critical thinking." To truly understand, the reader must properly
internalize a stream of symbolic information contained in a book or a speech.
As we shall see, much can go wrong in that process, but we expect for reading
to ultimately leave an appropriate impression [*tupōn*] on the reader's mental
state. But what is appropriate or proper?  Wittgenstein struggles to answer
that question in his lectures, where Turing machine enacts it with blunt force.
The Turing machine ingests symbols, incorporating them as part of its internal
structure.

I revisit the lines from Plato's well-worn dialogue because Turing's paper
presents considerable difficulties to the non-mathematically-inclined reader.
Yet it becomes more accessible when considered in the philosophic lineage of
Plato, Wittgenstein, and Derrida: all three concerned with the movement of
inscription between internal and external spaces. I want us to view computers
and programming not only as products of electrical engineering but also as part
of a persistent thought in Western culture about the ultimate relation between
symbol and comprehension.

What does it mean to understand a sign?---that is the larger question that
Turing addresses. And, as we will see in the following passages, a direct
connection exists between Wittgenstein's hermeneutics and Turing's ideas about
computation. Steeped in the intellectual context of Cambridge, the evolution of
their thought overlaps the search for intrinsic structure in fields as diverse
as literary studies and anthropology. Turing's ideas about symbolic
manipulation acquire a new meaning when considered against the background of
formalism and structuralism, developing in Europe at the same time.

It is precisely because Turing paper left so much non-mathematical residue in
the wake of its publication that it continues to be a source of debate,
misunderstanding, and controversy to the present day. Consider the following
attempts to describe the essence of Turing computation:

> Turing machine, n. A notional computing machine for performing simple
> reading, writing, and shifting operations in accordance with a prescribed set
> of rules, invoked in theories of computability and automata [_turing_2015].

> a criterion [...] that it shall be possible to to devise a computing machine,
> occupying a finite space, and with working parts of finite size
[@church_review_1937, 42].

> a human calculator, provided with pencil and paper and explicit instructions,
can be regarded as a kind of Turing machine [@church_review_1937, 43].

> To understand a Turing machine we need only know its table of commands
> [@kemeny_man_1955;  _turing_2015].

> A Turing machine plus random elements is a reasonable model for the human
brain [@putnam_issues_1961, 39].

> No Turing machine has ever been physically constructed or realized in
hardware as a device for its own sake, but general-purpose digital computers
have been programmed to simulate Turing machines [@jordain_condensed_1969, 550;
@_turing_2015]

In reading the above passages, one discovers a range of possible definitions.
The *Oxford English Dictionary* discusses Turing's original experiment in terms
of "a notational machine." It "performs operations" according to "a prescribed
set of rules." In short, the machine at least seems like a machine, not unlike
a steam engine or a mechanized doll. By contrast, Alonzo Church, who was one of
the first to read and to respond to Turing's paper, describes it as a
"criterion" for building a machine, not the machine itself. More confusingly,
it seems that a human armed with a pen and paper can already satisfy Turing's
criteria. Writing for the *Scientific American* in the fifties, John Kemeny
likens it to a "table of commands." In his reflection, it seems neither a
device nor a human being but an algorithm or a set of instructions. A decade
later, Hilary Putnam (along with a number of prominent philosophers of mind)
returns to Turing's paper to find a model of human
cognition.[@fodor_language_1975; @putnam_representation_1988]. Writing for one
of the earliest encyclopedias on computing, Philip Jordain finally encapsulates
the paradox at the heart of Turing computation: it is a device that can never
be constructed, yet all other computers are programmed in its image.

A mechanism, an idea, an algorithm---imitating a human or imitated by
humans---an impossible ideal or just a ordinary person holding a pencil, the
Turing machine traces a figure somewhere between the ideal and the physical
worlds. The indeterminacy of computation blurs the boundaries between the
physical and the symbolic worlds. Turing continues to strike a controversial
figure at the fault lines separating theory from practice: computer science and
electrical engineering. The Turing machine "abstracts away from the complexity
of real computer architectures," Thomas Haigh writes for the *Communications of
Computing Machinery*. The historian should avoid confusing hardware and
software, he concludes [@haigh_actually_2014]. No matter how hard computer
science tries to escape into the realm of pure mathematics, Haigh suggests, the
limits of physical engineering pull it back to the sphere of the
applied.[^ln1-cs] Part real mechanism and part dream; part physics and part
metaphysics, the Turing machine should be encountered on its own terms. Let us
take the moment to read the paper and to place it into the intellectual context
of the development of Turing's thought.

### Alan Turing's "On Computable Numbers"

Turing begins his paper suggestively: "we may compare a man in the process of
computing a real number to a machine that is only capable of a finite number of
conditions." [@turing_computable_1937, 231]. In effect, he asks his readers to
compare computation, a human mental process, to the mechanical action of a
machine. As Charles Petzold explained it in his book-length annotation on
Turing's paper, Turing "makes reference to 'states of mind' that are analogous
to machine states" [@petzold_annotated_2008, 67]. But the analogy itself leads
to contention. Neither mathematicians nor cognitive scientists agree on the
extent to which states of mind can be compared to discrete machine states.

Turing further imagines a machine "supplied with a 'tape' (the analogue of
paper) running through it, and divided into sections (called 'squares') each
capable of bearing a 'symbol'" [@turing_computable_1937, 231]. Much like a
movie reel, the tape moves through the mechanism one section at a time. At each
point only one section bearing one symbol can be said to be "in the machine."
"We may call this square the 'scanned square,'" Turing writes,

> The symbol on the scanned square may be called the "scanned symbol." The
> "scanned symbol" is the only one of which the machine is, so to speak,
> "directly aware" [@turing_computable_1937, 231].

The scanned symbols become a part of the machine's internal configuration. In
Turing's words, "the machine can effectively remember some of the symbols which
it has 'seen' (scanned) previously" [@turing_computable_1937, 231]. The
machine's "behavior" is therefore determined by its initial configuration (in
the arrangement of tape and scanning apparatus) plus the scanned symbol.

We imagine then a device not unlike a telegraph or a film projector, which
ingests reels of tape. But unlike telegraphs or film projectors, the ingested
symbolic representation becomes effectively, by definition, a part of the
machine's internal configuration. Remember that in constructing his
contraption, Turing continually appeals to the model of human cognition. A
child in the process of reading or doing mathematics similarly "ingests"
symbols.  These symbols really do become a part of the child's mental
apparatus, affecting a change in brain states on some real and empirically
observable neurological level. Turing's machine is capable of similar
internalization.

Where the child converts symbol into brain states, the machine transforms
software (symbol) into hardware (configuration). The machine does not just
scan, it "reads" in the Platonic sense, able to convert ideal forms into their
specific instantiations. It becomes "aware," in Turing's words. Consider by
contrast the action of a film projector. Unlike a Turing machine, the projector
does not internalize film reels. The film reel passes through without leaving a
trace within the mechanism.[^ln1-reading]

In addition to "reading," Turing's machine must be able to write. Turing writes
that "in some configurations in which the scanned square is blank (*i.e.* bears
no symbol) the machine writes down a new symbol on the scanned square"
[@turing_computable_1937, 231]. The machine can also erase and move symbols to
adjacent squares, one square at a time. Reading, writing, and symbolic
manipulation are thus mechanical actions at the core of Turing's computation.

The configuration state of the machine determines the movement of the "reading"
and "writing" apparatus along the surface of the tape. At its simplest
incarnation, the tape moves along one dimension only: left or right. Some of
the scanned symbols are meant to represent computable numbers (the whole point
of Turing's paper). Yet other symbols represent machine instructions. They
direct the movement of the reading and writing head. They tell the machine to
"write," "scan," or "erase" symbols. Today, we would call such instructions
"programs" or "control codes." The control codes and the computed data form a
part of the same continuous stream of information.

Just as the Turing machine is able to convert symbolic representation into
internal configuration states, it can conversely enact the opposite movement,
by representing internal configuration states symbolically. This remarkable
property allows for the creation of what Turing calls a class of universal
machines. Specific Turing machines could be configured to preform actions like
addition or multiplication. But the multiplication machine could not, for
example, be reconfigured for another purpose, because the physical movement of
its internals is fixed. An adding machine can only add. But the universal
Turing machine can do more than scan symbols: it has the ability to internalize
*other machine configurations*. Such a machine can "compute any computable
sequence" [@turing_computable_1937, 241]. In being able to internalize physical
configuration as symbol, the *universal* Turing machine can simulate all other
special-purpose Turing machines.

The transition of symbols into machine states (and the other way around)
defines modern programming. A universal machine, unlike other, definitive,
single-purpose and limited-state mechanisms (a clock for example), contains the
ability to take on differing internal symbolic configurations. It can imitate a
clock, an abacus, a scale, a book. In a later paper linking computing machinery
and intelligence, Turing implies it could eventually simulate human thought as
well [@turing_computing_1950].[^ln1-compete]

The universal Turing machine (UTM) finally encapsulates a model of computation
itself. The UTM can compute anything computable. In substituting the concept of
computability with "effective computability" Turing's paper belongs to the
annals of mathematical theory. But, it continues to elicit conflicting
responses widely because much of it contains tantalizing possibilities that
bare on symbolic manipulation more generally. The paper is riddled with
metaphors of cognition, for example. From the beginning we are asked to
consider the similarity between humans and machines in the process of
computation. Turing consistently describes machine states in terms of "states
of mind," "awareness," and "memory." All of these descriptions capture some
part of Turing's idea. But it eludes them also, because it does not fit neatly
into a reductive history of a given discipline: neither computer science, nor
cognitive science, nor mathematics. In connecting Turing to Wittgenstein, we
will perceive it ultimately as an experimental, ludic even, enterprise. Like
Turing's imitation game, which came decades later, the Turing machine
constituted a simulation, capable of imitating all other symbolic systems, from
intelligence, to calculus, and literature.

Reconstructing the influence of Wittgenstein's thought on Turing confirms the
place of Turing's "On Computability" in the conversation about language, pain,
and cognition. Seen in the light of Wittgenstein's philosophy, Turing's work
and consequently the early history of computing acquires a broader connotation,
beyond the narrow confines of the *Entscheidungsproblem*, the problem the paper
addressed explicitly. In 1936, on the eve of World War II, Turing imagined more
than a formula: it was a thing that could explore the limits of theory, and a
theory that identified a new class of emerging things. Through Turing's
well-documented involvement in Government Code and Cypher School (GC&CS) at
Bletchley Park, actual Turing machines changed the nature of war: used at first
to break encrypted military communications and then to compute missile
trajectories. But as I will argue here, Turing machines also changed humanity's
relationship with symbolic thought. And unless we understand Turing's legacy
beyond war-making, we risk limiting its creative potential to mechanisms of
destruction.

[^ln1-anticipate]: As Alonzo Church mentioned in his review of the paper a year
later, Turing's mathematical insight was anticipated by concomitant work in the
field [@church_review_1937].

[^ln1-platotr]: I translate the passage into literal, if awkward, English to
preserve some of the interesting characteristics of the original Greek. In
particular, note the parallelism between *exōthen* and *endothen*, the
ambiguity of *allotrion*, as something that comes from another, and the subtle
slide between *graphō* (letter, figure, writing) and *tupōn* (type, impression,
trace). I extend my gratitude to Stathis Gourgouris, Simos Zenios, and Guy
Smoot for their help with the Greek translations.

[^ln1-turingcog]: Turing's later work suggests that his use of cognitive language
throughout "On Computable Numbers" was not accidental, and that he meant it to
define sentience more generally [@turing_computing_1950].

### Wittgenstein's *The Blue and Brown Notebooks*

The nexus between Alan Turing and Ludwig Wittgenstein in the years between
1931-1939 at King's College, Cambridge gives us a glimpse into the intellectual
context of the Turing machine. Wittgenstein broached the problem of reading
machines first in *The Blue and Brown Books* along with *Philosophical Grammar*
(all compiled in the early 1930s), then in his lectures and remarks on the
foundations of psychology and mathematics from the late 1930s, and finally in
*Philosophical Investigations*, (written between 1945 and 1949). To give you a
sense of the timeline: Alan Turing's entered King's College in 1931
[@hodges_alan_1983, 78] and his paper on computable numbers appeared in print
in 1936. It is likely that the two philosophers met at the Moral Science Club,
where by the 1930s Wittgenstein "monopolized the discussion," even in the
presence of prominent philosophers like George Edward Moore
[@duncan-jones_g._1958, 25]. Turing attended Wittgenstein's lectures on the
foundations of mathematics in 1939.

Andrew Hodges, the Oxford mathematician and Turing's biographer, attributes
Turing's engagement with the mechanical basis of mathematical proof to the
tutelage of Cambridge mathematicians Max Newman and G.H. Hardy. Hodges writes
that in the summer of 1935, Turing "dreamed of machines." The idea of bridging
mathematics to the physical world by a mechanical process "revolved in Alan's
mind" [@hodges_alan_1983]. That may have been. However, reading Turing in the
context of Wittgenstein's notes and lectures suggests a parallel, if not an
alternative intellectual lineage.

As we shall see, there is a remarkable consistency between the multitude of
Wittgenstein's "broken" reading machines and Turing's universal symbolic
manipulator. The parallel is even more striking when one considers Turing's
later work on the "imitation game" as a litmus test for artificial
intelligence, echoing Wittgenstein's interest in functional language games. The
mathematical formulae in Turing's papers should not obscure the writer's
preoccupation with hermeneutics more generally. For example, literature on
Turing's intelligence test usually ignores the long discursive passages
analyzing poetry in the original paper.

If we take Turing machines to stand in as a kind of a universal symbol for
computation itself, capable of transforming the practice of arts and letters in
almost every field of aesthetic and intellectual activity, it becomes paramount
to view them outside of the narrow confines of mathematical theory.
Understanding Turing machines within the history of symbolic interpretation
more broadly, brings computing closer to the light of cultural criticism. The
bulk of this chapter is therefore concerned with drawing the intertextual
connections between Turing's early work on computation and Wittgenstein's
"middle period," between his *Tractatus* and *Philosophical Investigations*.
The two thinkers occupy the same vibrant intellectual milieu in Cambridge for
the best part of the decade. Their work during this period shows a significant
thematic overlap, which although acknowledged, receives scant attention in the
critical literature.[^ln1-cope]

[^ln1-cope]: See for example @copeland_what_2000 and @wagner_wittgenstein_2005.

Wittgenstein wrote that his *Blue and Brown Notebooks* comprise "some notes to
my pupils, so that they may have something to carry home with them, in their
hands if not their brains" [@wittgenstein_blue_1965, vii].[^ln1-notes] "The
Blue Book" begins with a question of interpretation: "What is a meaning of a
word?" From the start, Wittgenstein cautions his students against choosing the
easy answer, which holds that meaning resides in the head. Wittgenstein writes:

> It is misleading then to talk of thinking as of a "mental activity". We may
> say that thinking is essentially the activity of operating with signs. This
> activity is performed by the hand, when we think by writing; by the mouth and
> larynx, when we think by speaking; and if we think by imaging signs or
> pictures, I can give you no agent that thinks. If then you say that in such
> cases the mind thinks, I would only draw your attention to the fact that you
> are using metaphor, that here the mind is the agent in a different sense from
> that in which the hand can be said to be the agent in writing.

The "locality of thought" poses a problem of analogy. Wittgenstein explains
that when we see a sentence on paper, the external manifestation of a thought,
we assume that some analogous structure exists somewhere in the brain. Perhaps,
Wittgenstein speculates, we could even observe the brain directly, in the
process of writing. Both phenomena, brain- and paper- bound, could properly be
called the *expression* of thought. Yet neither can offer the definitive
location where thinking happens. Rather, Wittgenstein suggests, we are
witnessing a metaphor: some set of correlations between two distinct
activities. And it may be that the correlations themselves are what we mean by
"thought." Neither brain nor paper make sense as *the* site of cognition by
itself, just like it would not make sense to interrupt a metaphor---"memory the
warder of the ~~brain~~ (from *Macbeth)---and then look for it in the remaining
snippet.

Our difficulty in locating the definitive site of thought points to the
inadequacy of Cartesian dualism between body and mind. Neither physical nor
mental descriptions of thought are sufficient to locate the site of cognition,
Wittgenstein argues. As an example of such a difficulty and likely having a
passage from Descartes in mind[^ln1-descartes] Wittgenstein asks, "Can a
machine think" [@wittgenstein_blue_1965, 16]? The problem, as he explains, is
not one of finding a machine that can do the job---of manipulating signs, for
example. It lies in the ability of a machine to enact the both sides of the
metaphoric equation. "Doing the job," the manipulation of signs, must
correspond to something else. Severed from some other analogical structure, the
"blind" manipulation of signs is a meaningless activity. Meaning, Wittgenstein
seems to suggest, resides simply in this analogy between something (symbol) and
something else (mechanism).

Wittgenstein extends his thought experiments about reading machines in his
*Brown Notebook.* Let us study the word "reading," he suggests early on. By
reading, he means the activity of "translating script into sounds," "of writing
according to dictation," or "of copying in writing a page of print"
[@wittgenstein_blue_1965, 119]. Reading once again is "mechanical" reading,
without a sense of "understanding" or interpretation. What happens when an
average child reads a newspaper, for example? "His eyes glide along the printed
words, he pronounces them aloud or to himself, but other words he pronounces
after having seen their first few letters only, other again he reads out letter
by letter." The child acts as a "reading machine" when he pays no attention to
what he reads, even when he speaks the words out loud. Yet he reads
"faultlessly like a reliable machine." Another child merely pretends to read.
He guesses at the words, and on occasion repeats things "by heart", without
actually seeing them on the page [@wittgenstein_blue_1965, 121-22]. Should
either of these count as reading?

Wittgenstein continues to complicate such edge cases, challenging his
audience's intuitions of what it means to read and to understand. He gives also
the example of a hallucinating patient, who "reads" what to us looks like
gibberish, and the case of man who fakes reading Cyrillic by memorizing the
lines phonetically. He talks of machines too, which produce random sounds that
occasionally, by accident, correspond to some existing texts. In each case, we
envision two mechanisms, Wittgenstein writes, one visible and external and one
hidden and internal. To read, the reader must do more than go through the
motions of reading. Instead, we privilege the inward-facing signs of
comprehension as the "real criterion for a person's reading or not reading."
The physical motions, of gliding one's eyes across the page and saying the
words out loud, must connect in some way with appropriate internal, mental
representations.

But in fact no such internal mechanisms can be known to us or communicated to
others properly [@wittgenstein_blue_1965, 120]. We can only intuit the reader's
private experience of reading, or whether such reading attains the desired
correspondence between inward state and outward sign. A reading pupil must
convince his teacher that the scanned sign had the intended effect. This
requires more words in a sort of an interrupted hermeneutic circle, the two
sides of which do not quite connect to complete the communication feedback
circuit.

Wittgenstein finally describes the mechanisms of reading as an "indirect way
of transmitting a feeling." "Something that we can never know happens at the
other end" of the communication act. Communication, as we would say today, is
always mediated.  In conclusion of the notebooks, Wittgenstein imagines the
possibility of unmediated, "direct" modes communication, capable of
transmitting feelings from one person to another [@wittgenstein_blue_1965,
185].

Thought experiments in *The Blue and Brown Notebooks* do not amount to a
cohesive model of communication, semiotics, or the mind. They do however
contain the seeds of the reading and writing machines later imagined by Alan
Turing and subsequently passed into the foundations of computer science.
Wittgenstein's experimental thought machines prefigure the modern computer.
Wittgenstein conjures these fantastical broken machines ultimately to address
the problem of symbolic interpretation.

[^ln1-descartes]: Descartes writes in his 1637 *Discourse on Method*: "If there
were such machines having the organs and the shape of a monkey or some other
animal that lacked reason, we would have no way of recognizing that they were
not entirely of the same nature as these animals; whereas if there were any
such machines that bore a resemblance to our bodies and imitated our action as
far as this is practically feasible, we would always have two very certain
means of recognizing that they were not at all, for that reason, true men."
Also quoted in @dennett_can_2004, 297.

### Wittgenstein's *Philosophical Grammar*

*Philosophical Grammar,* written around the same time as the *Blue and Brown
Notebooks*, gives us another into the pre-history of the literary device. It
begins again with a problem of "understanding" and "not understanding." "To
understand language," Wittgenstein writes, means "to take in symbolism as a
whole" [@wittgenstein_philosophical_1974, 5]. From the very first passages,
Wittgenstein envisions "understanding" as a type of trans-mediation. In
comparing the understanding of language propositions to music, he writes: "for
explanation I can only translate the musical picture into a picture in another
medium and let one picture throw light on the other"
[@wittgenstein_philosophical_1974, 5 & 41]. And elsewhere: "How curious: we
should like to explain the understanding of a gesture as a translation into
words, and the understanding of words as a translation into gestures"
[@wittgenstein_philosophical_1974, 42]. Ultimately, he describes what we mean
by "understanding" as a "process of translation from one symbolism into
another; tracing a picture, copying something, or translating into another mode
of representation" [@wittgenstein_philosophical_1974, 45]. To understand
something something said is akin to modeling it in clay or drawing.

In light of our earlier discussion about metaphoric transference,
Wittgenstein's hermeneutics amount to the making of metaphors across media. To
understand, it is not enough to explain language in language. One must trade
symbolisms, creating a metaphor that explains one representational system in
terms of another. This process is not exact. How would one check if the "clay
model" corresponds to the "language model" properly? In thinking of the various
ways in which the process of translation breaks, Wittgenstein continually
returns to the pianola, a type of a player piano. In the player piano, the
relationship between music score sheet and the keyboard is rigidly defined.
Perforated sheet music passes through the machine, activating a set of
corresponding pins. The conceptual world of the mechanism and the conceptual
world of music notation correspond exactly. The machine in effect enacts the
metaphor.

![Electrically-operated musical instrument by Clyde Coleman of Chicago, Il.
1914, US1107495A.](images/pianola.png)

In the early passages of *Philosophical Grammar*, Wittgenstein explains: "Aren't
our sentences parts of a mechanism? As in a pianola? But suppose it is in bad
condition?  So it is not the effect but the purpose of the signs (the holes in
the pianola roll). Their purpose *within* the mechanism"
[@wittgenstein_philosophical_1974, 10]. Wittgenstein elaborates a few pages
later:

> The sentences that we utter have a particular purpose, they are to produce
certain effects. They are parts of a mechanism, perhaps a psychological
mechanism, and the words of the sentences are also parts of the mechanism
(levers, cogwheels, and so on). The example that seems to illustrate what we're
thinking of here is an automatic music player, a pianola. It contains a roll,
rollers, etc., on which the piece of music is written is some kind of notation
(the position of holes, pegs, and so on). It's as if the written sign gave
orders which are carried out by keys and hammers
[@wittgenstein_philosophical_1974, 69].

As was the case with reading automata in *The Blue and Brown Notebooks*,
Wittgenstein again substitute a physical mechanism for the process of symbolic
interpretation. On this view, words and music notation alike, have "a purpose"
to elicit some "effects" in the reader/player. But as before, we cannot always
expect the mechanism of interpretation to function properly, nor do we have a
reliable way to check its operation. "Suppose the pianola is in bad condition,"
Wittgenstein repeats. The signs on the roll could produce "hisses and bangs"
instead of music, for example. One could object that notes are always "meant"
to play on a mechanism in perfect working order. But to explain what is meant,
we would need to draw yet another diagram. By analogy, the "sense" of an
"order" lies in its "effect on an obedient man"
[@wittgenstein_philosophical_1974, 60-70]. The pianola exemplifies what will
come into a much starker contrast later in this chapter: that the mechanisms of
symbolic communication ultimately belong to a class of controlling devices.
Metaphors control in the sense of mediating state changes between two disparate
conceptual systems.

When drawing the analogy between mental and mechanical processes, Wittgenstein
explicitly rejects the model of language as a "psychophysical" mechanism.
Rather, as the title of the work suggests, Wittgenstein is in search for the
"grammar" governing the engagement: between speakers and listeners, readers and
writers, player pianos and musical scores. By the end of the work, grammar
emerges as a set of "conventions." Wittgenstein complicates the mechanism by
inserting an extra layer of "rules" that mediate between symbol and machine or
mental state. A convention could be included in a chart, for example. And it is
possible that "there is a part of the mechanism which resembles the chart, and
is inserted between the language-part of the mechanism and the rest of it"
[@wittgenstein_philosophical_1974, 190]. "Imagine a language consisting of
commands," Wittgenstein writes in conclusion.  It is to direct a human
"forwards," "back," "right," and "left," "quickly" and "slowly"
[@wittgenstein_philosophical_1974, 197] The grammar, like a table of
correspondences, explains the meaning of the signs. Today, we would call it a
"program." Programs translate arbitrary symbolic notation into physical action.
In this way, we can move away from speaking of "intended effects" or "proper
obedience," and rather concentrate on the mediating layer that describes the
rules of engagement.

### Lectures on the Foundation of Mathematics

Turing met Wittgenstein's at King's College sometime in the 1930s. Although
there are no records of them meeting explicitly until Turing's attendance of
Wittgenstein's lectures on the foundation of mathematics in 1939
[@wittgenstein_wittgensteins_1976, 7], both men's work exhibits sustained
attention to computing machines narrowly and to the mechanical manipulation of
symbols more generally. From the notes on Wittgenstein's lectures complied and
published by Cora Diamond, it is clear that Turing was a vociferous presence in
the class. His name is mentioned eighty-six times in the text, more than any
other student by a wide margin.[^ln1-margin] At some point of the course
Wittgenstein concludes his lecture in saying: "Unfortunately, Turing will be
away from the next lecture, and therefore that lecture will have to be somewhat
parenthetical. For it is not good my getting the rest to agree to something
that Turing would not agree to" [@wittgenstein_wittgensteins_1976, 67-68].

Like the notebooks beforehand, Wittgenstein structures his lectures around the
problem of symbolic interpretation. "I am going to talk about the interrelation
of mathematical symbols," Wittgenstein begins. We imagine that logical laws
represent some sort of "fixed" mechanisms "behind" the symbols used to express
them. "I am speaking against the idea of logical machinery," Wittgenstein says
in lecture XX. "The idea of logical machinery would suppose that there was
something behind our symbols" [@wittgenstein_wittgensteins_1976, 194]. We
imagine logic to be a sort of a "rigid mechanism" that can only turn this way
or the other. "Any rule can be imagined to be a description of a
mechanism---even the rule which says a pawn must not be moved in a certain
way," Wittgenstein writes [@wittgenstein_wittgensteins_1976, 282]. The parts of
the mechanism subsequently exist in a causal relationship to one another.
Pushing this or that lever will *always* result in such and such movement,
because of the way the mechanical parts are connected. We say that the
mechanism is rigid or the law is inexorable, when the results of an action are
absolutely fixed. Wittgenstein calls such a relationships "super-hardness."
Where a judge can be lenient, he explains, the law is compulsory. What we would
now call "an algorithm" compels predictable execution.

We are tempted, as before, to privilege the inner workings of the symbolic
mechanism, also at the core of meaning making in mathematics. "If I show you
the mechanism behind the [watch] dial, you will be able to predict the movement
of the hour hand for any given movement of the minute hand," Wittgenstein
writes. "And you will not be sceptical." Yet even there, we would be making an
assumption about a mechanism that functions well. "For instance, I may drop the
clock" Wittgenstein explains, "so that the machinery is broken, or a lighting
may strike it [@wittgenstein_wittgensteins_1976, 195]. How are we to know if
the mechanism functions properly or not? For that we would need "a picture" or
some sort of schematics that describe what the proper mechanism should look
like. The mechanism is in fact itself a type of a symbol for the perfected
behavior of the sort that we expect. Where we tried to find the mechanism
behind the symbol, we found also the symbol behind the mechanism. Once again we
encounter the spiral of interpretation between intent and effect, which never
quite manage to explain each other.

In his lectures on mathematics, Wittgenstein never finds a way out of this
recursive conundrum. The foundations of mathematics rely on some such mutually
dependent relationship between the physical and the symbolic worlds. Whether it
is in math or in ordinary language, some magic happens at the coupling of the
matter and sign. The precise point of contact concerns Wittgenstein in all
fields of human activity, from literature to psychology and mathematics.

In all of these fields, Wittgenstein finds an implicit analogy between "symbol"
and "mechanism." A type of metaphor, the analogy itself is atomic. It cannot be
split further into something like "sign" and "referent" or the "signifier" and
the "signified." Considered apart, the two parts of the metaphor are strictly
meaningless. In his lectures on aesthetics, Wittgenstein describes such a
semiotic relationship as the "concomitance between mechanism and its trace"
[@wittgenstein_lectures_1966, 16]. In giving an account of one's aesthetic
judgment, the best we can do is to "trace a mechanism"
[@wittgenstein_lectures_1966, 13].

It would be a mistake to reduce Wittgenstein's semiotics to the mechanical
theory of the mind. Rather, in presenting his students and readers with a
number of hypothetical machines, Wittgenstein attempts to discover the rule
book of what he later calls the language game---or at lest to suggest that such
a rulebook might exist. Much has been written on this aspect of Wittgenstein's
thought and its relation to Bertrand Russel's symbolic logic. In the context of
our conversation, Wittgenstein's "middle period" is important for its direct
influence on Turing's model of computation.

Several prominent characteristics pass from Wittgenstein's reading machines to
Turing's universals. First, the symbolic machine emerges from the metaphor-like
correspondence between internal machine state and external symbolic
representation. Second, Wittgenstein discusses symbolic representation in terms
of its delayed effects, that is, ultimately, a type of a remote control
mechanism. And finally, Wittgenstein imagines a mediating layer that holds the
rules for translation between state and symbol. All of these features, along
with a penchant for ambiguous thought experimentation, pass directly from
Wittgenstein to Turing. Turing consequently attempts to clean up after his
teacher's profusion of broken interpretation machines. Instead, he gives us one
thought experiment, encompassing all possible center and edge cases. In
addition, Turing describes the minimal physical requirements needed to actually
build such a contraption. Turing imagines the universal metaphor machine, given
the right requirements, able to convert any symbolic input into the
corresponding physical state of the mechanism. It is a machine that "traces the
mechanism" of all other metaphoric mechanisms.

[^ln1-margin]: The prominence of Turing's voice in the lecture notes could be
attributed to his later prominence.

## 1.3 Towards the Mechanism (Conclusion)

Literature in computer science tends to see universal Turing machines as
algorithms: in other words, as virtual, second-order symbolic representations.
Yet it is impossible to entirely disassociate the implementation from the idea.
In his review of Turing's "On Computable Numbers" paper, Alonzo Church, the
American mathematician whose work anticipated Turing's (independently) in
several important aspects, later wrote that "a human calculator, provided with
pencil and paper and explicit instructions can be regarded as a kind of a
Turing machine" [@church_computable_1937, 42-3; also cited in
@petzold_annotated_2008, 63]. Disregarding the broader, metaphysical
implications of that statement, note for now the persistence of two essential
implements required for the minimally viable operation of the Church--Turing
human and machine calculators. Pen and paper assert themselves through the
abstraction.[^ln1-abstraction]

What are we to make of universal Turing machines implemented in virtual worlds
like *Wireworld* (a cellular automaton simulation), or *Minecraft* (a procedurally
generated sand-box world-exploration game)?

![Universal Turing machine as an idea. "Nick Gardner's *Wireworld* multiplier,
via a Turing machine."](images/turing-idea.png)

At the very least, we must admit that such simulations cannot rest on the
proverbial "turtles all the way down," unless that is, one believes that the
universe itself is a type of a Turing machine [@deutsch_quantum_1985;
@lloyd_ultimate_2000; @piccinini_computational_2007]. At some point, the
virtual world simulation meets the limitations of the physical world. Until
physicists agree on the ultimate nature of the universe as computation (or
not), we continue to assume that Turing simulations comprise second-order
ideational constructs, floating on top of first-order physical mechanisms. In
the case of *Wireworld* and *Minecraft* the simulation "runs" on personal
computers. The physical capabilities of the bottom-most device limit the
computation power of all *n+1* order Turing simulations. Consequently, the
simulated UTM cannot outperform (in terms of cycles per second, instructions
per cycle, or its capacity to hold a number of instructions) the machine
executing the simulation. The bottom-most turtle may have its head in the
clouds, but its feet rest firmly on the ground.

The exact plane where the symbolic meets the literal is difficult to identify
definitively. At some imperceptible point software disappears into hardware.
Such ambiguity between hardware and software leads to some controversy in the
critical literature, as evidenced by Lev Manovich's playful response to
Kittler's "there is no software" argument. If I understand it correctly,
Kittler's short but often cited essay picks up the thread of Kittler's earlier
work to posit what he calls a "postmodern writing scene." "We do not write
anymore," writes Kittler: "human-made writing passes through microscopically
written inscriptions which, in contrast to all historical writing tools, are
able to read and write by themselves" [@kittler_there_1995]. According to this
schema, Kittler sees the paper-bound design blueprints of the first integrated
microprocessor as the last "real" piece of writing. Everything written after
that point is hardware (because software is hardware at that "microscopic"
level).

Manovich inverts Kittler's argument into "there is only software," by which he
means that in a pragmatic sense, the affordances of a given medium are
determined by software. A printed page begins to differ from its computed
analogy only when readers are able to effect something on the screen that they
could not on paper. To this end, Manovich encourages his readers to become
active developers of software, rather than its passive consumers
[@manovich_there_2011, 274]. In that, Manovich reasserts the possibility of
writing in the silicon age. Kittler (who passed in 2011) could perhaps object
to that line of reasoning in maintaining that chip architecture (the last
written work, according to him) still determines, as foundation, all higher
levels of textuality "floating" above the silicon bedrock. And no amount of
learning to code would give an ordinary subject the resources required to write
in silicon---a process so advanced and expensive as to be limited to a handful
of international chip manufacturers. In opening a series of nested black boxes,
the post-silicon writer hits the impenetrable casket of chip architecture. Few
of today's engineer-writers are able to work on such deeply-embedded hardware
level.

Before we ourselves get lost in the liminal space between matter and idea, let
us recover a measure of oddity found in the now ubiquitous operation of Turing
machines. Remember that Turing's original description of the Turing machine
derived from a legacy of thought experimentation. Turing does not begin to
build actual machines until his move to Princeton in 1936. A universal Turing
machine comes to life initially as an idea that can take on the structure of
other ideas expressed symbolically. And though Turing describes his machine in
the language of mathematics (where his most significant contribution lies), his
description also contains the bare minimum of a mechanical device. No matter
how symbolic a Turing machine aspires to be, no matter how ascendant to the
realm of the ideal, it remains rooted in the mechanics of reading, writing, and
interpretation.

So far, we too have confronted the literary device only as an idea: imagined
first in the methodological contexts of formalist literary analysis and then as
a thought experiment about generalized symbolic manipulation. But from a
strictly materialist point of view, ideas cannot exist without some physical
underpinnings. Forced to encounter the universal Turing machine *as a
mechanism*, the media historian will find that it borrows from a number of
extant designs, which, together and incrementally, give the UTM its physical
form.

A media history of the Turing machine as device differs from its intellectual
history as symbolic, mathematical abstraction in interesting and instructive
ways.[^ln1-turing] Bracketing for the moment the mathematical and cognitive
implications of Turing's work, I want to approach the Turing machine from the
perspective of a book historian and a media scholar. If the Turing machine is
to be taken at face value, not as an algorithm, but as an instrument, what kind
of a machine would it be? What are its antecedents?

Most of the minimal physical requirements to build a universal Turing machine
were within reach in the 1930s, at the time Turing authored his influential
paper. In practice, his proposal would require first, an apparatus capable of
"scanning" and "erasing" a "finite number of symbols." Second, we would need
what Turing calls "one-dimensional paper," divided into discrete squares "like
a child's arithmetic book" [@turing_computable_1937, 249].[^ln1-infinite]
Furthermore, we would need some sort of a mechanism to advance tape through the
machine, or, alternatively, to propel the scanning mechanism along the length
of the tape. Having assembled these elements, our creation would look roughly
like a cross between a telegraph, a film projector, and a
typewriter.[^ln1-davey]

Were we to patent the Turing machine in the United States, at the time of its
conception (1936-37), the above elements would find prior art in mechanisms
such as the "Numeral adding or subtracting attachment for type-writing
machines" [@daugherty_numeral_1894], "Combined Type-writing and Computing
Machine" [@degener_combined_1911], "Computing Attachment for Typewriters"
[@wright_computing_1914], "Computing Mechanism" [@wright_computing_1915], and
"Combined Type-writing and Adding Machine" [@ellis_combined_1914] among others.
All of these machines contain some combination of a reading and writing "head,"
storage tape, and movement mechanism.

By the end of the nineteenth century a number of lesser contraptions anticipate
the functional elements of Turing's machine. And by 1936, when Turing publishes
his paper on computable numbers, these inventions not only anticipate the
modern computer, but are brought to mass market in the widespread manufacture
of computing scales, dial recorders, electric tabulating machines, and
computing typewriters made by companies like Underwood Computing Machine,
Electromatic, and International Business Machines (IBM). Rather than a single
eureka moment, the invention of the universal machine should therefore be
viewed as a gradual historical process that culminates in Turing's universal
(and minimally viable) specifications.

A number of inventions at the end of the nineteenth century pertain
specifically to "circuit-controlling devices controlled by a traveling
perforated strip or tape" [@cuttriss_telegraphy_1893]. Prior to perforated
tape, the transmission of messages by telegraph required the presence of a
skilled operator, able to transcribe messages from text to Morse code, and into
the physical motion of a lever-operated circuit. In the operation of early
telegraphy, the human operator acted as a mute interpreter between text and
telegraph. The transcription of text into signal, and back onto paper, required
the real-time presence of human encoders and decoders.

The perforated tape decoupled the human from the machine. In US1187035 (1916)
on "Telegraphy", Albert and Ralph Bumstead explain: "the object of our
invention is to provide a system of telegraphy which does not require skilled
operators for the transmission and reception of messages"
[@bumstead_telegraphy_1916]. Instead, the message was transcribed into
perforation via mechanical means and then fed into the mechanism. The tape
mechanics of the typewriter could then be coupled with the electrics of the
telegraph, with perforated tape acting as a mediator between the two "worlds"
of mechanics and electricity.

A number of contraptions emerged at the time with the aim of transfiguring the
mechanical action of the typewriter into perforation, and, consequently,
perforation into script, completing the circuit between automated "encoding"
and "decoding." As one machine converted human input into mechanical states,
and into signal, another machine converted signals into mechanical states and
thereon into human-legible messages.

A multitude of inventions capitalized on the control capabilities of removable
storage media by the beginning of the of the twentieth century. These included
machines for tape-controlled telegraphic transmission
[@wheatstone_improvement_1874; @murray_tape-controlled_1905;
@bumstead_telegraphy_1916], tape-controlled printing [@creed_printing_1911],
printing telegraphs [@hallden_printing-telegraph_1929], and remote broadcast
programming devices for radio and television content [@vriendt_program_1934;
@brown_automatic_1936; @brown_selective_1936]. With the invention of punch
cards and perforated tape (also used in textile looms, as early as 1725), a
message meant for another human became also a physical medium---bumps and
holes---used to animate the mechanical movement of the transmission apparatus.

For example, of the 33 asserted claims in the Bumstead brothers' "Telegraphy"
patent, the first 13 relate to the "transmission of intelligence,"

> [...] adapted to initiate a succession of electrical impulses all of which
> have a character representing significance, a receiver adapted to detect
> variations in time intervals elapsing between successive impulses, a
> plurality of interpreting relays selectively actuated by said receiver, and a
> printed mechanism responsive for the combined action
> [@bumstead_telegraphy_1916, 12-13].

What begins as a description of a mechanism for information transmittal, ends
with a claim about hermeneutics of control. Starting with clause 14, the
brothers begin to describe "a telegraph system" capable of "transmitting
impulses" at varying time intervals. In the language of the patent, the length
of the time interval "represents significance," involving an automated receiver
responsible for "distributing, interpreting, and recording." The printing
mechanism is further "arranged to print the interpretation of the signals which
is made by the interpreting relays" [@bumstead_telegraphy_1916, 6]. The
interpreting relays transform time intervals into a "typographical form"
representing "a letter, a figure, or other characters," "in accordance with a
code" [@bumstead_telegraphy_1916, 13]. Initially, the telegraph prints to
"transmit intelligence." But the authors also understand that the varying time
intervals could also signify other information, meant to actuate a variety of
devices.

By the middle of the patent, the brothers describe their telegraph as a general
"controlling medium," which can power everything from typesetting machines to
more general "sunflower switches." "Indeed the detector and the interpreting
relay could be made to actuate a set of sunflower switches for an indicator
without including a printer at all," the authors conclude
[@bumstead_telegraphy_1916, 12].

Along with hundreds of similar inventions patented around the turn of the
twentieth century, Bumstead brothers describe a mechanism that could function
as a Turing machine with little modification. The automated telegraph, driven
by ticker tape, and connected to a printer contain all the necessary
requirements set out by Turing: a discrete symbolic language, the removable
storage medium, and a device that can alter its internal states based on the
reading and writing of scanned symbols. They are able "read" and "write" and
otherwise manipulate symbolic representation, they ingest tape, and they
convert covert symbol into internal structure. Like the Turing machine, the
Bumstead telegraph is capable of recursion: ultimately, it can produce and
interpret its own control codes. By 1905, Donald Murray, the inventor of the
popular Murray telegraph, could write that "if we disregard the small class of
telegrams that merely express emotions, *the essence of telegraphy is control*
[emphasis mine]." He wrote also that "telegraph systems, therefore, belong not
to the class of producing or distributing, but to the class of controlling
mechanisms" [@murray_setting_1905, 556]. For the automated telegraph, control
code and the message are one. The mechanism interprets some signals as figure
and character and other signals as control code affecting the internal
mechanical configuration of the device. The first type of code holds
"significance" for humans, where the second for the mechanism itself. It is
"transmitting intelligence" in a sense of externalizing machine states and
"interpreting" in the sense of mechanical reconfiguration of internal parts.

To rediscover the book in the guise of a computational literary artifact means
coming to terms with it as a robot---a device for remote machine control. It
entails seeing through to the simulated nature of the electronic text.
Everything that we know to be true of text in print---from the shape of the
letters to the position of text on a page, to characters, words, sentences,
paragraphs, sections, chapters, and manuscripts, to more abstract categories
like poems, novels, plays, and short stories, to authors, styles, narratives,
and discourses, in short to all textual constructs that have their dimensions
in physical space (and that is all of them), the entire burden of literary
theory---must be reconstructed again as a *simulation*.

Furthermore, it means also gaining awareness of other simulations that are
enacted simultaneously through the device. Where a book is a just a book, the
simulated book fulfills other functions. As a universal Turing machine, the
device has the potential to conjure multiple metaphors. The universal machine
is a machine for making all possible metaphors. It can simulate a book, a
telephone, an alarm clock, a calculator, a typewriter, a censor, a surveyor, a
surveillance system, and otherwise an instrument of governance. Its potential
to simulate other machines is unbounded.

Finally, the very metaphysical nature of Turing machines implies the
irreversible admixture of matter, content, and control. When reading a paper
and cloth book, one can definitively isolate a) the physical properties of
paper and cloth from b) the content of the book and from c) the legal and
political elements governing the production of textuality. To wit: tear out the
copyright notice along with the ISBN number, copy the words into a notebook,
and recycle the paper. The literary device, by contrast, ingests both symbolic
representation and control code through the same input stream. Where images of
governance (like trademark and copyright symbols) *signify*, computed text
*embodies*. Computation enacts control in exactly the sense by which
Wittgenstein suggests to insert a layer of "rules" between symbol and
interpretation, the sense by which Turing imagines computation as symbolic
embodiment, and in the sense carried out through a class of devices for remote
control and communication.

If symbols, something used to represent something else, elicit a type of an
illusion, the universal symbolic machine enacts the ultimate illusion. It
creates a phantasmal image of symbolism itself. The history of computing is
thus a history of symbolism in the broadest possible meaning of the word, which
includes lyric poetry and symbolic logic. The difficult truth for the
contemporary reader is that the computational metaphor, embodied on the level
of the device, resists interpretation by conventional means. Metaphors of
computation frame deep structure affecting basic everyday interaction with
computers. As with all metaphors, nothing is what it seems: to "save" a
document, to "copy" it and to "delete" it, to "surf" or to "browse" the
internet, to "run" a program, the softness of software and the hardness of
hardware, to "turn the page," to "bookmark," to "highlight," and ultimately to
"read a book"---these are all metaphors that obscure the underlying material
conditions of symbolic exchange. The metaphors ingratiate themselves to us in
daily use. With time they disappear from view: invisible metaphors of
invisibility.  When habituated, they alienate us from the symbol. A new wave of
estrangement is needed to rouse it from its metaphorical slumber.

In drawing the history of the book as a universal Turing machine, we observe
the evolution of symbolism into its final and totalizing form. By converting
machine states into symbols, the Turing machine represents the ultimate
negation of matter. It subsumes all lesser mechanisms amenable to
computation---which some would say includes brains and universes.[ln1-brains]
The universal Turing machine has the potential to mediate everywhere, yet,
paradoxically, it's method of "mediation" abstracts from any notion of medium
or intervening substance.

Under the command and control regime of the Turing machine, text loses its
adhesion to the world. Yet it would be a mistake to think of it as wholly
ethereal. The symbol itself, in its rawest form, anchors the Turing machine to
the confines of the physical universe. No matter the transcendental impulse,
the universal Turing machine cannot be abstracted beyond its minimal physical
requirements: "tape," "symbol," "scanned square," "in the machine"
[@turing_computable_1937, 231].[^ln1-inside]

A figure of computation emerges in the dual movement between symbol and
machine: the machine that pushes the symbol towards the ethereal, and the
symbol that pulls the machine back towards earth. This dynamic encapsulates the
bargain at the center of computational media, explored for the duration of the
book. The machine frees symbolic representation from its material confines. The
price of freedom is the very opacity of the material context. Where words etched
in paper or stone constituted a single site for textual activity, the digital
word exists in a simulated environment physically apart from the underlying
material substratum. Freedom reveals itself as a simulation.

[^ln1-google]: "Google's mission is to organize the world's information
and make it universally accessible and useful" (@google_about_2015).

[^ln1-brains]: For the first view see @putnam_minds_1960 and
@fodor_language_1975. For the second view see @deutsch_quantum_1985 and
@dyson_turings_2012.

[^ln1-inside]: Note that these are also minimal physical requirements for
interpretation: the ability to internalize and to externalize symbolically. My
definitions do imply a sort of a dualism, but not between mind and
body---simply between inside and outside, self and other, I and not-I.  This
has been said before in many ways.

[^ln1-normal]: The process of normalization continues today as contemporary
technologies like natural language processing and optical character recognition
struggle to bring non-regularized writing systems under the computational
umbrella.

[^ln1-pop]: See for example  @drucker_digital_2001; @golumbia_cultural_2009;
@marche_literature_2012.

[^ln1-ceruzzi]: See @ceruzzi_computing_2012, 11 who writes that "the modern
computer is a convergence of separate streams of information handling, each
with its own rich tradition of technological history." "One could add other
antecedents such as the development of radio, motion pictures, and photography"
[@ceruzzi_computing_2012, 11].

[^ln1-compete]: "We may hope that machines will eventually compete with men in
all purely intellectual fields" [@turing_computing_1950, 460].

[^ln1-infinite]: A true universal Turing machine would require a tape that is
infinitely long.

[^ln1-davey]: Mike Davey built and displayed a similar instrument at Harvard
University's Collection of Historical Scientific Instruments in 2012. He
writes, "my goal in building this project was to create a machine that embodied
the classic look and feel of the machine presented in Turing’s paper.  I wanted
to build a machine that would be immediately recognizable as a Turing machine
to someone familiar with Turing's work" [@davey_turing_2012].

[^ln1-reading]:The Turing machine in effect gives us a concise minimally viable
definition of "reading" and "becoming aware." Proper reading involves the
appropriate internalization of the symbol, for both human and machine.

[^ln1-cs]: Two separate departments offering competing degrees in software
engineering and computer science is a common occurrence in North American
universities.

[^ln1-caveat]: The institutional distinctions between software engineering and
computer science often hinge on the extent to which the discipline pays heed to
the physical limitations of computing. As usual the situation on the ground is
much more complicated, and the boundaries between software engineering and
computer science are fast eroding. Still, North American students often have
the choice to major in Computer Science or Software Engineering. It would not
be unusual for the one faculty to be located in the School for Liberal Arts and
Science and the other in the School of Engineering. Consider also the two major
professional organizations: Institute for Electrical and Electronics Engineers
(IEEE) and Association for Computing Machinery (ACM). See
@glass_comparative_1992; @parnas_software_1999; @glass_analysis_2004;
@vessey_unified_2005.

