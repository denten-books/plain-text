# Chapter 2: Surface

## Intro

I do not trust the text appearing before my eyes. Wendy Hui Kyong Chun calls
magnetic storage the "enduring ephemeral," which "creates unforeseen
degenerative links between humans and machines" [@chun_enduring_2008, 148]. If
the floating gate transistor,[^ln1-gate] where my text now lives, can be called
the enduring ephemeral, I will call my liquid crystal display, where the text
shows itself, fading persistence. This is not to believe that digital text can
transcend its material contexts. Only that it seems to drift from surface to
surface, beyond the field of vision, in ways that erode trust in the general
permanence of the literary system. If we are destined to dwell on surfaces, I
do not know to which surface to attach my attention: the screen or the floating
gate.

In Chapter One of *Plain Text*, we encountered the book as a device. I traced
the intellectual roots of the literary artifact to several ideas emerging at
the turn of the twentieth century. We saw it first as a formal device: a
technique for defamiliarizing or making strange habituated metaphors. We then
saw it as a literal device, related to the operation of universal Turing
machines. Finally, I argued that Turing machines themselves belong to the
history of the book, both in the lineage of thought about symbolic
interpretation and as mechanisms for their transmission.

Once we see the digital document in all of its forms for what it is, a
computational device, we can begin to come to terms with the simulated nature
of screen textuality. Ask yourself a simple question: Where does text reside?
In print, one can point to the page and be fairly certain of the answer: here,
on the page. Computation complicates matters significantly. One can point to
the screen, yet it would not be enough to say that the text *is* there. The
screen remains in flux. It is a site of temporary projection. The projection
emanates from the storage medium within, passing through multiple filters and
transformations on the way to the screen. We therefore observe the figure
stretch before us across at least two sites of inscription. The sign stretches
and splits, expressed in the configuration of magnetic pulse and circuit state
at one end and in the phases of liquid crystal on screen at the other. Both
locations afford distinct constraints to reading, writing, and interpretation.

Thus when Michael Heim refers to the "ephemeral quality" of the electronic text
or when Pamela McCorduck describes it as "impermanent, flimsy, malleable, [and]
contingent" they identify real-world attributes of digital inscription, at the
site of its projection. McCorduck tells the story of a rabbinate court, which,
when faced with the law prohibiting observant Jews from erasing God's name,
rule that words on the screen are not to be considered as writing, therefore
sanctioning erasure [@mccorduck_universal_1985, 51; also quoted
@heim_electric_1987, 192]. Conversely, when scholars like Johnna Drucker,
Katherine Hayles, and Matthew Kirschenbaum respond to Heim and company with
hardened materialism, they are also rightly describing properties of digital
inscription, but this time at the site of its archival immanence. The two camps
disagree because they speak neither of the same phenomenon nor at the same
site. The former group notices the ephemeral, transcendent state of the
projected word. The latter points instead to the "uniquely indelible nature of
magnetic storage" [@kirschenbaum_mechanisms_2008], to "drives, tapes, and
disks" as the "fundamental physical support" and "material substrates of
computing" [@drucker_performative_2013]. The hard drive and the screen
partition the sign between surface and depth, projection and archive.

Form and content lie flat on the printed page. Print interfaces are paper thin,
we might say. Ink adheres to paper in the way that pixels do not to screens.
The splintered sign complicates the traditional structuralist distinctions
between form and content. It occupies at least two distinct sites, each
entailing drastically differing accordances for reading, writing, and
interpretation. Were we to untangle the tightly wound coil of the circuit, we
would find ample distance between the hard drive and the screen. Where print is
flat, computed text resides at several levels and along multiple dimensions
[@halyes code is flat].

How did this multiplicity come to be? And what effect does it have on the life
of the mind? The purpose of this chapter is to open space between the visible
sign and the archived inscription. The structure of textual artifacts---from a
simple leaflet to a novel in multiple volumes---has remained remarkably stable
since the invention of movable type. One rarely finds a sentence that spans
several paragraphs, for example. Nor would a contemporary reader expect to find
pages of different length in the same tome. Long-standing historical
conventions guide the production of printed text. Semantic and decorative units
on a page exist within a strict hierarchy, so familiar to us as to become
almost invisible. No book of serious non-fiction will be typeset in cursive
font, for example. But unless something out of the ordinary attracts attention,
the reader will tend to gloss the "inconsequential" details of formatting in
favor of content. The material contexts of a well designed book fade from view
during reading.

For a few decades after the advent of magnetic storage media but before screen
technology, the outward shape of the sign disappeared altogether. It is
difficult to fathom now, but at the time after the introduction of magnetic
tape in the 1960s but before the wide-spread advent of cathode ray tube
displays in the 1980s, the typewriter operator and the computer programmer were
often expected to manipulate text blindly. Where the page or the punch card
gave immediate visual feedback, the combination of magnetic tape and screen
separated input from output. The word could be "processed" or altered with
codes that controlled attributes like indent size or justification *before*
committing ink to paper. A paper describing the popular IBM Magnetic Tape
Selectric Typewriter (MT/ST) introduced in 1964 describes the novelty of the
system as follows:

> It could be emphasized for the first time that the typist could type at
> "rough draft" speed, "backspace and strike over" errors, and not worry about
> the pressure of mistakes made at the end of the page [@may, 742].

The IBM Magnetic Tape Selectric Composer (MT/SC) further added a "programmable
control" unit to separate the input from the output. Final printing would be
accomplished by:

> mounting the original tape and the correction tape, if any, on the
> two-station reader output unit, setting the pitch, leading, impression
> control and dead key space of the composer unit to the desired values, and
> entering set-up instructions on the console control (e.g., one-station or
> two-station tape read, depending on whether the correction tape is present;
> line count instructions for the format control and space to be left for
> pictures, etc.; special format instructions; and any required control codes
> known to be omitted from the input tape. During printing, the operator
> changes type elements when necessary, loads paper as required, and makes and
> enters hyphenation decisions if justified copy is being printed [@bishop,
> 382].

The tape unit and the control unit thus intervene between the keyboard and the
printed page. The "final printing" combines roughly the "prepared copy" with
"control and reference codes" and "printer output" [@bishop; @may]. The
materials from the time often speak of three distinct human operators that
could be responsible for each stage of the production: one entering the copy,
one specifying the control codes, and one responsible for handling the paper
output. The machine operators could hypothetically work in isolation from one
another. The typist would see only elements of the copy; the typesetter or the
controller only formatting and control codes; and the printer only the
interpolated results.

![DIAGRAM from MT/SC]

Researchers working on these early IBM word processing machines saw the
separation of print into such distinct strata as one of their major
contributions to the history of print writ large. A consultant writing for the
*IBM Journal* in 1968 imagines the "evolution of composition" that proceeded
from handwriting, to wood engraving, movable type, letterpress, and, finally,
to the IBM MT/SC. "The IBM Selectric Composer provides a new approach to the
printing process in this evolution," he writes. He concludes to say that the
IBM Composer finally empowers the writer to once again write books "without the
assistance of specialists" [@frutiger, 10]. Marketing language aside, the
separation of the sign from its immedeate material contexts constituted a major
milestone in the history of writing and textuality.

In this chapter, I would like to give a historical account of a letter's
passage from paper to pixel. The movement proceeds in three stages, as
illustrated by three specific devices: first the mechanization of type reached
its apogee in the telegraph at the end of the nineteenth century. With the
advent of telegraphy, "content" meant for humans began to intertwine with
"control codes" used to operate machines remotely. Second, where the ticker
tape and the punch card were still legible without specialized "reader"
devices, the invention of magnetic tape submerged the mixed stream of letters
and control codes into an inscrutable substance. Finally, by the mid-twentieth
century, the screen emerged to simulate a measure of legibility lost in the
transition.

## WYSINAWYG (What You See Is Not Always What You Get)

Where does computed text reside? I offer the following three historical
preconditions for digital textuality. They are not meant as history, but rather
as signposts to mark the journey ahead. The schema proceeds roughly as follows:
first, content and control couple at the visible surface of removable storage
media (ticker tape and punch card); second, inscription splits into input and
output, retreating into magnetic storage to reemerge at last on the screen, in
the same guise, but also, as we suspect, somehow transformed: less solid and
concealing something beneath the phantasmal shell of its former
appearance.[^ln1-denning]

As we embark to explore the consequences of computed, simulted text, I propose
we keep the following three landmark mechanisms in view as signpost along our
journey: Goldberg's Controller, the IBM MT/SC, and Engelbart's Time Fob. In the
first of these, text structure and machine control lie before us for
inspection. The second one is mute: a black slate. The last of these belongs to
what Peter Denning calls the "third generation" of computer systems---an
assemblage of storage, input, and output technologies that continue to shape
the contemporary human encounter with text today. These devices tell us a story
of a fracture.  Through them, a part of the sign fades from view as an
arrangement of magnetic charge and floating gate. Another part appears as
flicker of the cathode ray and the flow of the liquid crystal.

### A. Removable storage media and automation, 1725--1964.[^ln1-loom]

"You must acknowledge that this is readable without special training," reads
the schematic illustration to a Goldberg 1911 patent, simply titled
"Controller." "My invention relates to all controllers," Goldberg writes.
Furthermore, the object of his invention is "to provide a mechanism operable by
a control sheet which is legible to every person having sufficient education to
enable him to read." Goldberg illustrates his invention in attaching to his
patent "a control sheet in which the control characters are in the form of the
letters of the ordinary English alphabet"  [@goldberg_controller_1915]. Rather
than using ticker tape, Goldberg uses perforations that form letters. On
Goldberg's control sheets, the language of machines and the language of humans
coincide.

![Goldberg's Control Cards [@goldberg_controller_1915].](images/control-2.png)

The Controller never caught on, but the patent makes it clear that Goldberg,
among others, was aware of the problem: the mechanization of type, automation,
and remote control required specialized training. With the advent of the
automated telegraph, content meant for people was now being intermixed with
machine-controlling code. To combat mutual unintelligibility, Goldberg imagines
using cards, perforated in the shape of the English alphabet. Besides carrying
(human-readable) content, the perforations do "double duty" to mechanically
manipulate the machine's "blocks," "handles," "terminal blades," and "plungers"
[@goldberg_controller_1915]. Early paper-based storage media, from Morse
code-based ticker tape systems, to the telegraphs of Hughes and Baudot, and to
punch cards that powered weaving looms, player pianos, and census tabulators
coupled message and control. The era of ticker tape punch cards can be thought
to end with the mass-market introduction of IBM's Magnetic Tape/Selectric
Typewriter in 1964.

### B. Magnetic tape, 1888--1968

"Historically unforeseen, barely a thing, software's ghostly presence produces
and defies apprehension," Wendy Chun writes in her *Programmed Visions*, an
influential monograph that continues to shape the field of software studies.
She quotes several prominent computer scientists and media historians to the
same effect. But what gives software its ephemeral quality? Embossed onto
ticker tape or punched into the card, early software protrudes through the
medium. In the age of the telegraph, the largest barrier to the comprehension
of software was encoding. But once the cipher is known and the format
identified, the inscription makes itself visible to view. Early programmable
media could hardly be called ephemeral or immaterial. Anecdotes circulate in
the digital humanities circles of Father Roberto Busa, an early (post-WWII)
pioneer in the field of computational philology, carting his punch cards around
Italy on a truck.[^ln3-busa] Code before its electromagnetic period was
burdensome, fragile, unwieldy, and, most of all, visible.

![IBM Mag Card II, introduced in 1969 for use in the Magnetic Card/Selectric
Typewriter (MC/ST) in 1969. "A simple relationship could be maintained between
a typed page and a recorded card" [@may_ibm_1981, 744]. Image by Pointillist
under GNU Free Documentation License, Version 1.2.](images/ibm-card.png)

The principles of magnetic recording were developed by Oberlin Smith (among
others), the American engineer who also filed several inventions related to
weaving looms at the end of the nineteenth century. In 1888, inspired by
Edison's mechanical phonograph, Smith made public his experiments with an
"electrical method" of sound recording using a "magnetized cord" (cotton mixed
with hardened steel dust) as a recording medium. These experiments were later
put into practice by Valdemar Poulsen of Denmark, who patented several
influential designs for a magnetic wire recorder [@smith_possible_1888;
@poulsen_method_1900; @engel_1888-1988_1988; @thiele_magnetic_1988;
@daniel_magnetic_1998; @vasic_coding_2004].

In 1964, IBM combined magnetic tape storage with its *Selectric* line of
electric typewriters, introducing the Magnetic Tape Selectric (MT/ST) line of
typewriters to the mass market. Writing for the *Encyclopedia of Library and
Information Science* in 1992, Daniel Eisenberg mentions the MT/ST as one of the
first word processors, defined by the ability to record strokes and to print
them onto paper *as a separate operation* [@eisenberg_word_1992]. The
separation of input and output allows for word processing as such. An article
in the *IBM Journal for Research and Development* explains that the real
significance of the MT/ST workstation was in the introduction of new "power
typing" technologies: "For the first time the typist could type at 'rough
draft' speed, 'backspace and strike over' errors, and not worry about the
pressure of mistakes made at the end of the page" [@may_ibm_1981, 742].

We may think of word processing as a temporal extension of the page. Words on
magnetic storage media begin to exist in the ephemeral state, giving the typist
an opportunity to edit and emend *before* commitment to paper, in its immutable
form, and as a separate operation, removed from the immediate process of
inscription. The very invention of word processing thus corresponds to the
decline of text into ephemera. What was visible through a hole punch on ticker
tape, was now submerged into tape. The tape no longer afforded human legibility
nor comprehension. Encoding used by MT/ST retained the familiar (from the
earlier sections) underlying structure (7-bit encoding, in this case) which, on
tape, ceased to be recoverable by the naked eye. The inscription lay literally
beyond (human) sense. We lack the perceptual apparatus to perceive "magnetic
domains" and "polarities"[^ln3-magnet] that take place of visible alphabets.
Magnetic storage remains, for all unassisted intents and purposes, a black
slate.

### C. Screen, 1968--today

By decoupling input and output, magnetic storage and solid state media afford
the injection of time and space, in arbitrary intervals, between the process of
inscription and comprehension. Content, coupled with control code, sinks
beneath the matte surface of electrical charge. The final movement in the
emergence of automated discourse reintroduces the illusion of immediacy into
the process of inscription. Text, invisible in its material substratum,
reappears on the screen, but, crucially, it no longer corresponds to its mirror
inscription. This property is as perilous as it is liberating: perilous,
because the flows of power and control can now be submerged under the
shimmering surface of the screen, and liberating, because loosely coupled to
their material substratum texts become both more fluid and more portable.
Plainly put, the systematic barriers to copying, sharing, exchanging, editing,
remixing, and disseminating texts are reduced to a minimum.

Ersatz skeuomorphism (between disk storage and screen image) leads to the
reception of digital text as an ephemeral artifact. With the illusory role of
the screen in mind, I propose 1968 as the year in which the contemporary
textual condition takes its present form. On December 9, 1968 Douglas
Engelbart, then founder and primary investigator at the NASA- and ARPA-funded
Augmentation Research Center lab at the Stanford Research Institute, gave what
later became known colloquially as "the mother of all demos
[@tweney_mother_2008]" before an audience of roughly one thousand or so
computer professionals attending the Fall Joint Computer Conference held at the
Convention Center in San Francisco [@rogers_demo_2005]. The demo announced the
arrival of almost every technology prophesied by Vannevar Bush in his
influential 1945 piece for *The Atlantic* [@bush_as_1945]. Speaking a little
over an hour,  through a headset, in a prerecorded address, Engelbart features
functional (live) prototypes of the following: graphical user interfaces, video
conferencing, remote camera monitoring, links and hypertext, version control,
text search, image manipulation, windows-based user interfaces, digital slides,
networked machines, mouse, stylus, and joystick inputs, and "what you see is
what you get" (WYSIWYG) word processing.

!["NOW IS THE TIME FOB." Schematics for a "display system"
[@engelbart_x-y_1970].](images/engel.png)

In his report to NASA, which sponsored research on "intellect augmentation"
along with DARPA, Engelbart describes his lab as a group of scientists
"developing an experimental laboratory around an interactive, multiconsole
computer-display system" and "working to learn the principles by which
interactive computer aids can augment the intellectual capability of the
subjects" [@engelbart_human_1969, 1]. Cathode Ray Tube (CRT) displays were
central to this research mission. In one of many patents that came out of
"intellect augmentation" laboratory, Engelbart pictures the "display system" as
a workstation that combines a typewriter, a CRT, and a mouse. The system is
frozen in mid-action, with the words "THE TIME IS NOW FOB" prominently
displayed on the screen. Although Engelbart does not explain the message, the
system's user is evidently in the process of editing a sentence and about to
correct the nonsensical FOB into a FOR. Engelbart writes, "One of the
potentially most promising means for delivering and receiving information to
and from digital computers involves the display of computer outputs as visual
representation on a cathode ray tube and the alternation of the display by
human operator in order to deliver instructions to the computer"
[@engelbart_x-y_1970].

The CRT closes the circuit between human and machine, with a few caveats. In
practice, the short-lived screen-less word processors (like the IBM MT/ST)
necessitated for the cognitively arduous task of continuously keeping the
underlying document structure in the mind's eye. The CRT lifts that burden by
unfolding the structure topographically, allowing for spatial navigation along
the document---restoring, in a sense, the natural affordances of print. Data
becomes visible again. Moreover, represented in the shimmer of the cathode ray,
it attaches itself lightly to the retina. Users trying out this way of writing
for the first time report that the screen liberates them from the material
confines of print textuality. One user, possibly Engelbart himself, writes the
following:[^ln3-follow]

[^ln3-follow]: I reproduce the text verbatim and preserving the line breaks,
since formatting is an important part of the reported experience.

```
    1B2B1 "To accommodate and preserve a thought or
    piece of information that isn't related to the work
    of the moment, one can very quickly and easily
    insert a note within the structure of a file at such
    a place that it will nether get in the way nor get
    lost.

    1B2B2 "Later, working in another part of the file,
    he can almost instantly (e.g. within two seconds)
    return to the place where he temporarily is storing
    such notes, to modify or add to any of them.

    1B2B3 "As any such miscellaneous thought develops,
    it is easy (and delightful) to reshape the structure
    and content of its discussion material.
```

Engelbart, interested in collecting empirical phenomenological accounts of the
system, records what must count as several of the most evocative passages to
appear on the pages of a NASA technical report. In the "Results and Discussion"
section an anonymous user continues to report:

```
1B4 "I find that I can express myself better, if I can
make all the little changes and experiments with wording
and structure as they occur to me." [Here the user
experiments a little with using structural decomposition
of a complex sentence.]
```

A deconstruction indeed follows, as the author begins to deviate from the
conventions of the technical report. The numbered passages, and unexpected
enjambment, heightens the staccato quality of the prose, which at times reaches
towards the lyric:


```
    1B4A "I find that I write faster and more freely,

        1B4A1 "pouring thoughts and trial words on the
        screen with much less inhibition,

        1B4A2 "finding it easy to repair mistakes or wrong
        choices

            1B4A22 "so while capturing a thought I don't
            have to inhibit the outpouring of thought and
            action to do it with particular correctness,

        1B4A3 "finding that several trials at the right
        wording can be done very quickly

            1B4A3A "so I can experiment, easily take a look
            and see how a new version strikes me--and often
            the first unworried attempt at a way to express
            something turn out to be satisfactory, or at
            least to require only minor touch up.

        1B4A4 "Finding that where I might otherwise
        hesitate in search of the right word, I now pour out
        a succession of potentially appropriate words,
        leaving them all the while the rest of the
        statement takes shape. Then I select from among
        them, or replace them all, or else merely change the
        list a it and wait for a later movement of the
        spirit.
```

When input and output coincide in time, as they do on paper, mistakes can be
costly. The writer must commit to making an inscription and, once made, the
inscription gains permanence in a way that is difficult to correct. One can
erase, removing a layer of physical material, or cover up, adding a layer of
white ink to repair the damage. Engelbart's anonymous writer reports a feeling
of freedom from such commitment to physical medium. He or she can simply
"backspace" and start over. The contemporary reader may take such things for
granted now, but imagine trying to write in that way for the first time.
Writing "comes easy," becomes "uninhibited," and it "pours out" experimentally.
Rather than manipulate language mentally, the writer "pours" the words onto the
screen and then "selects" the right one, without hesitation. The highly
hierarchical and blocky paragraph structure, along with its repetitive refrain,
"finding" and "I find that," gives the prose a hypnotic drive forward, which
matches the reported experience of liberation. Anonymous continues:

```
    1B4B "I find that,

        1B4B1 "being much more aware of

            1B4B1A "the relationships among the phrases of a
            sentence,

            1B4B1B "among the statements of a list,

            1B4B1C "and among the various level and members
            of a branch,

        1B4B2 "being able

            1B4B2A "to view them in different ways,

            1B4B2B "to rearrange them easily,

            1B4B2C "to experiment with certain special
            portrayals,

                1B4B2C1 "not available easily in unstructured data

                1B4B2C2 "or usable without the CRT display,

        1B4B3 "and being aware that

            1B4B3A "I can (and am seeking to) develop still
            further special conventions and computer aids

            1B4B3B "to make even more of this available and
            easy,

        1B4B4 "all tend to increase

            1B4B4A "my interest and experimentation

            1B4B4B "and my conviction that this is but a
            peek at what is to come soon.
```

The passages are too contrived to be spontaneous admissions of phenomenological
experience. Despite the experimental structure, the passages contain a
well-formed rhetorical message advancing key elements of Engelbart's research
program, which aimed to develop new data structures in combination with new
ways of displaying them. Yet I cannot help but be carried away by the fluency
of the prose and by the sheer audacity of the project. Here's someone who has
not only glimpsed the future, but has also brought it into being. The
contemporary author can drag and drop passages around with more facility, but
he has not himself structured his cognitive environment. In Engelbart's terms,
someone else has augmented the author's intellect, in ways that may or may not
fit the individual psyche. That feeling of effortless textuality cannot
therefore be taken at face value, by the unreliable phenomenological accounts
alone. To bring his system into being, Engelbart convened what he called a
"bootstrap community," which through recursive self-improvement could lift
itself up towards a smarter, more efficient, and as the report's lexicon
betrays, a more human way of working. To accomplish this, the group crafted
novel instruments for input and output. They wrote new programming languages,
compilers to interpret them, and debuggers to troubleshoot. They invented word
editors and format control languages. Here's how Engelbart diagrams a *part* of
his text-manipulation language in the same report:

!["State--chart portrayal of part of text--manipulation control language"
[@engelbart_human_1969, 36].](images/engel-edit.png)

The diagram shows much attention to the detail of and love for the writing
craft. But there is also much complexity. It is near impenetrable. In building
their own tools, Engelbart's team lifted themselves up by the bootstraps. But
it was not the machine that lifted them up---it was the process of creating the
machine. The very metaphor of bootstrapping suggests the impossibility of using
one's bootstraps to pull others out of the Platonic cave. As a side effect of
that effort, text, before readily apparent on the page, now enters a complex
system of executable code and control structure. The perception of material
lightness of textual being comes at the price of legibility. Would new authors
find the same ease in the complication of the mechanism? I suspect not unless
they become an active part of a "bootstrapping community" of their own.

[^ln1-brain]: We will later entertain the (real) possibility of
non-representational communication, suggested by early experiments in direct
brain-to-brain or brain-to-machine interfaces.

## Document Object Model (DOM)

It is in this tripartite sense of matter, form, and idea that one can best
understand the structure of modern "digital" documents. In the language of the
Document Object Model, the literary-theoretical concept of "form" can mean both
"class" and "instance" (object-oriented programming), or "set" and "object"
(set theory), or "type" and "term" (type theory). Although literature in
computer science rarely operates in the mode of intellectual history,
computer-aided text editors internalized a model of document structure
remarkably similar to the one suggested by Hegelian aesthetics, and in terms of
physical (media), form (formatting), and content (text) levels of analysis. The
Document Object Model weaves the language of the Hegelian universal into the
fabric of modern computing.

Describing *EDIT*, one of the first editors designed for the GE635 36-bit
mainframe computers in use at Bell Labs in 1968, Arthur Kaiman writes: "The
publication editor is divided into three related sections, the document layout
facility, the editing facility, and the printing facility"
[@kaiman_computer-aided_1968, 66]. The "layout," in Kaiman's vocabulary,
contains such things as justification, indentation, and spacing. These
"primitive requests" can be combined to describe more complex "structures of
the printed text." The creators of *QED*, another influential early text editor
(created for the SDS-930 time-sharing system at Berkeley) similarly encourage
the user "to think in terms of structure" of the text. Both *QED* and *EDIT*
begin to separate content and formatting for later recombination and imprinting
onto external storage media. Kaiman explains that "the user types the document
layout file and the text file, then produces a proof or master copy of the text
by printing the text according to the directions of the layout file. The text
file contains layout marks to be interpreted by the layout file." "Text," in
this schema, constitutes content meaningful only to the user, whereas layout
contains some elements meaningful to the human and some elements as code
instructions intended for device control. The notion of "formatting" therefore
mediates between the logical (semantic) and layout (stylistic) structural
representations.

![EDIT Document Model, 1968 [@kaiman_computer-aided_1968, 66].](images/edit.png)

A seminal paper in the field of structured documents proposes the following
model. First, "a document is an object composed of a hierarchy of primitive
objects," write the authors Futura, Scofield, and Shaw. We have two ideas from
the start: composability and hierarchy. A document is a thing made up of other
objects, like sentences and paragraphs. Furthermore, these things stand in a
hierarchical relationship to each other. Paragraphs contain sentences, and not
the other way around, for example.

Second, "each object is an instance of a class." Document level classes include
"letters," "theses," "recommendation," and "papers for a particular journal."
Lower-level classes include sections, paragraphs, footnotes, and so on.

Finally, "objects are further classified as either abstract or concrete." By
this, the writers mean abstract or "logical" objects, like words and ideas. In
describing FORMAT, an important early (circa 1968) "general-purpose" text
processor (written in FORTRAN IV for OS/360 devices), George Berns describes
the program's input as "free-form" (literally, free of form) in that it is
"entirely free of positional restraint [@berns_format_1968, 85;
@berns_description_1969, 141]." Text free of positional restraint, in that way,
can be described in terms of "content," in contrast to "formatted" objects made
"concrete," that is positioned in "one or more two-dimensional *page spaces*
and represent[ing] possible formatted images of abstract objects
[@furuta_document_1982, 417-19; @shaw_model_1980]." The concrete object, in
other words, gives physical shape, layout, or style to the instantiation of
abstract universal classes like paragraphs and sentences. Concrete objects are
abstract paragraphs and sentences "laid out" in page space.

Here is where things should get interesting for a scholar of textuality. The
Document Object Model further gives rise to three "operations," tied to the
"domain and range" of its constituent objects. *Editing*, in this model,
comprises operations that move from abstract to abstract, or, from concrete to
concrete domains.

+------------------------+--------------+-------------------------------+
| Operation              | Type         | Example                       |
+========================+==============+===============================+
| abstract to abstract   | Editing      | spelling correction \newline  |
| concrete to concrete   |              | move (data) table   \newline  |
|                        |              |                               |
+------------------------+--------------+-------------------------------+
| abstract to concrete   | Formatting   | apply font   \newline         |
|                        |              | break into pages \newline     |
+------------------------+--------------+-------------------------------+
| concrete to abstract   | Recognition  | optical character             |
| \newline               |              |   recognition  \newline       |
|                        |              | page layout analysis \newline |
+------------------------+--------------+-------------------------------+
| concrete to output     | Viewing      | print to paper \newline       |
| \newline               |              | publish to web \newline       |
+------------------------+--------------+-------------------------------+
| concrete to storage    | Filing       | save file    \newline         |
|                        |              | shelve book                   |
+------------------------+--------------+-------------------------------+

Table: Object operation types under the Document Object Model
[@furuta_document_1982, 419-20].

Spelling correction, for example, constitutes an editing manipulation where
abstract objects are modified into other abstract objects. Moving footnotes to
endnotes, or shifting data tables around the document would count as editing of
the "concrete to concrete" type. The authors define *formatting* as giving
concrete shape to ideas in the transformation between abstract and concrete
objects. Italicizing a word, for example, gives the idea of "emphasis" a
slanted form. The act of breaking a document into pages gives shape (and a
specific number of lines, for example) to the idea of a page.

The authors hint at, but do not discuss the opposite movement, from "concrete
to abstract" entities, as would be done in the process of optical character
recognition (OCR). An important part of the digitization process, OCR "lifts"
ideational content from the page image. Without OCR, common document formats
like `.pdf` and `.tiff` therefore remain *merely visual representations*. They
do not, at that stage, contain text or "abstract objects" as such. They are
just pictures. Similar to how humans must "read" a text first in order to
understand it, OCR attempts to "recognize" textual content from the image as a
first step to further manipulation. Leaving aside the question of machine
"understanding," recognition in this case implies more narrowly the
conversation of image into text. This implies also that textuality occupies a
distinct and privileged category in document epistemology, from the point of
view of the machine. Another way to think about machine text would be to
describe "images" as one type of "internal data structure" and text as another,
more "structured" and "more internal," mode of representation. Consider that in
the hierarchical Document Object Model images can contain text, but text
cannot contain images. Text, in that sense, lies at the innermost location in
series of nested "outer" containers. Lacking a model of "comprehension" or
"understanding," the Document Object Model merely posits text as "content" only
in the sense of it being the "innermost" object of recognition.

The "recognition" of characters does not, however, fully capture the variety of
abstract document objects, which besides letters and words include paragraphs,
tables, titles, and footnotes. These also count as "content." It is essential
therefore to know "where text resides on the page," since some elements of
positioning in themselves can carry meaning. For instance, proper names could
carry different connotations depending on their location in the text. A name in
the "author field" means something distinct from any other name mentioned in
the body of the document. Lawrence O'Gorman, an influential researcher in the
field of document image processing, calls the recognition of this sort of
object, at the intersection of concrete and universal, "document lay-out
understanding," which consists of "functional labeling of blocks [...]
distinguished in some way by their physical features (such as by font size) and
by the 'meaning' of the block [@ogorman_document_1993, 1162-63;
@ogorman_document_1995, 82-99 (in the reconstructed edition)]." But note also
that document layout (alternatively "formatting" or the arrangement of
"concrete objects") could also incorporate meaningless (to humans) structures,
such as the incidental "rivers" of empty space formed between the words. That
sort of concrete structure goes "unrecognized" because it does not correspond
to any abstract objects.

![Method for extracting document structure based on "nearest-neighbor clustering
of page components" [@ogorman_document_1993, 1164].](images/docstrum.png)

Finally, the Document Object Model defines *viewing* as the movement from
concrete objects to output device. This could include printing the document
onto paper, or publishing it online, for example. It is at this moment that the
full weight of Hegelian "universal concrete" makes itself known. The "concrete"
object in the Document Object Model is still only a *description* of the
two-dimensional space and represents some "possible formatted images of
abstract objects."[^ln3-dom] To repeat: the concrete object represents
"possible" formatted images, and not yet actual formatted images! To actualize
materially, the document must be fixed and flattened back out onto a medium
such as a screen or paper. These media have actual dimensions. In this way, a
footnote placed at the bottom of the page at the level of concrete object can
then be rendered at the bottom of an A1 (841mm × 1,189mm) size piece of paper
or at the bottom of a much smaller A4-sized sheet (210mm × 297mm).[^ln3-iso216]

In yet another formative paper in the history of contemporary textuality, Brian
Kernighan and Joseph Ossanna describe TROFF, a text processor written circa
1973 for the PDP-11 outputting to Graphic Systems Cat typesetter. In 1979,
Kernighan reports modifying the original program to produce output for a
greater variety of typesetters. Kernighan explains, "TROFF produces its output
in a device-independent form," and its output "must be processed by a drive for
that device to produce printed output" [@kernighan_troff_1992].

This stage flattens out the layers of ideas and visual style, to render them
and to make them visible on screen or page [@furuta_document_1982, 419-20;
@kimura_structure_1984]. Similar to Hegel's "universal concrete," the
"formatting layer" in the Document Object Model bridges the gap between ideas
and matter. Formatting is where ideas connect to physical shape. This is a most
delicate operation, for in giving shape to abstract ideas formatting does
something more notable than mere application of visual style. Formatter
designers from TROFF to FORMAT consistently describe their programs in explicit
terms of instrumental control. Berns, for example, explains that "text control"
as implemented in FORMAT aims to accomplish four "basic" tasks: "to read the
input, to interpret and convert the input as required; to keep the document
flowing smoothly from line to line, column to column, and page to page, unless
otherwise instructed, and to break this automatic flow as directed"
[@berns_description_1969].

Because formatting governs both meaning-carrying and purely decorative
elements, text control can involve operations like "replace word," "make
invisible," or "insert file." These commands intertwine with "free-form"
abstract and ideational content at the formatting level, to come into being in
the "viewing" stage of text processing, where the layers flatten across "a
two-dimensional space" in view of the user. SCRIPT and the related Generalized
Markup Language (GML) developed in the late 1960s by IBM (originally for use on
the CP67/CMS time-sharing system), and now at the basis of ubiquitous XML and
HTML markup languages through ISO 8879, describes a number of such text
transformations that occur to "generate the proper output form." In formatting,
SCRIPT represents the "logical topology" of text in its "canonical form" to
produce an "intermediate data structure," which it then "'unfolds' all at once"
by "'peeling' the data structure one level at a time" [@madnick_script_1968,
97]. As plain text, text control, and user command flows intertwine, the
structure of data on the disk no longer corresponds to what is visible at the
level of user terminal or line printer. Unlike many of the modern text editors,
SCRIPT, TROFF, and FORMAT make all of the laminate components in their
onion-like layered structure available to users for examination. But as we will
see shortly, the condition of complete system visibility persists only for a
short period in history. Once incorporated, the Document Object Model gains a
measure of opacity and even legal protection from "unauthorized access" to
protected innermost document layers.

Whatever model of semiotics one subscribed to in the late 1960s, the DOM fixed
the shape of the sign in accordance to emerging technology. The document object
model continues to structure contemporary text in all its forms: from print
typesetting software to web pages. It gives the material basis to the
conditions of contemporary text production.

!["System Command and Data Flow." Data structures at "disk file" level do not
necessarily correspond to text structures at "user terminal" or "line printer"
levels [@madnick_script_1968, 98].](images/script.png)

[^ln3-dom]: See @furuta_document_1982, 418: "Concrete objects are defined over
one or more two dimensional page spaces and represent possible formatted images
of abstract objects."

[^ln3-iso216]: A series of paper sizes are governed by the International
Standard ISO 216. In the Imperial System these equate to 33.1in × 46.8in and
8.27in × 11.7in respectively
[@international_organization_for_standardization_writing_1975].

## Malicious Code Injection (Conclusion)

In presenting canonical models of document structure, it is my hope to convince
the reader of the very real and literal sense of depth manufactured into the
structure of the contemporary Document Object Model. This includes print,
because even in that mode, publishing practices today rely on some of the same
machinery described in this chapter.

The gap between input and output is what gives rise to the ephemeral quality of
digital text. Temporary storage media located on the way from keyboard to page
or screen allows for rapid and frequent remediation. It keeps the ink in motion
unattached to a "sticky" medium like paper. However, the spatial elongation of
the sign also comes at a cost. Submerged in the passage between keyboard and
screen or paper, the inscription passes from view. In its ephemeral "liquid"
form it is also no longer legible to the naked human eye. It reappears again on
the screen or page already "processed," that is, altered by the intervention of
the "control unit." Writing or reading on a device can thus no longer remain a
solitary activity. Machine operators far removed from the site of
interpretation intervene to mediate the encounter between reader/writer, and
text.

The consequences of that intervention are immense. With time, supplemental
"control characters" designed to format documents fused with programming
languages, capable of generalized device control. Technological and legal
fictions rise to restore a measure of "stickiness" to text in its ephemeral
form. For example, manufacturers commonly embed digital rights management
circuits into video streaming devices to artificially limit the duplication of
broadcast material. Similarly, electronic book sellers often prevent readers
from copying and pasting words on the page. Such measures mimic some of the
constraints associated with static, paper-and-ink-bound media regimes.
Essential for the practices of unencumbered critical thought, control
structures exist in the hidden gap between the two parts of the splintered
sign. Ultimately, the "control" layer is capable of affecting more than print
design. It shapes the very structure of interpretation. In the language of the
Document Object Model, the formatting layer contains the essence of "machine
control." Long a marginal concept in literary theory, formatting is therefore
central to the practice of computational hermeneutics. Far from mere
inconsequential embellishment, formatting governs the interface between meaning
and matter, thought and page. It has the capability to embellish, to obscure,
to censor, to govern, and to emend.

The attached documents illustrate my thesis in practice. In the first image the
reader will find a visual "dotplot" representation of Laurence Sterne's *The
Life and Opinions of Tristram Shandy*, in plain text (`.txt`) file format. To
produce the image, I use the Helfman's self-similarity dotplot approach. Dotplots,
as Helfman explains, "reveal similarity structures in data regardless of format
and in text and software regardless of language" [@helfman_dotplot_1996]. They
can be used for authorship identification, plagiarism detection, or to find
similarity in genetic material. The following, is a simple dotplot from
Shakespeare:

+----+---+---+---+----+---+---+
|    |to |be |or |not |to |be |
+====+===+===+===+====+===+===+
|to  | • |   |   |    | • |   |
+----+---+---+---+----+---+---+
|be  |   | • |   |    |   | • |
+----+---+---+---+----+---+---+
|or  |   |   | • |    |   |   |
+----+---+---+---+----+---+---+
|not |   |   |   | •  |   |   |
+----+---+---+---+----+---+---+
|to  | • |   |   |    | • |   |
+----+---+---+---+----+---+---+
|be  |   | • |   |    |   | • |
+----+---+---+---+----+---+---+

Table: "Six words of Shakespeare." @helfman_dotplot_1996

When applied to raw, binary data, self-similarity plots can be used to study
data structures, to identify security threats, and to reverse engineer unknown
file types. Note that, at this level, we are not observing patterns of meaning
(as repetition of words or word clusters), but rather structural patterns in
the underlying bit structure. We cannot tell from the image what these types
mean, only that they are structured in a particular way. Structure, in this
sense indicates architecture by human hand. We expect random, encoded or
encrypted, data to render as undifferentiated patternless noise. Different file
formats, like the common `.docx` and `.mobi` will therefore leave a
recognizable signature, even when corrupted. The sparse topography of the
`.txt` file in the first image indicates a relative paucity in bit types. Plain
text formats are limited to human-legible UTF-8 or ASCII character sets (used
to to encode the `.txt` file). The square on the lower right likely represents
lower case letters, with the other two squares showing capitals and
punctuation.

The second image (Fig. 12) shows the same novel encoded into the popular
Mobipocket (`.mobi`) book format, used to store books on an Amazon Kindle
device, for example. While the plain text signature is still present, other
structures now also come into view. These are not human-legible under closer
examination (using a hex-editor for example) because the data is encrypted. The
plain text characters remaining comprise snippets of code, and some light
header and footer information, identifying the file to reader applications.

To produce the third image (Fig. 13), I encode the plain text version of the
novel into the Portable Document Format (`.pdf`), another commonly circulated
binary format for document storage. In an additional step, I use code injection
techniques outlined in @rahman_getting_2010, @stevens_malicious_2011, and
@maiorca_looking_2013 to introduce a malicious script into the header of the
file. Depending on the version of the reader's Adobe Acrobat Reader, the code
will execute when opening the document, with the potential of causing
significant corruption to the system. The injection is clearly visible in the
image, manifesting as a "cavity" of un-encrypted characters. Steps
could be taken to further mask the malicious script, blending it with the
background encrypted bit structure (shown as speckled noise), which would make
the injection more difficult to detect.

!["Binary file structure I." Laurence Sterne's *Tristram Shandy*, in `.txt` format.
Unaltered.](images/txt.png)

!["Binary file structure II." Laurence Sterne's *Tristram Shandy*, in `.mobi` format.
Unaltered.](images/mobi.png)

!["Binary file structure III." Malicious code injection into the text of Laurence
Sterne's *Tristram Shandy* in `.pdf` format. Cavitation indicating presence of
injected code.](images/pdf.png)

In conclusion, I do not mean to imply that the "closest possible" reading of
this sort, at the circuit and magnetic storage level, will somehow come to
supplement reading at the surface for meaning and representation. Microanalysis
is meant to complement close reading: giving it proper scope in time and space
for its operation. But reading at the surface alone also risks losing sight of
the naked struggle for power and control at the device level. The machine *can*
determine the message when unchecked. In these conditions, reading without
depth may struggle to even locate its object of study, as surface
representations change dynamically, tailoring themselves to fit the reader's
mood, to match the environment, or to please some remote censor. Best, Marcus,
and Sontag are right in treating claims to symptomatic reading with suspicion,
as claims to power. The reader of depth divines secret knowledge, with or
without merit, creating an imbalance of interpretation. Critical reading in all
dimensions must therefore begin with the ethics of mutual legibility. It
succeeds when readers reclaim the underlying material conditions of their
meaning making. The very architects of the "smart" literary device tell us: the
answer to the machine remains in the machine.

[^ln3-illusion]: Matthew Kirschenbaum puts it this way: "Computers are unique
in the history of writing technologies in that they present a premeditated
material environment built and engineered to propagate an illusion of
immateriality; the digital nature of computational representation is precisely
what enables this illusion---or else call it a working model---of immaterial
behavior" [@kirschenbaum_mechanisms_2012, 135].

[^ln5-mechanisms]: In this approach I build on the work by @galloway_protocol_2006;
@conti_visual_2008; and @kirschenbaum_mechanisms_2012.

[^ln5-root]: @stoltz_is_2013

[^ln5-osi]: Drafted in 1978 as ISO/TC97/Sc17/N46 and adopted by the
International Organization for Standardization in 1984, as ISO 7498.

[^ln5-layers]: The full OSI protocol stack includes Application, Presentation,
Session, Transport, Network, Data Link, and Physical layers
[@piatkowski_iso-ansi_1980; @miller_iso_1981; @ncs_open_1981; @day_osi_1983;
@day_revised_1995].

[^ln5-smart]: For examples see @grundy_information_1994;
@kaliski_abuse-resistant_1995; @hasebe_licensee_2003.

[^ln5-plato]: My reading of Plato would be impossible without help from the
Perseus Digital Library Project, which allows the reader to explore the Greek
originals side-by-side with translations, maps, dictionaries, and other
parallel texts. Sources consulted on Plato's theory of forms include
@hegel_philosophy_1870; @rist_platos_1975; @dixsaut_ousia_1991;
@woods_form_1993. I would also like to thank Stathis Gourgouris for his
generous comments on these passages.

[^ln5-magnet]: See for example @stefanita_magnetism_2012, 1-69 and
@ohmori_memory_2015.

[^ln5-busa]: See for example @hockey_history_2004, "Father Busa has stories of
truckloads of punched cards being transported from one center to another in
Italy."

[^ln5-loom]: These dates, as is usually the case with periodization, are
somewhat arbitrary. I suggest 1725 as an inaugural date when the French textile
worker Basile Bouchon used "drill paper" to automate industrial drawlooms
[@koetsier_prehistory_2001, 593-595; @randell_history_2003]. The inaugural
honors could also go to the brothers Banū Mūsā, ninth-century automata
inventors from Baghdad; to Jacques De Vaucanson, who delighted the public with
his lifelike mechanisms in the mid eighteenth century
[@riskin_defecating_2003]; or to Joseph Charles Marie Jacquard, who improved
upon and popularized Bouchon's looms on an industrial scale around the same
time.

[^ln5-reading]: All of the technologies I list here exist today (in the second
decade of the twenty-first century) commercially, much beyond the prototype
stage.

[^ln5-translate]: Translations are mine, unless cited otherwise.

[^ln5-barthes]: "The work is a fragment of substance," he writes. The work is
"moderately symbolic" where text is "radically symbolic." The work "occupies
space of books," where the text is "a process of demonstration," "experienced
only in an activity of production." He writes also that "the Text cannot stop
(for example, on a library shelf); its constitutive movement is that of cutting
across (in particular, it can cut across the work, several works)"
[@barthes_work_1978, 156-7].

[^ln5-descartes]: It is difficult to resist quoting from Descartes's
*Meditations on First Philosophy* when discussing idealism. He writes: "Let us
consider the things that people ordinarily think they understand best of all,
namely the bodies that we touch and see. I don't mean bodies in general---for
our general thoughts are apt to be confused---but one particular body: this
piece of wax, for example. It has just been taken from the honeycomb; it still
tastes of honey and has the scent of the flowers from which the honey was
gathered; its color, shape and size are plain to see; it is hard, cold and can
be handled easily; if you rap it with your knuckle it makes a sound. In short,
it has everything that seems to be needed for a body to be known perfectly
clearly. But as I speak these words I hold the wax near to the fire, and look!
The taste and smell vanish, the color changes, the shape is lost, the size
increases; the wax becomes liquid and hot; you can hardly touch it, and it no
longer makes a sound when you strike it. But is it still the same wax? Of
course it is; no one denies this. So what was it about the wax that I
understood so clearly? Evidently it was not any of the features that the senses
told me of; for all of them---brought to me through taste, smell, sight, touch
or hearing---have now altered, yet it is still the same wax."

[^ln3-marinetti]: "Il nostro amore crescente per la materia, la volontà di
penetrarla e di conoscere le sue vibrazioni, la simpatia fisica che ci lega ai
motori, ci spingono all'uso dell'onomatopea." [from Lo splendore geometrico a
meccanico e la sensibilità numerica]

[^ln3-echenbaum]: "Что касается 'формы', то формалистам было важно только
повернуть значение этого запутанного термина так, чтобы он не мешал постоянной
своей ассоциацией с понятием 'содержания', еще более запутанным и совершенно
ненаучным" [@echenbaum part3 of Teoria Formalnogo Metoda]

[^ln1-translate]: "In our discussion of this text we have been using an
authoritative French translation of Plato, the one published by Guillaume Bude.
In the case of *Phaedrus*, the translation is by Leon Robin. We will continue to
refer to it, inserting Greek text in parenthesis [@derrida_dissemination_1981,
71]."

[^ln1-gurevich]: Kittler mistakingly attributes "Algorithms in the World of
Bounded Resources" to Brosl Hasslacher. The author is rather Yuri Gurevich,
Principle Researcher at Microsoft Research and then a professor at the
University of Michigan. Hasslacher's essay entitled "Beyond the Turing Machine"
appeared in the same volume of collected essays, @herken_universal_1988.

[^ln1-bottom]: For example, in the Open Systems Interconnection (OSI) model of
communication, the top-most layer of protocols and interface method is called
the "application layer" and the bottom-most layer the "physical layer"
[@peterson_computer_2007, 26-28]. Timothy Colburn and Gary Shute describe it as
being "responsible for encoding bits onto a transmission medium, whether wires,
fiber optics, or radio broadcast, in ways that maximize the transmission rate
and minimize sensitivity to noise [@colburn_abstraction_2007, 181].

[^ln1-abstraction]: This is a topic of some contention in the literature. In
his influential paper on the topic, James Moor includes the immateriality of
software as one of the "three myths" of computer science. "As a practical
matter, what we regard as computer instructions, and consequently what we
regard as computer programs, is determined by computers available," he writes
[@moor_three_1978, 215]. Nurbay Irmark argues that software is instead a purely
abstract artifact, akin to a musical work [@irmak_software_2012]. See also
@turner_programming_2013; @colburn_software_1999.

[^ln1-turing]: The intellectual history of the Turing machine is well
established, in multiple works on the subject. It follows the Greek Diophantus,
René Descartes, Georg Cantor, David Hilbert, Gottlob Frege, Bertrand Russell,
Kurt Gödel, Ludwig Wittgenstein [@petzold_annotated_2008;
@herken_universal_1988; @grattan-guinness_development_1981].

[^ln1-alt]: "We have to think (in a completely novel way) the relation between
a science and the ideology [...] the fact that such an investigation confronts
us with the observation that every science, in the relationship it has with
ideology it emerged from, can only be thought as a 'science of ideology, would
disconcert us, were we not forewarned of the name of the *object* of knowledge,
which can only exist in the form of ideology" [@althusser_reproduction_2014,
46].

[^ln1-derr]: See @derrida_writing_1978. I am alluding particularly to
statements like "ethnology-like any science-comes about within the element of
discourse," and "this moment was that in which language invaded the universal
problematic; that in which, in the absence of a center or origin, everything
became discourse-provided we can agree on this word-that is to say, when
everything became a system where the central signified, the original or
transcendental signified, is never absolutely present outside a system of
differences. The absence of the transcendental signified extends the domain and
the interplay of signification ad infinitum" (278-294).

[^ln1-flip]: There is a long-standing joke in Marxist literature that involves
flipping Hegel, who prioritized the transcendent spiritual over the physical
and material forms of life, over "back to his feet." See for example
@marx_marx-engels_1978: "The form of wood, for instance, is altered, by making
a table out of it. Yet, for all that, the table continues to be that common,
every-day thing, wood. But, so soon as it steps forth as a commodity, it is
changes into something transcendent. It not only stands with its feed on the
ground, but, in relation to all other commodities, it stands on its head, and
evolves out of its wooden brain grotesque ideas, far more wonderful than
'table-turning' ever was" (320). See also @engels_ludwig_1941: "Thereby the
dialectic of the concept itself became merely the conscious reflex of the
dialectical motion of the real world and the dialectic of Hegel was placed upon
its head; or rather, turned off its head, on which it was standing before, and
placed on its feet again" (44).

