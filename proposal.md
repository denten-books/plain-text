---
title: "Plain Text: The Poetics of Human--Computer Interaction (Book Proposal)"
author: Dennis Tenen

---
\newpage

## Theme and Argument (Placeholder)
## Annotated Table of Contents
### Chapter 1: We Have Always Been Digital

This chapter introduces the book's central themes and arguments, commencing
some of the historical work necessary to the development of a shared critical
vocabulary in use throughout. I argue that discourse around the digital
humanities needs a robust sense of the digital. Popular intuitions about the
"look and feel" of digital aesthetics suggest that sometimes the adjective
carries the connotation of "discrete," while at other times, it is used to mean
something more fluid and continuous, past the point of human perception. A
discussion of Liquid Crystal Display technology (LCD) flows into a section that
deals with digital representation from the perspective of analytic philosophy
and through the aesthetics of Nelson Goodman. My summary of that tradition
reveals that language and text are already in some sense "born digital," that
is "reproducible" and "differentiated" throughout. Furthermore, digitality
depends on "reliable processes of copying and preservation"---attributes that
can mean something different to a philosopher than to a librarian. From these
insights I take it that "being digital" is not an intrinsic ontological
condition, but rather a structure imposed from without. Case studies from the
history of telegraphy illustrate the concluding discussion on the nature of
binary and plain text formats, in a distinction that supersedes the dichotomy
between analog and digital media.

### Chapter 2: Literature Down to the Pixel

In this chapter, I continue the historical narrative started in Chapter 1,
along with presenting the methodological and theoretical underpinnings of the
book. I think of it as the "laying the grounds" chapter. Having established the
roots of digital textuality in the history of character encoding, I begin the
work of moving from first-order concepts such as "text" and "code" up to
second-order concepts such as "file," "folder," and "document." The chapter
starts by developing a theory of "microanalysis," the closest possible kind of
reading that pays attention to the material contexts of knowledge production. I
argue here that the concern with value in literary criticism detracts from the
machinations of naked circuit control embedded into the contemporary text
apparatus. Unlike scholars in the Foucauldian tradition (who often trace the
machinations of power through discourse, on the level of representation), I
concentrate my analysis on mechanisms of control at the material roots of
literary practice. In constructing a media history through primary sources on
the early development of Turing machines, I show the explicit admixture of
content and code: one meant to communicate messages to humans and the other to
program universal machines. I conclude by arguing that Turing machines were
anticipated not by the Babbage calculator alone, but also through a series of
advances in communications, word processing, and media storage. A notion of
text (as opposed to number) is hence "baked into" the system.

### Chapter 3: Laying Bare the Device

At the heart of the book and central to its argument, Chapter 3 begins by
outlining a recent discussion on surface reading. I ask: What lies beneath the
text, literally? The question leads to the common distinction between form and
content. Here, I find that, going back to the Russian formalist reception of
Hegelian aesthetics, "form" was at times used to indicate concrete shape and at
times to indicate abstract universals, such as technique and formula. A case
study in removable storage---like ticker tape and floppy disks---elucidates the
movement of text: from human-legible inscription on the page and punch card to
magnetic inscription invisible to the naked human eye. The case study unfolds
the distinction between print, in which matter, form, and content lie flat, and
screen, where the three layers occupy physically distinct strata of the
Document Object Model, providing only the illusion of flattened textuality.
The apparent immateriality of digital text brings promise of epistemological
(social) and even phenomenological (personal) transformation. But it also has a
major practical drawback. Inscription on magnetic tape cannot be assumed to
correspond to the composite screen image. Forms of governance like Digital
Rights Management can now be embedded deep within the structure of the "data
object" itself and further hidden from view---precluding, and sometimes making
illegal outright, the possibility of interpretation (of any sort). The
discussion concludes with a stark image illustrating the contrast between
screen surface and the underlying bit structure. To produce the image, I use
reverse-engineering tools to inject malicious code into an Adobe Acrobat file
(`.pdf`). The deformed text threatens to damage the literary device. A thick
description of the literary device, now as gadget or instrument, brings
legibility to the fore of reading ethics.

### Chapter 4: Recursive Encounters with Oneself

This chapter continues the movement from the device to the reader. It begins
with a close reading of Beckett's *Krapp's Last Tape*. The title character
makes yearly audio recordings of himself, only to revisit them and to enter
into a sort of dialog with his own voice from the past. I posit this encounter
with the archive as Krapp's "media being" and suggest that such encounters are
commonplace, through similar practices of depositing "snapshots" of one's
consciousness into files, bookshelves, and folders. Sartre's idea of an
"appointment with oneself" helps us see this external structure of files,
folders, and library furniture as cognitive extension, in need of delicate
pruning and arrangement. Documents, in this light, are shown to exist not as
completed works, but as "vectors" that mutate and move through time and space.
Pushing off the communication model offered by Claude Shannon, I ask: What is
being externalized, communicated, and preserved? And answer: It is not simply a
message, but the subject itself.

### Chapter 5: Bad Links

If documents are vectors, where do they terminate? In this chapter I examine
three answers, given at three distinct moments in recent literary history.
First, I recall the discourse surrounding structuralist "intertextuality"---the
idea that textual meaning is always created in relation to another text.
Second, I review the promises and the failures of "hypertext," an idea which
gained prevalence in literary studies with the advent of the internet. Third, I
reflect on the current moment, in which "network analysis," a technique that
seeks to visualize linkages between texts, is being held up by some as the next
step in the evolution of textual studies. In all three of these methodological
moments, I find a similar premise of emergence: the notion that order appears
spontaneously as an aggregate result of simple interactions at the level of the
system. I take the occasion of examining the hyperlinked essays of Gwern (a
mysterious contemporary "researcher, self-experimenter, and writer") to further
criticize what I call the "systems view" of literature, which elevates networks
to the status of ethical and aesthetic actors.

### Chapter 6: Engineering for Dissent

In this final chapter, I argue for the recovery and the preservation of plain
textuality in the day-to-day practice of modern computing. Returning to the
history of the `.txt` file format, I find that early documents from the
International Telecommunication Union archive display unease with encrypted,
non-human-readable formats of information exchange. A theoretical treatment of
technological skepticism (from Karl Marx and Martin Heidegger to Lewis Mumford)
concludes with a discussion about a subject's role in actively shaping material
conditions of media being. As documents that reflect externalized states of
consciousness aggregate in storage locations far removed from the subject, they
become increasingly susceptible to centralized forces of surveillance and
control. Plain text allows political subjects to decouple externalized mental
states from mechanisms of governance. (In other words, to decide actively when
to opt in and when to opt out.) This affordance is not, however, a
deterministic property of literature, the internet, or any other information
exchange system.  Rather, the design of complex systems must itself become
critical practice which, in complement to critical theory, can actively
engineer for textual mechanisms that make individual dissent possible.


### Tech Appendix (optional)

The book assumes no prior technical expertise. It can be read sequentially as a
conventional piece of scholarship in literary/textual theory or new media
studies. But, because much of the book deals with conditions of textuality
extant and recoverable from modern computing devices, I propose to heed the
call of scholars like Jerome McGann and Wendy Chun for the advancement of
theory through practice. To this end, I envision an optional appendix that can
exist on paper or as a companion website, creating an "augmented reading
environment." The appendix would follow each chapter (sequentially) with a
series of experiments at the "command line," a powerful text-based way of
interacting with the computer.

Inspired by the ethos found in Kenneth Ward Church's classic "Unix for Poets"
and by the form of Roland Barthes's seminal *S/Z*, the appendix gives readers
an opportunity to test theoretical intuitions found in the body of the book
against the reality of contemporary computation. For example, the difference
between binary and plain text formats (discussed in the early chapters) could
be made more apparent in comparing the output of `cat file.txt` and `cat
file.pdf` in the terminal.[^ln-cat] In the later chapters, the conversation on
access could be augmented with an exercise on file permissions. Diagnostic
utilities like `ping` and `traceroute` would be brought to bear on network
effects mentioned in the "Bad Links" chapter. In this way, the appendix can
serve to extend historical and theoretical awareness into practical know-how.
An intuitive understanding of the political issues surrounding digital text, be
they "open access," "freedom of information," or "online censorship," begins to
develop at that instrumental level.

Ready-made tools and graphical interfaces for human-computer interaction often
obscure the underlying complexity of the computational environment. For
example, while writing a relatively complicated piece of code, a journalist in
my digital humanities class once confessed to being confused about the
relationship between files and folders. *Plain Text* is a book *about* files
and folders: it is about textuality as encoded in specific ways on machines
that have a shared material history. The book's technical appendix, although
not required for the comprehension of its main ideas, would help cultivate
theoretical intuitions based not on speculation alone but also on "knowledge at
hand."

[^ln-cat]: Use actual file names if you plan to test this out.

## Field Significance (Placeholder)

## Existing Literature (Placeholder)


## Audience and Market (Placeholder)


## Length and Format

I am writing the book as a traditional volume, expounding a sustained thesis
across six chapters (along with a short introduction). At this point, I am
aiming for a manuscript of around 80,000 words (not including citations),
allotting around 10,000 to 15,000 words per chapter. The chapters tend to have
five to seven more granular subsections that help to clearly demarcate chapter
structure.

The book could include an optional appendix, discussed in detail in the
Annotated Table of Contents. The appendix does not require any special
treatment. In addition, the manuscript contains 15--20 figures, primarily as
black-and-white diagrams from technical literature and images created by the
author. I have received a modest subvention to offset any costs associated with
image production, publishing, and preparation of the manuscript.

## Relationship to Dissertation and Other Published Work

The book bears a resemblance to my doctoral dissertation in the subtitle only. Several
paragraphs from the embargoed dissertation did make it into *Plain Text* in an
ad-hoc manner, but the book as a whole represents a completely new framework
and a new direction in my thinking about the subject.

With the approval of the press, I plan to place two of the book's shorter, more
peripheral chapters, in their redacted form, into journals that would help
promote and expand an audience for the book as a whole. I also plan to present
the same chapters (in an even more compact form) at several upcoming
conferences, including CHI, the Conference on Human Factors in Computing
Systems (a significant publication organ in the field of human-computer
interaction).

## Schedule to Completion

The research for this book was enabled by a year-long fellowship at the Berkman
Center for Internet & Society. Consequent to the research phase, I taught
several classes on the subject, which helped refine my thinking and provided
further notes and primary material. As of today, the manuscript stands at
roughly 60,000 words, with three chapters completed in their draft form. I am
writing actively and plan to have the first draft of the manuscript ready in the
summer of 2015. I am on leave next academic year, having cleared my schedule,
with plans of seeing this project through to publication.
