---
title: "Plain Text: The Poetics of Human--Computer Interaction"
author: Dennis Tenen
cover-image: "images/steno.png"
csl: csl/mla-no-biblio.csl
bibliography: plain-text.bib
toc: true
mainfont: "fbb"
fontsize: 12pt
---

Theme and Argument
------------------

This book is about the strange entanglement between humans, texts, and
machines. It examines key literary-theoretical ideas alongside the
intellectual history of software engineering that frame contemporary practices
of reading, writing, and interpretation. It is a deeply materialist work, in
which I argue that our most ingrained intuitions about texts are profoundly
alienated from the physical contexts of intellectual production. A new kind of
poetics is therefore necessary to preserve the free play of ideas implicit in
the method of humanistic inquiry.

The work of literary theory often defines itself in terms of specific texts.
My object of study is instead the nature of textuality itself. I am interested
here in how texts are produced; in the metaphors that guide computation; in
the forms, formulae, and formats that structure human-computer interaction; in
the literary device; and in the strange shape of contemporary inscription,
which, no longer a single mark on paper, stretches between the site of
fleeting projection, the screen, and the site of storage in its solid,
archival state.

The electronic book draws a compelling figure that belies material realities
of reading and writing, transformed by the advent of computation. The
electronic reading device on my desk is not a book, but a simulation of a
book. And everything associated with reading this metaphor must in itself be
understood under the sign of simulation. What kind of a metaphor is it? How
did it come into being and how does it affect practices of literary
interpretation? In *Plain Text* I attempt to come to terms with the conditions
of *simulated textuality*. The simulation-producing nature of computed text
preserves the outward appearance of printed text, while concealing the
specifics of governance and control. I mean governance and control in the
sense of shaping affordances: a mode of physical regulation that structures
the production, access, and the distribution of knowledge. The challenge of
*Plain Text* is in the description of such emerging but often occluded
technological possibilities.

A concern with the material conditions of simulated textuality leads us to a
rich archive of new and previously unexplored materials from the history of
philology, semiotics, telegraphy, and electrical engineering from the middle
of the nineteenth to the end of the twentieth centuries. These texts gain
significance when read next to foundational works in the philosophy of
aesthetics and literary theory. I deploy the archive to argue that theories of
interpretation evolved under the conditions tied to static print media. By
contrast, electronic text changes dynamically to suit its reader, political
context, and geography.  Consequently, I argue for the development of what I
term *computational poetics*: a strategy of interpretation capable of reaching
past the surface content to reveal the software platforms and the hardware
infrastructures that contribute to the production of meaning.

I appeal to the idea of "plain text" in the title of this book to signal an
affinity with a particular mode of computational meaning-making. Plain text
identifies a file format and a frame of mind. As a file format, it contains
nothing but a "pure sequence of character codes." Plain text stands in
opposition to "fancy text," "text representation consisting of plain text plus
added information" [@unicode_consortium_unicode_1990]. In the tradition of
American textual criticism, "plain text" alludes to an editorial method of
text transcription which is both "faithful to the source" and is "easier to
read than the original document" [@cook_time-bounded_1972]. Combining these
two traditions, I build a case for a kind of a systematic minimalism when it
comes to our use of computers---a minimalism that privileges access to source
materials, ensuring legibility and comprehension.  I do so in contrast with
other available modes of human--computer interaction, which instead privilege
maximizing system--centric ideals like efficiency, speed, performance, or
security.

My use of plain text implies also a poetics of reading and writing. The title
therefore further identifies an interpretive stance one can assume in relation
to the making and the unmaking of literary artifacts. Besides visible content,
all contemporary documents carry with them a layer of hidden information.
Originally used for typesetting, that layer affects more than innocuous
document attributes like "font size" or "line spacing." Increasingly, devices
that mediate literary activity encode forms of governance. These tacit
structures police intellectual property laws; they censor and carry out
surveillance operations. For example, the Digital Millennium Copyright Act,
passed in the United States in 1996, goes beyond written injunction to require
in some cases the management of digital rights (DRM) at the level of hardware.
An electronic book governed by DRM may subsequently prevent the reader from
copying or sharing stored content, even for the purposes of academic study.
Building on the recent work of scholars like Johanna Drucker, Lev Manovich,
Tung-Hui Hu, and Lisa Gitelman I make the case for an empowered *computational
poetics*, a method of inquiry that aims to bring implicit control structures
once again under the purview of interpretation and critique
[@manovich_there_2011; @gitelman_paper_2014; @hu_prehistory_2015].

Annotated Table of Contents
---------------------------

The passage from keystroke to pixel gives the book its shape. In the chapters
to follow, our mobile phones and laptops come fully into view as metaphor
machines engendering ubiquitous simulation. The first three chapters are thus
concerned with the structure of the computational metaphor. The **first
chapter** begins with an explication. What does it mean to turn a page, I ask,
when neither the page nor the action of turning correspond to their implied
analogies?  The analysis of the metaphor helps trace the intellectual history
of human--computer interaction, a field which progressed from "conversational
programming" to the "direct manipulation" paradigm shaped by cognitive
metaphor theory and immersive theater. The logic of "directness" leads to the
rapidly developing field of brain-to-computer interfaces. The chapter
concludes with a moment of speculative formalism, in which we consider the
possibility of affective literature that eschews language and representation.

At the core of the book's **second chapter** lies the notion of a modernist
literary device, understood both as literary technique and a thought
experiment about intelligent machines, directly connected to the birth of
modern computing. A section on literary technique in the thought of Percy
Lubbock, Walter Benjamin, and Mikhail Bakhtin opens the discussion.
Materialist poetics arise concomitantly with a mechanistic, rule-based view of
language leading to a series of thought experiments first in the writing of
Ludwig Wittgenstein, and then in the seminal paper of Alan Turing on an
imaginary computer capable of reading and writing. The verbs to read and to
write imply a type of cognitive processing. What does it mean to read and to
write for a machine? What about broken mechanisms of comprehension? At once a
device and an algorithm, the Turing machine blurs the boundaries between
software and hardware, code and content, intelligence and its imitation.

Two rich intellectual histories collide on the pages of the **third chapter**:
one, the material history of formatting as a concept in computer science and
the other, the intellectual history of form in literary theory.  Format
emerges as a concept that mediates between form understood as internal "rules
for construction" and form understood as "external shape." The formatting
layer transforms one type of structure, a series of bits arranged into tracks
and sectors, into another, letters arranged into sentences and paragraphs. I
draw a short history of text formats that commences with several "control
characters" limited in function to actions like "carriage return" or "stop
transmission." With time, the formatting layer encompassed all manner of
machine instruction, including structures of governance like "digital rights
management" and "copy protection." A manufacturer's ability to censor or to
surveil electronic books is contained within the formatting layer.

The **fourth chapter** begins with a discussion of an apparent paradox.  A
camp of media theorists and textual scholars in the 1990s conceived of
electronic texts as an ephemeral, almost immaterial, phenomenon. The text
shimmered and glared: it was spoken of in terms of *hypertext*, light writing,
and electricity. A generation of theorists that came after insisted on the
weighty materiality of electronic media. Reading began to engage the
morphology of rare metals, media archeology, hard drive forensics. Both
accounts, I argue, capture an aspect of the same underlying condition. The
perceived image of an archived inscription splits from its source. The sign
plausibly resides both on the screen and on the hard drive. It splits, in some
real a sense, diverging at the site its projection from the site of the
archive. Erasing an inscription on the screen, for example, may not elicit the
corresponding action on the disk. Using archival materials from the history of
telegraphy in the late nineteenth and early twentieth centuries, I chart the
gradual fracture and the ultimate illegibility of the computational sign.

The **fifth chapter** charts the emergence of screen reading. The screen
appears to restore a measure of visibility lost to magnetic inscription, with
one major side-effect. Fidelity between the word visible and the word archived
cannot be guaranteed. What the screen shows and what is stored on tape or hard
drive has only a contingent correlation. Screen reading further happens on
screens that refresh themselves at a rate of around 60 cycles per second
(Hertz). The digital word is technically an animation; it moves even as it
appears to stand still. This property of the medium attunes the reader to a
particular mode of apprehension, affecting not just the physics but also the
aesthetics of digital media.  Works by the philosophers Henri Bergson, Jakob
von Uexk√ºll, and John Goodman help construct a phenomenology of screen-based
digital perception.

The **sixth and final chapter** looks to the site of storage to find the media
"homes" that house the vast archives of our private media collections. It
begins with a close reading of Beckett's *Krapp's Last Tape*. Krapp makes
yearly audio recordings of himself, only to revisit them and to enter into a
sort of dialog with his own voice from the past. I posit this archival
encounter as Krapp's "media being" and suggest that such encounters are
commonplace. Writers and book collectors regularly deposit "snapshots" of
their consciousness into files, bookshelves, and folders. Jean-Paul Sartre's
idea of an "appointment with oneself" helps to reveal this external
construction of files, folders, and library furnishings as cognitive
extension, in need of delicate pruning and arrangement. A close reading of the
"home" folder, the default location of personal files on many systems,
concludes with the discussion of media homes.  Finally, I return to the theme
of displacement, arguing for a mode of inhabitance within media that is
uncanny or un-homed [*Unheimliche*], contrary to discourse that speaks in
terms of "digital natives" and those who are "born digital." I build on
Flusser's immigrant poetics to suggest a kind of information processing that
necessitates a purposeful movement between the polarities of settlement and
expatriation.

Contributions to Literature
---------------------------

The book contributes to the fields of literary theory, media studies, and
digital humanities. Scholarship the digital humanities is sometimes criticized
for being ahistorical or atheoretical, abandoning deep traditions of literary
theory and criticism, even where such traditions would help bolster the case
for the digital humanities. The related field of new media studies has the
opposite problem. Although theoretically sophisticated, it sometimes produces
research far removed from the actual practice of creating new
media.[^ln-hayles] By contrast, I situate *Plain Text* at the intersection of
theory and practice: somewhere between "technical literacy for new media
studies and literary theory" and "philosophical bases for computing in the
humanities."

Recent comparable books in this space include: *Paper Knowledge*, by Lisa
Gitelman (Duke University Press, 2014); *Coding Freedom: The Ethics and
Aesthetics of Hacking*, by Gabriella Coleman (Princeton University Press,
2012); *Mechanisms: New Media and the Forensic Imagination*, by Matthew G.
Kirschenbaum (MIT Press, 2012); *Files: Law and Media Technology*, by Cornelia
Vismann (Stanford University Press, 2008); *Programmed Visions: Software and
Memory*, by Wendy Hui Kyong Chun (MIT, 2013); *How We Think: Digital Media and
Contemporary Technogenesis* by Katherine Hayles (Chicago, 2012); *Beautiful
Data: A History of Vision and Reason since 1945*, by Orit Halpern (Duke,
2015); and several titles in the Electronic Mediations series at Minnesota
University Press, which published Lori Emerson's *Reading Writing Interfaces*
in 2014.

My work extends the research program represented in these volumes in several
important directions. While committed to broadly theoretical concerns---that
is, ideas that can guide or challenge the way we study texts, their
production, their meaning, and their impact on the people who use and produce
them---my argument also dwells in the realm of traditional philosophy and
(more narrowly) philosophy of text and technology. More than a decade of
professional experience in software development grounds my thought in the
fields of software and electrical engineering to an extent greater than one
generally finds in similar manuscripts. Finally, the range of primary
materials used in this book reveals my academic training in comparative
literature. The will encounter original translations---texts from Greek,
German, and Russian which undercut the preponderance of North American
material. Consider, for example, my third chapter, called "Form, Formula,
Format," which commences with a discussion of formalism first in aesthetic
philosophy through the works of Plato, Hegel, and the Russian formalists, then
in the works of textual critics like G. Thomas Tanselle, Jerome McGann, and
Johanna Drucker, and finally in the technical manuals describing something
called the document object model, which tests our theoretical intuitions based
on a specific case study crucial to our understanding of electronic text.

Although I do not mean to engage in the debate on disciplinary formation, I
prefer to describe my work as "computational culture studies," both in the
sense of "the study of computational culture" and as "computational approaches
to the study of culture." It is important for me to make the case for the
reciprocal motion between the constituent elements of "computation" and
"culture." Too often rhetoric around the digital humanities resembles a
one-way street, in which computational methods are promised to reform the
humanities unilaterally. Books like Alexander Galloway's *Laruelle: Against
the Digital* (University of Minnesota Press, 2014), Matthew Fuller's *Evil
Media* (MIT Press, 2012), and Johanna Drucker's *What Is?* (Cuneiform Press,
2013) represent the sharp edge of a critical counter-movement to digital
positivism. But this response, too, could be balanced against the constructive
potential of the digital humanities, which extend humanistic inquiry into new
and exciting directions. As was the case with the "linguistic turn" in the
decades prior, almost all fields of human knowledge are now experiencing a
turn towards computational methods that offer insights at previously
unavailable scales of analysis. Witness the emerging fields of computational
biology, computational chemistry, computational linguistics, computational
geometry, computational archeology, computational architectural design,
computational philosophy, and computational social science, among others. The
impact of computation therefore cannot be lightly dismissed. In *Plain Text*,
I stake out a middle ground between Stephen Ramsey's laudatory *Reading
Machines* (University of Illinois Press, 2011) and David Golumbia's critical
*The Cultural Logic of Computation* (Harvard University Press, 2009).

The book represents a new direction in my research, based on previously
unpublished work. The manuscript has received extensive revisions, with
comments on individual chapters from scholars like Brian Larkin, Barbara
Herrnstein-Smith, Bernard Harcourt, Susan Zieger, Johanna Drucker, Stefan
Andriopoulos, and Lydia Liu.

Author's Bio
-----------

This book is in part a reflection of my professional biography, which combines
a track record of excellence in the fields of literary scholarship and
software engineering.

I began my professional career at Microsoft, where I made significant
contributions to the development of the Microsoft XP operating system. This
experience translated directly to my co-founding of Columbia's Group for
Experimental Methods in the Humanities, where I direct a number of research
projects. The lab's work has been featured on the pages of *The New York
Times*, *TIME* magazine, *Der Spiegel Online*, *FiveThirtyEight*, and *Le
Monde*.[^ln-press] Since the fall of 2012, after spending a year in residence,
I have also been a faculty affiliate at Harvard's Berkman Center for Internet
and Society. My work in the digital humanities has been subject to numerous
grants and awards, including the Brown Institute Flagship Grant for media
innovation in partnership with Stanford University.

My training as a literary scholar concluded under the guidance of Elaine
Scarry and William Mills Todd, of Harvard University, at the department of
English and Comparative Literature. I am currently a fourth-year tenure-track
assistant professor at Columbia University's Department of English and
Comparative Literature, where I am also an affiliate member of the Data
Science Institute, New Media Center. I teach and lecture widely in the
departments of English, History, Computer Science, and Journalism usually on
topics of literary theory, computational culture studies, new media, and
digital humanities. My work has appeared on the pages of scholarly journals
like *Modernism/modernity*, *Boundary 2*, *Computational Culture* along with
popular press like *LA Review of Books* and *Public Books*.

Audience and Market
-------------------

In writing *Plain Text*, I have kept the above manifold audiences in mind. I
am interested in producing deep but accessible scholarship, which has impact
within and outside of academia. The diverse professional networks I have
developed over the years represent my audience and my community of support. I
plan to rely on them to promote the book, to solicit reviews, and to engage
into a dialog with my work.

*Plain Text* appeals to several key audiences. The first comprises media
scholars interested in the history of media, data, and computing in the
twentieth century. The second audience can be located in literary and textual
studies, among scholars seeking to understand the impact of technology on
literary theory or book history.  Finally, the manuscript targets the broader
audience of digital humanities and information science practitioners
(particularly in the field of human--computer interaction) actively engaged in
using and creating textual interfaces that shape contemporary reading and
writing praxis.[^ln-ipam]

There is at the moment a paucity of books that can be taught in classes like
the graduate seminar "Digital Studies | Prototyping Texts," taught at the
University of Victoria by Jentery Sayers; the undergraduate lecture course
called "Making and Knowing Project: What is a Book in the 21st Century?" by
Pamela Smith at Columbia; and "Text Transformations" by Matt Gold, at CUNY.
All of the above courses have requested and assigned advanced copies of draft
chapters from *Plain Text*, which bodes well for the book's wider reception.

Finally, I write for the broader public. My book answers the call put forth in
Bernard Harcourt's recent *Exposed: Desire and Disobedience in the Digital
Age*. Books like Harcourt's bring into focus a significant problem in
contemporary society, by which our digital lives become enmeshed in a system
of production that commodifies human experience. Devices that surround us
collect and trade in our reading habits, social interactions, and intimate
conversations. In *Plain Text* I argue widely for a new mode or reading, not
limited to our ability to code, but one that makes visible the ideals implicit
in our technological decisions: to buy a new phone, to contribute an online
review for a book, or to write using free software. Our challenge today is to
uproot ourselves from the comfort that rapidly descends on the digital
dwellings that house our intellectual life. It is in our broadly human, civic
interest, I argue, to keep "smart" technology at hand, under continual
scrutiny of critical, close, and closest possible reading.


Length and Format
-----------------

The book is a traditional volume, expounding a sustained thesis across six
chapters, along with a chapter-length introduction. The manuscript stands at
roughly 95,000 words (including citations).

Several chapters contain figures and illustrations, primarily as
black-and-white diagrams from technical literature and images created by the
author. The total number of illustrations is 20. I have received subvention
funds to offset any costs associated with image production, publishing, and
preparation of the manuscript.

[^ln-hayles]: Katherine Hayles and Ian Bogost among others have advanced this
argument.

[^ln-ipam]: For a representative sample of this group see the Culture
Analytics program hosted by UCLA, which includes over fifty participants from
the sciences and the humanities.

[^ln-press]: For a complete list of our press appearances consult
http://xpmethod.plaintext.in/impact.html#press.
