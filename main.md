---
title: "Plain Text: Human Technology"
author: "Dennis Tenen"
---

# Introduction
## Thesis
Plain text is a file format and a frame of mind. A fundamental concept in the development of computing, plain text stands in opposition to closed platforms, rarefied knowledge, and black-box devices. Instead, it offers a vision of data that is human-readable by design: portable, concise, and universal. This book contains an argument for plain text. It seeks to empower a community of writers, readers, publishers, and librarians. Together, we will convene a polity interested in reflecting critically on the ideas, tools, and practices that shape our daily encounter with computation.

The argument starts with foundational principles of media and literary studies and information science. I ask: what is at stake in the difference between digital and analog?  What contains more information a block of wood or a novel? How is text structured? What separates meaning, form, and formatting? Where does data end and meta-data begin? What does it mean to "have read a book" or to "know something"? To what extent is media the message? The formulation of these broadly philosophic concerns influences the more pragmatically-minded and applied discussion in the second half of the book. Thinking together about the nature of human-computer interfaces, knowledge as hardware and software, links, networking, inter-textuality, word processing, text encoding, and cryptography will allow us to approach issues of control and governance, access and cooperation, consensus and dissent, and privacy and surveillance.

A secondary aim of this volume is to convince the reader, especially one without much technical background, to view their computational environment as a literary system. I mean a "literary system" in opposition to what one might conventionally mistake for a "binary" or "digital" one, however imprecise those terms are in everyday use. And should I succeed, I ask the readers to apply the same critical acuity to reading code as they do to close-reading of prose and poetry. Admittedly, to treat computers as a literary system is an unusual proposition, but one that I hope to sustain on a firm basis, grounded in literary theory and in the history of modern computing. Detailed case studies from that history will point to (what I hope is an) unexpected confluence between the shared history of computing and literary thought. 

## Audience
A parallel audience to the one composed of non-technical readers is one that shares expertise in computer science or electrical engineering, but also one that does not usually view its daily practice in its historical, philosophical, and political contexts. Designers, software engineers, system administrators, and project managers are often asked to make choices at work that have not only technological, but broader social and cultural implications. Choosing a text editor, a filing system, or a social networking platform cannot be adequately addressed in shallow instrumental terms like efficacy, speed, or performance. Such choices also affect deep structures of knowledge transmission, the formation of collective and institutional memories, the quality of online discussion, and the ways in which we relate to our family, friends, and colleagues. Ultimately, in the concluding chapters, this book is meant to challenge the widely-held (if often hidden) notion that systems can give rise to ethical or political values. Values, as I will argue, must be projected from without, by free-willing agents that can voluntarily deliberate, form consensus, and  articulate shared goals. The only sentient beings answering to these criteria are humans (and not, for example, cyborgs or complex systems). The book then is ultimately an articulation of a new humanism, which runs counter to the recent theoretical turn towards post- and trans- humanisms which elevate systems (natural and artificial) to the privileged position of ethical and political actors. 

In situation computing as critical, textual, literary *practice*, I hope to make an theoretical intervention in the cluster of fields sometimes designated as "media studies," a cluster can include subfields like "science and technology Studies," "new media studies," "platform studies," "critical code studies," "media archeology," and my own preferred cognominate "computational culture studies." Where the thematic is clear, these are usually terms of self-description, and are not worth dwelling upon for too long. It is important for me only to insist on the reciprocal motion between the constituent elements of "computation" and "culture." On the one hand, the term of art can be understood as the critically reflective study of "computational culture," which would bring in a set of more specialize concerns to the field of media studies. On the other hand, I believe also in the importance of studying culture more broadly using computational approaches. This book does a bit less of that than my other work elsewhere, but I do mean it to serve as a foundation for someone interested in expanding their methodological toolkit into computational methods.  

As was the case with the "linguistic turn" in the decades prior, almost all fields of human knowledge are now experiencing a turn towards computation. Witness the emerging fields of computational biology, computational chemistry, computational linguistics, computational geometry, computational archeology, computational architecture design, computational philosophy, computational social science, and the list goes on. What all of these areas of study have in common is a shared methodological toolkit, often instantly recognizable by practitioners in quite diverse disciplines. In my own home discipline of literary studies, the turn towards computation is usually filed under "digital humanities" (DH). Although I consciously avoid the term of the art here, I am friendly to some of its aims and proposed interventions. But I also agree, to the extent that will become clear in the concluding chapters of this book, with the critique advanced by scholars like Brian Lennon, David Golumbia, Tara McPherson, and Johanna Druckrer, who accuse DH of historical myopia, theoretical shallowness, and eurocentrism (along a long list of other sins). In this light, the present book can be seen as a work that attempts to straddle the worlds of media theory and digital humanities, philosophy of technology and human-computer interaction, representing the best of what these traditions have to offer the academy at large. 


## Format
The book is a book, but also a tool. Readers will get much more out of it if they are able to actively follow along using their terminal emulator of choice. If these words mean nothing to you, rest assured that the text assumes no prior technical knowledge. It can be read sequentially as a conventional piece of scholarship in textual theory or "new media" studies. For those willing to take the plunge, I will often illustrate abstract theoretical concepts by asking the reader to type some commands into their terminals. Detailed instructions on how to set up this "augmented" reading environment, tutorials, and explanations can be found in the technical appendix and on the forthcoming companion website. 

Both novices and experts alike can benefit from exposure to ideas in the command line, on the level of the operating system. At the very least, the reader will walk way from this book with concepts and skills foundational to computing as critical thought and critical practice. But I hope that many readers will go beyond the basics, gaining deep-seated, intuitive, "hands-on" understanding of operational concepts like files, filing systems, networks, search tools, servers, and encryption technologies. Developing an intuitive understanding of systems that structure so much of our daily activity has the potential to radically transform one's experience with text, media, and digital devices. 

Unmoored theoretical concepts like "text" and "media" gain a palpable form when explored in the context of their instantiation. This is both model and method structuring the inquiry advanced here. Allow me to spend the next few paragraphs in laying bare the reasoning and the history behind this approach to the study technology, texts, and people.

## Pragmatism
The idea that "meaning" is always in some sense "operational meaning" is a proposition implicit in several related philosophical traditions. The first of these is pragmatism, broadly conceived. William James articulates that view when he writes that "reality is seen to be grounded in a perfect jungle of concrete expediencies [@james-pragmatism-conceptionoftruth]." For James (and, to some extent, for his fellow travellers in American pragmatism, Charles Sanders Peirce and John Dewey)[^ln-pragma-truth] the pragmatic answer to the question of truth could be reduced to the questions efficient causes and effects. In his essay "Pragmatism's Conception of Truth," James asks: "How will the truth be realized? What concrete difference will its being true make in anyone's actual life? What experiences will be different from those which would obtain if the belief were false?" Frank Ramsey, the young British philosopher close to Ludwig Wittgenstein, was influenced by the Americans and would later write that meaning "is to be defined by reference to the actions to which asserting it would lead [@ramsey-foundationsofmath p.155]." 

[^ln-pragma-truth]: For a more thorough discussion on the topic see @seigfried, @pihlström, and @putnam-james-theory. 

For the pragmatist, truth-carrying propositions of the shape "X is" (as in, "the author is dead" or "art is transcendent") beg the questions of "Where?," "When?," "For Whom?," and "What's at stake in maintaining that?" Following James's and Ramsey's pragmatic insight, I will maintain throughout that abstract categories like "text" cannot possibly be (although they often are) reduced to a number of essential, structural features. Rather, to borrow from a conversation on categories in Wittgenstein's *Philosophic Investigations*, categories denote a related "family" of practices, which may or may not share in any given familial characteristic [@Wittgestein-philo-invest].[^ln-more-witt] To visualize this "familial" model, imagine a Venn diagram, where overlapping fields (of textuality, in our case) intersect and diverge in a historically (culturally, practically) contingent and arbitrary ways. These fields lie in relation to specific communities of practice, which often do not in themselves employ a controlled vocabulary. What counts for "code" and "poetry" in one domain, like computer science, may not account for the very same in another domain, like creative writing. An engineer's evocation of code as poetry can diverge from a poet's. There's no sense in trying to reconciling divergent languages, where concepts like "poetry" exist only in their social instantiation. The language of poetry morphs from literary period to literary period: those who write code by day and poetry by night might employ differing if not outright contradictory vocabularies.

[^ln-more-witt]: For more on the connection between Wittgenstein and James see @goodman-wittandjames. 

The intellectual legacy of pragmatism is wide-ranging and diffuse. It is perhaps most pronounced in the teacher colleges, where James and Dewey are still read widely, which could explain the ascendancy of such pedagogical terms as "situated cognition"[^@lave&wenger, @johnseelybrown] and "experiential learning"[^@kolb]: both terms denoting some sense of necessary synthesis between of knowing and doing. In the field of linguistics, philosophy of language, and communication studies, pragmatics are well-encapsulated by the "language-as-action tradition," which harkens back to the Oxford language philosophers like J.L. Austin, Paul Grice, and John Searle [^@Trueswell].   Austin's "How to Do Things with Words," is perhaps the paradigmatic formulation of the idea that words don't just mean things, but that they enact change in the world.

When applied to task of writing media theory, history of science, or the philosophy of technology, the pragmatic tradition suggests we move beyond intellectual history, that is beyond mere words, into the examination of real-world materials, practices, and institutions that sustain ideas.

## Experimentalism and Media Archeology
Several broad intellectual movements tangentially related to pragmatism influenced my approach to writing this book. The first is experimentalism. Writing in the mid-19th century against the tradition of inductive "generalizers," Claude Bernard, a pioneer in experimental medicine, argues for the necessity of both theory and practice. "We cannot separate the two things," he writes, "head and hand." The "science of life" he writes, "is a superb and dazzlingly lighted hall which may be reached only by passing through a long and ghastly kitchen ." "We shall reach really fruitful and luminous generalizations about vital phenomena only in so far as we ourselves experiment and, in hospitals, amphitheaters, or laboratories stir the fetid or throbbing ground of life [^@bernard p3-15]." 

It is my belief also that the lighted halls of contemporary literary and media theory can be best through the long and ghastly kitchen of everyday practice. Take the example of a media scholar analyzing the last two decades of film production or photography without grasping the fundamentals of electronic photodetectors, RAW image formats, complementary metal–oxide–semiconductor (CMOS), digital editing tools, computer-generated imagery (CGI), or Photoshop image manipulation techniques. Such a study is in great peril of being terribly misguided by theoretical models that have no basis on reality. It is not that one cannot say anything about photography without knowing these things, but rather that one can say much more when he does. To my mind, theory must be continually checked and refined against practice, just as practice must be continually checked and refined against generalized insight. Similarly, it is my contention here that the fundamental theoretical concepts driving literary studies--word, text, narrative, discourse, author, story, book, archive--are thoroughly enmeshed in the underlying physical substratum of paper and pixels (but also ink, wood, and integrated circuit). These operational concepts cannot attain their full expressive potential without an internalized understanding of the technology and the daily practice that gives them rise. This book is an attempt to develop knowledge "at hand" and "fingertip knowledge" (both discussed in the later chapters).

It is likely that this line of reasoning is itself a part of experimental and material "turns" steering the academy toward critical practice, especially in fields long-dominated by theoretical reflection. The turn represents a generation's dissatisfaction with "armchair" philosophizing. Recall the burning armchair, the symbol of "experimental philosophy" movement proposed by Joshua Knobe and Shaun Nichols, who write that "many of the deepest questions of philosophy can only be properly addressed by immersion oneself in the messy, contingent, highly variable truths about how human being really are [^@knobe_nichols p3]." In the field of media and literary studies, it is almost impossible to avoid the influence of "archeology of knowledge," as advanced in its many permutations by Michel Foucault and his followers. Yet, such archeologies deal with "artefacts" and "excavations" only as metaphors for what remains, methodologically, a history of ideas. 

In the recent decade or so, a number of scholars are "making good" on the metaphor by turning their attention to actual artifacts and excavations, in what sometimes they dub as the history of craft or "artifactual knowledge." In preface to a recent volume on *Ways of Making and Knowing*, edited by Pamela Smith, Amy Meyers, and Harold Cook, the editors write that the "history of science is not a history of concepts, or at least not that alone, but a history of the making and using of objects to understand the world [^@smith p12]." As a historian of science in the Early Modern period, Smith translates that insight in the laboratory, where along with her students she bakes bread and smelts iron to recreate long-lost artisanal techniques. The major insight from Smith and her colleagues is that traditional "book" knowledge--the kind of information that finds itself into novels, textbooks, and technical manuals--represents only a small part of the sum total of human expertise. Much of our knowledge is instead secreted into the artefacts and institutions where it unfolds in daily practice. For literary and media scholars interested in key operational concepts that means supplementing theoretical insight with a robust sense of curiosity about the world. Digital technology, from typesetting software to e-book readers and word processors, shapes our everyday encounters with literature and textuality. That medium, as I will argue throughout, should not be taken as a value-neutral conduit of information. Typesetting software, ebook readers, and word processors contain in themselves implicit models of text and discourse-formation. They very literally contain system-level definitions of what a word is or what counts for a document. It is our job then to recover latent forms of textuality still extent on devices from mobile phones, to laptops, and super computers, and to expose them to critical interrogation. The task of media archeology on the level of the operating system is a literary scholar's version of baking bread and smelting iron. 

### Materialism
Finally, this book, and any notion of critical practice, owes a debt to the legacy of critical theory. In the past few decades, the project of critical theory (and related "schools" like cultural studies) has lost some of its evocative power. Rather than rehashing a dry academic debate, allow me enumerate some reasons for its decline in my own thinking. The first is the movement's overt political goals. Patently the "stock" of Marxism, socialism, communism and related ideologies has declined. Major critical theorists like Roberto Unger and Michel Berube are now legitimately writing about the left's political crisis [^@cite]. Moreover, the political aspirations of critical theorists were always somewhat difficult to defend in the face of other, contradictory academic values like objectivity, neutrality, and critical thinking. However problematic those terms are in themselves, we must acknowledge that they represent a set of deeply-seated beliefs about the nature of scholarship. Already present in Socratic or Confucian models of rhetoric, these values place an emphasis on questioning received knowledge and on empowering students to arrive at their own conclusions. In that light, the task of critique should be to expose political assumptions rather than to promote a particular political ideology. 

As journals, departments, and libraries struggle financially, a whole industry of middlemen thrives on the monetization of knowledge that rightly belongs to the public domain. Libraries spend inordinate amount of money to essentially buy back the research produced within their own community. Academic journals that operate on principles of peer review and volunteer labor are then entered into private circulation. Prices of $30-60 per article in the humanities are not unusual. In perpetuating these conditions we reduce the notion of critique to a meaningless rhetorical trope. The examination of our own immediate material contexts of knowledge production and dissemination are crucial to conversations about "world literature," "public discourse," "collective memory," or "politics in the archive."

*Plain Text* is an attempt to repay the debt of materialism. The alienation, as I will argue here, begins with the roots of my profession: namely the production of textuality in everyday life. It is quite likely that most of readers spend the majority of their waking hours in front of a personal computer, typing letters on a screen (among other things worthy of their own examination, but outside of the scope of this book). My goal then is to reclaim the ordinary material contexts of a dominant mode of knowledge production and dissemination. It is one thing to theorize about notions of form and content, and it is quite another to see how form and content are encoded in .txt and .pdf formats and to further how these distinctions then affect material divisions of labor between "knowledge workers," "content producers," typesetting sweatshops, and international conglomerates that control vectors of literary distribution.

## Structure
I tend to write concisely--a style that I think fits well with the subject matter, and something that should appeal to the audience. At this point, I am aiming for a manuscript of around 60-80k words, which would allot around 5-7k words per chapter (around 20-30 book pages).

### Chapter 1: Decoding Text 
Challenging the traditional dichotomy between form and content. In looking at the history of several paradigms of word processing I unearth the distinction between meaning (content), semantic structure (form), and visual style (typesetting). The chapter ends with a discussion about contemporary publishing practices and the ethics of outsourcing typesetting. Case studies from the history of digital typesetting (the ASCII and UNICODE standards) get us to a notion of textuality still deeply embedded into the operating system. 

### Chapter 2: We Have Always Been Digital 
Containing a discussion of terms "digital" and "analog" as categories that denote something existentially more than mere difference in mediation. A conversation about discreetness and continuity. The "soap opera" effect and how it challenges our intuitions about the above. 

### Chapter 3: Freedom of Information
Containing an argument against the "systems" definition of information advanced by Shannon and Weaver. In what Shannon calls a "strange feature" of this communication theory, information is defined as amount of "freedom" or entropy in the system. By contrast, I want to insist on the agency (freedom) of the sender and the receiver. Incidentally, we get some clarity on the differing ways in which information is invoked in different discourses.

### Chapter 4: Scratch Collector
Discussing the often overlooked congruence between data and metadata. Data vs. Information as it relates to interpretation. Paragraphs and novels as data structures. Diaries and code comments. Separation of code, comments, and data. An argument against object-oriented ontology and the impossibility of a literature for robots.

### Chapter 5: Media, Message, Mode
Media is defiantly not the message. Sources of that confusion and what's at stake. Encoding of the media on magnetic storage. A revisiting of modalities written and oral.  Derrida and Ong.

### Chapter 6: Platforms of Self
Understanding the document as a vector. The problem of drafts and versions. What is being transmitted through the vector? The appointment with one self: Beckett and Sartre. Pipes and I/O serialization. 

### Chapter 7: Processing Words
Text as an interface between human and machine. The notions of an interface (Galloway). Incompatible modes of understanding. Anne Finch and the liminal space between species.
What you see is not what you get. Isomorphism. Search. The brief moment of desktop publishing. Pen, typewriter, and word processor (with detours to Kittler and Heidegger). 

### Chapter 8: Bad Links
Why links are bad. The long history of intertextuality. The excitement of the 90s about it. The intertextual art of Gwern. Erudition and analogical thinking. The difference between hard-coded and symbolic links. Just a bit about the nature of knowledge or what is meant by "I've read that book." Snapshots, the Internet Archive, and the future of Wikipedia.

### Chapter 9: Writers' Room
Writing together. Models of co-authorship (and why we should pay attention). The massively multi-authored online novel (Wu Ming and Lo zar non è morto).

### Chapter 10: Hidden Message
Encrypted literature. Surveillance and counter-surveillance. Notions of textuality as embroiled in contemporary ideas of privacy, secrecy, and transparency. 

### Chapter 11: New Humanism
Computation does not necessarily work for the military-industrial apparatus (as argued by Golumbia, Lennon, and McPherson). Recovering and preserving textuality in computing. Engineering for dissent.

### Tech Appendix

## Timeline
I keep detailed logs of my daily writing practice. During the academic year, I average around 250 words per day, a number that nearly triples during breaks. Assuming a manuscript of around 80k words (and discounting the fact that large portions of this book are anticipated in my dissertation), a conservative estimate of my schedule would place the final draft somewhere towards the second half of summer, 2015. 

# Part 1

## 1.1 Decoding Text
### Introduction
In an ASCII-rendered plain text file, byte count corresponds to character count.[^ln-char] Let these words soak in for a moment. I will spend the rest of the book unpacking this idea. We will have to come to terms with what "plain text," "ASCII," and "bytes" really represent. But for now, a common-sense understanding of the sentiment should suffice. It is enough to have the intuition that texts and characters are concepts meant for humans and that bytes have something to do with (and for) machines. Remarkably, under the singular conditions of plain text (and even then, not always, and with many caveats), a unit of information meaningful to me (a human for the most part) gains a measure of equivalence to a byte, a unit of information "meant" for a computer.[^ln-human], [^ln-meaning]  

Not all texts are created equal. In print, traditional distinctions between form and content lie flat. The printing press firmly embeds letters into paper, leaving no space between ink and page. From the early days of the internet, the writing of media-minded critics like Jerome McGann [@mcgann1991], Johanna Drucker [@drucker1996], and Katherine Hayles [@hayles2004], has compelled literary scholars to re-evaluate textuality in its media-specific contexts. Their work reminds us that the flatness of digital text endures only as an illusion. A substantial gap separates presentation from source material. Low-level, operational intuitions governing textuality--ideas about form, content, style, letter, and word--change radically as text shifts its confines from paper to pixel. Forces of capital and control often exploit that gap, relying on technological obscurity and institutional momentum to promote their ends (for better or for worse). I contend here that some of the higher-level ills of the contemporary public sphere, the so called crisis in the academic publishing industry, for example, can be linked directly to our inability or unwillingness to come to terms with conditions of digital textuality. A society that cares about the long-term preservation of complex discursive formations like free speech, dialogue, and deliberation online, would do well to take heed of textual building blocks at their foundation. Text matters because how it is encoded, transmitted, and stored, decides who gets to decode, receive, and access.

[^ln-char]: There are many caveats here, to be explored later. Follow along with exercises related to the discussion in the Technical Appendix.

[^ln-human]: Recent theory challenges the conceptual boundaries between humans and machines in a concerted way. Perhaps, such boundaries were never that clearly articulated in the first place. It is also likely that other modalities of being are possible on the spectrum between human and machine, or human and complex system. We will have a chance to explore these possibilities in second half of the book. For now, I ask that the reader simply rely on the colloquial, pre-theoretical understanding of both person and instrument. However intertwined the hand and the hammer can be, there is an intuitive way in which a child can separate one from the other. There is deep-rooted instinct at work in that distinction, one that cannot and should not be dismissed as mere naivete. The concept of a human is in itself a powerful theoretical construct, and, as I will argue later, one necessary, not only for the understanding of key concepts in literary theory and computer science, but also in articulating an ethics of critical computation.

[^ln-meaning]: I write "meaning" in quotation marks, because the question of whether it makes sense to talk about meaning for artificial agents is a question that will remain unresolved, at least until the later chapters, when we have the chance to discuss notions of data and information as meaning-carrying units.    

### Form and Content 
What is text? In talking about texts of all kinds, literary scholars and computer scientists often make the distinction between form and content. For example, in her book on computational text generation, Kathleen McKeown writes that to produce discourse, writers and speakers "must decide what to say and how to present it effectively." A machine that generates text should, among other things, be able to determine "content and textual shape" of what needs to be said or written [@mckeown92 p.1]. Similarly, in her influential essay "Print is Flat, Code is Deep," Katherine Hayles writes about "the interplay between a text's physical characteristics and its signifying strategies" [^@hayles2007 p.72]. Let's dwell on the history of the distinction between content and textual shape, between a text's physical characteristics and its signifying strategies for a few paragraphs. I'll give you the standard version first, but then return to revise and to complicate it a bit because the traditional version hides a rather serious confusion, one that will become increasingly central to our conversation.

The dichotomy between form and content harkens back to traditional Platonic theory of essences. For Plato, the "essence" or an "idea" of something (like a chair) exists in a sort of an ideal, metaphysical state, somewhere beyond the confines of the material universe. By contrast, a physical instantiation of that object (a specific chair) comprises a somewhat more limited, even corrupted, version of that idea. The task of the philosopher then becomes to reconstruct the ideal notion of the perfect chair from many imperfect copies. A computer scientist will recognize in this chain of reasoning the principles behind object oriented programming: a way of building software that works by defining abstract "object classes" and invoking them as "class instances" [@hoare, @nygaard]. For Plato and later René Descartes, G.W.F. Hegel, and many other idealist philosophers, ideas provide us with enduring, universal, truths about the material, constantly changing, world.[^ln-descartes]

Hegel gives us the paradigmatic formulation of the distinction between form and content in his *Lectures on Aesthetics*. According to his system, classical art strives to reach a sort of an equilibrium between its ideational, spiritual content and "the configuration of sensuous material [@hegel-aesthetics-english p. 70]." Whole books have been written on Hegel's rather technical and sometimes idiosyncratic vocabulary. Rather than define terms precisely, Hegel likes to give his reader a sort of a cognitive cluster of related concepts. On the side of "content" (*Inhalt*, *Gehalt*), his reader will find concepts like inner life (*Innere Lebendigkeit*), feeling (*Empfindung*), soul (*Seele*), and spirit (*Geist*). All of these convey some sort of inwardness and other-worldliness, to the spirit (*Geist*) or mind (*Gedanken*, *Verstand*). On the side of "form" (same in German) he accumulates words like expression (*Ausdruck*), presentation (*Darstellung*), but also lines, curves, surfaces, carvings, colors, tones, word sounds, and generally material (*Linien*, *Krümmungen*, *Flächen*, *Aushöhlungen*, *Farben*, *Tönen*, *Wortklängen*, *Material*) [*hegel-aesthetics-german, *Einleitung*]. These all convey notions of this world and external manifestation, available for examination to the senses (*Sinne*). 

By contrast with classical art, the art of Romanticism seeks to disengage itself from matter, reaching the realm of pure self-reflective spirit, "freed from this immediate existence which must be set down as negative, overcome, and reflected into the spiritual unity [@hegel-aesthetics-english p.81]." He writes: "Poetry is the universal art of the spirit which has become free in itself and which is not tied down for its realization to external sensuous material; instead, it launches out exclusively in the inner space and the inner time of ideas and feelings [@hegel-aesthetics-english p.89]." Finally, "inwardness celebrates its triumph over the external and manifests its victory in and on the external itself, whereby what is apparent to the senses alone sinks into worthlessness" [@hegel-aesthetics-english p.81]. Romantic art triumphs over the external, material world, reaching at its pinnacle the stage of "free concrete spirituality" (*freie konkrete Geistigkeit*) [@hegel-aesthetics-german p.check on number]. 

Not all text is art, of course. But, if one believes in the potential for text to reach such lofty heights, he would also have to place value on the act of interpretation. The Hegelian art critic reaches beyond the pretty shimmering surfaces to divine internal, eternal metaphysical truths. Stephen Best and Sharon Marcus describe such a mode of interpretation as "symptomatic reading," a strategy that seeks latent or concealed meaning behind the surface of the text. For a Marxist critic like Louis Althusser or Frederic Jameson, that latent meaning may have something to do with hidden machinations of capital and ideology. The psychologically-minded reader may read in search of hidden drives, desires, or cognitive structures. By contrast, Marcus and Best describe several contemporary trends bulk at the Hegelian tradition, preferring instead to read at the surface of the text: descriptive reading, reading for form, for material, or "just reading [^@marcus-surface pp. 1-12]. 

The history of literary scholarship is punctuated by these moments of revolt against interpretation. In the late 1960, Susan Sontag wrote about "the need for more attention to form in art." Interpretation can be liberating, she wrote, but it can also stifle creativity. It "depletes the world" in some way and places the critic in a privileged, unnecessarily meddling position between reader and text. "If excessive stress on content provokes the arrogance of interpretation, more extended and more thorough descriptions of form would silence," she writes. "The best criticism, and it is uncommon, is of this sort that dissolves considerations of content into those of form [@sontag 8-9]. In yet an earlier revolt at the turn of the 20th century, Russian and Italian formalists strove to break with Hegelian normative aesthetics by wedding literary criticism with descriptive linguistics. In art, instead of inward symbols, they saw outward-pointing "devices" like rhyme and meter. In this vein the Italian futurist Filippo Marinetti wrote about the "grotesque funeral" of romantic notions of beauty, and the rise of a new "geometric and mechanical splendor." His generation was instead "in love with matter," wanting "to penetrate it and to understand its vibrations [@marinetti]."[^ln-marinetti] In an inversion of Hegelian humanism, form took on a spiritual function for the Russian formalists. Art cannot be reduced to "thinking in symbols," wrote Viktor Shklovsky in 1917. Words "die" and become invisible to us in frequent use. Everyday prose in that sense is transparent language, no longer capable of evoking wonder. Truly vital art can counteract that death by "resurrecting the word" in "making the form difficult." The study of poetic language (not necessarily poetry) therefore pays attention to the devices that aid in that renewal [@shklovsky, @echenbaum, @jakobson]. In other words, for formalists what we say is less important than how we say it. Or, at the very least, the two are intimately related.

[^ln-descartes]: It is difficult to resist quoting from Descartes' *Meditations on First Philosophy* when discussing idealism. He writes: "Let us consider the things that people ordinarily think they understand best of all, namely the bodies that we touch and see. I don’t mean bodies in general – for our general thoughts are apt to be confused – but one particular body: this piece of wax, for example. It has just been taken from the honeycomb; it still tastes of honey and has the scent of the flowers from which the honey was gathered; its colour, shape and size are plain to see; it is hard, cold and can be handled easily; if you rap it with your knuckle it makes a sound. In short, it has everything that seems to be needed for a body to be known perfectly clearly. But as I speak these words I hold the wax near to the fire, and look! The taste and smell vanish, the colour changes, the shape is lost, the size increases; the wax becomes liquid and hot; you can hardly touch it, and it no longer makes a sound when you strike it. But is it still the same wax? Of course it is; no-one denies this. So what was it about the wax that I understood so clearly? Evidently it was not any of the features that the senses told me of; for all of them – brought to me through taste, smell, sight, touch or hearing – have now altered, yet it is still the same wax."

[^ln-marinetti]: "Il nostro amore crescente per la materia, la volontà di penetrarla e di conoscere le sue vibrazioni, la simpatia fisica che ci lega ai motori, ci spingono all'uso dell'onomatopea." [@from Lo splendore geometrico a meccanico e la sensibilità numerica] 

[^ln-echenbaum]: "Что касается 'формы', то формалистам было важно только повернуть значение этого запутанного термина так, чтобы он не мешал постоянной своей ассоциацией с понятием 'содержания', еще более запутанным и совершенно ненаучным" [@echenbaum part3 of Teoria Formalnogo Metoda]

### The Problem of Duplicates 
My short history of the distinction between form and content is necessarily reductive. The situation on the ground was always more nuanced than the dichotomy would suggest, with a number of reasonable positions between radical idealism and radical materialism. But I was hoping to give you a taste of what was at stake: not just a dry academic debate about the nature of art, but the very possibility of art (and don't necessarily think "high art" here) to transform humanity. For Hegel, art reached for truth, transcending the deterministic physical universe. For the formalists, art worked to revitalize stale metaphors and ossified ways of thinking.   

The division of text into form and content makes a difference in more utilitarian ways as well. Imagine the challenge of compiling all known commentaries on Shakespeare's *Hamlet*, by hand or programmatically. The problem of what to count as a single text would be one of the first design challenges you would encounter. In the words of Barbara Mowat and Paul Werstine, the editors of Folger Digital Texts, "readers assume that there is a single text for the plays: what Shakespeare wrote. But Shakespeare’s plays were not published the way modern novels or plays are published today: as a single, authoritative text. In some cases, the plays have come down to us in multiple published versions, represented by various Quartos (Qq) and by the great collection put together by his colleagues in 1623, called the First Folio (F). There are, for example, three very different versions of *Hamlet*, two of *King Lear*, *Henry V*, *Romeo and Juliet*, and others. Editors choose which version to use as their base text, and then amend that text with words, lines or speech prefixes from the other versions that, in their judgment, make for a better or more accurate text [@digitalfolger, Textual Introduction]." Textual editors face such decisions routinely. What appears to us as one unified work, *Hamlet*, is an actuality a set of somewhat diverging drafts and editions. Errors in transcription and editorial interventions accumulate. The proliferation of unlicensed copies, translations, and imitations further adds to the complexity of the problem. 

Editors of classical literature will often solve the problem of diverging copies by designating one version as canonical, preserving the formal characteristics of the given version down to individual line breaks. It then becomes possible to collate commentaries, connecting each to individual words and passages at their canonical location. But the problem still remains in the abstract: the editor must force a single authoritative text where many exist. The act of deciding on what constitutes an authoritative edition can quickly become a contentious issue, particularly if the text in question has religious or political significance. 

A whole field of textual criticism exists in the service of negotiating "critical" editions which in some way preserve the struggle to reconstruct the authoritative text. But what should count for being authoritative? A number of logically possible answers find just as many ardent adherents. For some, the act of deriving the authoritative text lies in reconstructing authorial intent, through author's diaries or first-hand witness testimony. Others place a premium on reconstructing and analysing the writing process itself, in what has recently been dubbed as "genetic criticism  [@deppman, 1-36]". Yet another approach will compare multiple editions of the same text to derive a possible meta-text, that preserves all variation. Yet other editors will simply rely on their judgement to produce what they believe is a "true" text based on a number of personal and eclectic considerations [@greg, @bowers, @mcgann]. All of these approaches have at least this one thing in common: behind the fuzzy profusion of textual material they perceive the outlines of a single, unified work.[^ln-tanselle] Thus despite its careful attention to the materiality of the text, textual criticism often remains a classically idealistic pursuit. All real-word textual variants are corrupt in some way. The work exists as an ideal form in the realm of the ideal. 

[ln-tanselle]: In the words of G. Thomas Tanselle, a prominent contemporary textual scholar in the "copy-text" tradition: "Whatever concept of authorship one subscribes to, the act of reading or listening to receive a message from the past entails the effort to discover, through the text (or texts) one is presented with, the work that lies behind [@tanselle92, 18]." 

Goodman vs. Genette.

Duplicates in Computer Science. 

### Original, Originality
Drucker telling us to take heed of material. Copyright law vs. design patent! What constitutes a copy?

### WYSINWYG (What You See Is Not What You Get)
RUNOFF. http://web.archive.org/web/20141228030004/http://web.mit.edu/Saltzer/www/publications/CC-244.html

Pub! http://www.nomodes.com/pub_manual.html

Here's where things get a bit confusing. Hegel used the word form and material interchangibly. By form the formalists meant mostly semantic form. They were not "concrete" poets. Form was to them reproducible and somewhat independent of the material. This problem was already known to Plato and Aristotle. Summarize Material, Form, and Content w/ Form as something that mediates? Is the shape itself a thing?

Plain and fancy Text
Unix system. What you see is not what you get. What is plain text. Unix ideas of plain text. ASCII. From form and content to content, semantic markup, and typesetting. Semantic markup as part of the extra-linguistic meaning making.

Traditional distinction: Jacobson. Semantic, Stylistic, Content. Surface Depth.

http://www.unicode.org/reports/tr29/ The concept of Grapheme Clusters.

Semantic markup is interesting because it contains both material and ideal. The way textuality is encoded mediates between idea and matter. Mediation. Visible form and hidden form.

Controlling the interpretation. Controlling the distribution.

Lotman: "the material embodiment of a semiotic system." limited, hierarchical, and structured [^@lotman].
Barthes:
Derrida: "Everything is a text" [^@caputo].
TEI people: A text is an "ordered hierarchy of content objects" [^@derose]. Goodman and Genette.


## 1.2 We Have Always Been Digital

The original intuition, challenged by Nelson Goodman in the late sixties, still holds sway in the popular imagination. On this view, digitality has relates to digits, just as "analog" relates to analogies. First use of the word digital. The distinction between analog and metaphysical threat, Kittler and Golumbia. 

Language is digital. Soap opera effect. Gaps that allow the brain to fill it. Striation. Preserving striation. History of UTF8. Unix philosophy. 

Binary tends towards the continuoius (get the ch. Reality TV and the soap opera effect. Digitality is something worthy of being preserved.
### Digital Aesthetics
I therefore must already renounce and distance myself from the title of this section. "Digital culture" is already a misnomer, already archaic in its futuristic ambition. As a prefix, I think digi- has gone the way of the auto-, e-, i- and the way of the retro-suffixes like -bot, -mat, -lux, and -tron. A time will come when "digital humanities" will sound as redundant as "analog humanities" or "evidence-based medicine." Indeed that time has come. The digital is dissolving and has for the most part dissolved into the everyday—it has become familiar and therefore transparent to its native inhabitants. The aim of this dissertation is to make it strange again or at least to make digital culture seem less familiar and less naturalized to our ways of thinking.

What does the digital look like? It looks very blue for one—not just any kind of blue, but a particularly cool shade of pure blue, which passes from dark to translucent overtones. The resulting pages produced by an online image search under the query for "digital" are saturated with that color. Fractals predominate in the first dozen or so search results. There are things too of course, many expensive things like scanners, flash cards, circuit boards, and backup drives, but most of all it is cameras—digital cameras, the very idea of which is meant to stand in stark contrast to "traditional film photography." Very few other marketplace objects exhibit such a strong sense of the opposition between the digital and the analog. These pages also contain the outdated clichés of yesterday's digital: digital clocks, purple lightning bolts, and the abstract chrome landscapes made widely available by graphic editing software in the 1990s. There are numbers. The preferred arrangement is in a torrential grid—the matrix—descending in the background of a generic humanoid form, also translucent. Or better yet: a 3D sphere or a face made out of random characters. Ones and zeros are best arranged as an unending string, which runs at a slight angle on the Z-axis and beyond the frame, foregrounding whatever object that is meant to take on the digital as a property.
If we were to constrict our search chronologically to the twenty first century, we would see these images give way to a more varied palette, bright prime greens, yellows, and reds—blocky colors and retro-geometric pixelated shapes. Pixels take the place of numbers here—not the small invisible pixels of contemporary computer screens, but the large and boxy pixels that by their very visible boxy-ness flaunt the digital being of the image. Such an image alludes to the time when pixels really did stand out as individual units—the technology not being refined enough to produce the illusion of visual continuity. This faux lo-fi aesthetic is likely to appeal to the romantic nostalgia many may feel for the early days of computing, and yet it also is an assertion of independence from that history. No longer shall the digital serve to emulate reality, nor be judged merely by its degree of life-like verisimilitude. The blocky world of Markus Persson's Minecraft (2009) is the antithesis to the magical realism of Cyan's Myst (1995), the best-selling graphic-adventure PC game of the 20th century. Where the latter was lauded for immersive photorealistic landscapes, the former embraces the 8-bit low-fi aesthetic of 1980s gaming consoles. The net effect is an experiment in deconstruction: fragmented geometrical planes and almost cubist-like discontinuity of form.

The iconography of the digital works in the other direction too, by approaching and challenging the continuity of the analog world. The liquid-metal Photoshop font effects are thus supplanted by hyper-realistic renderings of fire, smoke, and water—fluid elements which are by their very nature difficult to render digitally, especially in movement.1 The digital element is meant to approach the boundaries of technological possibility, but absent the constraints of realism it pushes past reality, past nature, past mere fidelity to the natural world. A movie explosion without special effects thus looks cheap in comparison to the real thing. A flaming corporate website logo would lose much of its appeal were it produced by literally lighting a logograph on fire. A flaming corporate logograph does not simply say "we are hot" or "we are on fire" (that would be too naive)—it says that our fire is better than fire, more vivid and more life-like. The digital fire is the ideal, Platonic image of fire—it is an image that all fires should emulate.


### The problem of duplicates
The conversation between Goodman and Genette. Goodman's "Art and Authenticity." Benjamin. Immanence and transcendence. Goodman: thinking about the perfect copy. But there is a confusion here: fake art is not necessarily about a copy, it is about provenance. Autographic vs. allographic art. Whether forgery is possible. Digital vs. analog art. Analog art is medium bound. Digital abstracts from the material. 

## 1.3 Freedom of Information
Information is intentional. Against the "cybernatic" formal definitions. 

Kant, Schiller on beauty as freedom on beauty as freedom
Information as entropy. The strangeness of Weaver's "information as entropy". How much information in a brick? In a novel? Information as a possibility.

Freedom and information seem to have nothing to do with each other. They have everything to do with each other.
Makukov. Directed pan-spermia.Life Sciences in Space Research paper: http://arxiv.org/abs/1407.5618 Icarus paper: http://arxiv.org/abs/1303.6739 

What is information? The difference that makes a difference. Bateson's definition. Dorsality. Weaver's entropy. Explain. Amount of freedom. Confusion in that paper. Noise and information seem to be the same! Thermodynamic explaination. Transmitting things in stone (low entropy) vs. transmitting them through the air (high entropy). Does a block of wood have more "information" than a novel? This definition cannot account for it really.

Extended cognition hypothesis. Get this text from disertation. The monism problem.

Formal vs. instrumental definitions. Information is that which moves form a Mind > Encoding > Mediation > Decoding > Transmision. Coersion. Can information be coersed? Both on the sending and the recieving end. Can someone admit something is music by force? Can you force information. The deer and the tick. The deer does not "send" bodyheat information. The tick receives information as it does receive the action of gravity. Does a mountain erode from the top because it recieves information from the outside? Information here is simply used as a synonym for some material state of the univrse and the causal relationship between forces. Causality alone is not information. Laws of physics are not information. Well, unless...

Mis information. Man in the middle attacks. Information is intentional. Mind to mind communication. Where does the thought originate? Freedom. Free intent. Identity of coding and decoding is not necessery. What is however necessary is the 

Leroi-goran. Constructor theory of information. SUperinformation. http://arxiv.org/abs/1405.5563

 

## 1.4 Dysfunction by Data
Data.

### Scratch Collector
Metadata
k
Code and comments. Collector of chair or collector of scratches. Object oriented ontology. Object oriented languages. Competing paradigms: separation of code and data. No separation (Haskell).

## 1.5 Media, Message, Mode
Key terms: media, message, mode

### Intro
What happens in the change from speaking to writing? The violin (copy from dissertation here).

Attunement of listener. Message stays the same. Put a ear, eye, hand to the pipe. Same message, same medium, different mode.

Krap's Last tape here. 
Who are you communicating with? Pushing yourself through the pipe. The appointment with myself. The sum-total of material substratum. Building a wider platform. Todo, email, diary, music collection. Burning building-we grab our memories, and hoarding the disfunction of that personal sediment. You are the sum-total of your modalities. Commitments to self. Attunement of self. The message is you. Preserving ourself from entropy. 

Books are not media they are platforms. Platform is all of the above. Plus the economic / cultural contexts. Amazon Kindle is a platform. Who are you communicating with? Yoursef. What is the message. Ultimtely, it is a message of self-identity. 

### McLuhan
McLuhan's Understanding Media is a fitting companion to the modern conversation on extended cognition, first because it announces its allegiance to the hypothesis openly and from the very first lines of the treatise, and second because it so readily exceeds the hypothesis rhetorically, falling into the traps of metaphoric imprecision and limitless expansion. For those unfamiliar with the work, it would be useful to know that McLuhan conceives of his project as a study "on the extensions of man." He writes:
During the mechanical ages we had extended our bodies in space, today, after more than a century of electric technology, we have extended our central nervous system itself in a global embrace [...] Rapidly we approach the final phase of the extensions of man—the technological simulation of consciousness, when the creative process of knowing will be collectively and corporately extended to the whole of human society, much as we have already extended our senses and our nerves by the various media.1
Granted, McLuhan's writing lacks the precision of HEC, which is advanced from the platforms of analytic philosophy and cognitive science. And yet, it is clear that throughout Understanding Media, McLuhan is committed to a version of the extended mind hypothesis, which in his vocabulary translates into a vision of global, limitless expansion of consciousness, facilitated by technology. For McLuhan our collective "nervous system" is "technologically extended to the whole of mankind."2 Such holistic monism is declared literally as a matter of faith. "The aspiration of our time for wholeness, empathy, and depth of awareness is a natural adjunct of electric technology," he writes. "There is a deep faith to be found in this new attitude—a faith that concerns the ultimate harmony of all being."3 And elsewhere: "In this electric age we see ourselves being translated more and more in to the form of information, moving toward the technological extension of consciousness."4 And yet despite the frequency with which this refrain appears in the book, the author does little to argue for it. We are asked to subscribe to the extension thesis as a matter of apriori intuition. Nothing has been said to bolster the claims of the extension, and most of McLuhan subsequent argument hinges on the reader accepting this strong version of extension.
    Consider for example McLuhan's quintessential "the medium is the message" argument. I have shown elsewhere that we cannot take this to be literally true. The principles of information theory would hold that the medium is precisely content-neutral, particularly when it comes to the transmission of digital information. So what exactly does McLuhan means by "the medium is the message?" We must begin by understanding what he means by "the medium" and "the message." In one sense, he means the media to denote the conventional array of transition channels: radio, cinema, literature, television. But in another sense, he means these transition channels to act literally as extensions of the human sense apparatus. For example, in the beginning of chapter he writes that "the social consequences of any medium—that is, of any extension of ourselves—result from the new scale that is introduced into our affairs by each extension of ourselves, or by any new technology."5 Elsewhere he writes that "[...] that our human senses, of which all media are extensions, are also fixed charges [...]."6 The medium, for McLuhan, is thus a marked concept, different from its dictionary definition in that it contains the hypothesis of sense-extension.
    The message in McLuhan's sense is equally specialized, and again related to the extension hypothesis. "The 'message' of any medium or technology is the change of scale or pace or pattern that introduces into human affairs," writes McLuhan.7 In this sense the message should not be confused with "content" or "information." The idea of content only obscures the fact "it is the medium that shapes and controls the scale and form of human association in action."8 If media and messages are beginning to sound the same according to these definitions, it is because for McLuhan they explicitly are the same: "the content of writing or print is speech,"9 he writes, and "the 'content' of any medium is always another medium."10
    But this really is no thesis at all. McLuhan's dictum would not find cultural relevance if his famous dictum was merely a tautology. "The medium is the message" roughly translates into the proposition that all media, besides carrying their formal content (or no content at all, as is the case with electric light in McLuhan's initial example) affect our collective psyche in some way—in other words, a more generalized, popular version of our extension hypothesis. But how committed is McLuhan to the analogy between media and "extended consciousness" or "externalized nervous system." Not very. The metaphor is alluring but imprecise. For McLuhan everything has the potential to be mediafied—money, labor, technology, culture. It is all vaguely "an extension of man," not just the extension of the senses, corporeal, or cognitive extension. All products of human culture end up reconfiguring human culture as such—that is the "message" of McLuhan's thesis.
What is at stake here for us? What does the extension hypothesis mean for the study of human culture? Well, for one let's note that practically all examples of extended cognition in the wild—I dare say all thought experiments mentioned or staged in the literature on HEC—involve literary interfaces. Extended cognition in that sense requires the storage and retrieval of information, facilitated by a symbolic notation system, and a medium on which such information can be stored for later retrieval. For Otto, this system involved a notebook, a calendar, or a planner perhaps. For the pilots in the cockpit, the flow of information also proceeds across devices which accept input and offer output in symbolic notation: the number on the altimeter dial, the iconographic status indicators, the keypad, and the control panel. It is also worth noting that all such systems and devices are essentially dumb instruments. They become "cognitive" only in the moment of interaction. Without Otto, the pen and paper does nothing. It comes to life only at the point of interface.
The second observation we must make is that the hypothesis of extended cognition brings the mind out of the head and into the material sphere of existence. Taking HEC seriously means to supplement fMRI-based cognitive science with anthropological, social observation of cognition at work. And since we are talking about tools and habits of thought (rather than neurons, or brain-matter) we must acknowledge that the formation of the mind, at least in the extended sense, can span beyond one's own, private mental development. Extended, the mind gains a shared history.
HEC also implies that the long-standing anxiety over the impact of cognitive aids on our natural human capacities—an anxiety that has been around at least since the times of Socrates, an anxiety that is clearly expressed in Heidegger's philosophy of technology, and that is featured prominently in the recent cautionary tales of human decline by Richard Foreman and Nicholas Carr—that anxiety has at least the merit of considering the mind in its embodied, contextualized form. The critique acknowledges the impact of technology on our mental habits. But the negative value assessment is the least interesting part of that argument. Cognitive aids are only as "good" or as "bad" as the purposes for which they are used. If calculators have diminished our capacity to do math in our heads, they have also alleviated much tedium involved in mundane everyday arithmetic—at the bank, at the supermarket, and at home. And few would argue that mass literacy (as a technology) had anything but a positive effect on our society, and that despite whatever effects literacy may have on our "natural" ability to remember things without writing. "Natural" is, in this case, an artificial construct, tied to one's willingness to engage in nostalgic reverie about an idyllic state of unadulterated past.

## 1.6 Platforms of Self
Key terms: file, document, stream, net neutrality
Commands: grep, awk, sed 

Wikipedia as a Turing complete language. The power of versioning. Text as a vector. The problem of annotation. What are we annotating? Annotation solutions force a platform. Is Hamlet a platonic object? A family of related objects? Standard English editions in Europe.
### Problem of Drafts and Versions
Documents as vectors. Not completed things. Files as cognitive scaffolding for collective memory. Vissman. 

Science lecture vs. humanities. Stuff that is known. Stuff that is not known

What does it really mean to "know" something? Or to have "read" a book? I have had the following conversation countless times. Someone asks, "Have you read Nabokov's *Pale Fire*," and I respond, "Yes I have." But there is a world of a difference between reading it yesterday, last week, or ten years ago. The book as an interface leaves an organic trace in the human mind--an imprint that begins to fade as soon as it is created.

How much knowledge is there in the world? According to a recent paper published in Science, 295 exabytes (or billion gigabytes).[@hilbert] 

Whatever consciousness is, it is propelled forward on a thin edge of material substratum. Reality exists only in the now, where the past is a memory and the future only a possibility. Imagine whispering something to a friend. It does not have to be very complicated, something like "I love you" or "I miss you." The whisper dissipates as soon it is uttered. The percussion of the speaker's breath creates temporary order: giving shape and pushing air molecules into waves of pattern and form. That order begins dissipating as soon as it is created. Within milliseconds, molecules return to their natural state of chaos.

To steel ourselves against entropy, we change the substratum from air to stone. It's molecules are more stable. Etched in stone will be the same message. It will last longer now. But it will also take longer to create. You will have to carry around your tablet and chisel. The message etched in stone will outlive the whisper and indeed will

Repercussion? How we preserve ourselves today affects the future. Appointment with self. 

The essay by Heidegger. Uxcull phenomenology.  Leroi-Gourhan, André. 

The book as an interface between human and ?. We must see it in the context of interfaces.

### Krapp's Last Tape
Beckett sets the stage for his 1958 Krapp's Last Tape on "a late evening in the future."1 The reason for this rather ambiguous dating is probably technological. The first personal tape-recorders were manufactured in Germany in the early 1930s, with public demonstrations of the device happening as early as 1933 in Europe.2 The play makes it clear that Krapp is in the habit of reviewing and recording his tapes on the eve of his birthday. On this particular evening, he is turning sixty-nine, and he is listening to a recording of his thirty-nine year-old self, who in turn reports listening to a ten-to-twelve year-old tape. This dating sequence places the work well into the mid-1970s by a conservative estimate—a date which is ironically, more than a decade after the invention of the compact cassette tape (1962) by Phillips and only a few years before the introduction of the iconic Sony Walkman product line (1979).3 It is likely that Beckett wanted to protect the chronological integrity of the plot by shifting the time of the play forward. What he could not have predicted is the increasing pace of technological innovation in the twentieth century.
These modest annotations to Beckett's work are not meant to be facetious. The multiplicity of Krapp's fictional selves is made logically possible by the literary and the technological device alike. The seeming unity of Krapp's consciousness and indeed, the stage appearance of consciousness itself are aided by the use of the tape-recorder. The device on the stage creates the illusion of Krapp's inner life; it allows the author to shift the narrative in time; it multiplies and refracts the images of the main character of the play. The reel-to-reel player functions both as the audience and the actor, alternatively speaking and listening, recording and transmitting. And ultimately, Krapp's fate is not only linked to the tape-recorder, it is created by and for this technological medium.4
But just as Krapp is created by the tape, the tape is Krapp's creation—technology itself being inextricably enmeshed in the narcissistic activity of human culture. The tape-recorder cannot occupy the center stage—it must recede into the background to become invisible. The player exists to reflect Krapp's image back to Krapp and in the process, to record the encounter for later reevaluation and re-recording.5 This almost mythical recursion promotes Krapp's character to the archetypal role of the librarian, whose task is to collect, to preserve, and to curate his own personal experience—a librarian of the self. In this light, the specificity of the tape as a medium is not terribly important. The story would be similarly plausible were it set a century prior, using a conventional diary as its medium, or written some decades later under the title of Krapp's Last Facebook Page.6
Krapp's status as a librarian is confirmed in his elaborate filing system, by which he stores and organizes his recordings. He goes through several of his filing cabinets, "peering and poking at the boxes" as if to check the integrity of his collection, before settling on the tape from his thirty-ninth birthday ("Box Three, Spool Five" he says with relish.) The cardboard storage boxes, the drawers, the ledger, and the very word itself—"spool," "spooool"—make him increasingly happy. Beckett presents Krapp's archival activity as a kind of a Chaplinesque comedy routine, with erotic overtones: 
Krapp remains a moment motionless, heaves a great sigh, looks at his watch, fumbles in his pockets, takes out an envelope, puts it back, fumbles, takes out a small bunch of keys, raises it to his eyes, chooses a key, gets up and moves to front of table. He stoops, unlocks first drawer, peers into it, feels about inside it, takes out a reel of tape, peers at it, puts it back, locks drawer, unlocks second drawer peers into it, feels about inside it, takes out a large banana, peers at it, locks drawer, puts keys back in his pocket. He turns, advances to edge of stage, halts, strokes banana, peels it, drops skin at his feet, puts end of banana in his mouth and remains motionless, staring vacuously before him [...] He treads on skin, slips, nearly falls, recovers himself, stoops and peers at skin and finally pushes it, still stooping, with his foot over the edge of the stage into pit. He resumes his pacing, finishes banana, returns to table, sits down, remains a moment motionless, heaves a great sigh, takes keys from his pockets, raises them to his eyes, chooses key, gets up and moves to front of table, unlocks second drawer, takes out a second large banana, peers at it, locks drawer, puts back his keys in his pocket, turns, advances to the edge of stage, halts, strokes banana, peels it, tosses skin into pit, puts an end of banana in his mouth and remains motionless, staring vacuously before him7 
These stage directions exude a nervous energy one would expect before an erotic encounter: Krapp is being clumsy and excited. Box Three, Spool Five does indeed contain an account of a past romance, but the encounter Krapp is excited about is with the archive—that is with himself. The suggestive stroking of the banana punctuates the onanistic nature of Krapp's archival activity.
Let us envision Krapp's archiving habits for a moment. The stage directions specify a den and a small table containing two drawers that open towards the audience. The table holds a tape-recorder, a microphone, and "a number of cardboard boxes containing reels of recorded tapes."8 How many reels are there? Krapp is sixty-nine, and after more than forty years of recording he must have accumulated somewhere around forty reels (assuming that his recording sessions lasted around a reel each). Reading from the ledger, Krapp counts nine boxes. The reel from his thirty-ninth birthday is in box three, spool five. What of his tape-recorder? In 1958, when Beckett began writing his play (he continued to rework it well into the 1970s) there were at least several dozen tape-recorders on the market, with the most popular brands being Ampex, Crown, Magnetophon, Magnecorder, Sony, Webcor, and Wollensak (see Appendix, Table 1). The smaller portable, battery-operated versions of these recorders ranged in price from two to three hundred dollars, which adjusted for inflation would give us a range between 1,500 and 2,200 in 2009 dollars. The expense of the device contributes to the image of Krapp as a man of independent means, who has perhaps fallen on some hard times: he is wearing ill-fitting trousers, a black sleeveless coat, and a "surprising pair of dirty white boots, size ten at least, very narrow and pointed."9
Krapp's collection too has seen better times, for even the archetypal librarian of the self must face the problems faced by any librarian. The theoretically perfect recursion of the medium strains under practical scrutiny: classification systems deteriorate, descriptions lose their meaning,10 and even Krapp's own auditory mirror image betrays him when Krapp is forced to look up the word "viduity" in the dictionary (a word that made sense to him thirty years ago). Krapp's Last Tape, as it is conventionally interpreted, is a cautionary tale about "the last"—time, memory, desire, and nostalgia.11 But it is also a commentary about the "tape." Reel-to-reel recorders too will need further and progressively more expansive annotations for the play to continue to produce meaning. Thus, with the curtain drawn, we the audience, the readers, and the custodians of this work are almost immediately implicated in Krapp's narcissistic archival habits. Krapp's Last Tape is also a tape in our own collection—a tape that will continue to comfort and to unsettle us well into our own dotage.
In examining the encounter between Krapp, his tape-recorder, and his past self, I would like to shift the focus of the conversation about archives from the public to the private sphere. Jacques Derrida's "Archive Fever," given as a lecture in 1994 during a conference entitled "Memory: The Question of Archives" and later published in Diacritics, remains perhaps the paradigmatic text in the tradition that takes the archive to be a predominately public space, subject to the power dynamics between the patrons and the custodians of the institution. For Derrida and his followers, the archive "has the force of law, of a law which is the law of the house (oikos), of the house as place, domicile, family, lineage, or institution."12 Such a place preserves but also shelters the documents within. It remembers and forgets, so to speak. The word itself—archive—suggests arkheion: "initially a house, a domicile, and address," but also archons, or "those who commanded."13 In Derrida's understanding, the archive is thus both a location and a power structure. And ultimately, it is an institution, like the Freud Museum, where the paper was first given.
Consider by contrast Krapp's dingy collection. It is hardly an institution—it receives neither grants nor visitors, and Krapp himself is hardly a proper archon (he throws the tapes down in anger, and unlike Freud, he leaves no heirs to continue his lineage). In contrast to the Freud Museum, his collection mostly consists of documents that have only a deeply personal significance. His archive has less to do with social power structures and more to do with the mechanisms of private identity formation, remembrance, and nostalgia. To mimic Derrida here, we could say that his collection is a recollection—it is not a house, but a yearning for a house (nostalgia, from the Greek nostos, a homecoming14).
Of course, Krapp is only an archetype, the harbinger, and a symbol of a new type of an archivist. But even symbolically, his collection could not exist without the particular technology of the tape-recorder. That is to say that the semiotics of the private archive are enabled by the applied particularities (pragmatics) of the specific archiving practice (See Table 2).
Type:
Paper
Record / Cylinder 
Magnetic Tape
Digital / Cloud
Portability
high
low
average
device-independent
Capacity
low
low
average
virtually unlimited
Time shift
quick, tactile, imprecise
quick, tactile, imprecise
slow, linear, imprecise
near instant, precise
Search
indexed
none, visual
seek, mechanical
indexed
Size
small
large
small
irrelevant
Shape
square
round
long
fuzzy
Price
cheap
expensive
affordable
cheap
Power source
none
mechanical, electrical
batteries, electrical
batteries, electrical

Table 2: Media comparison, 20th Century
This chart is by no means complete. We have not accounted for the distinctions between digital storage devices, laser disks, film, or stone tablets for that matter. What matters is that the medium is largely independent from the type of information stored on it, and this contrary to Marshall McLuhan infamous "the medium is the message" dictum.15 The world itself "medium" is misleading in this context. We could for example say that paint is the medium of painting. But what about the photograph of a painting? Or its digital reproduction? The situation is even more confusing when we begin thinking about music, for example. What is the medium for J.S. Bach's Double Violin Concerto: the violin or the music sheet which contains the score? We are on yet more precarious terrain when considering hybrid "media," like film or television that are comprised of multiple sources and that use multiple modes of transmission.
The confusion enters the conversation when we conflate the modality of the information (e.g. music, image, text) with the physical channel of its transmission (the medium proper). Modality may very well be the message. Thus, it may be true that when one plays the violin, the music can be said to express itself in musical terms. But not the violin! I could use a violin to transmit a picture of an orchestra over a dial-up modem, for example. This would only involve the question of how to encode the visual information into a state transmittable by the violin (a primarily auditory instrument).
The channel of communication—the medium proper—is in fact, information-agnostic. That is to say that it has no preference about the message being transmitted (nor can it have a preference for anything at all, formally speaking—preference being a property we ascribe to objects that are at least animate). We could therefore transmit a sonata by playing a violin, as sheet-music, on a vinyl disk, recorded on tape, or by using an illegal peer-to-peer network. In each case, the information transmitted remains more or less the same, depending on the quality of your violin playing, the fidelity of your speakers, or the compression ratio of your digital encoding. It would be wrong too to consider any of these sources as somehow primal, with others being something like "mere copies" of the original. We could for example, start by composing music on paper. Alternatively, we could first play a piece of music and then transcribe it into musical notation. In an extreme but perfectly plausible case, we could compose by magnetizing a length of ferrous tape first, and only then play the violin to reproduce what we have "written."
The medium does not know anything about the message. The way in which we store, access, and retrieve the encoded information is determined by the medium, however. We are the ones being shaped by the media. I do mean this rather literally: the stage directions for Krapp's Last Tape would be very different were Krapp writing a diary, or browsing his online social networking profile, or if he were to embed a memory chip in his brain that was able to store and retrieve the same messages from his thirty-nine year-old self as the tape-recorder. The actor's body would move differently in each of these cases—his senses and his thought would be altered in many subtle ways, depending on the channel of communication.

The separation between mode and medium allows us to retain a certain clarity of vision in a rather muddled conversation about "media history." Modalities such as visual arts, music or literature do not necessarily evolve, in the normative sense of the word. Yes, it may be true that Filippo Brunelleschi invented the optical linear perspective in 1425. But the normative evolution of art could only make sense only against some concrete pragmatic goals, which the aesthetic realm lacks by definition. Nothing is gained or lost when the fashion changes from square-toed to pointy-toed shoes, and then back again—to use an example that would surely please Mr. Krapp. Neither is "better" or "worse" for the participants in that sphere of cultural activity. By contrast, the concept of the medium does contain some sense of normative valuation, also by definition. That is to say that the medium has a job, which is to facilitate the storage, the transmission, and the retrieval of information. And there is such a thing as doing this job better or more efficiently. More is always better in this case: more storage, faster access, more reliable transmission. When the quality of the information is not sacrificed, there are no instances were less would be preferable by anyone with limited time and resources. For example, I would like to be able to read or write faster. I value both of these activities, but my time to perform them is limited by my lifespan. Assuming I could gain speed without any degradation in clarity or comprehension, and barring any psychological ill effects, the idea of more in this case must be a good onto itself.
Armed with these insights, we can now return to the perhaps obvious idea that Krapp's collection could not exist without the particular technology of the tape-recorder. Krapp's Last Tape was made possible by the storage capacity, its portability, power source, size, search capacity, price, and yes, even the shape of the reel and the tape recorder. It is at this point, that I am able to restate the broadly historical thesis of this section: that these very same attributes have enabled a shift in the collecting practices of the western world—transposing the locus of our archival practice from the institutional to the private sphere.

### Identity
Anonymous authorship.


# Part 2 

## 2.1 Processing Words, Human-Computer Interfaces
Containing an argument for text as an interface between human and machine. History of combinatorial languages and logic.  Stack as a model of communication

"Pen is Mightier than a Sword" by Pam A. Mueller and Daniel M. Oppenheimer.
k

### Intro
Talk about stack exchange vs. 4chan vs. reddit

Heidegger. Extended cognition. Problems with Handwriting. Teaching children how to "write". Typing vs. handwriting.

Containing an argument for text as an interface between human and machine. History of combinatorial languages and logic. Isomorphism. Search. Protocol - interface. What you see is what you get. What you see is not what you get. Argument for text. Desktop publishing. Stream vs. Object containers.

Typesetting sweatshops.

http://word.mvps.org/faqs/general/wordvswordperfect.htm
http://wptoolbox.com/tips/MSWordToWP.html
modal vs. other kinds of processing 

### Interfaces 
What is a well-formed thought? Is being able to communicate one's reasoning clearly an integral part of clear reasoning? Can one think well, but write poorly? Or does thinking well in a sense also mean writing well? I don't mean to ask these questions to start an argument about cognition or rhetoric. Rather, I would appeal to the intuitive sense of connection between the written and the mental worlds and to simply note the natural correspondence between the two. There is a bit of magic in that correspondence—the kind of magic that becomes transparent (and disappears from view) through acclimation. Here is a simple to-do list from my partner. For some moments after reading it, her will has become my command. My arms and legs move under the spell of her bidding. For her part, she has ensured that the list reflects what she wants me to do. That is, it reflects what she wants. And in her absence, the to-do list did represent her volition accurately. I read it as a testament to her will; I was able to internalize the instructions; and then I acted on their behalf. We may say that the to-do list was used to synchronize an aspect of our mental lives. It was an interface of sorts, which has allowed us to bridge two separate mental worlds, mediated by a piece of paper. And yet how quickly we discard it! The interface itself is perhaps too thin and transparent to hold our (critical) attention.
An interface is literally a point of contact. The elevator button, for example, is a quintessential interface between you and the mechanism of the elevator. The button allows the will of the operator to become one with the action of the machine. It is an interface designed to accept human input. But, from the elevator's point of view, the human finger is the interface to the human. In the combined operation of human and elevator it is thus difficult to pinpoint the exact physical boundaries of the contact. The interface is paper-thin, we may say—it happens when a thing slides into the other, and for a moment both become one: a shared physiology and a shared intentional apparatus. We could say that our to-do list is a point of contact between two people. But before being that, it was a point of contact between a person, a piece of paper, and writing. For the purposes of this dissertation, a literary interface is a specialized point of contact between the mental, the symbolic, and the technological modes of being.
Let's examine the piece of paper more closely. A literary interface is first and foremost mediated by language. But language alone is not enough to constitute even a simple to-do list. We must also have writing—a way to record language for later recall or further dissemination. The to-do list also requires a pen and a piece of paper or any transferrable storage medium. I therefore insist on "literary" and not merely "textual" or "linguistic" interfaces, because my concern here is not with any individual text or utterance, but already with a system of such recorded texts or utterances—a physical, artifactual system, which encompasses a range of possible activities. These may include the ability to read and to write, but also to select, highlight, underline, format, annotate, review, redact, skim, commit to memory, store, archive, retrieve, search, borrow, lend, tag, comment, ruffle through the pages, digest, process (as in word processing), type, scribble, click, zoom, drag, drop, cut, and paste. It is this system as a whole that I propose to designate as "literary" (and this in contrary to some more specialized definitions of the same).
A literary interface is secondly an artifact of mental (cognitive) activity. To my mind, a text, like the to-do list for example, is always a privileged symbolic representation. I say this because I think it, and because what I write can be said to represent the state of my mind. Or at least I want it to represent accurately the state of my mind. Even if I wanted to deceive you as to the state of my mind, the deception would at least represent my desire to deceive (we will deal with truly un-intentional texts also in the scope of the dissertation). A text is a snapshot of sorts, which captures a fleeting moment from the stream of private, internal, and generally invisible mental events in the shape of a symbolic (representational), but nevertheless tangible, material, externalized and therefore visible artifacts. By contrast, spoken language is never fully externalized. At the exact moment of utterance my speech is still a part of my body. It is inside of me literally: on its way out, but still inside, near the tongue and the palate, still contained within my larynx. But in typing these words (rather than merely speaking them) I intend to spend much effort to enforce the congruity between what I think and what you read, asynchronously, through the intermediacy of language, text, and word-processing software (in my case). That intermediacy between the mental and the written is a part of the interface, in a way that the "interface between science and the humanities" may signify a common boundary between two distinct disciplines. The literary interface is privileged not just because it encodes an aspect of one's mental world, but because in the moment of contact, it is an aspect of that mental world. And for that moment, it is as dear to me as a toe or a finger, or perhaps as a dream or a recollection.

And finally, a literary interface is a material artifact. By this I mean that something like a pen, paper, a computer screen, or a keyboard is involved in the practice of using literary interfaces. Just like an elevator button, literary interfaces are physical objects. They come into being through usage, and make no sense as discrete objects, as in the case of the elevator control panel removed from the passenger and the mechanism of the elevator. Or rather, I should say that elevator buttons make no sense removed from the action of pressing buttons and transporting things and people between floors. An interface is a kind of a verbalized noun—its understanding must come not just in the examining the artifact, but in examining the artifact in action. Only in action can we observe the momentary unity between the literary, the cognitive, and the artifactual.


### Extended Cognition
The belief that the organic is the chief criterion of what is authentic in art and life continues, it need hardly be said, to have great force with us, the more as we become alarmed by the deterioration of the organic environment. The sense of something intervening between man and his own organic endowment is a powerful element in the modern consciousness, an overt and exigent issue in our culture.1
That technologies of the written word are somehow corrupting our native cognitive capabilities, that we are becoming dependent on externalized cognitive aids, and that such dependence has wide-ranging social repercussions, are worries that have permeated the popular culture since the days of Socrates. "I see within us all (myself included) the replacement of complex inner density with a new kind of self," Richard Foreman writes in an essay that accompanied his play The Pancake People. This new self is shallow, containing "less and less of an inner repertory of dense cultural inheritance."2 Nicholas Carr echoes these words in his recent article for the Atlantic Monthly, writing: "Over the past few years I’ve had an uncomfortable sense that someone, or something, has been tinkering with my brain, remapping the neural circuitry, reprogramming the memory." "The deep reading that used to come naturally has become a struggle," Carr concludes in an article which asks whether Google is making us stupid.3
And yet, many also instinctively believe that technology is working in exactly the opposite direction: that it expands, rather than contracts human possibilities. In a recent bestseller promoted by the likes of Bill Gates and Nicholas Negroponte, the authors and Microsoft researchers Gordon Bell and Jim Gemmell write about the era of total recall—a time when the advances in computer technology will "change the way we work and learn [...] unleash our creativity and improve our health," and ultimately "change what it means to be human."4 "The era of total recall is dawning," write Bell and Gemmell:
You may embrace full-scale “life logging,” and devote much effort to maximizing your e-memories, or you may prefer to record your activities only modestly and selectively, or even reject the whole idea and strive to leave as small a digital life-footprint as possible [...] Whether you are an early adopter, a late adopter, or a never-in-a-million-years nonadopter, society at large is on an inexorable path toward Total Recall technology and it is going to transform the world around you. The power of this transformation will be awesome.5
Regardless of your position in this on-going debate between the skeptics and the cheerleaders of new technology, it is important to note that both camps make some implicit assumptions about the role of technology in human development. Both arguments contain an implicit model of the mind, by which certain extra-corporeal prosthetic tools are seen to extend or diminish the mind's natural intellectual capabilities. The purpose of this chapter is to explore this thesis in a more formal way, first by summarizing the hypothesis of extended cognition, advanced recently by several prominent philosophers of mind, and second to contextualize that hypothesis historically, in order to test the philosophical intuitions implicit in the conversation against real-world experience.
The Hypothesis of Extended Cognition (HEC)
The hypothesis of extended cognition (HEC) holds that certain cognitive processes can be viewed as extending beyond the boundaries of the human body into their physical, social, and symbolic environments. Andy Clark and David Chalmers suggest an example involving Otto and Inga: two individuals on their way to an art exhibition. Inga remembers the location of the museum by memory. Otto suffers from Alzheimer's, and must consult his notebook to find the exhibition. Clark and Chalmers posit that the information in Otto's notebook is the same as the information in Inga's head. And were the notebook literally inside Otto's brain somehow, we would have no trouble equating the two cognitive acts of remembrance: Inga simply remembers how to get to the exhibition, while Otto incorporates some cognitive aids to facilitate his memory.6
For the externalists—Clark, Chalmers, Wilson, and others—the differences between Otto's and Inga's case are superficial: both are engaged in essentially identical cognitive tasks of recollection. On this view Otto's usage of a notebook constitutes something like a unified cognitive system, which encompasses parts of Otto's brain and parts of the physical pen-and-paper apparatus. The pen and the notebook simply constitute the material or technological elements of the system, enabling the storage and the retrieval of information. Similarly, the notation itself—the alphabet by which Otto is able to encode the needed information—can be seen as a symbolic and social component of the system. Not just Otto's notes, but all language, according to the externalists, serves as a kind of ready-made mental scaffolding, which enables a level of computation and analysis otherwise unavailable to primates.7 The study of cognition therefore must expand beyond the skin-and-bone boundary of the human brain to include the social, symbolic, and material (technological) artifacts involved in human thought. To study Otto's brain is to also to study the pen, the notebook, and the notes Otto takes when he uses these things to remember the details of his appointment.
In another paradigmatic example of HEC-based analysis, Edwin Hutchins examines the workings of a commercial airliner in flight, showing "how the cockpit system performs the cognitive task of computing and remembering a set of correspondences between airspeed and wind configuration."8 The system-level view of cognition draws attention to the combination of mechanical, electronic, and biological processes responsible for the flow and storage of information within the plane's cockpit. The system can be said to "remember" its speeds, writes Hutchins. It "computes," "controls," "makes use of representations" and otherwise distributes cognitive labor. Were we to ask, "Who is landing the plane?" we would expect Hutchins to answer "the cockpit system as a whole."9
Two types of extension
The opponents of HEC reject the view of cognition as anything other than what goes on inside the body and the brain. Fred Adams and Ken Aizawa in particular have staked out a clearly delineated position in defense of what the authors call "contingent intracranialism." On this view, the "mark of the cognitive" is located squarely within the brain, as a matter of a contingent empirical fact.10 To prove their point, Adams and Aizawa compare our intuitions about human tool use and animal digestion. Imagine someone using loping shears to trim a bush, for example. Although the activity of "trimming-a-bush" as a whole seems to be a combined product of human muscular contraction and the mechanical capabilities of the loping shears, we would not be compelled to think of loping shears as "extended muscular contraction."
By contrast, something like arachnoid digestion constitutes a digestive process that is truly external. Arachnoid digestion happens outside of the spider's body literally: the spider regurgitates digestive enzymes into or unto its prey. What happens in our stomachs happens outside the strict corporeal boundaries of the spider. We could therefore meaningfully talk about "extended digestion" when it comes to spiders. But, for Adams and Aizawa, Otto's notebook-reliant memory looks less like arachnoid digestion and more like the discrete movement of muscle against the mechanism of the garden shears. Otto is not thinking literally outside of his head. Like the man with the garden shears, he is using a tool to compliment the exercise of some internal, biological function. But it seems to me that this line of reasoning is simply begging the question. Adams and Aizawa merely appeal to a scientific standard of internalsim, where the scientific standard is precisely the thing that is being called into question. One gets the sneaking suspicion that the argument is really about definitions, with one side appealing to common sense and the other to scientific standards.11
My own suspicions about HEC rise from the observation that the existentialist argument seems to contain two distinct propositions about the nature of cognitive extension, each carrying distinct implications for practical analysis of complex cognitive tasks. Let's return to the example suggested by Hutchins in "How a Cockpit Remembers its Speed". We begin by noting that a plane is a curiously anthropomorphic structure. It has something like a head, a tail, and a belly: cockpit windows where we would expect eyes, and a hole where we would expect to see an anus. It is thus easy to imagine this structure as sentient somehow. We may for example, say "it thinks, it sees," or "it eats" without much stretching of the imagination.
Suppose then, instead of discussing a complex, high-level biological process such as cognition, we were to talk about digestion. The hypothesis of extended digestion would then hold that digestion is not limited by the human body, and that it may be seen as a systematic property of the plane as a whole. On this view, the plane—its service staff and food storage mechanisms—all participate in digestion, defined by the uptake of food, its distribution, and the disposal of waste. We may even go as far as to say that digestion is something that happens in the belly of the plane. Food is conveyed within by some mechanical means, it is then divvied up among the passengers, processed, and expelled in bulk with the emptying of the airplane's holding tanks.
How far are we willing to take the proposition of airplane digestion? Not very far at all, I would argue. Clearly, this is not digestion as we know it. It has some structural affinities to animal digestion (the food is conveyed within, broken down, expelled) along with important structural differences (the food it is not metabolized, for example). Thus a strong claim to airplane digestion must be rejected as an imprecise metaphor, by which the concept of a given process is transferred from one entity to another by structural similarity (the same would hold true were we to consider fueling as a type of digestion).
Such metaphoric transference may prove to be conceptually useful in certain types of analysis, as when the airlines want to improve the timely feeding of their passengers, for example. "The plane needs to eat," they might say. "Our staff has to feed the plane in a timely fashion." But, the metaphor strains under scrutiny. We may as well stick to a more exacting description of the process. In any case, what we have done here is extend the natural concept of "digestion" (in its ordinary meaning) to an inanimate entity, or a system of entities that includes biological and non-biological components. Furthermore, we have discovered that such a functional analogy is subject to confusion by metaphor.
Extrapolating from these observations, we should be able to draw the same conclusions about cognition. The cockpit may look as if it is "'remembering its speed," but its "memory"' is a mere metaphor. The two processes— human remembrance and whatever happens in the cockpit—never reach full equivalence. The metaphor does not inspire our full commitment. It is an alluring metaphor however, particularly because the cockpit's shape and location (in relation to the body of the plane) remind us of the human head. It might be a useful metaphor for analyzing the information flow within the cockpit, but it is imprecise when it comes to understanding human cognition as such. All that is meant by human cognition does not map precisely unto the cognition as applied to the airplane cockpit. Clearly some parts of the original definition are simply left out—the firing of neurons and the transmission of glutamate, GABA, or dopamine. Some aspect of the cockpit's operation may be likened to those biological processes, but nobody would hold that they are fully equivalent.
There is a possibility of another, weaker claim to extended digestion, to continue our example. The conveyance of food from the grocery shelves to the mouth of an individual airplane passenger may well be an important part of that passenger's digestive process. We are no longer talking about digestion in a metaphoric sense, as we did when thinking about the belly of the plane. I mean now literal digestion, as in "the breaking down of food." In that sense, there is no reason for us to view our own digestion as much different from a spider's. The preparation of food external to the human body could be viewed much in the same way as we view arachnoid digestion. Both are external processes evolved to aid in the break-down of tissues otherwise difficult to digest internally. The spider regurgitates enzymes, where we use a knife, a fork, a cheese grater, or any other kitchen implement for that matter. Following similar logic, we may view the catering company responsible for preparing the airline food as part of that extended digestion system. The cooks, the forks, and the stewards all literally facilitate the break-down and the conveyance of food into the passenger's belly. More than a thought experiment, the understanding of digestion in this extended sense could be quite useful in certain types of analysis, as in identifying the cause of foodborne illness, for example. In the previous case we were making a biomorphic analogy between two distinct processes: the digestion of food and the fuelling or the supply of the plane. But now, we are actually trying to expand the original concept of digestion, usually thought to be an internal process, to include all sort of external mechanisms. We are no longer making an imprecise analogy. Our position is one of true digestive externalism.
But in expanding the definition of digestion outwards, we run into what I would like to call "the problem of arbitrary limits." Let us return to cognition for the moment. In thinking about the cognitive tasks involved in landing a plane, we began by including the cockpit instrumentation and the communication between the pilots into the equation. But why limit ourselves to the plane in our analysis? The runway participates in the landing, and so do the dispatchers in the control tower. We may then say the airport system as a whole is landing the plane. That too seems to be an arbitrary boundary. The dispatchers rely on a global network which memorizes, computes, and predicts landing parameters. At the limits of this query is unbridled monism. The activity of "landing a plane" begins to lose its meaning when the activity of the pilot is coupled with the entire universe.
I conclude then, to say that extending the concept of cognition to the cockpit of the plane is subject to the limit problem. The disavowal of the body and/or brain as the natural boundary of cognition leads to an arbitrary placement of yet another boundary. We have simply substituted the natural physical limits of the brain with those of the airplane cockpit. And nothing holds us back from pushing the boundaries of cognition ever outward. Every boundary seems artificial, and every system seems to be a part of a larger system that could be seen as participating in the cognitive task at hand. In embracing the extension hypothesis literally, we have traded metaphoric imprecision for the problem of arbitrary limits.

### Engelbart Augmentation

### Cognitive style of Concrete Poetry
It may seem at first a bit odd to put the words "style" and "cognition" in the same sentence, but the concept of "cognitive style" is well-articulated in the scientific literature on the psychology of personality. The idea of cognitive stylistics was developed first by the American followers of Carl Jung, who like Katharine Cook Briggs and her daughter Isabel Briggs Myers (of the still ubiquitous Myers-Briggs Type Indicator offered by career placement centers across the country) were interested in applying insights from quantitatively-based psychological observation (psychometrics) to problems of labor and education. In the early 1950s, the idea of "personality type" gave way to "cognitive style" in the work of psychologists George Klein, Philip Holzman, Riley Gardner, and Herbert Schlesinger.1 For this new generation of scholars, the concept meant something like "the individual differences in adaptive modes of organizing and experiencing the stimulus world."2 That is to say that people simply have or develop a preference for a particular mode of thinking about and perceiving the world. Or even simpler: "everyone does it in his own way."3 Thus, in an early experiment Gardner observes a group of people categorizing objects by size, shape, and color. Predictably, different people perceive the differences between size, shape, and color in differing gradations.4 The converse of this experiment suggests also that certain modes of material organization favor a particular style of thought. We may assume, for example, that certain ways of organizing the world attract or "make sense" to a particular type of person. In the literature on education, the concept is therefore popular within the discussion of learning styles, by which teachers are encouraged to present their material in ways accessible to students with varying preferences for visual, auditory, tactile, or kinesthetic learning.
The hypothesis of cognitive styles underlies a particular belief about the connection between mental organization and the organization of objects in the real world. It is what Heidegger called "the correlation between being, word, gathering, hand, and writing"5 and perhaps what Nietzsche meant when he wrote that "our writing tools are also working on our thoughts."6 Heidegger in particular is often cited in this regard. In his meditation on Parmenides, delivered as a series of lectures during the war at the University of Freiburg, Heidegger is clearly bothered by what he perceives as the "irruption of the typewriter into the realm of the world of handwriting."7 Ever in search of essences, he imagines hand-writing to possess a special kind of magic, denoting "an original essential nexus, to which the indicating writing-hand belongs." He continues to say that:
[...] in handwriting the relation of Being to man, namely the word, is inscribed in beings themselves. The origin and the way of dealing with writing is already in itself a decision about the relation of Being and of the word to man and consequently a decision about the comportment of man to beings and about the way both, man and thing, stand in unconcealedness or are withdrawn from it.8
The typewriter somehow disturbs this idyllic picture, withdrawing "from man the essential rank of the hand, without man's experiencing this withdrawal appropriately and recognizing that it has transformed the relation of Being to his essence."9 In my favorite bit of condescension from the old master, Heidegger goes as far as to suggest that his readers misunderstand him precisely because type-setting is so groundless. "The typewriter is a signless cloud," he writes, "a withdrawing concealment in the midst of its very obtrusiveness […] not showing itself to its essence." "Perhaps that is why most of you, as is proven to me by your reaction, though well-intended, have not grasped what I have been trying to say."10
What is Heidegger trying to say here? And what precisely is being concealed by the typewriter? In "The Question Concerning Technology," originally published in 1954, Heidegger explains that technology is primarily a mode of revealing truth. To make this point, Heidegger begins with an analysis of a specific artifact—a silver chalice used for ceremonial rights. Initially, it seems that the primary purpose of the artifact is to facilitate something, the administration of ceremonial rites in this case. The cup is an instrument for something, in other words; it is a means to an end. Another way to put it would be to say that the ceremony is the cause for the cup's very existence. But there is more than just causa finalis, as Heidegger puts it. The physical properties of silver (causa materialis) also constitute a cause, as does the shape of the cup (causa formalis), and as does the silversmith who has fashioned the vessel (the silversmith being causa efficiens). In fact the cup's very instrumentality is grounded in this chain of causation. The cup is an occasion to bring forth the ceremony; to bring forth a certain property of silver; to bring forth the water-containing property of the vessel's shape; and finally to bring forth the craft of the silversmith. The making of the cup is not mere "handicraft manufacture," Heidegger writes, nor is it "only artistic and poetical bringing into appearance and concrete imagery," but rather a "bringing-forth, "poiesis in the highest sense."11
At its best, technology reveals truth. At this point of the essay Heidegger makes a distinction between traditional technology or "handicraft," and modern, machine-powered technology.12 Modern technology also reveals, writes Heidegger. But it does not "unfold into a bringing-forth in the sense of poiesis." Rather modern technology is a challenge or a provocation [Herausfordern] to nature. The figure of the natural betrays the extent of Heidegger's romanticism. "The revealing that is modern technology is a challenging, which puts to nature the unreasonable demand that it supply energy which can be extracted and stored as such," writes Heidegger.13 "But does it hold true for the old windmill as well?" he asks. And answers,
No. Its sails do indeed turn in the wind; they are left entirely to the wind's blowing. But the windmill does not unlock energy from the air currents in order to store it. In contrast, a tract of land is challenged in the hauling out of coal and ore. The earth now reveals itself as a coal mining district, the soil as a mineral deposit. The field that the peasant formerly cultivated and set in order appears different from how it did when to set it in order still meant to take care of and to maintain. The work of the peasant does not challenge the soil of the field. In sowing grain he places seed in the keeping of the forces of growth and waits over its increase. [By contrast] agriculture is now the mechanized food industry. Air is now set upon to yield nitrogen, the earth to yield ore, ore to yield uranium, for example; uranium set upon to yield atomic energy, which can be released either for destruction or for peaceful use.14
The passage is remarkable for its apparent prescience of the contemporary environmental conservation movement, which often implies a similar conservative romanticism about handicraft technology. Both ideologies contain a particular notion of "authentic" or "unadulterated" state of nature, which is "challenged," to use Heidegger's terminology, by the tools of modern technology. Handicraft, by contrast, is seen as an activity that operates in harmony with nature, without undue disturbance. This view is of course historically incorrect. Pre-modern hunting practices and agriculture have often led to large-scale ecological disturbances: pollution, species extinction, and deforestation. In this context, the distinction between modern and pre-modern itself begins to seem arbitrary. The latent romantic naturalism strains under further scrutiny. The silver chalice, for example, can be seen as the culmination of a long and destructive process of mining, ore processing, smelting, and manufacture, which at each stage involves the very opposite of Heidegger's ideal non-disruptive poiesis.
A more chartable reading of the passage would attempt to place Heidegger's critique of modern technology in the context of his phenomenology. Heidegger's phenomenology is a weighty, but well-explored topic, and for this reason I will limit our discussion to its most generally-known and relevant features. For Heidegger, our knowledge of the world comes in two flavors: presentness-at-hand [Vorhandenheit] and readiness-to-hand [Zuhandenheit]. When we think of some object in the world—a hammer, to use the famous example—we first imagine something like the formal definition of a hammer in a series of knowable facts about the object: a hammer is made of metal and wood, we use it to pound nails, it is man's first tool, and so on. The type of epistemological knowledge about the world, the knowledge that combines the readily observable properties and our shared understanding of the object, is called "present-to-hand" in Heidegger's system. "Ready-to-hand" knowledge by contrast is practical. I know something about the hammer, but I also have used a hammer—and in using it I understood the tool in an applied manner. But more than that, in using the hammer I understand something about the nail. An essential property of the transition between theoretical and applied knowledge of the world, is the disappearance of the tool. For Heidegger, the tool literally becomes a kind of "sight," helping us identify properties of the world that are particularly well-suited for its application. "Action has its own kind of sight," Heidegger writes in Being and Time.15 The hammer helps us experience the nail in a hammering kind-of-a-way. Hammering reveals something about the nail, and by extension, about metals in general. At the bottom of this experience is man's relationship to nature itself. All "good" technologies work in that way for Heidegger. "Technology comes to presence in the realm where revealing an unconcealment take place, where aletheia, truth, happens," he writes in "The Question Concerning Technology."16 The plow reveals something about the earth, just as the windmill reveals something about the air current.
Modern technology reveals too, but it breaks the "natural" phenomenological experience in two important ways. First, the tool fails to fully disappear into the experience. I imagine this to be the same kind of a feeling a musician has when playing an unfamiliar instrument. The instrument "stands in the way" of the unity between man and music. Second, the modern instrument introduces a kind of a perceptual bias. It treats nature as a reserve of energy [Bestand]—as a kind of a storehouse, an inventory, or a collection. Whereas the farmer's plow reveals the earth as fertile ground, the tractor reveals it to be a mere resource for mechanized agriculture. The earth ceases to be an object of knowledge, amenable to other ways of knowing. In this way, modern technology works to "order" or to "enframe" matter, interfering with the very process of truth-formation. Moreover, just as the earth ceases to be the object of knowledge, the ordering—or to use the very un-Heideggerian term, the commodification—of natural resources threatens to turn the human into a resource. For Heidegger, modern technology disrupts the status of the human as a proper subject:
Only to the extent that man for his part is already challenged to exploit the energies of nature can this revealing which orders happen. If man is challenged, ordered, to do this, then does not man himself belong even more originally than nature within the standing–reserve? The current talk about human resources, about the supply of patients for a clinic, gives evidence of this. The forester who measures the felled timber in the woods and who to all appearances walks the forest path in the same way his grandfather did, is today ordered by the industry that produces commercial woods, whether he knows it or not. He is made subordinate to the orderability of cellulose, which for its part challenged forth by the need of paper, which is then delivered to newspapers and illustrated magazines.
The commodification of both subject and object commodifies phenomenology itself. One can perceive more than a hint of Marx in this line of critique.
If the plow reveals something about the earth, the pen reveals something about language. The relationship between man and language is of a primary importance to Heidegger. In the realm of language, man stands in relation to being itself. Heidegger's own discourse often progresses through a series of etymological reconstructions, which contain an almost mystical sense of reverence for the veracity of meaning contained in the original, Greek understanding of a given concept. By similar logic, the hand represents a "pure," unadulterated relationship of man to language. The hand "contains an essence of the human being because the word, as the essential region of the hand, is the essential ground of being human."17 In the metaphoric juxtaposition between word and ground, the analogy between pen and plow becomes apparent. And just like mechanized agriculture, mechanized writing "deprives the hand of dignity in the realm of the written word and degrades the word to a mere means for the traffic of communication."18 The typewriter commodifies language in other words, turning it into the "standing reserve" of information. "In mechanized writing all humans begin to look the same," writes Heidegger.19 
Intermedia as Syncopation between Human, Machine, and Language
It has been suggested that Heidegger's distaste for mechanized writing stemmed from his inability to type.20 Don Ihde, a contemporary authority on Heidegger's philosophy of technology, suggests that all new mechanisms go through an awkward stage of sorts, in which they still feel unfamiliar to us, and therefore disruptive in the way an unfamiliar instrument is "in the way" of music for a musician. But with time, these technologies once again become transparent to us, and the link between man and language is once again restored in the fluent hands of a nimble typist.21 Such an attempt to "de-romanticize"22 Heidegger's argument cannot fully diffuse the rhetorical force of his critique. Heidegger's romanticism continues to exert considerable influence on contemporary thought, particularly when it comes to the discussion about emerging technology, and especially in the fields of literary and cultural studies. Perhaps the most visible (in a sense of well-known and often-cited) example of this trend is Friedrich Kittler's 1986 Gramophone, Film, Typewriter. In the conclusion of this book-length study, Kittler brings the Heideggerian rhetoric to its natural paranoiac crescendo: "A simple feed-back loop—and information machines bypass humans—their so-called inventors […] Electronics, a tube monster since Bletchley Park, replaces discourse, and programmability replaces free will […] Under the condition of high technology, literature has nothing more to say. It ends in cryptograms that defy interpretation and only permit interception." As evidence for this vision, Kittler submits a letter/poem which resembles a nonsensically-encoded communiqué addressed to Truman, Roosevelt, Stalin, and Churchill.23
A more tempered position, along the same Heideggerian lines, was advanced by Erich Kahler, a prominent American literary critic writing in the 1960s, who saw the history of the avant-garde movements in the 20th century following a downward trajectory of formal disintegration—from the initial purging of sentiment in the nouveau roman, to the dissolution of language in the final "typographical stage" of literary development.24 Kahler's ultimate worry was over what he called "the triumph of incoherence," which leads to "the dissolution of the linguistic form," "the divorce of language from its human source," and finally, to the destruction of consciousness itself (when consciousness for him is defined as coherent perception of the world25). "What started as poetry," writes Kahler, "ends up in typography."26 "Under the fanfares of thrilling innovations sounding everywhere, from Brazil to Iceland, literature fades away, not only into graphics, but into motley sound associations and mechanistic regimentation:" 
The overwhelming preponderance of collectivity with its scientific, technological and economic machinery, the daily flow of new discoveries and inventions that perpetually change aspects and habits of thought and practice, the increasing incapacity of individual consciousness to cope with the abstract anarchy of its environment, and its surrender to a collective consciousness that operates anonymously and diffusely in our social and intellectual institutions—all this has shifted the center of gravity of our world from existential to functional, instrumental, and mechanical ways of life. At the same time the hypertrophy of functional rationalization has produced an overcompensating irrationality, reversing to the bodily concrete or spiraling to the absurd. Hence the products of the avant-gardes display a strange blend of erratic imaginative vagaries with technological and pseudo-scientific aspirations. Fragments of unconscious and sensory experience are in a ghostly manner treated with an exactitude derived from the rational consciousness and information.27 
I take Kahler's reaction to concrete poetry as an eloquent, if somewhat misguided, expansion of Heidegger's "typewriters are ruining things" thesis. The argument is again a restatement of the connection between technology, language, and consciousness—a triad that resurfaces every few decades as a manifestation of our collective technophobic hypochondria.
In my understanding, the practice of concrete poetry stands in diametric opposition to the thesis advanced by Heidegger, Kittler, and Kahler—a vision of literary dissolution under the conditions of high technology. The artifice of Emmett Williams's "Sometimes" (Figure 4.1) lies in the reinserting of the writing implement into the protected world of the poetic. The poem is impossible without the machine. Reading or reciting it is not enough: we are meant to type, or at least to imagine typing the poem. Classical scansion is not sufficient either. We must be able to imagine the rhythm of the typewriter: the sharp hammer-like movement of its type-bars, the clicking of the platern, the whizzing sound and the bell of the lever-operated carriage return. The typewriter "thinks" in so far as it suggests a particular style—of writing, thinking—a style that has an impetus, a logic, and a poetry of its own. The rhythmic impetus of the typewriter pulls the poem along a particular metric trajectory. The poet disrupts that logic with a correction. The resulting grapheme, documents the interruption, and in the process pulls the material world into the literary. The smudge of the ribbon, the rejected versions of the poem, the mark of the proofreader, and yes the typewriter itself—all of these "extra-literary" elements of the creative process are elevated to the status of the poetic. Another way to describe the dynamic between literature and technology in this case, would be to say that the concretist aesthetic appropriates the extra-functional elements of the writing mechanism. What initially seems a mere artifact of literary production becomes art. Literature thus taints technology, stripping away the pretense of pure functionalism. Under the condition of the literary, to reverse Kittler here, technology gains a new voice.
Nothing is determined about the encounter between human, machine, and language. Each element of this triad contains a mere suggestion of rhythm and pace. The resulting symphony is a syncopation of all three elements. There is of course nothing particularly modern about his dynamic. The printing press introduced a particular poetics into the language as well. It is just that after a time, the cognitive style of the printing press has become transparent to us, particularly after publishing had congealed into a relatively stable system of production and distribution. The advent of the typewriter, of desktop publishing, and of distributed, online models of publication destabilizes the established stylistics. With each of these advancements we worry anew about the impact of technology on our way of thinking—a concern that goes back to the introduction of writing itself, as in Plato's Phaedrus.
The history of concrete poetry can be seen as the culmination of one such shift, spurred on by the transference of type-setting from the printer to the author. This dynamic may explain the simultaneous eruption of concrete poetry across multiple literary traditions. "The confused geography of its beginnings reflects the universality of its roots," Williams writes.28 He then suggests the following signposts upon this landscape: the "constellation" poetry of Eugene Gomerenger; the posters of Carlo Belloli and F.T. Marinetti; the Noigandres poets of Sao Paulo; the work of the Danish poet Oyvin Fahlstrom; the ideagrams of Dieter Roth; the sound-poetry experiments of the East German poet Carlfriedrich Claus; the collaborative work of the Vienna composer Gerhard Ruhm, architecht Friedrich Achleitner, a jazz musician Oswald Weiner, and the poets H.C. Atmann and Konrad Bayer in the early fifties; and finally Williams's own work with the Darmstadt Circle, which included the Kitasano Katue of Japan and the German dramaturgist Claus Bremer.29 To this topography we could add an increasingly long list of "intermedial" work by Vladimir Mayakovsky and Guillame Apollinaire in the early 1920s, several of Lewis Carroll's poetic experiments, and much work from non-western traditions, in alphabets that have always contained a strong visual element (Chinese, Arabic, etc).
In this light, concrete poetry can be seen as the culmination of a particular techno-cognitive style—a full-blown artistic movement which peaks at the eclipse of the typewriter age. The cognitive style of concrete poetry, if one may speak of such a thing, is one of cross-modal perception. It literally attempts to engage areas of the brain not normally affected by passive reading. Artists associated with Fluxus and concrete poetry were committed to the development of what they called intermedia. In his 1966 "Statement on Intermedia," Dick Higgins, the Cambridge-born poet, composer, and publisher, writes: 
For the last ten years or so, artists have changed their media to suit this situation, to the point where the media have broken down in their traditional forms, and have become merely puristic points of reference. The idea has arisen, as if by spontaneous combustion throughout the entire world, that these points are arbitrary and only useful as critical tools, in saying that such-and-such a work is basically musical, but also poetry. This is the intermedial [sic] approach, to emphasize the dialectic between the media. A composer is a dead man unless he composes for all the media and for his world.30
The spontaneous invention of this artistic program in Switzerland, Italy, Argentina, Germany, and the United States31 is contemporaneous with the turn to cross-modal perception studies in post-war psychology. At the core of this shared program is a new understanding of cognitive stylistics. As Marshal McLuhan, himself associated with the Fluxus movement, wrote in his 1967 Verbi-Voco-Visual Explorations, "the physics of typographic lineality have dominated our perception."32 But, as Kahler notes in his anti-concretist polemic, this approach has also erased the boundaries between the socially-constructed categories that separate the literary from the visual and auditory arts. With that expansion come the loss of specificity and the dissolution of the protective barriers that usually separate genre and medium. Fluxus could thus be viewed as a type of cognitive calisthenics, designed to loosen the rigidity of fixed mental perception—a mental rigidity reinforced by the rigidity in cultural categories (epistemology).

### Conclusion
If are are to take the hypothesis of extended cognition seriously, we must treat the tools of cognitive augmentation as seriously as we would our own mental development, in the traditional sense.



### Stenography
Transcription of speech was a major concern for the various stenographic movements in the English-speaking world, which go back the publication of Timothy Bright's Characterie: An Arte of Shorte, Swifte Secrete Writing by Character in 1588. In the introduction to this slim volume, Bright writes that his work was inspired by the "speedie kind of writing by character" mentioned first in Plutarch's Life of Cato the Younger, improved upon by Seneca, and then lost to history.1 
"The uses and diuers: short, that a swifte hande may therewith write orations or publike actions of speach, uttered as becometh the grauitie of such actions, verbatim. Secrete, as no kinde of wryting like, and herein (besides other properties) excelling the wryting by letters, and alphabet, in that, nations of strange languages, may hereby communicate their meaning together in writing, through of sundrie tongues, it is reported of the of the people of China, that they have no other kinde, and so traffike together many Prouinces of that kingdom, ignorant one of an others speach. Their characters are very long, and harde to make, that a dousen of mine, may be written and soone as one of theirs; besides, they wanting an alphabet, fal into an infinite number, which is a thing that greatlie chargeth memory, and may discourage the learner.2
The task of stenography then, from its early modern inception was first to bring handwriting closer to the speed of speech, and second, to imagine a universal alphabet that could be used by speakers of all languages and dialects. In modern terms, we might say that stenography was concerned first and foremost with our ability to cope with an increasing amount of information, and second with the international standardization of character encoding (that is, with the universal transmission of information). In The Elements of Tachygraphy, first published in 1869, David Philips Lindsley writes: 
Though we depend upon facilities to aid in mental and moral advancement, as much as in physical, yet we have been slow to apply to the mental and moral elevation of the race the principles that have enabled us to develop our material resources. Inventions to aid in the commerce of ideas are no less essential than those which we have realized in the interchange of coarser commodities. The art of writing was the original lever by which the race was at first raised above barbarism. Successive improvements in this art have marked the epochs of the greatest mental activity.3
In this program we thus see the birth of the intellect augmentation movement of the mid-twentieth century. The contemporary Unicode universal character encoding standard, used for the representation of text for computer processing is the natural development of this program. The unicode.org website mirrors Bright's Characterie in defining Unicode as "a consistent way of encoding multilingual plain text," which "brings order to a chaotic state of affairs that has made it difficult to exchange text files internationally."4
By the late 19th century stenography existed as a full-blown international movement concerned with universal spelling reform. John Westby-Gibson's The Bibliography of Shorthand contains no fewer than twenty volumes on the subject in the first half of the 17th century, thirty-six titles in the second half, fifty-six titles in the 18th century, and more than four thousand entries for the 19th century. This publishing activity was supported by the proliferation of stenographic societies across France, Germany, England, and the United States—many of these with regional chapters and publication organs. Westby-Gibson himself was editor of Shorthand; President of The Shorthand Society from 1886 to 18887; honorary member of the Shorthand Writers' association, London Branch; honorary member of the Manchester Shorthand Writers' Association; honorary Secretary and founder of the International Shorthand Congress, 1887; and finally, Chairman-elect of the Historical and Literary Section of the International Shorthand Congress.5 The meetings of these societies were often accompanied by public speeches and poem recitations, dully taken down by the stenographers in attendance. The 1843 issue of the Phonotypic Journal, supported by Isaac Pitman's Phonographic Institution contains the following several poems from the Nottingham and the Birmingham Phonetic Festivals:
From the proceedings of the
Nottingham Phonetic Festival
June 6, 1843
Held in the Exchange Hall 

Phonographers, awake, arise!
Nor think of slumber more;
This science, from our island home,
Shall spread from shore to shore 

[...]
Then sound the trumpet loud,
Shake, shake the ethereal arch!
Till heaven re-echo, earth re-sound
The phonographic march!

Our boasted name is legion,
A host of writing men;
We'll deluge nations with our ink,
And conquer with our pen!
[great applause]

From the proceedings of the
Birmingham Phonetic Festival
July 18th 1843, Held in the Assembly Room of Dees Royal Hotel 

O, this is the age for inventions! I 'm sure;
There never were heard of so many before;
We have flying aerials, drawing by light,
And a long list of other that give us delight.
The wonders of steam we may daily behold, 
And science will still many glories unfold;
But sear the whole range of this busy world round,
The most wonderful wonder is Writing by Sound.
Then write away, fly away; did you not dream
That Britons ere long would be writing by steam?
Your dream's nearly true, but steam it is found
Won't do for the work, so we're writing by sound.

The stenographers of the 19th century understood their movement as the kind of a global phenomenon that approximates our contemporary understanding of the internet and social networking. Again Lindsley from The Elements of Tachygraphy:
When Tachygraphy shall be generally known and used, an electric thrill of life will run through our communities, awakening new sympathies, and forming bonds of union long dissevered. What railroads have done in bringing friends together that could otherwise never interchange a visit during a lifetime, brief writing will do, in bringing minds together that would, without it, communicate with too much difficulty to be able to continue the acquaintance begun in youth; and aid in extending that more valuable interchange of thought among those of similar tastes, which tends both to the perfection of our knowledge of science, and its general diffusion.6
In this project stenography and typewriting technologies compete for the same vision of augmenting the natural human facilities of information processing and knowledge dissemination.7 Stenography is understood here as a thoroughly modern and modernizing technology that does for the mental and moral development what the steam engine and areal flight did for the material realm.
## 2.2 Bad Links, Intertextuality, Symbolic links
Rise of intertextuality. The promise of hypertext. Bush w/ Memex. Nelson. Failure of intertext. Borrow from bad links here.
It is my intention here to convince you that links are bad. They are bad when it comes to writing for the web in general, bad for books, bad for long-form journalism, and even worse in academic publication. It is not that I am against the idea of links. As we will see here, the problem lies in the way links are used. That is also to say that we can do something about using links better. But first, why are links so bad?

To start with, links are opaque. The worst of lot are links like this and this. Of the two “thises,” the first leads us to Google and the second to Bing. But your readers would not know that just by looking at the text. The best they can do is “hover” over the word with their mouse cursor, relying on the browser interface to show them where the link is going. And once they get there, there are no easy ways to get back. The writer must have faith in the browser to “do the right thing” in guiding the reader through an intertextual maze. And that is not right when it comes to writing. In most situations, the author should architect that experience explicitly. If you think about it, the old-fashioned apparatus of quoting an external text is itself a type of linking. But rather than quoting the whole text, the author only quotes the relevant bits. Sending readers away to do that work on their own is lazy and irresponsible. Imagine a tour guide who tells his tourists to “just go over there and look at some stuff,” and “come back when you’re done.” Links can be that disorienting.

Links disrupt the reading experience, and that is the second reason for why links are bad. It is possible that you want the reader’s experience to be disrupted. But in many cases you don’t. And the reader is already distracted by the proliferation of parallel windows and devices that augment their reading in some way. Do we need to make that distraction easier? Should I link the Wikipedia article on media multitasking or is it enough for my purposes to simply mention Wikipedia, or to trust my reader to look something up later, in a reference source of their own choosing? Or better yet, should I help the reader along by summarizing the findings? It mentions that most folks already read with a second screen in tow. It is not that unusual to see someone look something up on their phone or tablet while reading a newspaper or an e-book. Why? Because they don’t want to leave the flow of the first screen. There is great pleasure in immersive, uninterrupted reading.

Besides being disruptive, links are ugly. They are ugly together, as in when many links conspire to produce a tangled mess. And they are also ugly when naked on their own, like this: https://docs.google.com/document/d/1TaGiFBG_WSEGKFey9sR0pafjjKK7Fuc0jhF5d4K1ouA/edit. That string of characters is not meant for human consumption! The period at the end kills me entirely. Meaningless punctuation inside of links coupled with regular punctuation ruins the sentence and the paragraph. Of course, I could just tell you to read something on Google Docs. That looks much better, but then we are making the opaqueness problem worse by hiding the address behind words that may or may not be related to the destination. It seems that we are stuck compromising on either transparency, reading flow, or visual impact.

Links aren’t very secure to begin with, but hiding links behind words further compromises security. You’ve probably heard of link-baiting: the purposefully malicious attempts to trick a reader into revealing personal information when following a link that masquerades as a legitimate destination. You can visit my site to learn more about link-baiting. You shouldn’t have clicked that! (Don’t worry, that was the real Google login page.) But even if one means well, viruses and browser exploits can inject bad links into your otherwise legitimate ones. A common technique is to install a browser script along with some seemingly useful “search bar” that will redirect all legitimate links to a site that makes money by advertising. Worse yet, you could end up on a site that attempts to further compromise your computer. Links are not secure because in linking, we outsource the relationship between reader and content to the browser.

Links are opaque, disruptive, ugly, unsafe, and they rot. Links don’t last because the content at the address is dynamic. It is not guaranteed to be there decades, months, minutes after your initial visit. In that case, why even bother? The link works best for ephemeral output (like a tweet). We must think of something much more robust for any “serious” writing that hopes to survive to the end of the week. And for the really good stuff, the kind of stuff that is the purview of librarians, we need to cultivate sustainable, long-lasting, responsible practices of online citation. It should work as well, if not better, than the familiar bibliographic citation in print. This practice should combat digital decay, not aid it. We need to think about the ways our links can be accessed, mined, and preserved with the archive-grade zeal of the rare book librarian.

Finally, links are terrible for accessibility. It is bad enough that clicking on a small word like this is difficult for people with any sort of fine-motor control problems. Being a little older in itself can make the online reading experience painful. Things are much worse for those with Parkinson’s or for the blind. Sina Bahram, a blind usability expert (who is himself blind) reports that some sites contain thousands (!) of links in advance of actual content. Screen readers for the blind must read each one of them out loud. For the screen reader, there is no difference between garbage links and useful content. If you thought looking at links is disruptive, imagine listening to a robotic voice that pronounces every slash and every useless number in: http://www.youtube.com/watch?v=92pM6hJG6Wo. And that is why Sina Bahram listens to his reader at 950 words per minute.

Any one of these issues alone should give us pause. Together, they are a cause of grave concern. How did we get here? And what can we do to make links good again?

How did we get here is not an easy question. A part of the story is surely the excitement we once felt about hypertext. Links were supposed to break the hegemony of linear narrative, ushering in a new interconnected world. To some extent the dream came true. But links also brought with them such things as Search Engine Optimization (SEO). Google’s PageRank algorithm tracks, among other things, the number of incoming and outgoing links. This bias for connectivity encourages “link farms”: sites that attempt to game the system by aggregating links or cross-linking their own content. A sure sign of a vacuous SEO-driven piece of writing is a certain cynical and strategic use of links to other popular sources. How long until the SEO logic infects poetry, fiction, or investigative journalism?

What can we do to make links better? There are a few things we all can do now. First, let’s use links sparingly. Think smartly about whether you need to link or whether you can make do with a good, old-fashioned quote or citation.  Don’t link just because you can. Second, link explicitly: Youtube.com is better than this. Third, realize that online content is dynamic. It makes no sense to link a dynamic resource when the intent is to create a link to a static version of a document. Tools like the Save Page Now service, hosted by the Internet Archive, do just that. You can find this essay at http://sprintbeyondthebook.com/2014/02/bad-links/ but its earlier draft is best captured in a snapshot here: http://web.archive.org/web/20140208220625/http://sprintbeyondthebook.com/2014/02/bad-links/. Finally, do not neglect the humble footnote. Footnotes provide a nice blend between usability, transparency, and good knowledge design.

1: http://web.archive.org/web/20140208220625/http://sprintbeyondthebook.com/2014/02/bad-links/
## 2.3 Writers' Room, Textual Cooperation
Writing together. Models of co-authorship (and why we should pay attention). The massively multi-authored online novel (Wu Ming and Lo zar non è morto).

Auteur - genius romantic ideas of authorship. Lab life of writer's rooms. Tangibility. Distributed authorship.

I've been thinking quite a bit recently about the "costs" of collaboration, about writing (and researching) together, and about the tangled forests of drafts, manuscripts, and versions that sprout in the wake of co-authorship.

This brings me to a strange (but meaningful) space between textual criticism and version control

## 2.4 Hidden Message, Cryptography
F. C. Bakewell's Copying Telegraph secrecy already built in.
Privacy, secrecy, surveillance, and transparency.
Stuff about Lull here? Artificial intelligence. Gwern and encryption. Cypher punk. Surveilence and privacy being the same side of the coin. Hackable media. Ability to encrypt and decrypt. Political potential. Enabled by plain text.

Internet is not rhyzomatic. Mediation is at stake. " But the bottom line is that dumb-pipe email is unmediated, and therefore it's a business that Google wants to get out of as soon as it can."

" It's also why I believe Google will kill Gmail as soon as it comes up with a mediated alternative everyone loves. Of course, Google may offer an antiquated "Gmail view" as a semi-obscure alternative to the default "Inbox"-like mediated experience."

http://www.computerworld.com/article/2838775/why-google-wants-to-replace-gmail.html

## 2.5 New Humanism
### Metaphysical Dread about Computation
Brian Lennon and Golumbia. The argument basically boils down to the cultural logic of computation being complicit in the military industrial complex. That complicity manifests itself in a shared set of tools. By that logic: the we should also condemn the libraries' efforts to help up archive and store information. Condemn the poets for using metaphors because these are also used in advertising. Something perverse about that: it is as if we would worry about knowledge because knowledge is used for mechanisms of control.

Deeper metaphysical dread about computation, that should be understood historically (where Lennon gets it right). 

### Engineering for Dissent
Agency. Deliberation. Consensus. Dissent. Dissent is the least developed of these. Engineering for dissent. The ability to create shared goals and to exit. engagement with shared project. The subject of my next book. 

# Tech Appendix

## Prepare
How to run the terminal. What is it. And why?
Intro to POSIX

## Chapter 1
Key terms: binary, digital, analog, plain text, surface, depth
Commands: pwd, ls, cd, cat, wc

Where am I? `pwd`, `ls`, `cd`
Bits, bytes, and characters: `wc`
 
## Chapter 2

## Chapter 3

## Chapter 4

## Chapter 5

# Odds and Ends 
Too often anxiety about algorithmic thinking, data, and digitization is fueled by simplistic and downright misguided ideas about the underlying technologies. Part I of this book is dedicated to building a critical vocabulary that goes hand-in-hand with digital literacy. Those with an engineering background will be introduced to an intellectual history of ideas that guide practice. And those readers interested in "theory," will gain a measure of technical competency required for higher-level thinking (opinion-formation and decision-making) about the subject.

Athanasius Kircher's Universal Polygraphy
George E. McCracken

Minimalism. Plain

Elegant Variation, Fowler

If you've never interacted with your computer through a text-based terminal, understand for now that the command line is a sort of a call-and-response dialog between you and your system. This way of interacting with computers predates modern graphical user interfaces (GUIs) and is still commonly used by professional programmers and system administrators.

More than an interface, the command line encapsulates a philosophy of computing: write simple programs that do one thing well.

This philosophy contrasts sharply with alternative vision: where "things just work," glossy visual interfaces. Surfaces and alienation. 

That computer interfaces entail politics is not an uncontroversial assumption and one which will become central to the argument of my book.

Despite the ubiquity of Unix-like systems (which run a lion share of servers, super-computers, Apple gadgets, and Android devices), the textual roots of computing are obscured by visual 

The battle for the soul of computing. Whether the internet empowers participatory governance, deliberation, and dissent, or whether it ushers in a new era of mass surveillance and centralized control depends crucially on which of these two models of computing prevails.


## Security, access
Security, privacy. Surveillance. Openness. Secrecy. Part of the same coin. Crypto vs. open source movement.
Commands: crypto, pgp, chmod, groups, file permissions

Authorship is better thought of as access. How that is codified. Groups.

## Networking
Key terms: internet, rhizome, web, network, infrastructure, hardware, and software.
ping, traceroute, the terminal way: multiple users. personal vs. central computers

Internet is not a rhyzome. Central control. Surface vs. depth structures--twitter is rhyzomatic on the surface. 

Actor-networks. We are pushing ourselves through the wires. Hardware in control. 

rg Wilhelm Friedrich Hegel 
