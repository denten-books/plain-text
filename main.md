---
title: "Plain Text: Human Technology"
author: "Dennis Tenen"
---

# Introduction

## Thesis, Audience
Plain text is a file format and a frame of mind. A fundamental concept in the development of computing, plain text stands in opposition to closed platforms, rarefied knowledge, and black-box devices. Instead, it offers a vision of data that is human-readable by design: portable, concise, and universal. This book contains an argument for plain text. It seeks to empower a community of writers, readers, publishers, and librarians. Together, we will convene a polity interested in reflecting critically on the ideas, tools, and practices that shape our daily encounter with computation.

The argument starts with foundational principles of media and literary studies and information science. I ask: what is at stake in the difference between digital and analog?  What contains more information a block of wood or a novel? How is text structured? What separates meaning, form, and formatting? Where does data end and meta-data begin? What does it mean to "have read a book" or to "know something"? To what extent is media the message? The formulation of these broadly philosophic concerns influences the more pragmatically-minded and applied discussion in the second half of the book. Thinking together about the nature of human-computer interfaces, knowledge as hardware and software, links, networking, inter-textuality, word processing, text encoding, and cryptography will allow us to approach issues of control and governance, access and cooperation, consensus and dissent, and privacy and surveillance.

A secondary aim of this volume is to convince the reader, especially one without much technical background, to view their computational environment as a literary system. I mean a "literary system" in opposition to what one might conventionally mistake for a "binary" or "digital" one, however imprecise those terms are in everyday use. And should I succeed, I ask the readers to apply the same critical acuity to reading code as they do to close-reading of prose and poetry. Admittedly, to treat computers as a literary system is an unusual proposition, but one that I hope to sustain on a firm basis, grounded in literary theory and in the history of modern computing. Detailed case studies from that history will point to (what I hope is an) unexpected confluence between the shared history of computing and literary thought. 

A parallel audience to the one composed of non-technical readers is one that shares expertise in computer science or electrical engineering, but also one that does not usually view its daily practice in its historical, philosophical, and political contexts. Designers, software engineers, system administrators, and project managers are often asked to make choices at work that have not only technological, but broader social and cultural implications. Choosing a text editor, a filing system, or a social networking platform cannot be adequately addressed in shallow instrumental terms like efficacy, speed, or performance. Such choices also affect deep structures of knowledge transmission, the formation of collective and institutional memories, the quality of online discussion, and the ways in which we relate to our family, friends, and colleagues. Ultimately, in the concluding chapters, this book is meant to challenge the widely-held (if often hidden) notion that systems can give rise to ethical or political values. Values, as I will argue, must be projected from without, by free-willing agents that can voluntarily deliberate, form consensus, and  articulate shared goals. The only sentient beings answering to these criteria are humans (and not, for example, cyborgs or complex systems). The book then is ultimately an articulation of a new humanism, which runs counter to the recent theoretical turn towards post- and trans- humanisms which elevate systems (natural and artificial) to the privileged position of ethical and political agents. 

## Format
The book is a book, but also a tool. Readers will get much more out of it if they are able to actively follow along using their terminal emulator of choice. If these words mean nothing to you, rest assured that the text assumes no prior technical knowledge. It can be read sequentially as a conventional piece of scholarship in textual theory or "new media" studies. For those willing to take the plunge, I will often illustrate abstract theoretical concepts by asking the reader to type some commands into their terminals. Detailed instructions on how to set up this "augmented" reading environment, tutorials, and explanations can be found in the technical appendix and on the forthcoming companion website. 

Both novices and experts alike can benefit from exposure to ideas in the command line, on the level of the operating system. At the very least, the reader will walk way from this book with concepts and skills foundational to computing as critical thought and critical practice. But I hope that many readers will go beyond the basics, gaining deep-seated, intuitive, "hands-on" understanding of operational concepts like files, filing systems, networks, search tools, servers, and encryption technologies. Developing an intuitive understanding of systems that structure so much of our daily activity has the potential to radically transform one's experience with text, media, and digital devices. 

## Theory, Method

### Pragmatism
Unmoored theoretical concepts like "text" and "media" gain a palpable form when explored in the context of their instantiation. This is both model and method structuring the inquiry advanced here. Allow me to spend the next few paragraphs in laying bare the reasoning and the history behind this approach to the study technology, texts, and people.

The idea that "meaning" is always in some sense "operational meaning" is a proposition implicit in several related philosophical traditions. The first of these is pragmatism, broadly conceived. William James articulates that view when he writes that "reality is seen to be grounded in a perfect jungle of concrete expediencies [@james-pragmatism-conceptionoftruth]." For James (and, to some extent, for his fellow travellers in American pragmatism, Charles Sanders Peirce and John Dewey)[^ln-pragma-truth] the pragmatic answer to the question of truth could be reduced to the questions efficient causes and effects. In his essay "Pragmatism's Conception of Truth," James asks: "How will the truth be realized? What concrete difference will its being true make in anyone's actual life? What experiences will be different from those which would obtain if the belief were false?" Frank Ramsey, the young British philosopher close to Ludwig Wittgenstein, was influenced by the Americans and would later write that meaning "is to be defined by reference to the actions to which asserting it would lead [@ramsey-foundationsofmath p.155]." 

[^ln-pragma-truth]: For a more thorough discussion on the topic see @seigfried, @pihlström, and @putnam-james-theory. 

For the pragmatist, truth-carrying propositions of the shape "X is" (as in, "the author is dead" or "art is transcendent") beg the questions of "Where?," "When?," "For Whom?," and "What's at stake in maintaining that?"

Following James's and Ramsey's pragmatic insight, I will maintain throughout that abstract categories like "text" cannot possibly be (although they often are) reduced to a number of essential, structural features. Rather, to borrow from a conversation on categories in Wittgenstein's *Philosophic Investigations*, categories denote a related "family" of practices, which may or may not share in any given familial characteristic [@Wittgestein-philo-invest].[^ln-more-witt] To visualize this "familial" model, imagine a Venn diagram, where overlapping fields (of textuality, in our case) intersect and diverge in a historically (culturally, practically) contingent and arbitrary ways. These fields lie in relation to specific communities of practice, which often do not in themselves employ a controlled vocabulary. What counts for "code" and "poetry" in one domain, like computer science, may not account for the very same in another domain, like creative writing. An engineer's evocation of code as poetry is divergent from a poet's. There's no sense in reconciling the language. Poetry exists only in its social instantiation. The language of poetry morphs from literary period to literary period: those who write code by day and poetry by night might employ differing if not outright contradictory vocabularies.

[^ln-more-witt]: For more on the connection between Wittgenstein and James see @goodman-wittandjames. 

The intellectual legacy of pragmatism is wide-ranging but often diffuse. It is perhaps most pronounced in the teacher colleges, where James and Dewey are still read widely, which could explain the ascendancy of such pedagogical terms as "situated cognition"[^@lave&wenger], "experiential learning"[^@kolb], and "constructivism."[@]

In the academy. Discourse analysis.Discourse Analysis, STS and Kuhn, Model-dependent realism.

### Materialism
Marxism, media archeology, pam smith.
The logic of pragmatic theory naturally suggests materialism. Why? 

In viewing text as merely surface phenomenon, we are in danger of misapprehending deep structures that . A critic could (Email as intertext seems rhizomatic and decentralized. But, yet at the layer of infrastructure (routers, switches, service providers) it is highly hierarchical. Understanding that underlying structure of information helps us expose the flows of power and control. We can understand how censorship happens. Or surveillance. 

A corrective to Marxist materialism that views materialism as representation of such. Superstratum and substratum. Surface and depth. A corrective to Marxism. Publishing is broken @kfitzpatrick.

That is not to suggest that depth. Respond to @marcus.

Media archeology. Actual archeology though. Unix operating systems that run everything from super computers, televisions, and mobile phones. Excavating text through the kernel. Discovering latent tools, practices, and forms of textuality still extent on the device.

The methodological move from theory, to history, into practice follows a recent interest in the fields of philosophy, history, and literary studies in supplementing thought with a robust sense of doing and making. My own version of is embodied in the idea of "experimental methods." What does it mean to “experiment” in the study of history, literature, or philosophy? In answering that question I draw inspiration from two distinct spaces. First, the laboratory, where scientists bracket the world in search for independent variables and reproducible results. Second, the studio, where artists let the world in: to disrupt rigid modes of perception under circumstances that are always indeterminate and subjective [@cage]. In both spaces, thought is secreted in practice, “on the fetid and throbbing ground of life [@bernard].”[^ln-xpmeth] 

[^ln-xpmeth]: I've quoted this formulation in the mission statement of xpmeth.github.io website 
[^ln-cage]: "Here the word 'experimental' is apt, providing it is understood not as describing an act to be later judged in terms of success and failure, but simply as of an act the outcome of which is unknown." John Cage as quoted in Nyman, Michael (1974). Experimental Music: Cage and Beyond. Cambridge, UK.

Making and knowing. How does this work for texts? Restate thesis. 

It is one thing, for example, to theorize about form and content, and it is quite another to see how form and content are encoded in .txt and .pdf formats and to further how these distinctions then affect material divisions of labor between "knowledge workers," "content producers," typesetting sweatshops, and international conglomerates that control vectors of literary distribution.

## Market & Reach

Media Studies, STS, Philosophy of Technology 
Affinities to science and technology studies, new media studies, platform studies, critical code studies, media archeology, computational culture studies. A group of media theorists discussing photography in the last few decades fail to grasp some fundamental truths about the medium divorced from the mechanics of CMOS censors, optics, and from the practice of editing images digitally in Photoshop. A conversation divorced from the material stratum of images and from the practice of photography is restricted to the surface image. It can deal only with the relationship of pixels on the screen (or dots on a page). In response to this line of critique, media studies as a field has been undergoing a practical turn from surface to materiality in practice Similar books.
My approach to media theory attempts to make good on the promise. Where I often begin with philosophical 
Only in this way can media studies answer the lofty goals of critique. There is no hope of reaching from the screen to the political consequences without grounding analysis in practice. A critique in tradition of the Frankfurt school, requires further understanding of the economic reality of media, its legal and legislative context, issues of intellectual property and labor conditions. 

Digital Humanities.
Brings it closer to digital humanities, which is very material but often atheoretical. Theory in material and practice. Similar books. @kirshenbaum

Human-computer interaction. Knowledge workers, architects, and designers.
For CS folk, grounds practice in a theoretical discussion that attracts a wider audience to computing fundamentals. Confusion due to technical literacy. Books like "visual thinking," but many interfaces are still heavily textual (email, blog, etc).

But it is all really literary theory, textual scholarship, philology. Kernighan, Julia Hershberg. Elaine Scarry, Bill Todd. Bruce Robbins and Jean Howard. Brian Larkin and Alexander Galloway. DH: Ray Siemens
The key terms are important a in a range of fields. Expanding literary studies. motivate me: information, digital, data. OS as a type of literature, but not reduced to text. Text as far as the concept of text is explicitly "baked into" the system. A close reading of code and system architecture.
Media archeology: textual archeology. Computers containing vestiges of ideas and direction. Can be done in situ. Applied turn in media studies. Confusion due to technical literacy. Forms of latent textuality still extant. Berkman center. Reaching out.

Something like a textbook in "applied media studies" or "theoretical digital humanities."
I teach widely around the country (DHSI, Lede, NYU) and I use these materials myself. I can see a course structured around these skills and ideas. 

## Chapter Outlines
I tend to write concisely--a style that I think fits well with the subject matter, and something that should appeal to the audience. At this point, I am aiming for a manuscript of around 60-80k words, which would allot around 5-7k words per chapter (around 20-30 book pages).

### Chapter 1: We Have Always Been Digital
Digital. Analog. Soap opera effect. 
### Chapter 2: Freedom of Information
The "systems" definition of information. Shannon and Weaver. Argue for the freedom of the sender and receiver instead of the system.
### Chapter 3: Text, Form, Formating
Text as meaning, semantics structure, and style. 
### Chapter 4: Scratch Collector
Data and metadata.
### Chapter 5: Media, Message, Mode
### Chapter 6: Platforms of Self
### Chapter 7: Textual Interfaces
### Chapter 8: Hardware, Software, and the Platonic Forms
### Chapter 9: Bad Links
### Chapter 10: Processing Words
### Chapter 11: Code and Crypt
### Chapter 12: New Humanism
### Tech Appendix

## Timeline
I keep detailed logs of my daily writing practice. During the academic year, I average around 250 words per day, a number that nearly triples during breaks. Assuming a manuscript of around 80k words (and discounting the fact that large poritions of this book are anicipated in my dissertation), a conservative estimate of my schedule would place the final draft somwhere towards the second half of ther summer, 2015. 

# Part I

## We Have Always Been Digital
Key terms: binary, digital, analog, plain text, surface, depth
Commands: pwd, ls, cd, cat, wc

In an ASCII-rendered plain text file, byte count corresponds to character count.[^ln-char] Let these words soak in for a moment. The rest of the book will be spent unpacking this idea. We will have to come to terms with what "plain text," "ASCII," and "bytes" really represent. But for now, a common-sense understanding of the sentiment will suffice. It is enough to have the intuition that texts and characters are concepts meant for humans and that bytes have something to do with (and for) machines. Remarkably, under the singular conditions of plain text (and even then, not always, and with many caveats), a unit of information meaningful to me (a human for the most part) gains a measure of equivalence to a byte, a unit of information meant for a computer (which is, however likable, still a machine).

[^ln-char]: There are many caveats here, to be explored later. Follow along with excercises related to the discussion in the Technical Appendix.

Recent theory challenges the conceptual boundaries between humans and machines in a concerted way. Perhaps, such boundaries were never that clearly articulated in the first place. It is also likely that other modalities of being are possible on the spectrum between human and machine, or human and complex system. We will have a chance to explore these possibilities in Part II of the book. For now, I ask that the reader simply rely on the colloquial, pre-theoretical understanding of both person and instrument. However intertwined the hand and the hammer can be, there is a way in which even a child can separate one from the other. There is a deep-rooted instinct at work in that distinction, one that cannot and should not be dismissed as mere naivete. The concept of a human is in itself a powerful theoretical construct, and, as I will argue later, one necessary, not only for the understanding of key concepts in computer science, but also in articulating an ethics and a politics of computation.

But before we can get there, we need to gain clarity on the key terms of the conversation. Too often anxiety about algorithmic thinking, data, and digitization is fueled by simplistic and downright misguided ideas about the underlying technologies. Part I of this book is dedicated to building a critical vocabulary that goes hand-in-hand with digital literacy. Those with an engineering background will be introduced to an intellectual history of ideas that guide practice. And those readers interested in "theory," will gain a measure of technical competency required for higher-level thinking (opinion-formation and decision-making) about the subject.

Digitality is first in a long series of these muddled terms. The original intuition, challenged by Nelson Goodman in the late sixties, still holds sway in the popular imagination. On this view, digitality has relates to digits, just as "analog" relates to analogies. First use of the word digital. The distinction between analog and metaphysical threat, Kittler and Golumbia. 

Language is digital. Soap opera effect. Gaps that allow the brain to fill it. Striation. Preserving striation. History of UTF8. Unix philosophy. 

Binary tends towards the continuoius (get the ch. Reality TV and the soap opera effect. Digitality is something worthy of being preserved.

### Text Plain and Fancy 

## Freedom of Information
Information is intentional. Against the "cybernatic" formal definitions. 

Information as entropy. The strangeness of Weaver's "information as entropy". How much information in a brick? In a novel? Information as a possibility.

Freedom and information seem to have nothing to do with each other. They have everything to do with each other.
Makukov. Directed pan-spermia.Life Sciences in Space Research paper: http://arxiv.org/abs/1407.5618 Icarus paper: http://arxiv.org/abs/1303.6739 

What is information? The difference that makes a difference. Bateson's definition. Dorsality. Weaver's entropy. Explain. Amount of freedom. Confusion in that paper. Noise and information seem to be the same! Thermodynamic explaination. Transmitting things in stone (low entropy) vs. transmitting them through the air (high entropy). Does a block of wood have more "information" than a novel? This definition cannot account for it really.

Extended cognition hypothesis. Get this text from disertation. The monism problem.

Formal vs. instrumental definitions. Information is that which moves form a Mind > Encoding > Mediation > Decoding > Transmision. Coersion. Can information be coersed? Both on the sending and the recieving end. Can someone admit something is music by force? Can you force information. The deer and the tick. The deer does not "send" bodyheat information. The tick receives information as it does receive the action of gravity. Does a mountain erode from the top because it recieves information from the outside? Information here is simply used as a synonym for some material state of the univrse and the causal relationship between forces. Causality alone is not information. Laws of physics are not information. Well, unless...

Mis information. Man in the middle attacks. Information is intentional. Mind to mind communication. Where does the thought originate? Freedom. Free intent. Identity of coding and decoding is not necessery. What is however necessary is the 

Leroi-goran. Constructor theory of information. SUperinformation. http://arxiv.org/abs/1405.5563

 

## Text, Form, Formatting
POSIX. Form. Style. Content.
What is and what is not information. From abstract to specific. Material substratum.
UTF History. Unix ideas of plain text.
Traditional distinction: Jacobson. Semantic, Stylistic, Content. Surface Depth.

Version control, drafts, versioning. What is a text?

http://www.unicode.org/reports/tr29/ The concept of Grapheme Clusters.

Wikipedia as a Turing complete language. The power of versioning. Text as a vector. The problem of annotation. What are we annotating? Annotation solutions force a platform. Is Hamlet a platonic object? A family of related objects? Standard English editions in Europe.
## Scratch Collector
Data, Metadata
Code and comments. Collector of chair or collector of scratches. Object oriented ontology. Object oriented languages. Competing paradigms: separation of code and data. No separation (Haskell).

## Media, Message, Mode
Key terms: media, message, mode

What happens in the change from speaking to writing? The violin (copy from dissertation here).

Attunement of listener. Message stays the same. Put a ear, eye, hand to the pipe. Same message, same medium, different mode.

Krap's Last tape here. 
Who are you communicating with? Pushing yourself through the pipe. The appointment with myself. The sum-total of material substratum. Building a wider platform. Todo, email, diary, music collection. Burning building-we grab our memories, and hoarding the disfunction of that personal sediment. You are the sum-total of your modalities. Commitments to self. Attunement of self. The message is you. Preserving ourself from entropy. 

Books are not media they are platforms. Platform is all of the above. Plus the economic / cultural contexts. Amazon Kindle is a platform. Who are you communicating with? Yoursef. What is the message. Ultimtely, it is a message of self-identity. 

## Filing System, Platform of Self
Key terms: file, document, stream, net neutrality
Commands: grep, awk, sed 

Documents as vectors. Not completed things. Files as cognitive scaffolding for collective memory. Vissman. 

Science lecture vs. humanities. Stuff that is known. Stuff that is not known

What does it really mean to "know" something? Or to have "read" a book? I have had the following conversation countless times. Someone asks, "Have you read Nabokov's *Pale Fire*," and I respond, "Yes I have." But there is a world of a difference between reading it yesterday, last week, or ten years ago. The book as an interface leaves an organic trace in the human mind--an imprint that begins to fade as soon as it is created.

How much knowledge is there in the world? According to a recent paper published in Science, 295 exabytes (or billion gigabytes).[@hilbert] 

Whatever consciousness is, it is propelled forward on a thin edge of material substratum. Reality exists only in the now, where the past is a memory and the future only a possibility. Imagine whispering something to a friend. It does not have to be very complicated, something like "I love you" or "I miss you." The whisper dissipates as soon it is uttered. The percussion of the speaker's breath creates temporary order: giving shape and pushing air molecules into waves of pattern and form. That order begins dissipating as soon as it is created. Within milliseconds, molecules return to their natural state of chaos.

To steel ourselves against entropy, we change the substratum from air to stone. It's molecules are more stable. Etched in stone will be the same message. It will last longer now. But it will also take longer to create. You will have to carry around your tablet and chisel. The message etched in stone will outlive the whisper and indeed will

Repercussion? How we preserve ourselves today affects the future. Appointment with self. 

The essay by Heidegger. Uxcull phenomenology.  Leroi-Gourhan, André. 

The book as an interface between human and ?. We must see it in the context of interfaces.


# Part II

## Textual Interfaces
Containing an argument for text as an interface between human and machine. History of combinatorial languages and logic.  Stack as a model of communication

Talk about stack exchange vs. 4chan vs. reddit

Handwriting. Teaching children how to "write". Typing vs. handwriting.

## Hardware, Software, Algorithm
One of my favorite "virtual" disagreements in print is between Kittler and Lev Manovich. "There is No Hardware" and "There is Only Software."

Turing's machine. Universalism vs. drucker. Bit, byte. State machines. The magic of boostrapping. Plato and Epicurus.

History of computation. Lull (universal language) > Leibniz (binary code) > Boole (logic) > Church (logic gates) > Turing (universal machine) > cloud computing (platform as service)

### Algorithmic Imagination
We can now conclude the detour into system theory and return to our initial question, but in a much more limited, albeit more productive form: can a text replenish itself? Can it bloom? Can it reproduce? We are beginning to "zoom in" from viewing literature as a system to considering the autopoietic potential of a single text. But the question still seems somewhat odd to me, having again the flavor of an anthropomorphic (or at least biomorphic) metaphor. Can this inanimate object—a text—enact or want to enact anything on its own? Or are we simply making yet another metaphor that attributes volitional characteristics to an inanimate object? To put it another way: do we imagine a text as a type of a tool, or is it something more—something capable of containing objectives beyond the authorial intent? A tool—take a needle for example—is quite passive in this regard. I can poke my neighbor with a needle, and he could say that it was the needle that poked him. But clearly it was I who actively meant to do the poking, and not the needle. The action may have unintended consequences of course: I poked maliciously, but as a result, the neighbor was rid of his headache. Still, we must say that the needle in this case was simply an instrument of my volition. Left to its own devices, the needle "does" nothing. It has no creative or generative potential, we might say. What would it take for us to begin considering the creative or generative potential of an inanimate object? To put it another way: is a text something like a needle, or is it something more than simply a tool or a thing? 
    Another tradition of asking this kind of questions is distilled in John Searle's seminal "Chinese Room" thought experiment, which first appeared as an article on the pages of Behavioral and Brain Sciences in 1980.1 Searle's concern in this thought experiment was with artificial intelligence, but in a fashion typical to the discussion (see the previous chapter on Alan Turing and Ludwig Wittgenstein), the readers were asked to test their intuitions against a distinctly discursive apparatus. Imagine being locked in a room with "several baskets full of Chinese symbols," writes Searle. You do not understand a word of Chinese but you are given something like a rulebook, or a giant look-up table (in your language), which you can use to reference the appropriate response to anything that may be asked of you in Chinese:
The rules specify the manipulations of the symbols purely formally, in terms of their syntax, not their semantics [...] Suppose that unknown to you the symbols passed into the room are called "questions" by the people outside the room, and the symbols you pass back out of the room are called "answers." Suppose furthermore, that the programmers are so good at designing the programs, and that you are so good at manipulating the symbols, that very soon your answers are indistinguishable from those of a native Chinese speaker.2
 
And so you sit there, in what is essentially a black box, blindly sorting incomprehensible (to you) symbols, passing and receiving some sort of cards through a slot in the wall (or a similar contraption). To the person outside of this box, it looks as if the room can speak Chinese. But, you of course know that you do not speak the language. Your function within this system is purely mechanical—the point of the experiment being to show that the formal manipulation of symbols does not rise to anything that we may reasonably recognize as speaking or understanding a particular language. Knowing Chinese, according to Searle, requires the appropriate intentional mental state. Moreover, for Searle such mental states are purely biological phenomena, and a property of very particular wetware, just as are "growth, reproduction, the secretion of bile, and digestion."3 Thus, the question of attributing intentional states to essentially algorithmic systems for him hinges on an a priori distinction between living and non-living organisms. 
    We arrive then at the same stumbling block that we hit in our discussion of autopoiesis. In an attempt to define an essential property of a living (thinking, self-reflexive, talking) system, we are confronted with the erasure of the very boundaries that we were trying to establish. Searle, along with the critics of autopoiesis applied to social systems, beg the question by simply insisting on the distinction between wetware and hardware, arguing that properties such as thought, language fluency, and recursive self-regeneration, are exclusive properties human, or at least, biological systems. The distinction between wetware and hardware may well be worth preserving, even when we cannot quite come to an agreement on its formal definition. I am intentionally not taking a clearly defined side in this recurring debate in order to avoid the argument about definitions. Yet the question of machine literature comes into close contact with these conversations—the practice of talking with machines evolving out of precisely such thought experiments as Searle's Chinese room.
    In rehashing the premise of Searle's Chinese room, we therefore have a slightly different vantage point from those interested in the difference between functionalist (behavior oriented) and structuralist (intent-oriented) explanations of cognitive phenomena. Note, for example, that the Chinese room is not strictly a mechanical contraption. It contains inanimate elements proper (the room itself), an algorithm for deciphering the sinographs (presumably produced by other human programmers), and finally, you—the human who does the looking-up and the sorting of the characters. The Chinese room is clearly not a simple inanimate object then. It is an amalgam of species. The wonderfully strange (and I am guessing, unintended) byproduct of Searle's thought experiment is the inversion of the mechanistic model of the mind—since it is not that he asks us to imagine a machine inside the human brain, but a whole human being inside the machine. And so we might follow Searle's intuition to say that the Chinese room does not really speak Chinese. Or, we might take the functionalist approach to the problem, and maintain that we don't really care about the innards of the black box: it seems to speak Chinese, and so it does. I do, however, want to point our attention toward the algorithm at work inside the contraption—the very chart by which the human is able to blindly sort the appropriate responses in a language that she does not speak. Were we to try and locate the seat of intelligence in the overall system, it does seem that we would have to single out this humble piece of paper—for it is the only inalienable part of the overall mechanism. We could take away the room, replace the human with a computer, and still have essentially the same experiment. If anything generates language proficiency in the Chinese room, it is this algorithm—which means that the emphasis on the computer in the conversation on artificial intelligence is slightly misplaced. Just like the Chinese room, the computer is a disposable black box. Were we to atomize the metaphor of "artificial intelligence," it would be the algorithm that would contain the "artificial" and the "intelligence" portions of the mechanism.
    What is an algorithm? The word itself comes from the Arabic Al-Ḵuwārizmī, which according to the Oxford English Dictionary means "the native of Ḵwārazm (Ḵiva), surname of the Arab mathematician Abu Ja'far Mohammed Ben Musa, who flourished early in the 9th cent., and through the translation of whose work on Algebra, the Arabic numerals became generally known in Europe." The original meaning of the word simply denoted "the Arabic, or decimal system of numeration."4 But in the contemporary sense it means something like "a process, or a set of rules," or perhaps a "step-by-step procedure" for reaching a decision or a clinical diagnosis in the case of medicine.5 As such, the algorithm looks to be a type of what J.L. Austin dubbed as a "performative utterance." In contrast to descriptive statements ("The emperor isn't wearing anything at all!"), a performative utterance has the qualities of a) being unfalsifiable and b) constituting an action or a part of the action.6 Austin's paradigmatic illustration for these two properties are the wedding vows. Saying "I do" does not describe the action in a way where the description could be considered true or false. The vows are a kind of action. They bring something forth in a way a needle prick can bring forth the reaction of pain. 
    The algorithm looks to be a special kind of a performative utterance, which differs from other types in that it does not elicit the action immediately. The algorithm is a time capsule of sorts—it will perform when it is called to action (where the wedding vows are valid as soon as they are uttered). This seems like a minor difference at first—the ability to shift something I will now, into action later. Imagine for example, a contraption that will cook an egg for me at some specified time in the future. It is as if a splinter of my volitional desire (to cook an egg) has been broken off to perform an action by itself (cooking the egg), independently and yet on my behalf. In this way the algorithm, although being a dead, inanimate thing (made out of symbols), seems to possess a spark of animate force capable of acting in the world. The algorithm is a special kind of performative utterance which, like an enchanted object, continues to do the master's bidding even in the absence of the master. We could call these kinds of utterances "imperative." 
    The imperative is a type of a performative utterance in that it enacts rather than describes things in the world. Unlike other performatives, the imperative utterance is often meant to enact something at a later time and place, without the immediate presence of the original author. The paradigmatic example of an imperative utterance would be the legal concept of a will, by which "a person's formal declaration of his intention as to the disposal of his property or other matters to be performed after his death, most usually made in writing."7 The legal definition contains something common to all such imperatives, namely that they must usually be recorded somehow—on paper, on audio tape, video, or by similar means. All this to say that an imperative utterance is usually a document of some sort. Looking back into Searle's thought experiment, we see that the Chinese room does contain a document of that kind. Something does speak Chinese in the room—the look-up chart which contains the heuristic that we were asked to follow blindly. At the very least we would have to agree that the person composing the chart does speak Chinese, and that his language ability was transposed in time and place by the means of that document. But is that ability transferred to the mechanism of the black box, or does it remain squarely in the mind of the original Chinese speaker? This and similar problems contained in the premise of procedurally-derived literature cannot be resolved by the purely theoretical thought exercise. We must look to the archive for the traces of machine composition and consider the practice of interacting with algorithmically-composed texts.

Here is where I begin to get a little suspicious about the accepted history of ideas when it comes to formalism as a movement in literary criticism. In 1894, Georges Polti—a relatively minor French author—published Les Trente-Six Situations Dramatiques (translated into English in 1916 by William R. Kane as "Thirty-Six Dramatic Situations," published by the Editor Company). Judging by the number of imitations, the work was an almost immediate international success and remains in print today, in 2010. Unlike Propp, Polti is very explicit about his influences. The work begins with a quote from J.W. Goethe, who writes that "Gozzi1 maintained that there can be but thirty-six tragic situations. Schiller took great pains to find more, but he was unable to find even so many as Gozzi."2 Polti writes that "in France, Gerard de Nerval3 alone had grasped and presented briefly the ensemble of all dramatic production, in an article upon Soumet's 'Jane Grey,' in L' Artiste,"4 but that "since Nerval, no one has treated, in Gozzi's genuinely technical manner, of the secrets of invention."5 To derive his thirty-six situations Polti assembles "the principal dramas of China, of India, of Judea, and, needless to say, of the Greek theater," along with "the Spanish authors, the French classics, the Italians, the Germans of the Romantic revival, and our modern dramatic literature," and finally "two hundred of the examples […] from other literary genres akin to the dramatic: romance, epic, history, and from reality [!]"6 The stated purpose of Polti's project is to ask "Which are the dramatic situations neglected by our own epoch? […] Which, on the other hand, are most in use today? Which are the most neglected, and which the most used, in each epoch, genre, school, author? What are the reasons for these preferences?"7 These questions lead Polti to his thirty-six situations: supplication, deliverance, crime, pursuit, disaster, revolt, abduction, enigma, madness, ambition, and so on. Many of these correspond to Propp's thirty-one morphemes, although to his credit, Propp's improves on Polti's scheme by arranging the situations in chronological (from the point of view of the plot) sequence.
    Despite the lofty historical and philosophical ambitions, Polti's work skews decidedly towards the craft of writing plots. The reader never does find out why certain "situations" are more prevalent in one epoch or the other. Rather the book's conclusion contains the following remarkable appeal to the reader:
Thus, from the first edition of this little book, I might offer (speaking not ironically but seriously) to dramatic authors and theatrical managers, ten thousand scenarios, totally different from those used repeatedly upon our stage in the last fifty years. The scenarios will be, needless to say, of a realistic and effective character. I will contract to deliver a thousand in eight days. For the production of a single gross, but twenty-four hours are required. Prices quoted on single dozens. Write or call, No. 19, Passage de l'Elysee des Beaux-Arts. The Situations will be detailed act by act, and, if desired, scene by scene.8

Besides Polti's largely unacknowledged influence on the development of Russian Formalism,9 the principle impact of his work was and remains in the field of applied composition studies. Thirty-Six Dramatic Situations inspired countless imitations in the "writer's aid" genre, among these the most popular examples being William Wallace Cook's Plotto (1928), and Wycliffe A. Hill's Plot Genie (1931),10 among many others. Plot Genie in particular shows the genre's direct lineage to Ramon Llull's combinatorial diagrams. The booklet came with a cardboard wheel, by which the author could select a random combination of characters and plot devices.11
    The proliferation and the popularity of combinatorial writer aids in the early twentieth century have to be attributed, at least in part, to the burgeoning American pulp fiction market. James D. Wood—a scholar and a contributor to The Pulp Companion online fan community—describes it in the following terms: 
The year is 1935. On every street corner, newsstands are brimming with pulp magazines. Readers young and old thrill to the battles of G-8 and Operator 5, to the adventures of the Spider, the Shadow and Doc Savage […] You are a pulp fiction writer. Seated behind your Remington typewriter, your fingers dance and the pages fly: trench-coated private eyes and sultry gun molls, hard riding sheriffs and gun-slinging desperadoes, fearless spacemen and bug-eyed monsters—for a penny a word, you can do it all […] It’s Friday night. After a long day at the keyboard, should you have a bite of supper or just go to bed? The phone rings. It’s the editor of Strange Science Magazine, and as usual, he sounds like he’s double-parked. "I need a 50,000 word space opera,” he barks. "On my desk, first thing Monday morning!" As a pulp fiction writer, you are a professional. You have no time to sit and wait to be inspired—you must produce on demand. As much as you need your dictionary and thesaurus, you need your story plotter.12

The turn of the twentieth century—modernism—is commonly characterized as the dawning of mass production: interchangeable parts, machine tools, and electrical power. We are accustomed to thinking that the paradigmatic aesthetic concern of the moderns was mass production, or rather the mass mechanical re-production of the work of art. Mechanical reproduction certainly contributed to the sharp decline in book prices in the first decades of the twentieth century, but the means of producing texts underwent a radical change too, unrelated to the mechanisms of the printing press. In the twentieth century we began to produce and consume algorithmically-constructed texts on a large scale.
    Polti's Thirty-Six Dramatic Situations, Cook's Plotto, and Hills' Plot Genie were met with excoriating critical reception. "The subject and the scorn almost placed the subject of situation in the category of untouchables," Carl Dahlström writes in the 1936 issue of PMLA. In the concluding sentences of his book, Cook reports a conversation with a London publisher who believes that "Plotto will be condemned publicly—and probably used privately."13 The critical exile continues to this day: JSTOR14 contains exactly one article devoted to Polti's work, a single mention of Plotto in a French-language article on mass literature, and nothing on Plot Genie.15 By what logic does the relatively obscure Vladimir Propp become canonized in the graduate literary studies curriculum,16 and the massively popular Georges Polti relegated to almost complete obscurity? I want to make sure that my intentions in asking this are not misunderstood. I have no interest in promoting Polti's work, or detracting from Propp's contribution to the field. I merely want to point to the intuitive sense of collective discomfort with the notion of algorithmic composition. The idea just seems somehow to lessen the weight given to human agency in the act of literary creation—even to the point of preventing conversation on the topic. Polti himself understood this problem very clearly: "But I hear myself accused, with much violence, of an intent to 'kill imagination.' 'Enemy of fancy!' 'Destroyer of wonders!' 'Assassin of prodigy!" he writes at the end of Thirty-Six Dramatic Situations. "These and similar titles cause me not a blush," he concludes.17 
    The enemy, in this case, is what Polti calls "the ultra-romantic" notion of the imagination—"the charlatanesque 'faculty,' analysis of which is, it would seem, eternally interdicted."18 Polti writes:
One vigorous blow was, for the moment, given to this legend of the Imagination by Positivism, which asserted that this so-called creative faculty was merely the kaleidoscope of our memories, stirred by chance. But it did not sufficiently insist upon the inevitably banal and monotonous results of these chance stirrings, some of our memories-precisely those least interesting and least personal-repeating themselves a thousand times in our minds, returning mercilessly in all manner of method-less combinations.19

The alternative to the method-less meandering of romantic imagination is guided experimentation. Here Polti envisions the extension of his inquiry, a "New Art" that thrives on the numerous, yet unexplored combinations of dramatic possibility.20 Pulp fiction was perhaps that new art, but Polti and his followers could not have anticipated the radical potential of procedural composition enabled by the developments in computer science and information technology.

### Philosophical Foundations of Computing
The magic of hardware-software distinction. "Where the Platonic rubber meets the road." Goodman and the problem of self-identity.

The dream of a universal language. Lully. Leibniz with digital and logic. Boole with boolean logic. Shannon with the insight that boolean logic can be implemented in circuits. Finally, Turing, with his Unversal Turing Machine. Answer the following questions here:  How does Turing define the state of the machine? What is the equivalent of a "program" or "software" in the language of the paper? What is the difference between a Turing machine and a universal Turing machine? How is the state of the machine similar to a "state of mind?" What is the difference between what we understand as "software," "hardware," and "data" in Turing's language?

"Claude Shannon first explicitly posed the question of finding the smallest possible universal Turing machine in 1956. He showed that two symbols were sufficient so long as enough states were used (or vice-versa), and that it was always possible to exchange states by symbols." Get at this. States and symbols.

"Where the Platonic rubber meets the road." Goodman and the problem of self-identity.


### The problem of duplicates
The conversation between Goodman and Genette. Goodman's "Art and Authenticity." Benjamin. Immanence and transcendence. Goodman: thinking about the perfect copy. But there is a confusion here: fake art is not necessarily about a copy, it is about provenance. Autographic vs. allographic art. Whether forgery is possible. Digital vs. analog art. Analog art is medium bound. Digital abstracts from the material. 

### Duplication, censorship
### Annotation
### Collaboration

## Bad Links, Intertextuality, Symbolic links
Rise of intertextuality. The promise of hypertext. Bush w/ Memex. Nelson. Failure of intertext. Borrow from bad links here.
It is my intention here to convince you that links are bad. They are bad when it comes to writing for the web in general, bad for books, bad for long-form journalism, and even worse in academic publication. It is not that I am against the idea of links. As we will see here, the problem lies in the way links are used. That is also to say that we can do something about using links better. But first, why are links so bad?

To start with, links are opaque. The worst of lot are links like this and this. Of the two “thises,” the first leads us to Google and the second to Bing. But your readers would not know that just by looking at the text. The best they can do is “hover” over the word with their mouse cursor, relying on the browser interface to show them where the link is going. And once they get there, there are no easy ways to get back. The writer must have faith in the browser to “do the right thing” in guiding the reader through an intertextual maze. And that is not right when it comes to writing. In most situations, the author should architect that experience explicitly. If you think about it, the old-fashioned apparatus of quoting an external text is itself a type of linking. But rather than quoting the whole text, the author only quotes the relevant bits. Sending readers away to do that work on their own is lazy and irresponsible. Imagine a tour guide who tells his tourists to “just go over there and look at some stuff,” and “come back when you’re done.” Links can be that disorienting.

Links disrupt the reading experience, and that is the second reason for why links are bad. It is possible that you want the reader’s experience to be disrupted. But in many cases you don’t. And the reader is already distracted by the proliferation of parallel windows and devices that augment their reading in some way. Do we need to make that distraction easier? Should I link the Wikipedia article on media multitasking or is it enough for my purposes to simply mention Wikipedia, or to trust my reader to look something up later, in a reference source of their own choosing? Or better yet, should I help the reader along by summarizing the findings? It mentions that most folks already read with a second screen in tow. It is not that unusual to see someone look something up on their phone or tablet while reading a newspaper or an e-book. Why? Because they don’t want to leave the flow of the first screen. There is great pleasure in immersive, uninterrupted reading.

Besides being disruptive, links are ugly. They are ugly together, as in when many links conspire to produce a tangled mess. And they are also ugly when naked on their own, like this: https://docs.google.com/document/d/1TaGiFBG_WSEGKFey9sR0pafjjKK7Fuc0jhF5d4K1ouA/edit. That string of characters is not meant for human consumption! The period at the end kills me entirely. Meaningless punctuation inside of links coupled with regular punctuation ruins the sentence and the paragraph. Of course, I could just tell you to read something on Google Docs. That looks much better, but then we are making the opaqueness problem worse by hiding the address behind words that may or may not be related to the destination. It seems that we are stuck compromising on either transparency, reading flow, or visual impact.

Links aren’t very secure to begin with, but hiding links behind words further compromises security. You’ve probably heard of link-baiting: the purposefully malicious attempts to trick a reader into revealing personal information when following a link that masquerades as a legitimate destination. You can visit my site to learn more about link-baiting. You shouldn’t have clicked that! (Don’t worry, that was the real Google login page.) But even if one means well, viruses and browser exploits can inject bad links into your otherwise legitimate ones. A common technique is to install a browser script along with some seemingly useful “search bar” that will redirect all legitimate links to a site that makes money by advertising. Worse yet, you could end up on a site that attempts to further compromise your computer. Links are not secure because in linking, we outsource the relationship between reader and content to the browser.

Links are opaque, disruptive, ugly, unsafe, and they rot. Links don’t last because the content at the address is dynamic. It is not guaranteed to be there decades, months, minutes after your initial visit. In that case, why even bother? The link works best for ephemeral output (like a tweet). We must think of something much more robust for any “serious” writing that hopes to survive to the end of the week. And for the really good stuff, the kind of stuff that is the purview of librarians, we need to cultivate sustainable, long-lasting, responsible practices of online citation. It should work as well, if not better, than the familiar bibliographic citation in print. This practice should combat digital decay, not aid it. We need to think about the ways our links can be accessed, mined, and preserved with the archive-grade zeal of the rare book librarian.

Finally, links are terrible for accessibility. It is bad enough that clicking on a small word like this is difficult for people with any sort of fine-motor control problems. Being a little older in itself can make the online reading experience painful. Things are much worse for those with Parkinson’s or for the blind. Sina Bahram, a blind usability expert (who is himself blind) reports that some sites contain thousands (!) of links in advance of actual content. Screen readers for the blind must read each one of them out loud. For the screen reader, there is no difference between garbage links and useful content. If you thought looking at links is disruptive, imagine listening to a robotic voice that pronounces every slash and every useless number in: http://www.youtube.com/watch?v=92pM6hJG6Wo. And that is why Sina Bahram listens to his reader at 950 words per minute.

Any one of these issues alone should give us pause. Together, they are a cause of grave concern. How did we get here? And what can we do to make links good again?

How did we get here is not an easy question. A part of the story is surely the excitement we once felt about hypertext. Links were supposed to break the hegemony of linear narrative, ushering in a new interconnected world. To some extent the dream came true. But links also brought with them such things as Search Engine Optimization (SEO). Google’s PageRank algorithm tracks, among other things, the number of incoming and outgoing links. This bias for connectivity encourages “link farms”: sites that attempt to game the system by aggregating links or cross-linking their own content. A sure sign of a vacuous SEO-driven piece of writing is a certain cynical and strategic use of links to other popular sources. How long until the SEO logic infects poetry, fiction, or investigative journalism?

What can we do to make links better? There are a few things we all can do now. First, let’s use links sparingly. Think smartly about whether you need to link or whether you can make do with a good, old-fashioned quote or citation.  Don’t link just because you can. Second, link explicitly: Youtube.com is better than this. Third, realize that online content is dynamic. It makes no sense to link a dynamic resource when the intent is to create a link to a static version of a document. Tools like the Save Page Now service, hosted by the Internet Archive, do just that. You can find this essay at http://sprintbeyondthebook.com/2014/02/bad-links/ but its earlier draft is best captured in a snapshot here: http://web.archive.org/web/20140208220625/http://sprintbeyondthebook.com/2014/02/bad-links/. Finally, do not neglect the humble footnote. Footnotes provide a nice blend between usability, transparency, and good knowledge design.

1: http://web.archive.org/web/20140208220625/http://sprintbeyondthebook.com/2014/02/bad-links/
## Processing Words
Containing an argument for text as an interface between human and machine. History of combinatorial languages and logic. Isomorphism. Search. Protocol - interface. What you see is what you get. What you see is not what you get. Argument for text. Desktop publishing. Stream vs. Object containers.

Typesetting sweatshops.

http://word.mvps.org/faqs/general/wordvswordperfect.htm
http://wptoolbox.com/tips/MSWordToWP.html
modal vs. other kinds of processing 
## Cryptonauts
Stuff about Lull here? Artificial intelligence. Gwern and encryption. Cypher punk. Surveilence and privacy being the same side of the coin. Hackable media. Ability to encrypt and decrypt. Political potential. Enabled by plain text.

Internet is not rhyzomatic. Mediation is at stake. " But the bottom line is that dumb-pipe email is unmediated, and therefore it's a business that Google wants to get out of as soon as it can."

" It's also why I believe Google will kill Gmail as soon as it comes up with a mediated alternative everyone loves. Of course, Google may offer an antiquated "Gmail view" as a semi-obscure alternative to the default "Inbox"-like mediated experience."

http://www.computerworld.com/article/2838775/why-google-wants-to-replace-gmail.html

## New Humanism
"Neuroscience has put a new spin on free will and culpability: It "can help us see that all behavior is mechanical, that all behavior is produced by chains of physical events that ultimately reach back to forces beyond the agent’s control."

Post humanism as latent monism. What is the problem with monism? Two types of monism:
stuff monism and thing monism. Everything is made of the same matter (information). Everything is a part of the same thing, living organism. S

Todd Presner and the Ethics of the Algorithm. Drucker on What is? (mathesis).

Humanism: Agency, Deliberation, Consensus, Dissent.
Assuming for now that the reader holds some, if not all, of these ideals I ask: to what extent do the platforms that define contemporary media use answer to their implicit ideals? Impoverished platforms.

But to begin answering it we must make a short detour into the somewhat arid land of systems theory. The idea of autopoiesis was popularized by the biologists Humberto Maturana and Francisco Varela in the early 1970s. It means literally "self-creation" or "self-production." Maturana and Varela used the term to describe an essential property of a living system. The autopoietic, and therefore living, organism is defined as "a unity of components which (i) participate recursively in the same network of productions of components which produced these components, and (ii) realize the network of productions as a unity in the space in which the components exist."1 The paradigmatic example of such a system is a biological cell, whose components exhibit spatial integrity, and which maintains the production of its internal components to perpetuate its existence. All this to say that an autopoietic system produces and maintains its own constituent parts, in contrast to an allopoietic system—take a wrist watch for example—which relies on other systems for its maintenance (in this case, human labor). Subsequent to its introduction, the concept of autopoiesis has found wide-spread use in general systems theory and in the study of large-scale social systems: science, business, law, and literature. Thus, for example, in his influential 1985 monograph on the sociological theory of law, Niklas Luhmann envisions the legal system as an autopoietic, self-organizing entity operating within a distinct sphere of influence. Others, like the literary theorist Joseph Tabbi, have applied the concept of autopoiesis to literature, which as a system also seems to be self-reflexive, self-organizing, and self-perpetuating.2 

Critics have pointed out that such an extension of the original concept is metaphorical at best, and at worst can lead to a kind of an "epistemological solipsism."3 The first problem is that autopoiesis was originally meant to describe living organisms, as opposed to non-living ones. In so far as they are living organisms, social systems like law or literature patently occupy a different order of existence than biological ones like cells or primates. It is therefore not very clear as to what we may mean when we call the legal or the literary systems "self-organizing," since it is precisely the living "self" in "self-organization" that we are trying to establish. And it does not help that in colloquial speech, we often do ascribe other volitional or intentional properties to whole systems, as is the case when we say something like "the people have spoken" or "corporation XYZ made a decision to stop selling its products." In all of these examples, the unified and self-perpetuating quality of the given system seems either imprecise or metaphorical. Thus, "the people have spoken" may actually mean "there was a national vote," and "corporation XYZ made a decision" may simply mean that its board members met and have decided on something among themselves. In this anthropomorphizing imprecision, the distinction between the living and the non-living systems itself gets lost.

The second problem stems from the first. In identifying the body politic or a corporation as a type of volitional or intentional entity, we in effect already have drawn an artificial boundary around its constituent members. By contrast, a cell presents a clearly demarcated membrane that separates its internal functions form the external. One may object that even a cell is not a truly unified or self-reliant system, requiring external resources for its operation. This problem intensifies when we apply the concept of autopoiesis to social systems, which are not particularly well-insulated entities—as is the case with governments, corporations, and literature. Such systems lack "natural" membranes that clearly demarcate their insides from their outsides. Moreover, both cells and social systems are fundamentally bound by laws of nature and firmly enmeshed in the context of their habitation. Thus to see their operation as "self-generating" is to engage in a kind of a solipsistic epistemology, by which we imagine a particular system as a hermeneutically sealed unit, separate from its environment, and able to produce its own circumstances, or as the extreme version of the proposition would have it, its own reality.4 The idea of literature as an autopoietic system must be subject to these very same caveats. Before even considering the possibility of literature as an autopoietic entity, we must understand that social systems are by definition artificially constructed entities, that they lack clear boundaries, and that their function cannot be strictly equated, even on the systems level, to the operation of biological organisms.

Technology, Complex Systems, in defense of Humanism
Post humanism. Complex systems. Neo platonism. A disempowering political program. If you think complex systems have emerging intelligence, they have the right to speak. There is something like intelligence, but there is a mode of intelligence that should be reserved for humans. Plain text offers that possibility. No amount of fancy theoretical footwork can obscure real inequalities that exist in the world today. Platform lock in. Global south. Mumford. Values cannot come from within systems. There has to be an outside, and the Kantian solution is to proceed as if there is an outside. That is a small space to remain human, all the more befuddling when that space is diminished by those professing in the humanities. Reading of Heidegger. Technology that answers to human values. 

My concern is with post-human ideology, that, in the name of forests, animals, and ecosystems, brings algorithms, markets, military bots, and manufactured goods into the sphere of ethics as actors. The agenda is one of determinism, which in its many guises has always been used as a mode of oppression, control, and to excuse violence.

Agency is a tiny and speculative bulwark against forces of determinism. We should not be too eager to dismantle it. In that light, poisoning oceans etc. can only make sense as a human relationship. Someone must be on that other shore! An ethics posited between a man and an ocean alone are dangerous and impossible. I'd site the lineage of good ole Kant, Marx, Sartre, and Arendt for that line of reasoning,

How to confront the foundational violence of humanism. Use non-European sources here as well.

Latent monism. Plotonius. Monism of the underlying matter (everything is made of one stuff, information) and monism of the universe is one: Dr. Bronner's monism.

Monism is bad because it totalizes reality. There is no space for dissent. Monism and pluralism the same. Computation is the pinnicle of secular idealism. But it must be moderated by a retreat into the material, and into the human, which is a always a being part god and part man and woman. Yes this is a species of dualism. But without dualism, there's no space to escape the totalizing pull of the algorithm.

Computation then is the pinnacle of secular universalism, or secular idealism. The traditional space of the intellect / soul / mind / rationality is now taken on by the algorithm. Humanism is what moderates such universalism, which always threatens to subsume concrete existence into a monistic totality, from which dissent is not possible (think of the Borg in Star Trek--total assimilation into one shared reality, the hive, a rhizomatic, unified whole). Humanism (when applied justly too all members of our species) also allows us to enter into shared projects: to deliberate and to consent. But these projects are limited engagements: discrete in time and space. They do not equal to all of reality. There's space in-between. Each allows for the possibility for dissent, which frees us for new projects, the possibility of quiet self-reflection, and the possibility to reconstitute ourselves in ever changing and non-arbitrary ways.
### Hospital as an Archive

### Electronic Discovery

### Media Archeology
This is not a technological prolbem. Prolifiration of formats ensures a business of waste. Data must be stored in human readable formats both so we can study it AND to protect it. This is not just minimal computing for them, but a vision of computing for us. It is a political stance. The weight of .pdf vs. .txt. It is not a computational challenge. Digital dicay. The need to obviate media archeology. Data must be held in plain text.

### New Humanism
Humans as systems. But as recursive and self referential systems. The ability to incorporate models to alter behavior. Frustrates predicative models. Charles Goodhart "Goodhart's Law." and Robert Lucas. Lucas Critique. Pluralism.

"We recognize that separating humanity from nature, from the whole of life, leads to humankind’s own destruction and to the death of nations. Only through a re-integration of humanity into the whole of nature can our people be made stronger. That is the fundamental point of the biological tasks of our age. Humankind alone is no longer the focus of thought, but rather life as a whole . . . This striving toward connectedness with the totality of life, with nature itself, a nature into which we are born, this is the deepest meaning and the true essence of National Socialist thought.” – National Socialist professor of biology, Ernst Lehmann."

Opposed to monism. Dialogical and dialectical systems. Including dualism!

Monism. Haeckel, Ernst the Monist League (*Monistenbund*) as the founding of the Nazi Party. "The religion of the future" from Otto Herrmann's article. 

"Modern science and philosophy are revealing the world to us as a spiritual commonwealth, self-existing, self-governing and self directing." (Herrmann, 1913). The idea of ecology is not necessarily offensive. It is when it is turned into monism, one ecology in other words, is when it becomes fascism.

The ideas that systems are self directing. 

Christianity embracing dualism (strangely enough). I write this as a committed atheist.

"Any observed statistical regularity will tend to collapse once pressure is placed upon it for control purposes"  Goodhart, Charles (1981). "Problems of Monetary Management: The U.K. Experience". Anthony S. Courakis (ed.), Inflation, Depression, and Economic Policy in the West (Rowman & Littlefield): 111–146

Campbell, Donald T., Assessing the Impact of Planned Social Change The Public Affairs Center, Dartmouth College, Hanover New Hampshire, USA. December, 1976.

"The more any quantitative social indicator (or even some qualitative indicator) is used for social decision-making, the more subject it will be to corruption pressures and the more apt it will be to distort and corrupt the social processes it is intended to monitor."

These sociologists are noticing a broader effect. Humans are recursive machines. We are able to reprogram ourselves in opposition to predicative model. We trade on the knowledge gap. Those who are modelled and those able to escape modeling. Sartre and negation. More than negation. A positive ability to incorporate model and to morph into new practices. Agency, deliberation, consensus, dissent. <-- this should be the last word of the book!

# Tech Appendix

## Prepare
How to run the terminal. What is it. And why?
Intro to POSIX

## Chapter 1
Where am I? `pwd`, `ls`, `cd`
Bits, bytes, and characters: `wc`
 
## Chapter 2

## Chapter 3

## Chapter 4

## Chapter 5

# Notes
Athanasius Kircher's Universal Polygraphy
George E. McCracken

Minimalism. Plain

Elegant Variation, Fowler

If you've never interacted with your computer through a text-based terminal, understand for now that the command line is a sort of a call-and-response dialog between you and your system. This way of interacting with computers predates modern graphical user interfaces (GUIs) and is still commonly used by professional programmers and system administrators.

More than an interface, the command line encapsulates a phislosophy of computing: write simple programs that do one thing well.

This philosophy contrasts sharply with altertive vision: where "things just work," glossy visual interfaces. Surfaces and alienation. 

That computer interfaces entail politics is not an uncontriversial assumption and one which will become central to the argument of my book.

Despite the ubiquity of Unix-like systems (which run a lion share of servers, super-computers, Apple gadgets, and Android devices), the textual roots of computing are abscured by visual 

The battle for the soul of computing. Whether the internet empowers participatory governance, delibiration, and dissent, or whether it ushrs in a new era of mass surveilance and centralized control depends crucially on which of these two models of computing prevails.


## Security, access
Security, privacy. Surveillance. Openness. Secrecy. Part of the same coin. Crypto vs. open source movement.
Commands: crypto, pgp, chmod, groups, file permissions

Authorship is better thought of as access. How that is codified. Groups.

## Networking
Key terms: internet, rhizome, web, network, infrastructure, hardware, and software.
ping, traceroute, the terminal way: multiple users. personal vs. central computers

Internet is not a rhyzome. Central control. Surface vs. depth structures--twitter is rhyzomatic on the surface. 

Actor-networks. We are pushing ourselves through the wires. Hardware in control. 

