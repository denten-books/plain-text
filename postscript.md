
# Microanalysis

Object of study.

Why am I reading Ltour. Because latour gives us a way to see much lit.

In a study on the construction of scientific knowledge, Bruno Latour and Steve
Woolgar perform what they call an ethnography of a science lab by exposing the
passage of ideas from applied experiment to literary production. For Woolgar
and Latour a laboratory functions as a factory of sorts, ingesting matter and
artifact to produce fact and inscription, beyond simplistic notions of
knowledge-making and discovery [@latour_laboratory_1986]. A cite of production. 

Although much cited in the study of culture, science, and technology,
*Laboratory Life* has had less of an impact on the study of literature, even
though Latour and Woolgar borrowed much the other way around. In the 1986
postscript to the American edition, they remark on the broad trend in literary
theory toward treating texts as objects of interpretation, disavowing the kind
of criticism aimed at the "real meaning of texts," at "what the text says,"
"what really happened," or "what the authors intended"
[@latour_laboratory_1986, 273]. Similarly, the authors wanted to aim research
in the social study of science at the "contingent character of objectification
practices." Science, in their view, is itself a type of literary system,
"generating texts whose fate (status, value, utility, facticity) depends
subsequently on interpretation" [@latour_laboratory_1986, 273]. Throughout the
book, Woolgar and Latour use the term literature to mean something "inscribed,
printed, or published," a combination of verbs that coincides with "literature"
consistently throughout [@latour_laboratory_1986, 47-53]. Viewed as a work of
literary theory, *Laboratory Life* reifies the research program began by the
post-structuralists. Where Jacques Derrida could remark offhandedly that
"everything is a text,"[^ln2-derrida] Woolgar and Latour make concrete the
literal transformation of matter into text. No longer was literature an
illustration of something that happens in the laboratory: Latour and Woolgar
showed the laboratory itself to function as an inscription-making machine.

The conventional way to understand Woolgar and Latour brings the interpreter
into the laboratory, breaking the illusion of scientific objectivity: instead
of "discovering" facts, scientists construct them (therefore, *social
constructivism*). Paradoxically, as Latour and Woolgar worked to undermine the
empirical unity of science (turning it into a kind of hermeneutics), they
performed literary analysis as an empirical method. To "read" the laboratory,
researchers observed the space in person, embedded into the fabric of its
everyday activity. As ethnographers, Woolgar and Latour were interested in
discovering models of objectivity (and science) that emanate from the practice
doing science localized to the particular laboratory under observation. A
theory of knowledge formation therefore becomes visible through ethnographic
description. In the *Laboratory Life* the reader is asked to examines a range
of evidentiary material along with published work. Floor plans, research
samples, workflow diagrams, dialog transcriptions, time sheets, and logbooks
all become a part of the epistemology.

To view Woolgar and Latour as scholars of literature (and not just of
laboratories) is to open up the floodgates of textuality. The laboratory, the
courthouse, the hospital---these institutions cannot be reduced to text, but
the lesson of *Laboratory Life* is that they are, in part, literary systems.
Beneath every scientific discovery, every popular song, every film, radio, or
television serial, every art or architectural project, every political office,
every legal judgment, every restaurant meal, every doctor's prescription, every
website, and every machine manual---beneath that giant and perplexing pile of
human activity lies a complex network of circulating textual documentation.
Woolgar and Latour show that literary scholarship can involve more than just
reading books, but also making visible that textual undercurrent: following it
and mapping its movements across rooms and offices, all the while exposing the
mechanisms of its mutation and locomotion. It is an exciting prospect: to view
the hospital as a library, where cadres of physicians and administrators
convert human stories into diagnoses, into controlled vocabularies, into files,
into billable codes, into inscriptions, and into archives. Or to see the legal
system as a process of literary discovery, where legions of attorneys and
paralegals pore over terabytes of textual material, transforming inscription
into evidence. That is not all these institutions are, but they are also that;
and there is much work to be done there for a scholar of literature.

On an average day in 2008, at home, an average American read around 100,500
words a day. At 250 words per page, that is around 402 printed pages.  Between
the years of 1980 and 2008, the consumption of information in bytes---a measure
that would obviously privilege storage-heavy content like sound and
video---grew at a modest 5.4 percent per year. Reading, in decline until the
advent of the internet, has tripled in the same period. Reading in print
accounted for 26 percent of verbal information consumed in 1960. That number
fell to 9 percent in 2008, but the consumption of words digitally increased to
27 percent of total consumption, which means that reading has increased its
share of the overall household attention span [@bohn_how_2009;
@hilbert_worlds_2011; @hilbert_info_2012]. The first decade of the twenty-first
century saw a 20 percent increase in library visitation
[@u.s._institute_of_museum_and_library_services_public_2010]. According to
UNESCO data, literacy rates continue to rise globally, as the world calibrates
imbalances of access along the lines of gender and geography
[@huebler_adult_2013]. By a conservative estimate, the number of scientific
publications grows at about 4.7 percent per year, which means that the amount
of published research roughly doubles every 15 years or so, and the figures are
much higher in some fields [@archambault_welcome_2005; @crespi_empirical_2008;
@larsen_rate_2010]. The number of books published in the United States almost
tripled from 2005 to 2009 [@bowker_u.s._2009].

All measures point to a drastic expansion of the textual field. At the same
time, we are often told that reading of short stories, novels, poetry, and
plays appears to be at grave risk [stephens_rise_1998; @merrin_television_1999;
@nea_reading_2004; @golumbia_cultural_2009; @fish_digital_2012;
@marche_literature_2012].[^ln2-internet] Something does not add up. As a
society we are reading, writing, and publishing more each year. The
reconciliation of vocabularies locates the source of the perceived metaphysical
threat in the culture's profound alienation from the material contexts of
literary production. The language of literary theory is supremely tuned to deal
with symbols. Only after long reflection, on the order of centuries, do we
begin to note the sheer strangeness of the textual interface: the medieval
palimpsest, the stylus, and the goat parchment. Yet we cannot afford to care
less about the keyboard and the screen today that we do about ink and paper.  A
battle is quietly brewing for the soul of computing and hence for the control
of our basic reading and writing apparatus.

Where literacy thrives, the very nature of what constitutes a literary text (of
any kind) has changed significantly with the advent of ubiquitous computing and
its related techniques involving the internet, integrated circuits, magnetic
storage, miniaturization, and search and suggest algorithms. By many accounts,
the second half of the twentieth century saw a major technological shift
affecting the production, access, and distribution of knowledge, in a shift
comparable in its consequences to those accompanying the spread of the
Gutenberg printing press in the fifteenth century [@johns_piracy:_2009;
@kovarik_revolutions_2011]. Matters always central to the field of literary
studies remain vitally important to the functioning of modern society. Literary
studies, when conceived broadly, provide fertile grounds for collaboration
between diverse disciplines interested in the changing dynamics of narrative,
interpretation, language, form, prosody, composition, dialog, discourse, story,
genre, authorship, influence, and text. It is in this core conceptual cluster
of operational terms that I want to locate a notion of poetics capable of
addressing not only the machinations of poetry and prose, but also of pixel,
code, string, script, inscription, list, document, file, record, project, and
archive.

Moreno on microanalysis!

Microanalysis opens the gap between text as it is embedded into storage media
and text as it is seen on the screen.

the closest possible kind of reading
that pays attention to the material contexts of knowledge production.

Such textual proliferation comes at a cost. Until recently, the bread and
butter of literary scholarship has been close reading. Close reading, like
critical thinking, is an idea more easily performed than explained, because the
details become contentious as soon as they are formalized.[^ln2-close] I will
tread carefully, therefore, by committing myself to a broad definition of close
reading that involves some notion of deliberate and reflective practice aimed
at deep comprehension. The Partnership for Assessment of Readiness for College
and Careers (PARCC), the organization responsible for the controversial
Common Core standards being implemented in schools across the United States
today, promotes close reading as "thorough," "methodical," and "analytical"
practice that "enables students to reflect on the meanings of individual words
and sentences; the order in which sentences unfold; and the development of
ideas over the course of the text, which ultimately leads students to arrive at
an understanding of the text as a whole" [@parcc_parcc_2012, 7]. The general
movement here is from "text" on the page to "work" (text as a whole, in the
language of the report). The model of textuality implicit in the institutional
project of close reading assumes an environment of received literary canons,
naturally accessible to the human intellect. For the duration of the "Gutenberg
galaxy," the age of print, a well-educated person might have been expected to
internalize some several hundred or perhaps thousands of major texts
constituting the canon. Close reading was honed to operate on that naturalized
scale.

The expansion of the textual field has radically increased the cognitive
demands of literary engagement. The pipeline between text and work has
lengthened considerably. On the one side, the matter of canon formation can no
longer be relegated to stable, long-term systems of social filtering. Seen from
the perspective of a literary interface, the database, the social stream, and
the search engine are tools for dynamic, "on the fly," generative
canon-formation. Consider the task of finding an unknown (to me) factoid
online, about philosophy in the times of Andalusian Spain, for example. Where
in the past I might have started with a subject catalog compiled by librarians,
today I construct a search query, using resources that I believe will return a
reasonably authoritative list of texts on the subject. The search engine, in
effect, replaces (or rather complements) centuries-long processes of
canon-formation. A near-instantaneous list of results now becomes my ephemeral,
but nevertheless authoritative, collection of relevant literature.

Each text in the returned list still requires the instrumentation of close,
analytical interpretation. However, the same discipline of critical and
reflective deliberation exercised on the level of an individual text needs to
also be exercised on the level of procedurally generated search engine results:
Where to search? Using what engine? How to construct the query? What are the
implicit biases of the system?  The academic question of canon-formation
transforms into a (not yet critical) practice of rapid, iterative, generative
canon-making. Whatever ideals motivate close reading between "text" and "work"
surely must drive the process on the level of dynamic corpus composition.

Examples of macroanalysis. The various practices of distant reading arise from
the condition in which canons are no longer accessible, in their entirety, to
the unaided (natural) human intellect. These include distant reading and
macroanalysis in literary studies [@jockers_macroanalysis_2013;
@moretti_distant_2013], culturomics in economy [@aiden_uncharted:_2014],
e-discovery in law [@scheindlin_electronic_2004; @scheindlin_electronic_2009],
automatic essay evaluation in education [@shermis_handbook_2013], and medical
informatics in medicine [@shortliffe_biomedical_2013], among others. At the
foundations of these nascent disciplines is a shared toolkit of statistical
natural language processing [@manning_foundations_1999; @jurafsky_speech_2008],
automatic summarization [@radev_centroid-based_2004; @nenkova_pyramid_2007],
machine learning [@rasmussen_gaussian_2006; @flach_machine_2012], network
analysis [@opsahl_node_2010; @szell_measuring_2010; @takhteyev_geography_2012],
and topic modeling [@wallach_topic_2006; @blei_probabilistic_2012].

Where distant reading perceives patterns across large-scale corpora,
microanalysis breaks literary systems down to their minute constituent
components.

![Micro, macro, and close reading.](images/micro.png)

Where distant reading and macroanalysis are concerned with text aggregates,
microanalysis, of the type suggested (but not carried out to its logical
conclusion) by Kittler and Latour and Woolgar, occupies the other side of the
text--work equation. Note that contrary to what one may intuit, distant reading
often happens prior to close reading and not the other way around. In most
cases, the reader must find the text before analyzing it. Canons, corpora,
collections, libraries, and archives are all aggregates that mediate the
process of discovery. Microanalysis, too, constitutes a study of mediation, but
on the level of physical minutiae otherwise not readily observed in cursory
exploration. The instruments of microanalysis may coincide with computational
tools, designed to find hidden patterns lurking above or beneath a given
document.[^ln2-iarkho] The micro-instrumentation might also include a
screwdriver, a binding needle, or a soldering iron: sharp tools that help to
pry open and to scrutinize otherwise magical textual black boxes.

The pre-modern model of literary transmission assumes relatively short physical
distances separating authors, texts, and readers. Were I to write these words
in front of you, on paper, I would simply pass the page into your hands. In
receiving this text, you could be fairly certain that no third party meddled in
the process of passing the note. When communicating in this way, it makes sense
to talk about notions of strong "authorial intent" and "fidelity to the
original," because authors and their works are thought to occupy the same
contiguous space and time. The advent of cheap mechanical reproduction of print
(for the sake of brevity let's say the printing press) has introduced a range
of devices that mediate between the author and the reader. Distance, time, and
mediation subsequently weaken facile notions of authorial fidelity or intent.
At the very least, we know that editorial practices, publishing markets, and
communication technologies can introduce an unintended element of noise into
the channel. At the maximal break down of the communication act, long-distance,
asynchronous communication is susceptible to "man-in-the-middle" attacks, by
which a third party maliciously alters the content of communication
[@needham_using_1978].

Changing material conditions of textual transmission push against familiar
literary critical ideas. For example, as the mechanical reproduction of print
weakens the material basis for authorship attribution, the notion of authorship
itself undergoes change. That is not say that the author is dead, as Barthes
would have it. Authors continue to live and to collect royalties from the sale
of their works. The weakening of the authorship function merely makes certain
ways of talking about things like "authorial intent" and "fidelity to the
original" difficult to sustain. Massively collaborative writing projects like
Wikipedia and procedural narrative generation (machine writing) further erode
ideas of authorial production based on individual human agency. Yet, it would
be a mistake to believe that the myth of autopoiesis (the literature that
"writes itself," writing that writes, discourse that speaks, etc.)[^ln2-varela]
can displace the myth of the author. A discipline of close attention to the
atomic particulars of encoding, transmission, storage, and the decoding of text
at the site if its application to the human condition ultimately aims to
reclaim subjective agency, in motion. This may seem strange at first: to
recover the subject in the physical minutiae of the literary--technological
encounter. Yet the point of contact is crucial, for it is here that the subject
seems to disappear, in a compressed moment of time that needs to be unpacked
with some precision.

